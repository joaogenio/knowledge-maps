[
    {
        "doc_title": "DICOM Metadata Quality Analysis for Mammography Radiation Exposure Characterization",
        "doc_scopus_id": "85085502602",
        "doc_doi": "10.1007/978-3-030-45688-7_16",
        "doc_eid": "2-s2.0-85085502602",
        "doc_date": "2020-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Control and Systems Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2207"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Digital imaging and communication in medicines",
            "First year",
            "Human tissues",
            "Mammographic",
            "Metadata quality",
            "Population exposure",
            "Radiation Exposure"
        ],
        "doc_abstract": "© 2020, The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Switzerland AG.The usage of ionizing radiation on human tissues for medical purposes has been object of regular analyses using Digital Imaging and Communication in Medicine (DICOM) metadata. Particularly, the DICOM metadata related to mammographic studies has been used to support the monitoring of individual and population exposure. The objective of this work was to analyze the quality of DICOM metadata to characterize radiation exposure in mammographic studies performed during the first year of activity of a mammography equipment. Although DICOM metadata allow to characterize the radiation dose in mammographic studies, the results show that it is pertinent to effectively improve the quality of the stored metadata.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "DICOM metadata quality auditing for medical imaging stakeholders characterisation: a pilot study",
        "doc_scopus_id": "85048754093",
        "doc_doi": "10.1080/21681163.2018.1480971",
        "doc_eid": "2-s2.0-85048754093",
        "doc_date": "2019-03-04",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Computational Mechanics",
                "area_abbreviation": "ENGI",
                "area_code": "2206"
            },
            {
                "area_name": "Biomedical Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2204"
            },
            {
                "area_name": "Radiology, Nuclear Medicine and Imaging",
                "area_abbreviation": "MEDI",
                "area_code": "2741"
            },
            {
                "area_name": "Computer Science Applications",
                "area_abbreviation": "COMP",
                "area_code": "1706"
            }
        ],
        "doc_keywords": [
            "Digital imaging and communication in medicine metadatum",
            "Digital imaging and communication in medicines",
            "Imaging modality",
            "Information quality",
            "Medium size",
            "Metadata quality",
            "Pilot studies",
            "Radiology",
            "Stakeholder of medical imaging",
            "Usage level"
        ],
        "doc_abstract": "© 2018, © 2018 Informa UK Limited, trading as Taylor & Francis Group.The metadata that are part of a vast number of medical imaging exams might be a valuable source for medical imaging stakeholder’s characterisation. The study reported in this article aimed to assess the quality of Digital Imaging and Communication in Medicine (DICOM) metadata related to medical imaging stakeholder’s characterisation, particularly in terms of what attributes are available and their usage trends. The DICOM metadata of medical imaging exams carried out in a medium size hospital during a one-year period (i.e. 5 144 417 images, corresponding to 97 612 exams performed on 61 256 patients) were analysed. The results show that the use of the DICOM attributes for health care stakeholder’s characterisation varies with the medical imaging modalities, concerning the number of available attributes, and respective usage levels and data quality. Therefore, the filling in of DICOM metadata could be optimised, which may be relevant for the clinical practice as well as for the development of data bases that might support clinical research.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "DICOM metadata analysis for population studies",
        "doc_scopus_id": "85054312269",
        "doc_doi": "10.4018/IJEHMC.2019010101",
        "doc_eid": "2-s2.0-85054312269",
        "doc_date": "2019-01-01",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Computer Science Applications",
                "area_abbreviation": "COMP",
                "area_code": "1706"
            },
            {
                "area_name": "Health Informatics",
                "area_abbreviation": "MEDI",
                "area_code": "2718"
            }
        ],
        "doc_keywords": [],
        "doc_abstract": "Copyright © 2019, IGI Global.This article reports an experimental study to determine how to use the stored Digital Imaging and Communication in Medicine (DICOM) metadata to perform population studies. As a case study, it was considered three types of medical imaging studies (i.e. routine head computed tomography, thorax computed radiography and thorax digital radiography) stored in the picture archiving and communication systems (PACS) of three healthcare institutions. The final sample consisted of DICOM metadata belonging to 1370360 images, corresponding to 109160 medical imaging studies performed on 72716 patients. The study followed a methodological approach that allows the identification of the number of patients with performed studies by age group and gender, as well as the average number of studies by patient, age group and gender in each one of the three healthcare institutions. The results show the relevance of the aggregation and analyses of DICOM metadata stored in heterogeneous PACS facilities.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "NeuronRead, an open source semi-automated tool for morphometric analysis of phase contrast and fluorescence neuronal images",
        "doc_scopus_id": "85028572236",
        "doc_doi": "10.1016/j.mcn.2017.08.002",
        "doc_eid": "2-s2.0-85028572236",
        "doc_date": "2017-12-01",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Molecular Biology",
                "area_abbreviation": "BIOC",
                "area_code": "1312"
            },
            {
                "area_name": "Cellular and Molecular Neuroscience",
                "area_abbreviation": "NEUR",
                "area_code": "2804"
            },
            {
                "area_name": "Cell Biology",
                "area_abbreviation": "BIOC",
                "area_code": "1307"
            }
        ],
        "doc_keywords": [
            "Animals",
            "Image Processing, Computer-Assisted",
            "Neurons",
            "Rats"
        ],
        "doc_abstract": "© 2017Neurons are specialized cells of the Central Nervous System whose function is intricately related to the neuritic network they develop to transmit information. Morphological evaluation of this network and other neuronal structures is required to establish relationships between neuronal morphology and function, and may allow monitoring physiological and pathophysiologic alterations. Fluorescence-based microphotographs are the most widely used in cellular bioimaging, but phase contrast (PhC) microphotographs are easier to obtain, more affordable, and do not require invasive, complicated and disruptive techniques. Despite the various freeware tools available for fluorescence-based images analysis, few exist that can tackle the more elusive and harder-to-analyze PhC images. To surpass this, an interactive semi-automated image processing workflow was developed to easily extract relevant information (e.g. total neuritic length, average cell body area) from both PhC and fluorescence neuronal images. This workflow, named ‘NeuronRead’, was developed in the form of an ImageJ macro. Its robustness and adaptability were tested and validated on rat cortical primary neurons under control and differentiation inhibitory conditions. Validation included a comparison to manual determinations and to a golden standard freeware tool for fluorescence image analysis. NeuronRead was subsequently applied to PhC images of neurons at distinct differentiation days and exposed or not to DAPT, a pharmacological inhibitor of the γ-secretase enzyme, which cleaves the well-known Alzheimer's amyloid precursor protein (APP) and the Notch receptor. Data obtained confirms a neuritogenic regulatory role for γ-secretase products and validates NeuronRead as a time- and cost-effective useful monitoring tool.",
        "available": true,
        "clean_text": "serial JL 272354 291210 291734 291737 291852 291857 31 Molecular and Cellular Neuroscience MOLECULARCELLULARNEUROSCIENCE 2017-08-25 2017-08-25 2017-09-01 2017-09-01 2018-09-15T03:20:49 S1044-7431(17)30086-6 S1044743117300866 10.1016/j.mcn.2017.08.002 S300 S300.2 FULL-TEXT 2018-09-15T03:05:00.10329Z 0 0 20171201 20171231 2017 2017-08-25T17:18:44.280684Z articleinfo articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid hubeid indexeddate issn issnnorm itemstage itemtransactionid itemweight openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sortorder srctitle srctitlenorm srctype ssids alllist content subj subheadings suppl tomb volfirst volissue volumelist yearnav figure e-component body acknowledge affil appendices articletitle auth authfirstini authfull authkeywords authlast footnotes grantnumber grantsponsor highlightsabst primabst ref 1044-7431 10447431 true 85 85 C Volume 85 7 57 69 57 69 201712 December 2017 2017-12-01 2017-12-31 2017 article fla © 2017 Published by Elsevier Inc. NEURONREADOPENSOURCESEMIAUTOMATEDTOOLFORMORPHOMETRICANALYSISPHASECONTRASTFLUORESCENCENEURONALIMAGES DIAS R 1 Introduction 2 Materials and methods 2.1 Rat cortical neuronal and SH-SY5Y neuroblastoma cell cultures 2.2 Immunocytochemistry and image acquisition 2.3 The NeuronRead algorithmic workflow 2.3.1 Cell body segmentation 2.3.2 Neuritic segmentation 2.3.3 Extracted morphological features 2.4 Data analysis and statistics 3 Results 3.1 The NeuronRead workflow and cell body recognition 3.2 Validation of NeuronRead neuritic segmentation 3.3 Evaluation of cell body parameters with NeuronRead 3.4 Time and DAPT-dependent network alterations detected by NeuronRead 4 Discussion 5 Conclusion Abbreviations Appendix A Supplementary data References ARGANDACARRERAS 2010 1019 1029 I ASCOLI 2008 1 3 G BAXES 1994 G DIGITALIMAGEPROCESSINGPRINCIPLESAPPLICATIONS BILLECI 2013 2 L BITTNER 2009 10405 10409 T BRABET 1988 701 708 P CARTER 2010 M GUIDERESEARCHTECHNIQUESINNEUROSCIENCEGUIDERESEARCHTECHNIQUESINNEUROSCIENCE CHALFOUN 2013 41 52 J CHUANG 2015 437 447 J DACOSTA 2002 283 310 L DACRUZESILVA 2003 1553 1561 E DEHMELT 2011 100 L DEYTS 2012 1714 1729 C DOTTI 1988 1454 1468 C DOUGHERTY 2003 E HANDSONMORPHOLOGICALIMAGEPROCESSING ENCINAS 2000 991 1003 M EVANGELOPOULOS 2009 2138 2144 M FANTI 2011 870 881 Z HENRIQUES 2009 1449 1461 A HO 2011 230 S HUNTER 2012 10 S KAPITEIN 2011 9 20 L KIM 2015 459301 H KOFFIE 2011 63 R KONIETZKO 2012 200 216 U LEE 2007 47 58 H LEGLAND 2016 D MORPHOLIBJMORPHOLIBJV120 LIU 1991 297 305 J LLEO 2011 1513 1527 A MEIJERING 2010 693 704 E MEITZEN 2011 177 181 J MITCHELL 2007 350 362 P MULLER 2012 a006288 U PANI 2013 e73857 G PANI 2014 188 199 G PINHO 2015 36 37 A PURVES 2008 D NEUROSCIENCE RAGHAVAN 2014 7429 7440 S DAROCHA 2015 288 301 J ROLLS 2007 7 M RONCHI 2016 351 364 G SCHINDELIN 2012 676 682 J SCHNEIDER 2012 671 675 C SERRA 2009 603 611 V SHAKED 2012 N BIOMEDICALOPTICALPHASEMICROSCOPYNANOSCOPY SOILLE 2013 P MORPHOLOGICALIMAGEANALYSISPRINCIPLESAPPLICATIONS SVEDRUZIC 2015 55 65 Z TERRY 1991 572 580 R TRAZZI 2013 20817 20829 S TSAI 2010 3216 3221 N VINCENT 1991 583 598 L WANG 2015 e0130178 Y XIONG 2006 494 505 G DIASX2017X57 DIASX2017X57X69 DIASX2017X57XR DIASX2017X57X69XR 2018-09-01T00:00:00.000Z UnderEmbargo © 2017 Published by Elsevier Inc. item S1044-7431(17)30086-6 S1044743117300866 10.1016/j.mcn.2017.08.002 272354 2018-09-15T03:05:00.10329Z 2017-12-01 2017-12-31 true 1817708 MAIN 13 54587 849 656 IMAGE-WEB-PDF 1 gr1 6507 163 172 gr2 7773 164 89 gr3 9323 79 219 gr4 11428 164 161 gr5 8701 164 160 gr6 10208 94 219 gr7 7453 149 219 gr8 4911 78 219 gr1 59757 487 513 gr2 156638 1026 557 gr3 30057 193 535 gr4 176406 771 758 gr5 47748 509 497 gr6 73107 308 714 gr7 52429 517 758 gr8 31911 269 758 gr1 196636 1296 1364 gr2 551727 2728 1481 gr3 111970 514 1422 gr4 656676 2049 2014 gr5 460179 2257 2202 gr6 305580 817 1897 gr7 181432 1373 2014 gr8 111783 716 2014 mmc2 mmc2.zip zip 3226 APPLICATION mmc3 mmc3.zip zip 5184539 APPLICATION mmc4 false 3184209 APPLICATION mmc1 mmc1.docx docx 7108222 APPLICATION YMCNE 3219 S1044-7431(17)30086-6 10.1016/j.mcn.2017.08.002 Fig. 1 Processing workflow of the NeuronRead macro. Schematic flowchart detailing each step of the NeuronRead Macro taken during neuronal soma segmentation (upper part) and neurite segmentation (lower part). Fig. 1 Fig. 2 Details of the NeuronRead workflow, applied to Phase Contrast Images. A–D: Cell body segmentation. A. Raw PhC neuronal image. Mid-range values of background grey levels clearly dominate, as suggested by the example intensity profile shown below. B. Resulting image after grey-level ‘bottom-hat’ filtering. As shown in the intensity profile, the background is almost removed. Only objects with shape and size fitting the structuring element (SE) stand out more clearly. C. Automatic threshold (upper image) and subsequent morphological opening (image below). D. The original shape of cell bodies, as recovered after morphological reconstruction (upper image). Final result with refinements obtained with watershed segmentation (image below). E–F: Neuritic segmentation. E. The difference of Gaussians image masked with cell body areas. F. Skeletonized neuritic pathways superimposed on the original image. Structures attached to the image boundaries are not measured. Scale bar=50μm. Fig. 2 Fig. 3 NeuronRead versus manual detection of neuronal cell bodies areas. A. Neuronal cell body recognition with NeuronRead in PhC microphotographs of neuronal cultures at 4days in vitro. Raw data on the left, automatic cell body recognition on the right (halos surrounding cell bodies, in yellow). Scale bar=50μm. B. Graphical comparison of the average neuronal cell body areas determined by NeuronRead and by manual analysis of the PhC images. There were no statistical differences (ns) between both measurements. n =10 images, in a total of ca. 300 cell bodies. (For interpretation of the references to colour in this figure legend, the reader is referred to the web version of this article.) Fig. 3 Fig. 4 NeuronRead validation in PhC and fluorescence neuronal images. A. A set of 30 pairs of fluorescence (‘Fluor.’)-phase contrast (‘PhC’) microphotographs of neurons at 4days in vitro (raw images at the left) were analyzed with the NeuronRead macro (middle images) leading to the neuritic tracing in NeuronRead-Fluor images (in green) and NeuronRead-PhC images (in orange). The fluorescence images were additionally analyzed with the NeuriteQuant plugin, resulting in the NeuriteQuant-Fluor tracing (right image, in blue). Scale bar=100μm. B. Bland-Altman plot of the comparison between NeuronRead and NeuriteQuant analyses of fluorescence images. The plot shows an average difference between both methods of almost 0%, with 95% of the results differing <5%. C. Bland-Altman plot of the comparison between phase contrast image analysis with NeuronRead and fluorescence image analysis with NeuriteQuant. The plot shows an average difference between NeuronRead and NeuriteQuant of −27.01%, demonstrating that there is less information available in PhC images than in fluorescence images. (For interpretation of the references to colour in this figure legend, the reader is referred to the web version of this article.) Fig. 4 Fig. 5 Neuritic length analysis of neuronal cultures treated with the EGFR inhibitor. A. Neuronal cultures at 4days in vitro under control conditions (left image) and treated with 10μM of the EGFR inhibitor PD168393 (right image) to stall the neuritic outgrowth. Scale bar=100μm. B. Images were analyzed with NeuronRead (PhC and Fluor. images) and NeuriteQuant (only Fluor. images). All three methods were able to detect the same effect of the EGFR inhibitor treatment. n =20 images. *, p <0.05 using Student's t-test. Fig. 5 Fig. 6 Phase contrast microphotographs of neuronal cultures at different differentiation stages, exposed or not to DAPT. A. Representative PhC images of rat cortical primary neurons cultured for 1, 4, 10 and 14days in vitro (DIV) in the presence (‘DAPT’) or absence (‘Control’) of 1μm DAPT in the last 24h. NeuronRead can robustly extract data from either positive (1 DIV) or negative (4, 10, 14 DIV) PhC contrasts, and in non-optimized conditions, since microphotographs were taken to living neurons growing on plastic wells, in their normal culture media, in the presence of dead cells and cellular debris. Bar, 50μm. B. NeuronRead assessment of the effects of DAPT incubation on neuronal cell number (from PhC microphotographs in A.), and the fold-increases calculated for each time point. Statistical analysis: + p <0.05, ++ p <0.01 for DAPT vs control data at each DIV, using the two-tail paired Student's t-test. Fig. 6 Fig. 7 NeuronRead assessment of neuronal cell bodies morphometric parameters. Primary cortical neurons in increasing days in vitro (DIV) were incubated (‘DAPT’) or not (‘CTRL’) with 1μM DAPT for 24h. Cell body features analyzed with NeuronRead included A. Area; B. Perimeter; C. Circularity; and D. Roundness. Statistical significant differences: *p <0.05; **p <0.01 for data against 1 DIV values, or between indicated time points (control condition). + p <0.05, ++ p <0.01 for DAPT vs CTRL data, at each time point (DIV). Fig. 7 Fig. 8 NeuronRead assessment of neuritic network parameters. Primary neurons were cultured at increasing days in vitro (DIV) in the presence (‘DAPT’) or absence (‘CTRL’) of 1μM DAPT in the last 24h. The NeuronRead macro was applied to PhC images to retrieve A. the Total Neuritic network length, and B. the Neuritic length per neuron, for each image (c.a. 148mm2 of area/image). Statistical significant differences: ***p <0.001, ****p <0.0001 for data vs 1 DIV values or between the indicated time points (control condition). + p <0.05, +++ p <0.001, for DAPT vs control data at each DIV. Fig. 8 NeuronRead, an open source semi-automated tool for morphometric analysis of phase contrast and fluorescence neuronal images Roberto A. Dias a b 1 Goncalves Bruno P. Gonçalves a b 1 Joana F. da Rocha a b Odete A.B. da Cruz e Silva b Augusto M.F. da Silva c 1 Sandra I. Vieira a b ⁎ 1 a Cell Differentiation and Regeneration group, Institute of Biomedicine (iBiMED), Department of Medical Sciences, Universidade de Aveiro, Aveiro, Portugal Cell Differentiation and Regeneration group Institute of Biomedicine (iBiMED) Department of Medical Sciences Universidade de Aveiro Aveiro Portugal b Neurosciences and Signalling group, Institute of Biomedicine (iBiMED), Department of Medical Sciences, Universidade de Aveiro, Aveiro, Portugal Neurosciences and Signalling group Institute of Biomedicine (iBiMED) Department of Medical Sciences Universidade de Aveiro Aveiro Portugal c Instituto de Engenharia Electrónica e Telemática (IEETA), Departamento de Electrónica e Telecomunicações (DETI), Universidade de Aveiro, Aveiro, Portugal Instituto de Engenharia Electrónica e Telemática (IEETA) Departamento de Electrónica e Telecomunicações (DETI) Universidade de Aveiro Aveiro Portugal ⁎ Corresponding author. 1 Equally contributing authors. Neurons are specialized cells of the Central Nervous System whose function is intricately related to the neuritic network they develop to transmit information. Morphological evaluation of this network and other neuronal structures is required to establish relationships between neuronal morphology and function, and may allow monitoring physiological and pathophysiologic alterations. Fluorescence-based microphotographs are the most widely used in cellular bioimaging, but phase contrast (PhC) microphotographs are easier to obtain, more affordable, and do not require invasive, complicated and disruptive techniques. Despite the various freeware tools available for fluorescence-based images analysis, few exist that can tackle the more elusive and harder-to-analyze PhC images. To surpass this, an interactive semi-automated image processing workflow was developed to easily extract relevant information (e.g. total neuritic length, average cell body area) from both PhC and fluorescence neuronal images. This workflow, named ‘NeuronRead’, was developed in the form of an ImageJ macro. Its robustness and adaptability were tested and validated on rat cortical primary neurons under control and differentiation inhibitory conditions. Validation included a comparison to manual determinations and to a golden standard freeware tool for fluorescence image analysis. NeuronRead was subsequently applied to PhC images of neurons at distinct differentiation days and exposed or not to DAPT, a pharmacological inhibitor of the γ-secretase enzyme, which cleaves the well-known Alzheimer's amyloid precursor protein (APP) and the Notch receptor. Data obtained confirms a neuritogenic regulatory role for γ-secretase products and validates NeuronRead as a time- and cost-effective useful monitoring tool. Keywords Semi-automated analysis ImageJ macro PhC microphotographs Neuronal differentiation and regeneration Gamma-secretase Alzheimer's amyloid precursor protein (APP) 1 Introduction The highly specialized neuronal morphology is intimately interconnected with its role, and the function of neuronal networks depends on their complex connections at both regional and single cell level (Kapitein and Hoogenraad, 2011; Purves et al., 2008; Rolls et al., 2007). Morphometric analyses are thus applied to neuronal images to study correlations between neuronal structure and function. Neuronal morphometric analyses help to assess network distortions associated with neurological disorders and injury, and can assist high throughput screens of neuronal differentiation and regeneration (da Costa et al., 2002; Ho et al., 2011; Mitchell et al., 2007). However, neuronal images typically acquired from primary cultures (Carter and Shieh, 2010) can be difficult to image and analyze. Even when grown in a 2D environment, neurons present significant morphological variations throughout the culture resulting in highly heterogeneous images. Problems as uneven illumination are relatively common and derive from e.g. unevenly distributed neurons, out-of-focus neurites, and the lower height of neuronal cells (Xiong et al., 2006). Other imaging problems may occur when working with living cells, such as artifacts arising from dead cells and debris. Although still having to deal with some of these noisy features, fluorescence imaging against a dark background has resolved some of the problems and led to a scarcer use of phase contrast (PhC) images. Processing tools freely available for neuronal cultures analysis are thus usually devoted to fluorescence and not PhC microphotographs (Ascoli, 2008; Meijering, 2010; Xiong et al., 2006). PhC images are nevertheless easier to obtain, almost cost-free (just requiring a properly equipped imaging equipment), and may be easily used to image live cells, besides fixed ones. This brightfield microscopy technique explores alterations in the cells' refraction index and circumvents the need for staining reagents, being used to improve the contrast of unlabeled and unprocessed biological samples, such as live cells (Shaked et al., 2012). PhC microscopy is thus a cost-effective solution that can simultaneously assure imaging of entire populations and live cells. This optical contrast technique is widely used in cellular migration and morphology studies (Serra et al., 2009; Pinho et al., 2015), including studies in neuronal differentiation (da Rocha et al., 2015; Kim et al., 2015; Raghavan and Bitar, 2014). It has been used to create solutions in cell biology for cell tracking and automation of cell counting (via deep learning methodologies and newly developed segmentation algorithms) (Chalfoun et al., 2013; Wang et al., 2015). Nevertheless, and although they are useful, almost no freeware tools dedicated to the automatic or semi-automatic analysis of PhC neuronal images are available. Currently, NeuronGrowth (Fanti et al., 2011) and NEMO (Billeci et al., 2013) were the only tools retrieved by our survey. NeuronGrowth is a program that automatically quantifies the extension and retraction of neurites and filopodia in time-lapse sequences of two-dimensional images. NeuronGrowth was implemented as a free ImageJ plug-in, in Java language, being an independent multi-platform system that contains entire digital image pre-processing and processing modules (Fanti et al., 2011). In PhC images this program can be used to track and measure neurites, and in fluorescence images, it can be used to track filopodia. Unfortunately, NeuronGrowth can only be applied to images obtained from time-lapse experiments where the same sample field is imaged through time. NEMO (Billeci et al., 2013) is also designed to handle and process large quantities of data on single neuronal cells as they evolve over time. This freeware is written in MATLAB code, can handle fluorescence and brightfield images of neuronal 2D cultures and organotypic slices, and uses 3-way principal component analysis (PCA) for variables analysis. NEMO performs morphological analysis using local and global variables; local variables are related to the dendritic tree, while global variables are related to the whole cell structure and include features as radial extension, soma area and cone angle (Billeci et al., 2013). This program is more dedicated to the automated analysis of images in batch, which has the benefit of time but may result in less accurate measures. When used in a semi-automated manner NEMO can be very efficient; the downside it that images must be correctly labeled before analysis and the tool is relatively complex. The work here described addresses the need for a simple and straightforward tool that could work in the widely used ImageJ platform, which could handle not only PhC but also fluorescence images, in a semi-automated manner in order to minimize error in cell segmentation and improve accuracy in morphological features' extraction. We have therefore developed NeuronRead, an ImageJ macro that is capable of analyzing both types of images. PhC/fluorescence pair images of primary neurons at 4days in vitro (DIV) were used to validate NeuronRead by comparison to manual determinations and to a recognized golden standard for neuronal images, NeuriteQuant (Dehmelt et al., 2011). NeuronRead was subsequently applied to a scientific question in order to assess its applicability. The macro was used to detect neuronal morphological alterations induced by DAPT, a drug that inhibits the γ-secretase complex. This enzymatic complex cleaves, among other, the Alzheimer's amyloid precursor protein (APP) (Svedružić et al., 2015), a protein central to the Alzheimer's disease (AD) and with functions in cell migration and differentiation (da Cruz e Silva and da Cruz e Silva, 2003; da Rocha et al., 2015; Konietzko, 2012; Müller and Zheng, 2012; Pinho et al., 2015). It also cleaves the Notch receptor into the intracellular domain of the Notch receptor protein (NICD), promoting NICD nuclear signaling that is involved in cell-cell communication and neuronal development (Lee and Lundell, 2007). The quantitative data extracted with NeuronRead demonstrated its robustness in detecting minor changes in morphological parameters of cell bodies and neuritic network, further validating the macro, and adding to our knowledge on how DAPT interferes with neuronal differentiation. 2 Materials and methods 2.1 Rat cortical neuronal and SH-SY5Y neuroblastoma cell cultures Rat cortical primary neurons were established by dissociation of E18 embryonic cortices, as described in (Henriques et al., 2009). Briefly, upon euthanize the mothers, the embryo cortices were dissociated for 5–10min/37°C with 0.23mg/mL trypsin/0.15mg/mL deoxyribonuclease I-supplemented Hank's balanced salt solution. Dissociated cells were plated at 1.0×105 cells/cm2 onto poly-d-lysine-coated dishes in B27/0.5mM glutamine/60μg/mL gentamicin-supplemented Neurobasal medium (GIBCO, Invitrogen). A minimum number of pregnant female Winstar rats (9–12weeks; Harlan Interfaune Ibérica, SL) was used, and all steps were taken to ameliorate animal suffering. All experimental procedures complied the ARRIVE guidelines, observed the European legislation for animal experimentation (EU Directive 2010/63/EU) and were approved and supervised by our Institutional Animal Care and Use Committee: Comissão Responsável pela Experimentação e Bem-Estar Animal, CREBEA. Primary neuronal cultures were maintained (5% CO2/37°C) for 1, 4, 10 or 14days before being imaged. In DAPT conditions, primary neurons were incubated with 1μM DAPT [N-[N-(3,5-difluorophenacetyl)-l-alanyl]-S-phenylglycine t-butyl ester (InSolution™ γ-Secretase Inhibitor IX, Calbiochem)] for 24h, before culture imaging. Cultured neurons were also incubated for 18h (from 3 to 4 DIV) with 10 μM of PD168393 (Sigma-Aldrich), a drug inhibitor of the known neuritic promotor epidermal growth factor receptor (EGFR) (Evangelopoulos et al., 2009; Tsai et al., 2010). After treatment, neurons were fixed with 4% paraformaldehyde (PFA) in PBS for ICC. Human neuroblastoma SH-SY5Y cells (ATCC CRL-2266) were grown in Minimal Essential Medium supplemented with F-12, 10% FBS, 0.5mM l-glutamine, 100U/mL penicillin and 100mg/mL streptomycin (Gibco, Invitrogen) at 37°C/5% CO2. SH-SY5Y cells were differentiated for 5days with 10 μM retinoic acid (RA, Sigma-Aldrich) and for further 7days with 10ng/mL of brain-derived neurotrophic factor (BDNF) in serum-free medium; medium was changed every 2–3days (Encinas et al., 2000). 2.2 Immunocytochemistry and image acquisition Fixed rat 4 DIV cortical neurons were permeabilized with 0.2% Triton/in PBS, washed with PBS, and blocked with 3% BSA/in PBS for 1h. Neurons were incubated for 2h with a primary antibody (1:200) against Gαo, a protein highly abundant in the inner side of the neuronal plasma membrane (Brabet et al., 1988), allowing for the visualization of the complete neuronal network. Following washing with PBS, cells were incubated with an anti-rabbit secondary antibody for 1h, washed with PBS and deionised water, and mounted onto glass slides using a Vectashield mounting medium (Vector Labs). Digitized images (n =30 images) of fixed cortical primary neurons at 4 DIV were acquired by PhC illumination using a LCPlanFl20x/0.40 objective in an Olympus IX-81 widefield epifluorescence inverted microscope equipped with a 12 bit CCD monochromatic 1376×1032 pixel digital camera, binning 1x (F-view II, Soft Imaging System) (Serra et al., 2009; da Rocha et al., 2015). Paired fluorescence images of the same areas, labeled with an anti-Gαo antibody, were also acquired [filtersets: DAPI (BP 330-385/FT 400/LP 420); GFP/FITC (BP 450-480/FT 500/LP 515); TexasRed/TRICT (BP 510-550/FT 570/LP 590); exposure time for Gαo: around 100–200ms]. Additional images of live cortical primary neurons at 1, 4, 10, and 14 DIV, incubated (‘DAPT’) or not (‘control’) with DAPT, were also acquired by PhC illumination under the same Olympus IX-81 microscope. In each condition, 5–10 images were taken per sample (n =3 experiments), with a total of c.a. 500 cells being analyzed per condition, as in (Pani et al., 2013). Live differentiated SH-SY5Y neuroblastoma cells were also imaged under the Olympus IX microscope using PhC techniques. 2.3 The NeuronRead algorithmic workflow NeuronRead is a macro script designed to use image processing techniques and to run within the ImageJ environment, which provides an efficient support for the semi-automated quantitative analysis of bioimages (Schindelin et al., 2012; Schneider et al., 2012). It was developed focusing on PhC images but can also process fluorescence images. The processing workflow and the major settings are described below (Figs. 1 and 2 ). The whole computational procedure integrates image enhancement, segmentation and feature extraction steps that provide robust quantitative descriptors of the neuronal images. The algorithm first deals with cell body segmentation, which subsequently drives the neuritic network recognition steps. The algorithm implementation relies both on native ImageJ functionalities and on companion plugins such as MorphoLibJ v1.2.0 (Legland et al., 2016), Skeletonize3D and AnalyzeSkeleton (Arganda-Carreras et al., 2010). A great majority of the operations are automated, and the interactive steps are clearly indicated. 2.3.1 Cell body segmentation Generally, PhC (and Fluorescence) raw images are not compatible with straightforward automated image analysis approaches, impairing the estimation of reliable quantitative features. Our cell-body segmentation strategy assumes that cell bodies and neuritic structures may be considered as tiny objects of interest within a large background comprising mid-range grey level values that clearly dominate the global or regional intensity-based statistics. Noise, intrinsic artifacts and the need to handle rather thin objects were the immediate driving factors determining the chain of pre-segmentation steps that provide thresholding “friendly” images as shown in Fig. 2B from the input raw images shown in Fig. 2A The main idea is to make our target objects stand out relative to the background and other objects whose shape and size do not qualify them as cell bodies. Given the very nature of neuronal images, our choice to obtain an appropriate tradeoff between noise and contrast enhancement relied upon grey-scale morphological operators (Dougherty et al., 2003; Soille, 2013). Mathematical morphology provides the conceptual basis for these operators. The basic idea is to express formally how well a small probing object fits the appearance of the target objects. The probing object, normally called the structuring element (SE), may assume any shape but often regular shapes such as disks, squares or lines are used. Binary erosion and dilation operators that are straightforwardly perceived using set-theoretic definitions are the fundamental building blocks of more complex morphological operations recurrently applied in this work. Most of the binary morphological operators are fully extensible to grey-level image analysis tasks. Erosion and dilation operators applied to grey-scale images can be looked at as regional minimum and maximum filters, respectively, considering the regions restricted by the chosen SE. The opening operator is defined as an erosion followed by a dilation, and the closing operator is defined as a dilation followed by an erosion. For a thorough overview of mathematical morphology techniques and their applications in image analysis please refer to (Dougherty et al., 2003; Soille, 2013). Our approach to obtain contrast enhanced images for reliable cell body segmentation consisted of a bottom-hat operation preceded by median filtering. This preliminary step removes the effect of the corpuscular spots. The bottom-hat operation (or ‘black top-hat’) is formally defined as the difference image of the closed and original versions of the image. Since the closing operation emphasizes the darker valleys, most of them matching our target cell bodies, the result of the bottom-hat clearly promotes the conspicuousness of the cell bodies. This filtering approach practically removes the background clutter and leaves out, for further processing, only the cell body candidate regions. For the sake of visibility Fig. 2B shows the complement of the bottom-hat image. Notice that the neuritic networks are almost faded and the effect of the white halo surrounding the cell bodies is practically negligible. The image is now ready for proper cell body segmentation. The size and shape of the SE are critical parameters for successful segmentation. Given the acquisition setup, heuristic arguments suggest that the best performance is achieved with disk-shaped SE with a radius of 5 to 10pixels. Cell body segmentation consists of thresholding the bottom-hat filtered image and its subsequent binary morphological filtering. Most of the time, the automatically computed threshold level is acceptable. However, the user can optimize the results with minimal manual adjustments. The binary images still undergo morphological opening to remove the tiny regions whose size prevents them to be considered as live cell bodies. The opening filters with the above-mentioned SE's impose considerable damage to the original body shapes (Fig. 2C). In this phase, border objects that are only partially visible are also removed. A morphological reconstruction is then used to recover the original body shapes, as shown in Fig. 2D (upper). An extra refinement in cell body delineation is provided by watershed techniques (Vincent and Soille, 1991) that often succeed in separating visually overlapped cell bodies. The binary processing phase in body segmentation concludes as shown in Fig. 2D (lower). The user may still mark for removal the few miss-segmented cell body components, or add any cell body that was left unrecognized by the macro, by visual inspecting the superposition of the candidate masks to the raw grey-scale image. The end result of this process is a body cell mask image that is ready to be labeled and measured using native ImageJ functionalities. Each cell body (binary object) in each image will thus be numerically labeled, making it possible to measure its morphological features, such as area or perimeter. 2.3.2 Neuritic segmentation To emphasize the tiny neuritic structures, contrast enhancement and differential filtering were applied. Contrast-limited adaptive histogram equalization (CLAHE) and difference of Gaussians (DoG) filtering provide a good compromise between structural emphasis and noise impact in the subsequent thresholding phase. DoG parameters were matched to the neurite expected width range. We empirically determined that standard deviations for each Gaussian of 1 and 3-pixels were appropriate choices. As shown in Fig. 2E, this intermediate image is then automatically masked with a dilated version of the cell bodies' image, making then a band-pass interactive threshold to easily identify the neuritic components. Again, image labeling enabled the identification and removal of disconnected structures with an area smaller than 200 pixels. This threshold was previously experimentally determined, with smaller areas leading to the recognition of image artifacts such as neurites. The last step consisted of user-supervised skeletonizing, branch identification and length estimation, by using the AnalyzeSkeleton plugin. To visually validate the neuritic skeleton composed by the segmented neuritic components, the skeleton was automatically superimposed on the original image as shown, resulting in Fig. 2F. The NeuronRead macro was developed on images taken under a 20×/0.4 objective (3.1pixels/μm scale), but can work on different amplification settings (such as a 10× objective - 1.55pixels/μm) with little user intervention, showing NeuronRead robustness in dealing with images of different scales. Some features such as the SE radius and the image scale are asked and can be altered while the macro is running. Noteworthy, the macro alters the scale at two different time points: 1) at the beginning, it removes any previous scale associated with the image or software, so that it does not impair any of the morphological operations the macro performs; 2) near the end, the macro asks for the image scale (number of pixels per micrometer) and applies it to the image being analyzed, so that every extracted feature comes at the desirable unit, normally μm, instead of pixels. The macro is customizable, and advanced users can apply the macro to images with different scales/magnifications by adjusting some parameters in the macro's code, including 1) the radius of different morphological filters that are applied during the macro; as well as 2) the areas used during “Analyze Particles” to remove unwanted objects from the image. As a rule, higher magnifications used during image acquisition will require higher values for these parameters, while lower magnifications will require lower values. 2.3.3 Extracted morphological features The quantitative features of the population become available in the “Log” window at the end of the macro. These include Neuritic Parameters (Total Neuritic Length) and Cell Body Parameters (Cell body count, Average Area, Circularity, Roundness, and Perimeter). Individual shape features are also available under the windows “Cell bodies” and “Branch information”. They can be saved as column based “.txt” files for further analysis in a software of choice. The macro does not retrieve neuritic length per cell, but this is easily obtained by dividing the total neuritic length by the number of cells scored in that image. 2.4 Data analysis and statistics All data is expressed as mean±standard error of the mean of at least three independent experiments. For NeuronRead validation, statistical significance analysis was conducted by the Bland-Altman method (comparison between NeuronRead and NeuriteQuant) and by the unpaired Student's t-test (control versus EGFR-inhibitor cultures). In the DAPT assay, statistical significance analysis was conducted by one-way analysis of variance (ANOVA) followed by the Tukey-Kramer Multiple Comparisons Test (different DIV within a condition - Control or DAPT), and the t-test (Control versus DAPT at a specific DIV); samples not passing the Kolmogorov-Smirnov normality test were evaluated by the unpaired-t-test with Welch-correction. 3 Results 3.1 The NeuronRead workflow and cell body recognition The image processing workflow based on the ImageJ environment was applied to PhC and fluorescence neuronal 2D-images, with the intent of extracting quantitative morphological details. This workflow (Figs. 1 and 2), named NeuronRead, was first developed and optimized using PhC images taken at living primary cultured neurons. Images of cultures at various differentiation days (days in vitro, DIV) were used to assure that NeuronRead could efficiently extract information from increasingly complex neuritic networks. The developed macro returns several primary parameters, such as cell number; cell body area, perimeter, circularity, roundness, and total neuritic length. Secondary parameters such as ‘neuritic length per cell’ can be obtained by dividing primary parameters by the number of cells. NeuronRead runs in a semi-automatic manner, requiring user-interaction on 4 occasions: first to input if the image to be analyzed is a PhC or fluorescence image; second, to improve cell body recognition (if necessary); third, to improve neuritic detection; and fourth, to input the scale. If wanted, this last step can be surpassed and the conversion from pixels to micrometers only performed by the user in another software of choice, such as Microsoft Excel, after gathering all information from all the images. A tutorial explaining how to install the macro can be found as a supplementary file. A comparison between the raw NeuronRead output and a manual evaluation of the number of cell bodies showed a percentage difference of 5.8%, and the values obtained were not significantly different (paired t-test analysis). This error mainly arises from the presence of large cell clusters (resulting in false negatives), or from the presence of debris in the live cells preparation (resulting in false positives). However, since the macro allows the user to add cell bodies or remove false positives (2nd user interaction step), this minor error can even be easily corrected. At this step NeuronRead also allows the user to alter the automatic threshold set for the cell body, further improving cell body recognition and optimizing the “cell body area” value retrieved with NeuronRead. This parameter is nevertheless greatly optimized, with a difference of 7.3% in cell body area estimations before and after user-interaction (Fig. 3 ). Naturally, close attention must be paid to threshold values. A low threshold value may increase the number of false positives, while high threshold values can lead to missed cell bodies. The same is particularly true for the neuritic detection threshold. While a lower threshold allows a more sensitive neuritic detection, in preparations with a high amount of debris this can lead to an overestimated neuritic length. Our macro was tested in both fixed and live neuronal cultures that did not have their culture media changed, and was able to deal with both types of cultures. 3.2 Validation of NeuronRead neuritic segmentation Our macro is able to extract morphometric data not only from PhC but also from neuronal fluorescence images. Its efficacy was first demonstrated by comparison to an established freeware tool, NeuriteQuant. This golden standard was chosen by its accuracy in neuritic network evaluation of fluorescence images (Dehmelt et al., 2011). To validate NeuronRead efficacy, the macro was applied to the same fluorescence images analyzed with NeuriteQuant. These were images of 4 DIV neuronal cultures immunolabeled against Gαo, a highly abundant neuronal protein that clearly stains and delineates the neuritic network (Brabet et al., 1988) (Fig. 4A upper panel). Results show that NeuronRead is as efficient in analyzing fluorescence images as NeuriteQuant, with 95% of the results having a difference <5% (Fig. 4B, Bland-Altman Plot). NeuronRead also performed as NeuriteQuant in 4 DIV neurons fluorescently immunolabeled against the cytoskeleton marker acetylated beta-tubulin (data not shown). Afterward, using paired neuronal PhC/fluorescence images (Fig. 4A), the data extracted with NeuronRead from PhC images was compared to the data extracted with NeuriteQuant from paired fluorescence images. The Bland-Altman plot of Fig. 4C shows that quantitative data extracted from PhC images with NeuronRead was on average 27% lower than the ones obtained from fluorescence with NeuriteQuant. The same was observed when comparing NeuronRead analysis of PhC images with NeuronRead analysis of fluorescence images (Suppl. Fig. S1). Overlay of the resulting neuritic skeleton onto the original PhC image (Fig. 4A, lower panel) shows that the macro is running as expected: generally detecting the entire neuritic network present in the image. Together with the previous results on fluorescence images (Fig. 4B), this indicates that the main reason for the difference in the neuritic length found in fluorescence versus PhC images is the poorer signal-to-noise ratio of raw PhC images, and the higher contrast of the fluorescence ones. These results demonstrate that 1) NeuronRead can be used as a reliable alternative to NeuriteQuant to analyze fluorescence images, while 2) also being able to analyze neuronal PhC images. However, results also highlight the fact that PhC images normally exhibit less detail than fluorescence images regarding the neuritic network and should not be used for ‘absolute’ determinations. When aiming for absolute values, one should use fluorescence images where the neuronal cytoskeleton or cytosol has been thoroughly labeled to highlight the maximum morphological details, as occurs by immunolabelling the highly abundant Gαo protein. We have also tested NeuronRead efficacy in the analysis of neuronal cultures at 12 DIV, a time point at which the neuritic network has reached a high density. Comparison of the results obtained with NeuronRead and NeuriteQuant showed a difference of around 1% between both analyses, meaning that NeuronRead is efficient in analyzing the neuritic net at both low (4 DIV) and high (12 DIV) density neuronal cultures (Suppl. Fig. S2). Regarding the detection of cell bodies, comparison of NeuronRead with manual analysis showed a small difference between both methods (≈3%), mainly due to an increase in cell agglomerates in 12 DIV images. This results in both an underscoring of the number of cells and in an over-segmentation of cell somas by the watershed function. Nonetheless, users can eliminate this small error by manually adding or removing cell bodies that were misidentified by NeuronRead. NeuronRead robustness and sensitivity were also evaluated by using a similar approach as the one described in (Pani et al., 2014). Briefly, by using the ImageJ “Noise” function, two different types of noise (Salt and Pepper, and Gaussian noises) were incrementally added to both PhC and Fluorescence images (Suppl. Fig. S4). Quantitative analyses of these images showed that NeuronRead's ability to extract cell bodies morphometric data is extremely resistant to noise levels, with no significant changes detected, even when noise was visually noticeable. NeuronRead's ability to extract neuritic data was also resistant to the addition of Salt and Pepper noise to PhC images, and in fluorescence images only a high level of noise affected its analysis (Sup. Fig. S4A). Moreover, NeuronRead also effectively extracted neuritic data in the presence of low-to-medium levels of Gaussian noise (Sup. Fig. S3B). The next step was to evaluate if neuronal PhC images, analyzed with NeuronRead, could be used to detect relative alterations in the neuritic network. For that, we tested if the macro could accurately quantify alterations in the neuritic network in PhC images of neurons exposed to an inhibitor of the epidermal growth factor receptor (EGFR). EGFR translates signals from the pro-survival and pro-neuritogenic EGF and is involved in neuritic outgrowth (Evangelopoulos et al., 2009; Tsai et al., 2010). Differentiating neurons that were under 18h of EGFR inhibition should thus yield a decrease in their total neuritic length per cell, when compared to control conditions (Fig. 5A). The analysis of neuronal PhC images using NeuronRead showed a significant reduction of 13.0% in neuritic length per cell when compared to control neurons, virtually identical to the difference obtained when analyzing fluorescence images (13.2%) (Fig. 5B). These results thus show that both types of images can be analyzed and used to evaluate differences in neuritic length between experimental conditions. Regarding some of the performance characteristics of both methods, in a standard PC (e.g. Intel® Core™ i5-5200 Dual Core 2.2GHz, 8GB RAM, 500GB Hard Drive and Intel® HD Graphics 5500) NeuriteQuant took considerably more time analyzing each image (1–2min with NeuronRead vs 8–10min with NeuriteQuant). Another advantage in using NeuronRead was its accurate detection of cell bodies in PhC images, which we did not find as reliable when using NeuriteQuant. The type of images analyzed also contributes for this difference, most probably due to how the fluorescent probe used stains the cellular body. Indeed, NeuronRead applied to fluorescence images also lost some accuracy in automated detecting the cell bodies, although this was easily corrected manually. Also, while both software programs require some user intervention, NeuronRead allows this while the macro is running, whereas NeuriteQuant requires a more laborious set up before the plugin starts the analysis (Dehmelt et al., 2011). NeuronRead is thus highly versatile and robust, and can be applied to neuronal PhC and fluorescence images, and also to PhC images of e.g. neuronal-like cell models, such as differentiated SH-SY5Y neuroblastoma cells (Supp. Fig. S4). 3.3 Evaluation of cell body parameters with NeuronRead NeuronRead was then applied to extract morphometric data from PhC microphotographs of primary neurons at 1, 4, 10 and 14 DIV. In parallel, the macro was applied to study the effect of inhibiting γ-secretase on neuronal differentiation. The time points of neuronal culture were chosen based on their associated differentiation events (Pani et al., 2013). At 1 DIV the small cellular processes start emerging from the soma, and at 4 DIV these processes have partially elongated, and a major process (the axon) can be seen, along with the smaller elongating dendrites. At 10 DIV the neuritic elongation tends to cease, to give rise to synaptic maturation, which is on-going at 14 DIV, a time point when neurons are almost structural and functionally mature (Dotti et al., 1988). Primary neurons were cultured and left to differentiate in the absence (‘Control’) or presence of 1 μM of DAPT for 24h (‘DAPT’). This pharmacological inhibitor of the γ-secretase complex inhibits the cleavage of Notch receptor into NICD, and APP into its APP Intracellular Domain (AICD), thus enabling the evaluation, to some extent, of the role of APP and Notch processing and nuclear signaling in neuritogenesis. At the indicated DIV, the wells were placed on the microscope and random fields imaged by PhC illumination (Fig. 6A). NeuronRead can be successfully applied to both positive and negative PhC images (Fig. 6A), and the nature of the PhC images to be analyzed is chosen when NeuronRead is started. A first comparative analysis of the PhC microphotographs immediately retrieved DAPT-induced differences in cell number. The average cell number was thus determined with NeuronRead, and the DAPT-induced change in cell number calculated as fold increases (Fig. 6B). While DAPT increased cell number at the initial 1 and 4 DIV periods, it had a detrimental effect at the later 14 DIV period, decreasing the number of mature neurons (Fig. 6B). NeuronRead provides various primary morphological measurements related to the neuronal soma, common in software tools for neuronal digital analysis, including the cell body area and perimeter. Using this tool it was possible to establish that the cell body area (Fig. 7A) increased with time of differentiation for both conditions (control and DAPT). Nonetheless, in control conditions, the increase in cell body area stopped when the network started to mature (at 10 DIV), while in DAPT it did not. In the earliest period (1 DIV) DAPT had a slightly negative effect on cell body area (from 92.6±3 to 84±3μm2, p <0.05). Further on, until 10 DIV, DAPT had generally no effect, while at 14 DIV it greatly increased cell body area (from 125.2±7.2μm2 in control to 152.3±11.9μm2 in DAPT conditions, p <0.05). The cell body perimeter presented a similar time-dependent profile in control conditions, increasing with time in culture until 10 DIV and then slightly decreasing until 14 DIV (Fig. 7B ‘CTRL’). DAPT had very similar time-dependent effects on cell body perimeter as for cell body area, although with smaller amplitudes. For example, it also increased the perimeter at 14 DIV, from 43.2±1.1μm in control to 46.8±1.8μm in DAPT (p <0.05). Other shape descriptors used to monitor time and DAPT effects on neuronal cell bodies include Circularity (4π×[Area]/[Perimeter]2) and Roundness [4×[Area]/π[Major axis]2, or the inverse of Aspect Ratio: (Minor Axis)/(Major Axis)]; both descriptors vary between 0 and 1 (perfect circle) (Fanti et al., 2011). NeuronRead detected steady increases in neuronal cell body Circularity with time in culture, from 0.74±0.01 at 1 DIV to 0.81±0.00 at 14 DIV, towards more circular shapes (value of 1). DAPT incubation had no detectable effect on this parameter (Fig. 7C) but presented a negative effect on cell body Roundness in the more immature 1 DIV neurons (from 0.73±0.01 in CTRL to 0.69±0.01 in DAPT, Fig. 7D). 3.4 Time and DAPT-dependent network alterations detected by NeuronRead Quantitative data on the neuritic networks was extracted with NeuronRead using two approaches. The first evaluated the average neuritic network of each microphotograph (of 444*333=148mm2 of the area) (Fig. 8A); the ‘Total neuritic length’ parameter is thus the sum of all the neuritic segments, of all the neurons in the image. In the second approach, these values were normalized to the number of cells (Fig. 8B). The time-dependent profile of the neuritic networks with increasing DIV (Fig. 8) were as expected (Pani et al., 2013). In control conditions, the total neuritic length increased with time in culture until 10 DIV, from which it stabilized. The major increases occurred from 4 to 10 DIV, a time point when the dendrites (in higher number than axons and also highly ramified) have their major expansion (Fig. 8A, “CTRL”). DAPT was able to further increase total neuritic length, but only in the more immature cultures: from 7058±698 μm to 10,657±460 μm at 1 DIV (p <0.01), and from 12,142±1481 μm to 15,502±521 μm at 4 DIV (p <0.05) (Fig. 8A, “DAPT”). The neuritic network per neuron also increased with time in culture until 10 DIV (Fig. 8B, “CTRL”), as expected for non-mitotic cells as neurons. DAPT was again observed to further increase the neuritic network per neuron at the earlier time points: at 1 DIV from 88±12μm to 115±4μm (p <0.01); at 4 DIV from 314±11μm to 392±33μm (p <0.01), but also at 14 DIV (Fig. 8B, “DAPT”). This latter positive effect is most probable associated to the previously DAPT-induced 30% decrease in cell number, observed in Fig. 6. 4 Discussion Quantitative analyses of neuronal morphologic characteristics are widely used to study correlations between morphology and function for various applications, including therapeutic drug development for neuroregeneration (Mitchell et al., 2007). Neuronal features more relevant for quantitative assessment include cell body area and roundness, and neuritic-related parameters such as neuritic length and branching (Baxes, 1994; da Costa et al., 2002; Ho et al., 2011). Although fluorescence microphotographs are nowadays more widely used in cellular imaging, partially due to the high number of freeware tools dedicated to them, PhC images are easier to obtain and more affordable. For example, these PhC images of neuronal cultures can provide valuable and easy-to-obtain morphological data regarding alterations induced by drugs to neuronal cells and their network. Since PhC images are potentially inexpensive in terms of imaging reagents (antibodies or dyes), sample preparation or staining, they are less time-consuming. Another advantage of this technique is its non-invasiveness so that neurons can be imaged alive. As downsize, these images have intrinsic lower contrast, resulting in less absolute information and in a higher difficulty in their analysis. Technical difficulties of PhC images include the low contrast between objects and background (low signal-to-noise ratio), uneven illumination resulting from shining light on 2D-objects, vignetting (darkening of the image corners), and shade-off and halo patterns characteristic of the PhC optical system (Shaked et al., 2012). However, these last two are considered minor obstacles, and the halo effect can emphasize contrast differences in the less contrasting negative PhC images. Despite these issues and the potential of PhC images, there are few freeware tools capable of analyzing PhC neuronal images in an automatic or semi-automatic manner (Carter and Shieh, 2010). Our search for freeware tools for automatic or semi-automatic analysis of PhC neuronal images only retrieved NeuronGrowth (Fanti et al., 2011) and NEMO (Billeci et al., 2013). NeuronGrowth cannot be applied to images as the ones herein presented since these were not obtained from time-lapse experiments; it would thus be necessary to mark all the neurites manually if this program was to be used. NEMO (Billeci et al., 2013) performs various morphological analyses and, although very efficient, it is more dedicated to the automated analysis of single cells in images in batch, as time-lapse images, and is more time consuming (e.g. the images need to be correctly labeled before analysis). In our institute, we perform multiple analyses of neuronal differentiation and regeneration processes in 2D-cultures. This requires a customized image processing workflow that can handle very specific imaging contexts and is able to tackle the processing problems of both types of neuronal images. A sequence of processes and analyzing steps using the ImageJ platform was thus established and optimized, and termed ‘NeuronRead’. The workflow developed is able to quantify parameters such as the cell number, cell body area, and total neuritic length, in a semi-automatic manner. It requires little user-interaction, in order to supervise cell body identification and to reduce noise before neuritic detection. Further, similar to NeuronGrowth and NEMO, NeuronRead can be applied to both PhC and fluorescence images. Validation of our macro was based on various comparative experiments. The robustness of NeuronRead in detecting cell somas and correctly extracting their area was tested by comparison with manual determinations. Indeed, the average cell body areas of 4 DIV neurons retrieved by NeuronRead were not significantly different to our manual evaluation performed with the help of ImageJ tools (Fig. 3). Some small variations in cell body detection may occur when analyzing images of high-density cultures, which can be easily surpassed with manual intervention. Nevertheless, and since the quality of the thresholding process determines the success of the subsequent segmentation process, the inclusion of alternative improved watersheding algorithms in a near future may contribute to minimize over-segmentation effects in this type of images. The macro's ability to extract and quantify the neuritic network in PhC and fluorescence images was compared to the widely used tool NeuriteQuant, applied to fluorescent images (Figs. 4 and 5). There was no statistical significance between the results obtained with both methods (NeuronRead and NeuriteQuant) when these were applied to fluorescence images, either in basal conditions or in conditions of neuritic growth inhibition (Figs. 4 and 5). The macro could also accurately detect the neuritic network of PhC images, but the absolute values taken from PhC images were always below the ones obtained using the paired fluorescence ones (around 25% lower). This results from the fact that PhC images possess a poorly differentiated background where thick and thin, bright and dim neurites coexist, while good fluorescent probes can increase the signal-to-noise ratio and enhance smaller or thinner structures that are almost invisible in PhC images. Nevertheless, although PhC images render less absolute neuritic information, they are very useful to compare experimental conditions, and be used to accurately detect alterations imposed to the neuritic network by variables external or internal to the culture. A final validation of the macro emerged from the data extracted from PhC control images with increasing differentiation days (Figs. 6–8). The average cell body areas measured with NeuronRead (80–150μm2) were in the same range of the soma sizes of serotonin (5-HT)- and tyrosine hydroxylase (TH)-positive embryonic neurons in culture (85–200μm2) (Liu and Lauder, 1991). Further, NeuronRead has detected a slight time-dependent increase in cell body circularity, particularly from 1 DIV (an early period of high somatic plasticity) to 4 DIV (Fig. 7C). Regarding the somatic roundness, the values obtained with NeuronRead (0.70–0.74) are virtually identical to the ones reported by Pani et al. for E17-rat cortical primary neuronal cultures (roundness of 0.70–0.72) (Pani et al., 2013). These authors also observed similar time-dependent slight increases in the somatic area (from 1 to 14 DIV) and in the roundness (from 4 to 14 DIV; as in Fig. 7) of primary rat cortical neurons. Of note, not long ago the same group released the ImageJ macro ‘MorphoNeuroNet’ that enables the automated tracing of neurites in fluorescently stained primary neurons cultured for up to 23days (Pani et al., 2014). Confirming its applicability, NeuronRead also extracted the expected increase of total neuritic length with DIV (Fig. 8), which reflects the well-known time-dependent neuritogenesis in culture (Dotti et al., 1988; Pani et al., 2013). Indeed, the neuritic network increased from 1 to 10 DIV, stabilizing mainly from 10 to 14 DIV, a period more associated with neuritic maturation. Pani et al. also observed similar time-dependent increases in the neuritic area of primary cortical neurons, particularly from 1 to 10–12 DIV, from when it also mainly stabilized (Pani et al., 2013, 2014). Further, our macro retrieved an average 1 DIV neuritic length (≈88μm) that is close to the value reported for 1 DIV primary cerebellar granule neurons of P8-rat pups (61±18μm; measured with an in-house tool applied to fluorescent images) (Mitchell et al., 2007). Lastly, the NeuronRead macro was used to analyze how DAPT, a pharmacological inhibitor of γ-secretase, affected the neuritic establishment. γ-Secretase is an enzyme that cleaves several molecules, including the adhesive and neuritogenic APP (da Cruz e Silva and da Cruz e Silva, 2003; Lleó and Saura, 2011; Konietzko, 2012; Müller and Zheng, 2012), and the development-related Notch receptor (Chuang et al., 2015; Lee and Lundell, 2007). DAPT treatment first (1–4 DIV) increased and later (14 DIV) greatly lowered the number of neurons per image (Fig. 6). Since these cultures are mostly constituted by post-mitotic neurons, alterations in the number of cells should mainly reflect altered cell death. These results suggest lower survival of mature neurons when γ-secretase products are absent in DAPT-treated neurons. This may be partially due to the absence of the NICD and AICD peptides. For example, the presence of AICD seems to be crucial for the synaptogenic process to occur (Bittner et al., 2009). Contrarily, in immature neurons, AICD may potentially induce apoptosis (Figs. 6B, 1–4 DIV DAPT) (Konietzko, 2012; Müller and Zheng, 2012). An influence of neuronal maturity on cell death has been suggested, based on age-related biochemical alterations such as altered caspase-3 cleavage in old and young cultured neurons after injury (Meitzen et al., 2011). A potentially time-dependent effect of AICD in cellular apoptosis would be very interesting and should be further pursued. Further analyses revealed that at 1 DIV DAPT decreases the somatic area, perimeter, and roundness (Fig. 7A,B,D), while having no apparent effect on circularity (Fig. 7C). Although apparently very similar, circularity uses a relation between area and cell perimeter and is less sensitive to major/minor cell axes asymmetries than roundness, a parameter more indicative of cell elongation. Early differentiating neurons exposed to DAPT thus have smaller soma with less round shapes. We have already observed an induction of cell body plasticity by DAPT in other cell models (HeLa, COS-7, and SH-SY5Y cell lines), including elongation, acquisition of irregular shapes, and increased number of processes protruding from the cell body (data not shown). The latter also agrees with DAPT increasing the neuritic length in early differentiating neurons (1–4 DIV) (Fig. 8). In the more mature neurons (Fig. 8B, 14 DIV) this increment is higher and also relates to the lower number of cells (Fig. 6). The number of cells and the cell body area appear to have an inverse relationship, and lower cell number may relate to their increased sizes, as DAPT increases the somatic area and perimeter (Fig. 7A–B, 14 DIV DAPT). Of note, the time-dependent profile of DAPT-induced neuritic length (total or per cell) also peaks around 10 DIV as in control conditions (Fig. 8). APP is upregulated during neuronal differentiation, and its in vivo deletion (alone or together with its family members) alters neuronal maturation at the neuritogenic and synaptogenic levels [reviewed in (Hunter and Brayne, 2012; Müller and Zheng, 2012)]. In this working hypothesis, AICD restrains neuritogenesis at earlier time points of neuronal differentiation, while being a facilitator of neuronal maturation at later periods. Since γ-secretase has various substrates (Lleó and Saura, 2011), including molecules already related to neuronal differentiation and regeneration such as Erb4 (Ronchi et al., 2016), and the already mentioned Notch receptor (Chuang et al., 2015; Lee and Lundell, 2007), it remains to be confirmed if AICD is one of the mediators of the effects of DAPT here observed. Nevertheless, Trazzi et al. (2013) linked excessive AICD production to a reduced neuritic length phenotype, using differentiating trisomic neuronal precursors (NPCs) that bear an extra APP gene copy (Trazzi et al., 2013). Further, the same reduced neurite outgrowth could be accomplished by either APP or AICD overexpression in euploid differentiating NPCs cultures (Deyts et al., 2012). The authors also reported that AICD inhibition, via γ-secretase inhibition with Compound E, stimulates neurite outgrowth in rat H19-7 immortalized hippocampal cells, mouse N2a neuroblastoma cells, and mouse cortical primary neurons (Deyts et al., 2012). In mature neurons, AICD may intervene in neuronal survival and in correct neuronal synaptic maturation, since long-term AICD inhibition reduces spine density in vivo (Bittner et al., 2009). Given the strong relationship between cognitive decline and synaptic loss in AD (Koffie et al., 2011; Konietzko, 2012; Terry et al., 1991), there is a need for more studies relating AICD role to neuronal differentiation and maturation. 5 Conclusion NeuronRead proved to be a flexible, practical and useful tool in bioimaging analysis of PhC and fluorescence microphotographs of primary neurons in neuronal cultures. It does not need manual tracing of the neurites as in other neuronal analysis software programs, it requires minor user-interaction to increase its accuracy in morphological detection, and the errors associated with its automated detection are minor, particularly for comparative analyses. The macro is also customizable, with the user being able to fit the macro to its needs (e.g. batch processing and analysis). In synthesis, this ImageJ Macro is reliable, fast, easy to apply, and considerably robust in extracting morphometric data from the easier, faster and affordable PhC images, with the plus of also being applicable to the neuritic analysis of fluorescence images. It can thus be easily used in routine operations involving morphometric analyses of neuronal cultures. Abbreviations AD Alzheimer's disease AICD APP intracellular domain ANOVA one-way analysis of variance APP amyloid precursor protein CLAHE contrast-limited adaptive histogram equalization DoG difference of Gaussians DIV days in vitro EGFR epidermal growth factor receptor NICD Notch intracellular domain NPCs neuronal precursors NS not statistically significantly different PhC phase contrast SE structuring element Acknowledgements This work was supported Fundação para a Ciência e Tecnologia (Portuguese Ministry of Science and Technology), the COMPETE program, QREN, and the European Union (FEDER): Centre for Cell Biology CBC Pest-OE/SAU/UI0482/2014, Institute for Biomedicine iBiMED UID/BIM/04501/2013, PTDC/SAU-NMC/111980/2009, SFRH/BD/90996/2012, SFRH/BD/78507/2011; Image acquisition was performed in the LiM facility of iBiMED, a node of PPBI (Portuguese Platform of BioImaging): POCI-01-0145-FEDER-022122. We would like to acknowledge Prof. Dr. Pedro Quelhas (INEB, Porto) for his valuable advice on cell body detection; Dr. Sandra Rebelo and Ana Gabriela Henriques (iBiMED, UA), and Dr. Ivan Lalanda and Dr. Carlos Duarte (CNC, Universidade de Coimbra), for helping to establish the neuronal cultures. Authors declaration The authors have no conflict of interest to declare. Appendix A Supplementary data Supplementary figures Image 1 NeuronRead macro: file of the NeuronRead macro, to be installed Image 2 NeuronRead Test Images: Pair fluorescence/PhC images of neuronal cultures to test the macro Image 3 NeuronRead Tutorial: a simple tutorial on how to install and run NeuronRead Image 4 Appendix A Supplementary data Supplementary data to this article can be found online at References Arganda-Carreras et al., 2010 I. Arganda-Carreras R. Fernández-González A. Muñoz-Barrutia C. Ortiz-De-Solorzano 3D reconstruction of histological sections: application to mammary gland tissue Microsc. Res. Tech. 73 2010 1019 1029 10.1002/jemt.20829 Ascoli, 2008 G.A. Ascoli Neuroinformatics grand challenges Neuroinformatics 6 2008 1 3 10.1007/s12021-008-9010-5 Baxes, 1994 G.A. Baxes Digital Image processing: Principles and Applications 1994 Wiley Billeci et al., 2013 L. Billeci C. Magliaro G. Pioggia A. Ahluwalia NEuronMOrphological analysis tool: open-source software for quantitative morphometrics Front. Neuroinform. 7 2013 2 10.3389/fninf.2013.00002 Bittner et al., 2009 T. Bittner M. Fuhrmann S. Burgold C.K.E. Jung C. Volbracht H. Steiner G. Mitteregger H.A. Kretzschmar C. Haass J. Herms Gamma-secretase inhibition reduces spine density in vivo via an amyloid precursor protein-dependent pathway J. Neurosci. 29 2009 10405 10409 10.1523/JNEUROSCI.2288-09.2009 Brabet et al., 1988 P. Brabet A. Dumuis M. Sebben C. Pantaloni J. Bockaert V. Homburger Immunocytochemical localization of the guanine nucleotide-binding protein Go in primary cultures of neuronal and glial cells J. Neurosci. 8 1988 701 708 Carter and Shieh, 2010 M. Carter J.C. Shieh Guide to Research Techniques in Neuroscience, Guide to Research Techniques in Neuroscience 2010 Elsevier 10.1016/B978-0-12-374849-2.00017-3 Chalfoun et al., 2013 J. Chalfoun M. Kociolek A. Dima M. Halter A. Cardone A. Peskin P. Bajcsy M. Brady Segmenting time-lapse phase contrast images of adjacent NIH 3T3 cells J. Microsc. 249 2013 41 52 10.1111/j.1365-2818.2012.03678.x Chuang et al., 2015 J.-H. Chuang L.-C. Tung Y. Lin Neural differentiation from embryonic stem cells in vitro: an overview of the signaling pathways World J. Stem Cells 7 2015 437 447 10.4252/wjsc.v7.i2.437 da Costa et al., 2002 L.F. da Costa E.T.M. Manoel F. Faucereau J. Chelly J. van Pelt G. Ramakers A shape analysis framework for neuromorphometry Network 13 2002 283 310 da Cruz e Silva and da Cruz e Silva, 2003 E.F. da Cruz e Silva O.A. da Cruz e Silva Protein phosphorylation and APP metabolism Neurochem. Res. 28 2003 1553 1561 Dehmelt et al., 2011 L. Dehmelt G. Poplawski E. Hwang S. Halpain NeuriteQuant: an open source toolkit for high content screens of neuronal morphogenesis BMC Neurosci. 12 2011 100 10.1186/1471-2202-12-100 Deyts et al., 2012 C. Deyts K.S. Vetrivel S. Das Y.M. Shepherd D.J. Dupré G. Thinakaran A.T. Parent Novel GαS-protein signaling associated with membrane-tethered amyloid precursor protein intracellular domain J. Neurosci. 32 2012 1714 1729 10.1523/JNEUROSCI.5433-11.2012 Dotti et al., 1988 C.G. Dotti C.A. Sullivan G.A. Banker The establishment of polarity by hippocampal neurons in culture J. Neurosci. 8 1988 1454 1468 10.1016/0012-1606(89)90269-8 Dougherty et al., 2003 E.R. Dougherty R.A. Lotufo Society of Photo-optical Instrumentation Engineers Hands-on Morphological Image Processing 2003 SPIE Encinas et al., 2000 M. Encinas M. Iglesias Y. Liu H. Wang A. Muhaisen V. Ceña C. Gallego J.X. Comella Sequential treatment of SH-SY5Y cells with retinoic acid and brain-derived neurotrophic factor gives rise to fully differentiated, neurotrophic factor-dependent, human neuron-like cells J. Neurochem. 75 2000 991 1003 10.1046/j.1471-4159.2000.0750991.x Evangelopoulos et al., 2009 M.E. Evangelopoulos J. Weis A. Krüttgen Mevastatin-induced neurite outgrowth of neuroblastoma cells via activation of EGFR J. Neurosci. Res. 87 2009 2138 2144 10.1002/jnr.22025 Fanti et al., 2011 Z. Fanti M.E. Martinez-Perez F.F. De-Miguel NeuronGrowth, a software for automatic quantification of neurite and filopodial dynamics from time-lapse sequences of digital images Dev. Neurobiol. 71 2011 870 881 10.1002/dneu.20866 Henriques et al., 2009 A.G. Henriques S.I. Vieira M.E. Crespo-López M.A. Guiomar de Oliveira E.F. da Cruz e Silva O.A.B. da Cruz e Silva Intracellular sAPP retention in response to Abeta is mapped to cytoskeleton-associated structures J. Neurosci. Res. 87 2009 1449 1461 10.1002/jnr.21959 Ho et al., 2011 S.-Y. Ho C.-Y. Chao H.-L. Huang T.-W. Chiu P. Charoenkwan E. Hwang NeurphologyJ: an automatic neuronal morphology quantification method and its application in pharmacological discovery BMC Bioinf. 12 2011 230 10.1186/1471-2105-12-230 Hunter and Brayne, 2012 S. Hunter C. Brayne Relationships between the amyloid precursor protein and its various proteolytic fragments and neuronal systems Alzheimers Res. Ther. 4 2012 10 10.1186/alzrt108 Kapitein and Hoogenraad, 2011 L.C. Kapitein C.C. Hoogenraad Which way to go? Cytoskeletal organization and polarized transport in neurons Mol. Cell. Neurosci. 46 2011 9 20 10.1016/j.mcn.2010.08.015 Kim et al., 2015 H. Kim S. Kim Y. Song W. Kim Q.L. Ying E.H. Jho Dual function of Wnt signaling during neuronal differentiation of mouse embryonic stem cells Stem Cells Int. 2015 2015 459301 10.1155/2015/459301 Koffie et al., 2011 R.M. Koffie B.T. Hyman T.L. Spires-Jones Alzheimer's disease: synapses gone cold Mol. Neurodegener. 6 2011 63 10.1186/1750-1326-6-63 Konietzko, 2012 U. Konietzko AICD nuclear signaling and its possible contribution to Alzheimer's disease Curr. Alzheimer Res. 9 2012 200 216 Lee and Lundell, 2007 H.-K. Lee M.J. Lundell Differentiation of the Drosophila serotonergic lineage depends on the regulation of Zfh-1 by Notch and Eagle Mol. Cell. Neurosci. 36 2007 47 58 10.1016/j.mcn.2007.05.011 Legland et al., 2016 D. Legland I. Arganda-Carreras J. Schindelin MorphoLibJ: MorphoLibJ v1.2.0 2016 10.5281/ZENODO.50694 Liu and Lauder, 1991 J.P. Liu J.M. Lauder Serotonin and nialamide differentially regulate survival and growth of cultured serotonin and catecholamine neurons Brain Res. Dev. Brain Res. 62 1991 297 305 Lleó and Saura, 2011 A. Lleó C.A. Saura γ-secretase substrates and their implications for drug development in Alzheimer's disease Curr. Top. Med. Chem. 11 2011 1513 1527 Meijering, 2010 E. Meijering Neuron tracing in perspective Cytometry A 77 2010 693 704 10.1002/cyto.a.20895 Meitzen et al., 2011 J. Meitzen K.R. Pflepsen C.M. Stern R.L. Meisel P.G. Mermelstein Measurements of neuron soma size and density in rat dorsal striatum, nucleus accumbens core and nucleus accumbens shell: differences between striatal region and brain hemisphere, but not sex Neurosci. Lett. 487 2011 177 181 10.1016/j.neulet.2010.10.017 Mitchell et al., 2007 P.J. Mitchell J.C. Hanson A.T. Quets-Nguyen M. Bergeron R.C. Smith A quantitative method for analysis of in vitro neurite outgrowth J. Neurosci. Methods 164 2007 350 362 10.1016/j.jneumeth.2007.04.021 Müller and Zheng, 2012 U.C. Müller H. Zheng Physiological functions of APP family proteins Cold Spring Harb. Perspect. Med. 2 2012 a006288 10.1101/cshperspect.a006288 Pani et al., 2013 G. Pani N. Samari R. Quintens L. de Saint-Georges M. Meloni S. Baatout P. Van Oostveldt M.A. Benotmane Morphological and physiological changes in mature in vitro neuronal networks towards exposure to short-, middle- or long-term simulated microgravity PLoS One 8 2013 e73857 10.1371/journal.pone.0073857 Pani et al., 2014 G. Pani W.H. De Vos N. Samari L. de Saint-Georges S. Baatout P. Van Oostveldt M.A. Benotmane MorphoNeuroNet: an automated method for dense neurite network analysis Cytometry A 85 2014 188 199 10.1002/cyto.a.22408 Pinho et al., 2015 A.C. Pinho R. Dias A.R. Cerqueira O.A.B. da Cruz e Silva S.I. Vieira APP and its secreted fragment sAPP in SH-SY5Y neuronal-like migration Microsc. Microanal. 21 2015 36 37 10.1017/S1431927614013853 Purves et al., 2008 D. Purves G. Augustine D. Fitzpatrick M. Hall A. LaMantia J. McNamara L. White Neuroscience 4th ed 2008 Sinauer Associates, Inc. Massachusetts Raghavan and Bitar, 2014 S. Raghavan K.N. Bitar The influence of extracellular matrix composition on the differentiation of neuronal subtypes in tissue engineered innervated intestinal smooth muscle sheets Biomaterials 35 2014 7429 7440 10.1016/j.biomaterials.2014.05.037 da Rocha et al., 2015 J.F. da Rocha O.A.B. da Cruz E Silva S.I. Vieira Analysis of the amyloid precursor protein role in neuritogenesis reveals a biphasic SH-SY5Y neuronal cell differentiation model J. Neurochem. 134 2015 288 301 10.1111/jnc.13133 Rolls et al., 2007 M.M. Rolls D. Satoh P.J. Clyne A.L. Henner T. Uemura C.Q. Doe Polarity and intracellular compartmentalization of Drosophila neurons Neural Dev. 2 2007 7 10.1186/1749-8104-2-7 Ronchi et al., 2016 G. Ronchi K. Haastert-Talini B.E. Fornasari I. Perroteau S. Geuna G. Gambarotta The Neuregulin1/ErbB system is selectively regulated during peripheral nerve degeneration and regeneration Eur. J. Neurosci. 43 2016 351 364 10.1111/ejn.12974 Schindelin et al., 2012 J. Schindelin I. Arganda-Carreras E. Frise V. Kaynig M. Longair T. Pietzsch S. Preibisch C. Rueden S. Saalfeld B. Schmid J.-Y. Tinevez D.J. White V. Hartenstein K. Eliceiri P. Tomancak A. Cardona Fiji: an open-source platform for biological-image analysis Nat. Methods 9 2012 676 682 10.1038/nmeth.2019 Schneider et al., 2012 C.A. Schneider W.S. Rasband K.W. Eliceiri NIH Image to ImageJ: 25years of image analysis Nat. Methods 9 2012 671 675 Serra et al., 2009 V. Serra F. Camões S. Vieira M. Faustino J. Tomé D. Pinto M. Neves A. Tomé A. Silva E. da Cruz e Silva J. Cavaleiro Synthesis and biological evaluation of novel chalcone-porphyrin conjugates Acta Chim. Slov. 56 2009 603 611 Shaked et al., 2012 N. Shaked Z. Zalevsky L. Satterwhite Biomedical Optical Phase Microscopy and Nanoscopy 2012 Soille, 2013 P. Soille Morphological Image Analysis: Principles and Applications 2013 Springer Svedružić et al., 2015 Ž.M. Svedružić K. Popović V. Šendula-Jengić Decrease in catalytic capacity of γ-secretase can facilitate pathogenesis in sporadic and Familial Alzheimer's disease Mol. Cell. Neurosci. 67 2015 55 65 10.1016/j.mcn.2015.06.002 Terry et al., 1991 R.D. Terry E. Masliah D.P. Salmon N. Butters R. DeTeresa R. Hill L.A. Hansen R. Katzman Physical basis of cognitive alterations in Alzheimer's disease: synapse loss is the major correlate of cognitive impairment Ann. Neurol. 30 1991 572 580 10.1002/ana.410300410 Trazzi et al., 2013 S. Trazzi C. Fuchs E. Valli G. Perini R. Bartesaghi E. Ciani The amyloid precursor protein (APP) triplicated gene impairs neuronal precursor differentiation and neurite development through two different domains in the Ts65Dn mouse model for Down syndrome J. Biol. Chem. 288 2013 20817 20829 10.1074/jbc.M113.451088 Tsai et al., 2010 N.-P. Tsai Y.-C. Tsui J.E. Pintar H.H. Loh L.-N. Wei Kappa opioid receptor contributes to EGF-stimulated neurite extension in development Proc. Natl. Acad. Sci. U. S. A. 107 2010 3216 3221 10.1073/pnas.0912367107 Vincent and Soille, 1991 L. Vincent P. Soille Watersheds in digital spaces: an efficient algorithm based on immersion simulations IEEE Trans. Pattern Anal. Mach. Intell. 13 1991 583 598 10.1109/34.87344 Wang et al., 2015 Y. Wang Z. Zhang H. Wang S. Bi Segmentation of the clustered cells with optimized boundary detection in negative phase contrast images PLoS One 10 2015 e0130178 10.1371/journal.pone.0130178 Xiong et al., 2006 G. Xiong X. Zhou A. Degterev L. Ji S.T.C. Wong Automated neurite labeling and analysis in fluorescence microscopy images Cytometry A 69 2006 494 505 10.1002/cyto.a.20296 "
    },
    {
        "doc_title": "A study to understand the acceptance of DICOM Structured Reports on Breast Imaging",
        "doc_scopus_id": "85040256014",
        "doc_doi": "10.1016/j.procs.2017.11.088",
        "doc_eid": "2-s2.0-85040256014",
        "doc_date": "2017-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Breast Cancer",
            "Breast imaging reporting and data systems",
            "Digital imaging and communication in medicines",
            "Free texts",
            "General practitioners",
            "Global communication",
            "Management strategies",
            "Structured reports"
        ],
        "doc_abstract": "© 2017 The Authors. Published by Elsevier B.V.Purpose: To create a Digital Imaging and Communication in Medicine Structured Reports (DICOM-SR) Repository and compare the acceptance of Free Text (FT) versus Structured Reports (SR) in communication of Breast Imaging findings. Materials and Methods: It was conceptualized the MamoCatalogue to the structuring of the Reports and the SR were converted into DICOM-SR and integrated with Dicoogle. After that, seven representative Breast Imaging Reports were selected and evaluated by a group of 25 Physicians. Each Physician evaluated the seven Reports, in FT and SR with a 3 months timelag, about their, Structure, Clarity and assertiveness, Diagnostic/Recommendations, Easiness of reading, Full reading, Partially reading with Breast Imaging Reporting and Data System (BI-RADS) focus and Ambiguity. Results: A DICOM-SR Repository was created and the assessment of the acceptance of the FT vs. SR revealed that there is a global trend favoring FT. Nevertheless, a group wise analysis revealed that for Gynaecologists and General Practitioners (GP) the differences between FT and SR weren't significant, unlike what happens with Radiologists. Conclusion: The DICOM-SR Repository allows the query/retrieve data for Reports and the communication with Gynaecologists and GP by SR was satisfactory. Although, Radiologists acceptance must be reinforced upon global communication and management strategy.",
        "available": true,
        "clean_text": "serial JL 280203 291210 291871 31 90 Procedia Computer Science PROCEDIACOMPUTERSCIENCE 2017-12-14 2017-12-14 2017-12-14 2017-12-14 2018-09-11T16:30:52 S1877-0509(17)32288-3 S1877050917322883 10.1016/j.procs.2017.11.088 S300 S300.5 HEAD-AND-TAIL 2018-09-11T15:48:05.609895Z 0 0 20170101 20171231 2017 2017-12-14T17:50:08.977695Z rawtext articleinfo articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids confeditor contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid hubeid indexeddate issn issnnorm itemstage itemtransactionid itemweight oauserlicense openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sortorder srctitle srctitlenorm srctype ssids alllist content oa subj suppl tomb vol volfirst volissue volumelist yearnav affil articletitle auth authfirstini authfull authkeywords authlast primabst ref 1877-0509 18770509 true 121 121 C Volume 121 89 672 680 672 680 2017 2017 2017-01-01 2017-12-31 2017 CENTERIS 2017 - International Conference on ENTERprise Information Systems / ProjMAN 2017 - International Conference on Project MANagement / HCist 2017 - International Conference on Health and Social Care Information Systems and Technologies, CENTERIS/ProjMAN/HCist 2017 Maria Manuela Cruz-Cunha João Eduardo Quintela Varajão Rui Rijo Ricardo Martinho Joe Peppard José Ramón San Cristóbal Josep Monguet article fla © 2017 The Author(s). Published by Elsevier B.V. ASTUDYUNDERSTANDACCEPTANCEDICOMSTRUCTUREDREPORTSBREASTIMAGING TRIBUNA L LI 2016 1020 1025 H GUIDELINE 2005 3 8 A REINER 2007 313 319 B BARBOSA 2010 15 21 F SOCIETY 2011 93 96 E WEISS 2008 739 747 D JOHNSON 2009 74 80 A KAHN 2009 852 856 C WANG 2014 1251 1259 K CLUNIE 2007 33 56 D HUSSEIN 2004 891 896 R NOUMEIR 2006 295 306 R KAHN 2011 295 304 C HUANG 2004 175 187 H PACSANSIMAGINGINFORMATICSBASICPRINCIPLESAPPLICATIONS COSTA 2011 848 856 C MATOS 2016 0 P ADYNAMICAPPROACHSUPPORTINTEROPERABILITYFORMEDICALREPORTSUSINGDICOMSR SICKLES 2013 121 140 E BIRADS 2013 121 132 A BOSMANS 2012 295 302 J MARCOVICI 2014 1265 1271 P GARCIA 2015 132 145 R MARGOLIES 2016 259 264 L MORGAN 2014 T SCHWARTZ 2011 L KRUPINSKI 2012 63 69 E TRIBUNAX2017X672 TRIBUNAX2017X672X680 TRIBUNAX2017X672XL TRIBUNAX2017X672X680XL Full 2017-11-10T01:10:54Z ElsevierWaived OA-Window This is an open access article under the CC BY-NC-ND license. © 2017 The Author(s). Published by Elsevier B.V. item S1877-0509(17)32288-3 S1877050917322883 10.1016/j.procs.2017.11.088 280203 2018-09-11T15:48:05.609895Z 2017-01-01 2017-12-31 true 840237 MAIN 9 46555 849 656 IMAGE-WEB-PDF 1 ScienceDirect Available online at www.sciencedirect.com Procedia Computer Science 121 (2017) 672â€“680 1877-0509 Â© 2017 The Authors. Published by Elsevier B.V. Peer-review under responsibility of the scientific committee of the CENTERIS - International Conference on ENTERprise Information Systems / ProjMAN - International Conference on Project MANagement / HCist - International Conference on Health and Social Care Information Systems and Technologies. 10.1016/j.procs.2017.11.088 10.1016/j.procs.2017.11.088 Â© 2017 The Authors. Published by Elsevier B.V. Peer-review under responsibility of the scientific committee of the CENTERIS - International Conference on ENTERprise Information Systems / ProjMAN - International Conference on Project MANagement / HCist - International Conference on Health and Social Care Information Systems and Technologies. 1877-0509 Available online at www.sciencedirect.com ScienceDirect Procedia Computer Science 00 (2017) 000â€“000 www.elsevier.com/locate/procedia 1877-0509 Â© 2017 The Authors. Published by Elsevier B.V. Peer-review under responsibility of the scientific committee of the CENTERIS - International Conference on ENTERprise Information Systems / ProjMAN - International Conference on Project MANagement / HCist - International Conference on Health and Social Care Information Systems and Technologies. CENTERIS - International Conference on ENTERprise Information Systems / ProjMAN - International Conference on Project MANagement / HCist - International Conference on Health and Social Care Information Systems and Technologies, CENTERIS / ProjMAN / HCist 2017, 8-10 November 2017, Barcelona, Spain A study to understand the acceptance of DICOM Structured Reports on Breast Imaging Liliana Tribunaa*, Augusto Silvab, Pedro SÃ¡ Coutoc, Luis BastiÃ£od a Department of Radiology, Hospital da Luz, Aveiro, Portugal bDETI/IEETA, University of Aveiro, Portugal cCIDMA/DMAT, University of Aveiro, Portugal dBMD Software, Lda. Portugal Abstract Purpose: To create a Digital Imaging and Communication in Medicine Structured Reports (DICOM-SR) Repository and compare the acceptance of Free Text (FT) versus Structured Reports (SR) in communication of Breast Imaging findings. Materials and Methods: It was conceptualized the MamoCatalogue to the structuring of the Reports and the SR were converted into DICOM-SR and integrated with Dicoogle. After that, seven representative Breast Imaging Reports were selected and evaluated by a group of 25 Physicians. Each Physician evaluated the seven Reports, in FT and SR with a 3 months timelag, about their, Structure, Clarity and assertiveness, Diagnostic/Recommendations, Easiness of reading, Full reading, Partially reading with Breast Imaging Reporting and Data System (BI-RADS) focus and Ambiguity. Results: A DICOM-SR Repository was created and the assessment of the acceptance of the FT vs. SR revealed that there is a global trend favoring FT. Nevertheless, a group wise analysis revealed that for Gynaecologists and General Practitioners (GP) the differences between FT and SR weren't significant, unlike what happens with Radiologists. Conclusion: The DICOM-SR Repository allows the query/retrieve data for Reports and the communication with Gynaecologists and GP by SR was satisfactory. Although, Radiologists acceptance must be reinforced upon global communication and management strategy. Â© 2017 The Authors. Published by Elsevier B.V. * Corresponding author. Tel.: +0-000-000-0000 ; fax: +0-000-000-0000 . E-mail address: lilianatribuna@ua.pt Available online at www.sciencedirect.com Sci nceDir t Procedia Computer Science 00 (2017) 000â€“000 www.elsevier.com/locate/procedia 1877-0509 Â© 2017 The Authors. Published by Elsevier B.V. Peer-review under responsibility of the scientific committee of the CENTERIS - International Conference on ENTERprise Information Systems / ProjMAN - International Conference on Project MANagement / HCist - International Conference on Health and Social Care Information Systems and Technologies. CENTERIS - International Conference on ENTERprise Information Systems / ProjMAN - International Conference on Project MANagement / HCist - International Conference on Health and Social Care Information Systems and Technologies, CENTERIS / ProjMAN / HCist 2017, 8-10 November 2017, Barcelona, Spain A study to understand the acceptance of DICOM Structured Reports on Breast Imaging Liliana Tribunaa*, Augusto Silvab, Pedro SÃ¡ Coutoc, Luis BastiÃ£od a Department of Radiology, Hospital da Luz, Aveiro, Portugal bDETI/IEETA, University of Aveiro, Portugal cCIDMA/DMAT, University of Aveiro, Portugal dBMD Software, Lda. Portugal Abstract Purpose: To create a Digital Imaging and Communication in Medicine Structured Reports (DICOM-SR) Repository and compare the acceptance of Free Text (FT) versus Structured Reports (SR) in communication of Breast Imaging findings. Materials and Methods: It was conceptualized the MamoCatalogue to the structuring of the Reports and the SR were converted into DICOM-SR and integrated with Dicoogle. After that, seven representative Breast Imaging Reports were selected and evaluated by a group of 25 Physicians. Each Physician evaluated the seven Reports, in FT and SR with a 3 months timelag, about their, Structure, Clarity and assertiveness, Diagnostic/Recommendations, Easiness of reading, Full reading, Partially reading with Breast Imaging Reporting and Data System (BI-RADS) focus and Ambiguity. Results: A DICOM-SR Repository was created and the assessment of the acceptance of the FT vs. SR revealed that there is a global trend favoring FT. Nevertheless, a group wise analysis revealed that for Gynaecologists and General Practitioners (GP) the differences between FT and SR weren't significant, unlike what happens with Radiologists. Conclusion: The DICOM-SR Repository allows the query/retrieve data for Reports and the communication with Gynaecologists and GP by SR was satisfactory. Although, Radiologists acceptance must be reinforced upon global communication and management strategy. Â© 2017 The Authors. Published by Elsevier B.V. * Corresponding author. Tel.: +0-000-000-0000 ; fax: +0-000-000-0000 . E-mail address: lilianatribuna@ua.pt 2 L Tribuna et al. / Procedia Computer Science 00 (2017) 000â€“000 Peer-review under responsibility of the scientific committee of the CENTERIS - International Conference on ENTERprise Information Systems / ProjMAN - International Conference on Project MANagement / HCist - International Conference on Health and Social Care Information Systems and Technologies. Keywords: Breast cancer; Free Text; Structured Reports; DICOM Structured Reports. 1. Introduction The incidence of Breast Cancer has been increasing over the past 20 years and its diagnosis has been performed in increasingly young patients 1. Demographic trends estimate a continuous increase of the values mentioned above, therefore early diagnosis and the optimization of the treatment are fundamental elements for the reduction of mortality rate and the increased of survival of patients with Breast Cancer 1, 2, 3. The Imaging Examinations play a fundamental role in the diagnosis and prognosis of this pathology 1, and the effective communication of Imaging findings is a crucial element in the diagnostic by imaging, and to promote the best patient care and support for the requesting Physician 4. Since the beginning of time, Reports could take one of two forms, Free Text (FT) or Structured Reports (SR) 5. In 2000 the Digital Imaging and Communications in Medicine - Structured Reports (DICOM-SR) was published and defined the data structure for the construction of a SR in DICOM format 6. Thus, due to the potential of this type of documents, particularly in the area of the Breast Imaging, this article describes the concept of a DICOM-SR Repository in Breast Imaging, where it is possible to search, query and analyse data and, in addition, compares the acceptance of Radiologists and non-Radiologists by FT versus SR, in the reporting of Breast Imaging findings. 2. Background 2.1. Radiology Reports The FT, used in the majority of the cases, usually does not have an explicit reporting structure and its methodology of writing is based on the Radiologists professional experience, which can result in narratives extremely subjective evaluations 6. The reduction of this variability should be promoted, because the Standard Reports will facilitate the understanding of these documents by the requesting Physicians 7. On the other hand, the SR present their organized contents in a clear and organized form, based on Templates or Checklists and three essential properties are recognized: structured format, consistent organization and standardized language 8. This type of report has the purpose of implementing the concept of standardization of the Clinical Reports and to promote their continuous improvement 9, promising to increase the consistency of the Report, increase the productivity of the Radiologists and improve the communication of the results with the requesting Physicians 7 , 10. With consistent format and terminology, the SR allow recovery and analysis of information from the Report, both by humans and by Information Systems (IS), in order to support the medical research, the clinical decision, to support the Quality Improvement (QI) processes, and, also, to evaluate inherent characteristics to the Reports 7 , 11. The successful implementation of SR is a difficult task, because it is dependent on the Radiologists acceptance. Liliana Tribuna et al. / Procedia Computer Science 121 (2017) 672â€“680 673 Available online at www.sciencedirect.com ScienceDirect Procedia Computer Science 00 (2017) 000â€“000 www.elsevier.com/locate/procedia 1877-0509 Â© 2017 The Authors. Published by Elsevier B.V. Peer-review under responsibility of the scientific committee of the CENTERIS - International Conference on ENTERprise Information Systems / ProjMAN - International Conference on Project MANagement / HCist - International Conference on Health and Social Care Information Systems and Technologies. CENTERIS - International Conference on ENTERprise Information Systems / ProjMAN - International Conference on Project MANagement / HCist - International Conference on Health and Social Care Information Systems and Technologies, CENTERIS / ProjMAN / HCist 2017, 8-10 November 2017, Barcelona, Spain A study to understand the acceptance of DICOM Structured Reports on Breast Imaging Liliana Tribunaa*, Augusto Silvab, Pedro SÃ¡ Coutoc, Luis BastiÃ£od a Department of Radiology, Hospital da Luz, Aveiro, Portugal bDETI/IEETA, University of Aveiro, Portugal cCIDMA/DMAT, University of Aveiro, Portugal dBMD Software, Lda. Portugal Abstract Purpose: To create a Digital Imaging and Communication in Medicine Structured Reports (DICOM-SR) Repository and compare the acceptance of Free Text (FT) versus Structured Reports (SR) in communication of Breast Imaging findings. Materials and Methods: It was conceptualized the MamoCatalogue to the structuring of the Reports and the SR were converted into DICOM-SR and integrated with Dicoogle. After that, seven representative Breast Imaging Reports were selected and evaluated by a group of 25 Physicians. Each Physician evaluated the seven Reports, in FT and SR with a 3 months timelag, about their, Structure, Clarity and assertiveness, Diagnostic/Recommendations, Easiness of reading, Full reading, Partially reading with Breast Imaging Reporting and Data System (BI-RADS) focus and Ambiguity. Results: A DICOM-SR Repository was created and the assessment of the acceptance of the FT vs. SR revealed that there is a global trend favoring FT. Nevertheless, a group wise analysis revealed that for Gynaecologists and General Practitioners (GP) the differences between FT and SR weren't significant, unlike what happens with Radiologists. Conclusion: The DICOM-SR Repository allows the query/retrieve data for Reports and the communication with Gynaecologists and GP by SR was satisfactory. Although, Radiologists acceptance must be reinforced upon global communication and management strategy. Â© 2017 The Authors. Published by Elsevier B.V. * Corresponding author. Tel.: +0-000-000-0000 ; fax: +0-000-000-0000 . E-mail address: lilianatribuna@ua.pt Available online at www.sciencedirect.com Sci nceDir t Procedia Computer Science 00 (2017) 000â€“000 www.elsevier.com/locate/procedia 1877-0509 Â© 2017 The Authors. Published by Elsevier B.V. Peer-review under responsibility of the scientific committee of the CENTERIS - International Conference on ENTERprise Information Systems / ProjMAN - International Conference on Project MANagement / HCist - International Conference on Health and Social Care Information Systems and Technologies. CENTERIS - International Conference on ENTERprise Information Systems / ProjMAN - International Conference on Project MANagement / HCist - International Conference on Health and Social Care Information Systems and Technologies, CENTERIS / ProjMAN / HCist 2017, 8-10 November 2017, Barcelona, Spain A study to understand the acceptance of DICOM Structured Reports on Breast Imaging Liliana Tribunaa*, Augusto Silvab, Pedro SÃ¡ Coutoc, Luis BastiÃ£od a Department of Radiology, Hospital da Luz, Aveiro, Portugal bDETI/IEETA, University of Aveiro, Portugal cCIDMA/DMAT, University of Aveiro, Portugal dBMD Software, Lda. Portugal Abstract Purpose: To create a Digital Imaging and Communication in Medicine Structured Reports (DICOM-SR) Repository and compare the acceptance of Free Text (FT) versus Structured Reports (SR) in communication of Breast Imaging findings. Materials and Methods: It was conceptualized the MamoCatalogue to the structuring of the Reports and the SR were converted into DICOM-SR and integrated with Dicoogle. After that, seven representative Breast Imaging Reports were selected and evaluated by a group of 25 Physicians. Each Physician evaluated the seven Reports, in FT and SR with a 3 months timelag, about their, Structure, Clarity and assertiveness, Diagnostic/Recommendations, Easiness of reading, Full reading, Partially reading with Breast Imaging Reporting and Data System (BI-RADS) focus and Ambiguity. Results: A DICOM-SR Repository was created and the assessment of the acceptance of the FT vs. SR revealed that there is a global trend favoring FT. Nevertheless, a group wise analysis revealed that for Gynaecologists and General Practitioners (GP) the differences between FT and SR weren't significant, unlike what happens with Radiologists. Conclusion: The DICOM-SR Repository allows the query/retrieve data for Reports and the communication with Gynaecologists and GP by SR was satisfactory. Although, Radiologists acceptance must be reinforced upon global communication and management strategy. Â© 2017 The Authors. Published by Elsevier B.V. * Corresponding author. Tel.: +0-000-000-0000 ; fax: +0-000-000-0000 . E-mail address: lilianatribuna@ua.pt 2 L Tribuna et al. / Procedia Computer Science 00 (2017) 000â€“000 Peer-review under responsibility of the scientific committee of the CENTERIS - International Conference on ENTERprise Information Systems / ProjMAN - International Conference on Project MANagement / HCist - International Conference on Health and Social Care Information Systems and Technologies. Keywords: Breast cancer; Free Text; Structured Reports; DICOM Structured Reports. 1. Introduction The incidence of Breast Cancer has been increasing over the past 20 years and its diagnosis has been performed in increasingly young patients 1. Demographic trends estimate a continuous increase of the values mentioned above, therefore early diagnosis and the optimization of the treatment are fundamental elements for the reduction of mortality rate and the increased of survival of patients with Breast Cancer 1, 2, 3. The Imaging Examinations play a fundamental role in the diagnosis and prognosis of this pathology 1, and the effective communication of Imaging findings is a crucial element in the diagnostic by imaging, and to promote the best patient care and support for the requesting Physician 4. Since the beginning of time, Reports could take one of two forms, Free Text (FT) or Structured Reports (SR) 5. In 2000 the Digital Imaging and Communications in Medicine - Structured Reports (DICOM-SR) was published and defined the data structure for the construction of a SR in DICOM format 6. Thus, due to the potential of this type of documents, particularly in the area of the Breast Imaging, this article describes the concept of a DICOM-SR Repository in Breast Imaging, where it is possible to search, query and analyse data and, in addition, compares the acceptance of Radiologists and non-Radiologists by FT versus SR, in the reporting of Breast Imaging findings. 2. Background 2.1. Radiology Reports The FT, used in the majority of the cases, usually does not have an explicit reporting structure and its methodology of writing is based on the Radiologists professional experience, which can result in narratives extremely subjective evaluations 6. The reduction of this variability should be promoted, because the Standard Reports will facilitate the understanding of these documents by the requesting Physicians 7. On the other hand, the SR present their organized contents in a clear and organized form, based on Templates or Checklists and three essential properties are recognized: structured format, consistent organization and standardized language 8. This type of report has the purpose of implementing the concept of standardization of the Clinical Reports and to promote their continuous improvement 9, promising to increase the consistency of the Report, increase the productivity of the Radiologists and improve the communication of the results with the requesting Physicians 7 , 10. With consistent format and terminology, the SR allow recovery and analysis of information from the Report, both by humans and by Information Systems (IS), in order to support the medical research, the clinical decision, to support the Quality Improvement (QI) processes, and, also, to evaluate inherent characteristics to the Reports 7 , 11. The successful implementation of SR is a difficult task, because it is dependent on the Radiologists acceptance. 674 Liliana Tribuna et al. / Procedia Computer Science 121 (2017) 672â€“680 L Tribuna et al. / Procedia Computer Science 00 (2017) 000â€“000 3 2.2. DICOM-SR The Digital Imaging and Communications in Medicine (DICOM) standard proposes a set of rules for coding, storage and transfer of medical information and ensured the interoperability between the various entities of the Picture Archiving and Communication System (PACS), regardless of the equipment and manufacturer type that, otherwise, would be incompatible 12. Given its potentiality, an extension of the same was published, that aims the implementation of SR in DICOM format, defining the constitution of objects that encode the information of Clinical Reports, as well as their relationships 13. The DICOM-SR files have a Header, which encodes the information of the patient and study identification, and the Content Tree, responsible for the coding of the Report itself. The latter has the information elements hierarchically connected, in a tree model, identifying the Sources and Targets Nodes and their relationships (Figure 1). Each element of information has a name and a value, forming the pairs Name-Value 13, 14, 15. The DICOM-SR are defined for sharing, viewing and storing of SR, allowing the increase of the accuracy and value of Clinical Reports. There are many inherent benefits to this type of documents, highlighting the best communication with the requesting Physician, to obtain more precise diagnostics, greatest speed and less fatigue in the Report, consistent identification information, archive support, transfer and/or simultaneous manipulation with the target object of report and the possibility of relevant referencing, through hyperlinks 15. In addition, the use of this type of Reports allows the execution of data mining actions to the Reports database 12. The DICOM-SR has developed the SR Templates, defining several standard structures of application 14, and the Breast Imaging Report Templates define the structure and the coding for a Report of Breast Images 16. The DICOM- SR Part 16: Content Mapping Resource describes the DICOM terminology used throughout its Templates 17, specifying the DICOM Content Mapping Resource (DMCR), which defines the terminology by the integration of multiple Lexicons and their value assignment for representation in DICOM format 18. 2.3. PACS The concept of PACS consists of a set of subsystems for the image acquisition and digital information, storage and visualization, integrated by digital networks and appropriate software 19. It was developed in order to respond to the high needs for storage and transmission of medical information in clinical institutions 20. The PACS uses the DICOM standard, however a common problem is the fact that the Imaging study be stored in this system and their Reports are to be managed by the Radiology Information System (RIS) or Hospital Information System (HIS). Delegating the management and storage of the Imaging Reports to the PACS, using the DICOM-SR can be the solution 21. The Dicoogle is an open-source PACS, which is distinguished from the others systems to possess a more agile mechanism for indexing and recovery, allowing the indexing of any type of document. Thus, adding all the others DICOM metadata, the Dicoogle can automatically remove, index, and store all metadata discovered in the Header DICOM, including the private DICOM attribute tags, with no need for reconfiguration and/or re-engineers 22. Figure 1 â€“ Diagrams of SR trees 14. 4 L Tribuna et al. / Procedia Computer Science 00 (2017) 000â€“000 3. Materials and Methods The research was conducted in Hospital da Luz Aveiro and consisted of two stages, the first in the creation of the Repository DICOM-SR and the second in the evaluation of the communication of Breast Imaging findings of the FT versus SR. In Figure 2, we present the flowchart of research actions, with the several undertaken steps, for better understanding. The first phase was initiated with the mapping of all possible fields in the Mammography and Breast Ultrasound Reports. This mapping was based on Breast Imaging Report Templates of standard DICOM and in DICOM terminology, with help of the European Medical Information Framework Catalogue (EMIF Catalogue). The EMIF Catalogue allows users, create their own database fingerprint, to create an appropriate form to its database23. In our case, it enabled the creation of a form with all the components (all the issues, as well as all the possible answers) that should be in the Report of Mammography and/or Breast Ultrasound. The form was created in an Excel document and it was later imported into the online EMIF Catalogue platform, which allowed the introduction of SR of Mammography and/or Breast Ultrasound, constituting the MamoCatalogue (Figure 3). These SR were later converted into the DICOM-SR format, with help of the tool wildcard2cmd-sr, developed by Matos et al. 24 and, subsequently integrated into the Dicoogle â€“ PACS open source. In the second phase a sample of 25 Physicians was gathered, from the specialties of Radiology, Gynaecology/Obstetrics and General Practioners (GP). The sample collected beheld the specialties of Gynaecology/Obstetrics and GP, for these are the responsible for the requisition of a large part of the Breast Imaging Examinations and, the specialty of Radiology, because Radiologists are responsible for the preparation of Imaging Reports. The sample was submitted to two different moments of evaluation, as suggested by Barbosa et al. 6 and Johnson et al. 9, first with the analysis of the FT and after at least 3 months, with the evaluation of the same Reports in the SR format. The selection of the Reports for analysis was performed in the following way: seven reports were defined for appreciation, because they are seven categories of classification Breast Imaging Reporting and Data System (BI-RADS) 25; we opted for examining a report from each one of the categories BI-RADS, for these are closely Figure 2 - Flowchart of research actions. Figure 3 - Interface of the MamoCatalogue. Available in Liliana Tribuna et al. / Procedia Computer Science 121 (2017) 672â€“680 675 L Tribuna et al. / Procedia Computer Science 00 (2017) 000â€“000 3 2.2. DICOM-SR The Digital Imaging and Communications in Medicine (DICOM) standard proposes a set of rules for coding, storage and transfer of medical information and ensured the interoperability between the various entities of the Picture Archiving and Communication System (PACS), regardless of the equipment and manufacturer type that, otherwise, would be incompatible 12. Given its potentiality, an extension of the same was published, that aims the implementation of SR in DICOM format, defining the constitution of objects that encode the information of Clinical Reports, as well as their relationships 13. The DICOM-SR files have a Header, which encodes the information of the patient and study identification, and the Content Tree, responsible for the coding of the Report itself. The latter has the information elements hierarchically connected, in a tree model, identifying the Sources and Targets Nodes and their relationships (Figure 1). Each element of information has a name and a value, forming the pairs Name-Value 13, 14, 15. The DICOM-SR are defined for sharing, viewing and storing of SR, allowing the increase of the accuracy and value of Clinical Reports. There are many inherent benefits to this type of documents, highlighting the best communication with the requesting Physician, to obtain more precise diagnostics, greatest speed and less fatigue in the Report, consistent identification information, archive support, transfer and/or simultaneous manipulation with the target object of report and the possibility of relevant referencing, through hyperlinks 15. In addition, the use of this type of Reports allows the execution of data mining actions to the Reports database 12. The DICOM-SR has developed the SR Templates, defining several standard structures of application 14, and the Breast Imaging Report Templates define the structure and the coding for a Report of Breast Images 16. The DICOM- SR Part 16: Content Mapping Resource describes the DICOM terminology used throughout its Templates 17, specifying the DICOM Content Mapping Resource (DMCR), which defines the terminology by the integration of multiple Lexicons and their value assignment for representation in DICOM format 18. 2.3. PACS The concept of PACS consists of a set of subsystems for the image acquisition and digital information, storage and visualization, integrated by digital networks and appropriate software 19. It was developed in order to respond to the high needs for storage and transmission of medical information in clinical institutions 20. The PACS uses the DICOM standard, however a common problem is the fact that the Imaging study be stored in this system and their Reports are to be managed by the Radiology Information System (RIS) or Hospital Information System (HIS). Delegating the management and storage of the Imaging Reports to the PACS, using the DICOM-SR can be the solution 21. The Dicoogle is an open-source PACS, which is distinguished from the others systems to possess a more agile mechanism for indexing and recovery, allowing the indexing of any type of document. Thus, adding all the others DICOM metadata, the Dicoogle can automatically remove, index, and store all metadata discovered in the Header DICOM, including the private DICOM attribute tags, with no need for reconfiguration and/or re-engineers 22. Figure 1 â€“ Diagrams of SR trees 14. 4 L Tribuna et al. / Procedia Computer Science 00 (2017) 000â€“000 3. Materials and Methods The research was conducted in Hospital da Luz Aveiro and consisted of two stages, the first in the creation of the Repository DICOM-SR and the second in the evaluation of the communication of Breast Imaging findings of the FT versus SR. In Figure 2, we present the flowchart of research actions, with the several undertaken steps, for better understanding. The first phase was initiated with the mapping of all possible fields in the Mammography and Breast Ultrasound Reports. This mapping was based on Breast Imaging Report Templates of standard DICOM and in DICOM terminology, with help of the European Medical Information Framework Catalogue (EMIF Catalogue). The EMIF Catalogue allows users, create their own database fingerprint, to create an appropriate form to its database23. In our case, it enabled the creation of a form with all the components (all the issues, as well as all the possible answers) that should be in the Report of Mammography and/or Breast Ultrasound. The form was created in an Excel document and it was later imported into the online EMIF Catalogue platform, which allowed the introduction of SR of Mammography and/or Breast Ultrasound, constituting the MamoCatalogue (Figure 3). These SR were later converted into the DICOM-SR format, with help of the tool wildcard2cmd-sr, developed by Matos et al. 24 and, subsequently integrated into the Dicoogle â€“ PACS open source. In the second phase a sample of 25 Physicians was gathered, from the specialties of Radiology, Gynaecology/Obstetrics and General Practioners (GP). The sample collected beheld the specialties of Gynaecology/Obstetrics and GP, for these are the responsible for the requisition of a large part of the Breast Imaging Examinations and, the specialty of Radiology, because Radiologists are responsible for the preparation of Imaging Reports. The sample was submitted to two different moments of evaluation, as suggested by Barbosa et al. 6 and Johnson et al. 9, first with the analysis of the FT and after at least 3 months, with the evaluation of the same Reports in the SR format. The selection of the Reports for analysis was performed in the following way: seven reports were defined for appreciation, because they are seven categories of classification Breast Imaging Reporting and Data System (BI-RADS) 25; we opted for examining a report from each one of the categories BI-RADS, for these are closely Figure 2 - Flowchart of research actions. Figure 3 - Interface of the MamoCatalogue. Available in 676 Liliana Tribuna et al. / Procedia Computer Science 121 (2017) 672â€“680 L Tribuna et al. / Procedia Computer Science 00 (2017) 000â€“000 5 related to the degree of abnormality in the examination and, therefore, with the descriptions of the Imaging findings 26; the selected Report was drawn randomly, within a set of possible Reports. For the data collection performed in the second phase of the research a Questionnaire (Figure 4) was used, which composed of two distinct parts and for closed answer 27. The first part of the Questionnaire concerns the analysis of the FT and, in addition to the demographic data, is constituted by a block of seven questions, which should be answered for each of the examined Reports. The second part is identical to the previous one, however concerning the SR. The demographic data selected will characterize the sample and were the following: Age, Gender, Specialty and Years of service. The issues that formed the body of the Questionnaire were based on the literature concerning good practice in the Imaging Reports and the pros and cons of the FT and SR, and were as follows: Structure7, Clarity and assertiveness7, Diagnostic/ Recommendations4, Easiness of reading7, Full reading28, Partially reading with BI- RADS focus28, and Ambiguity 6. The first four issues were listed on the 5-point satisfaction Likert scale, as Marcovici et al. used in their research29 and assumed values of Not satisfied (1) to Totally satisfied (5). The remaining issues, of binary nature, were answered in the Affirmative or Negative 30. 4. Results As a result of the first phase of the investigation, the MamoCatalogue was created, an online platform that enables the creation, file and research of SR. In this platform it is possible to enter Mammography and/or Breast Ultrasound Reports, in Portuguese, using the DICOM terminology. The users, in order to make the report, go through the form and, using the checklist, will respond to the issues they consider applicable, by selecting the appropriate responses. Text boxes are available in all issues, allowing the Radiologists to complement their answers, or, if they are not satisfied with the terminology, use the FT. In addition to multiple choices answers, there are also issues of data type, Yes/No type and numerical type. The MamoCatalogue is available in for authorized users and already has 51 SR of Mammography and/or Breast Ultrasound. Subsequently, the SR were exported from MamoCatalogue in CSV format and converted, through the wildcard2cmd-SR tool, for the DICOM- SR format and finally integrated with the Dicoogle, conceptualising the DICOM-SR Repository. The construed DICOM-SR documents were, thus, stored in Dicoogle, being able to perform researches (Figure 5) and queries to the documents, by setting the desired attributes. The images corresponding to each DICOM-SR may also be stored in Dicoogle, allowing the visualization of Report and Images simultaneously and on the same workstation. In a system of this type, the file, handling and management of Reports and Images is carried out jointly. Figure 4 - Questionnaire used as evaluation instrument. Figure 5 â€“ Illustrative figure of a research conducted to the DICOM-SR integrated with the Dicoogle, with the attribute â€œPatientSex:Mâ€�. 6 L Tribuna et al. / Procedia Computer Science 00 (2017) 000â€“000 In the second phase of the investigation, 28 % of the respondents had a specialty of Radiology (n=7, Age=41,3 Â± 6,2), 36% of Gynaecology/Obstetrics (n=9, Age=50,6 Â± 12,1) and 36% of GP (n=9, Age=60,4 Â± 8,8). The Physicians questioned had on mean Â± standard deviation (SD) Â± 13.2 years of service. Based on the analysis of the Table 1, there is a global trend favouring the FT at the expense of the SR, for Structure, Clarity and Assertiveness variables, Diagnostic/ Recommendations and Easiness of Reading, revealing the considerable differences tested (p value < 0.05). The Physicians are, on mean (SD), 3,93 (0,86) satisfied with the Structure of the FT and 3,21(0,98) with the SR, the Clarity and Assertiveness was listed with on mean (SD) of 3,96 (0,80) for the FT and 3,39 (1,03) for the SR, and the Diagnosis / Recommendations obtained a satisfaction mean (SD) of 4,04 (0,83) for the FT and 3,50 (0,94) for the SR. However, the same cannot be verified when the FT vs. SR differences are tested for each of the medical specialties. For Gynaecology/Obstetrics, although the tendency for the FT, the measured differences FT vs. SR were not significant for any of the variables under study (Table 2) and, the same occurs for the group of GP (Table 3). Otherwise, it was in the Radiology speciality (Table 4) that significant differences were found, in particular for the variables Report Structure, Clarity and assertiveness and Diagnosis and recommendations. FT SR Differences Mean (SD) Mean (SD) P value Structure 3,93 (0,86) 3,21 (0,98) 0,71 (0,98) 0,001 Clarity and assertiveness 3,96 (0,80) 3,39 (1,03) 0,57 (1,01) 0,010 Diagnostic / Recommendations 4,04 (0,83) 3,50 (0,94) 0,54 (0,97) 0,011 Easiness of reading 3,97 (0,84) 3,42 (0,98) 0,55 (0,99) 0,011 Ratio of evaluated answers with YES P value Full reading 0,97 0,87 0,044 Partially reading with BIRADS focus 0,21 0,19 0,812 Ambiguity 0,17 0,31 0,012 FT SR Differences Mean (SD) Mean (SD) P value Structure 3,78 (0,83) 2,99 (0,97) 0, 879 (1,15) 0,0751 Clarity and assertiveness 3,89 (0,70) 3,43 (0,90) 0,46 (0,99) 0,1552 Diagnostic / Recommendations 3,85 (0,78) 3,41 (0,92) 0,43 (1,03) 0,2332 Easiness of reading 3,83 (0,79) 2,99 (0,87) 0,51 (0,97) 0,106 2 Ratio of evaluated answers with YES P value Full Reading 0, 98 0,83 0,051 Partially reading with BIRADS focus 0,17 0,11 0,673 Ambiguity 0,19 0,33 0,160 1 â€“ Paired sample t test 2 â€“ wilcoxon signed rank test FT SR Differences Mean (SD) Mean (SD) P value Structure 4,13 (0,90) 3,71 (1,10) 0,41 (0,74) 0,131 Clarity and assertiveness 4,06 (0,90) 3,71 (1,37) 0,35 (1,08) 0,362 Diagnostic / Recommendations 4,14 (1,00) 3,81 (1,23) 0,33 (0,92) 0,317 Easiness of reading 4,19 (0,86) 3,81 (1,28) 0,38 (0,94) 0,258 Ratio of evaluated answers with YES P value Full reading 0,94 0,97 0,681 Partially reading with BIRADS focus 0,29 0,27 0,908 Ambiguity 0,14 0,27 0,283 Table 1 - Comparison of the global results FT vs. SR. Table 4 - FT vs. SR â€“ specialty of Radiology. Table 2 - FT vs. SR â€“ specialty of Gynaecology/Obstetrics Table 3 - FT vs. SR â€“ specialty of GP. Liliana Tribuna et al. / Procedia Computer Science 121 (2017) 672â€“680 677 L Tribuna et al. / Procedia Computer Science 00 (2017) 000â€“000 5 related to the degree of abnormality in the examination and, therefore, with the descriptions of the Imaging findings 26; the selected Report was drawn randomly, within a set of possible Reports. For the data collection performed in the second phase of the research a Questionnaire (Figure 4) was used, which composed of two distinct parts and for closed answer 27. The first part of the Questionnaire concerns the analysis of the FT and, in addition to the demographic data, is constituted by a block of seven questions, which should be answered for each of the examined Reports. The second part is identical to the previous one, however concerning the SR. The demographic data selected will characterize the sample and were the following: Age, Gender, Specialty and Years of service. The issues that formed the body of the Questionnaire were based on the literature concerning good practice in the Imaging Reports and the pros and cons of the FT and SR, and were as follows: Structure7, Clarity and assertiveness7, Diagnostic/ Recommendations4, Easiness of reading7, Full reading28, Partially reading with BI- RADS focus28, and Ambiguity 6. The first four issues were listed on the 5-point satisfaction Likert scale, as Marcovici et al. used in their research29 and assumed values of Not satisfied (1) to Totally satisfied (5). The remaining issues, of binary nature, were answered in the Affirmative or Negative 30. 4. Results As a result of the first phase of the investigation, the MamoCatalogue was created, an online platform that enables the creation, file and research of SR. In this platform it is possible to enter Mammography and/or Breast Ultrasound Reports, in Portuguese, using the DICOM terminology. The users, in order to make the report, go through the form and, using the checklist, will respond to the issues they consider applicable, by selecting the appropriate responses. Text boxes are available in all issues, allowing the Radiologists to complement their answers, or, if they are not satisfied with the terminology, use the FT. In addition to multiple choices answers, there are also issues of data type, Yes/No type and numerical type. The MamoCatalogue is available in for authorized users and already has 51 SR of Mammography and/or Breast Ultrasound. Subsequently, the SR were exported from MamoCatalogue in CSV format and converted, through the wildcard2cmd-SR tool, for the DICOM- SR format and finally integrated with the Dicoogle, conceptualising the DICOM-SR Repository. The construed DICOM-SR documents were, thus, stored in Dicoogle, being able to perform researches (Figure 5) and queries to the documents, by setting the desired attributes. The images corresponding to each DICOM-SR may also be stored in Dicoogle, allowing the visualization of Report and Images simultaneously and on the same workstation. In a system of this type, the file, handling and management of Reports and Images is carried out jointly. Figure 4 - Questionnaire used as evaluation instrument. Figure 5 â€“ Illustrative figure of a research conducted to the DICOM-SR integrated with the Dicoogle, with the attribute â€œPatientSex:Mâ€�. 6 L Tribuna et al. / Procedia Computer Science 00 (2017) 000â€“000 In the second phase of the investigation, 28 % of the respondents had a specialty of Radiology (n=7, Age=41,3 Â± 6,2), 36% of Gynaecology/Obstetrics (n=9, Age=50,6 Â± 12,1) and 36% of GP (n=9, Age=60,4 Â± 8,8). The Physicians questioned had on mean Â± standard deviation (SD) Â± 13.2 years of service. Based on the analysis of the Table 1, there is a global trend favouring the FT at the expense of the SR, for Structure, Clarity and Assertiveness variables, Diagnostic/ Recommendations and Easiness of Reading, revealing the considerable differences tested (p value < 0.05). The Physicians are, on mean (SD), 3,93 (0,86) satisfied with the Structure of the FT and 3,21(0,98) with the SR, the Clarity and Assertiveness was listed with on mean (SD) of 3,96 (0,80) for the FT and 3,39 (1,03) for the SR, and the Diagnosis / Recommendations obtained a satisfaction mean (SD) of 4,04 (0,83) for the FT and 3,50 (0,94) for the SR. However, the same cannot be verified when the FT vs. SR differences are tested for each of the medical specialties. For Gynaecology/Obstetrics, although the tendency for the FT, the measured differences FT vs. SR were not significant for any of the variables under study (Table 2) and, the same occurs for the group of GP (Table 3). Otherwise, it was in the Radiology speciality (Table 4) that significant differences were found, in particular for the variables Report Structure, Clarity and assertiveness and Diagnosis and recommendations. FT SR Differences Mean (SD) Mean (SD) P value Structure 3,93 (0,86) 3,21 (0,98) 0,71 (0,98) 0,001 Clarity and assertiveness 3,96 (0,80) 3,39 (1,03) 0,57 (1,01) 0,010 Diagnostic / Recommendations 4,04 (0,83) 3,50 (0,94) 0,54 (0,97) 0,011 Easiness of reading 3,97 (0,84) 3,42 (0,98) 0,55 (0,99) 0,011 Ratio of evaluated answers with YES P value Full reading 0,97 0,87 0,044 Partially reading with BIRADS focus 0,21 0,19 0,812 Ambiguity 0,17 0,31 0,012 FT SR Differences Mean (SD) Mean (SD) P value Structure 3,78 (0,83) 2,99 (0,97) 0, 879 (1,15) 0,0751 Clarity and assertiveness 3,89 (0,70) 3,43 (0,90) 0,46 (0,99) 0,1552 Diagnostic / Recommendations 3,85 (0,78) 3,41 (0,92) 0,43 (1,03) 0,2332 Easiness of reading 3,83 (0,79) 2,99 (0,87) 0,51 (0,97) 0,106 2 Ratio of evaluated answers with YES P value Full Reading 0, 98 0,83 0,051 Partially reading with BIRADS focus 0,17 0,11 0,673 Ambiguity 0,19 0,33 0,160 1 â€“ Paired sample t test 2 â€“ wilcoxon signed rank test FT SR Differences Mean (SD) Mean (SD) P value Structure 4,13 (0,90) 3,71 (1,10) 0,41 (0,74) 0,131 Clarity and assertiveness 4,06 (0,90) 3,71 (1,37) 0,35 (1,08) 0,362 Diagnostic / Recommendations 4,14 (1,00) 3,81 (1,23) 0,33 (0,92) 0,317 Easiness of reading 4,19 (0,86) 3,81 (1,28) 0,38 (0,94) 0,258 Ratio of evaluated answers with YES P value Full reading 0,94 0,97 0,681 Partially reading with BIRADS focus 0,29 0,27 0,908 Ambiguity 0,14 0,27 0,283 Table 1 - Comparison of the global results FT vs. SR. Table 4 - FT vs. SR â€“ specialty of Radiology. Table 2 - FT vs. SR â€“ specialty of Gynaecology/Obstetrics Table 3 - FT vs. SR â€“ specialty of GP. 678 Liliana Tribuna et al. / Procedia Computer Science 121 (2017) 672â€“680 L Tribuna et al. / Procedia Computer Science 00 (2017) 000â€“000 7 The interaction results between the Specialities and Type of Report were non-significant, meaning that the response patterns were identical (FT scores were higher than SR scores) for all the variables presented. Despite differences between FT vs. SR scores were significant only for the Radiologists. The influences of Age and Years of Service in the Results were non-significant. 5. Discussion For the execution of the research a mechanism for structuring Mammography and/or Breast Ultrasound Reports was developed, in the first instance and with the help of the EMIF Catalogue, which in the likeness to the developed by Johnson et al. 9 itâ€™s characterized by having section headers, consistent order of observations and terms for report reproduced from a controlled Lexicon, in our case the DICOM terminology. The integration of the Reports under this mechanism led to the creation of MamoCatalogue, where the introduction of the SR is performed according to the mechanism of checklist, which, as recommended by Marcovici et al. 29, allows the Radiologist is more focused on the important aspects of the images. 51 SR were introduced in the MamoCatalogue, that, a posteriori, were converted into DICOM-SR and integrated with the Dicoogle resulting in a DICOM-SR Repository, in line with the data bases developed in Wangenheim quetsche et al. 31, GarcÃ­a et al. 32 and Margolies et al. 33 investigations. The integration with the Dicoogle allowed the visualization of the Imaging study as a whole, watching Images and Reports on the same workstation, as described by Noumeir 15 and it allowed the realisation of query and retrieve operations to the data base. In addition, it is possible to study or withdraw elations of the population by statistical analysis operations. The constituted DICOM-SR Repository is the beginning of a data base, which once stronger, with the insertion of more studies in the context of the Breast Imaging, can play an important role in the areas of teaching, research and clinical decision support, making possible operations of data mining, as documented by Garcia et al. 34 and Margolies et al.33. In sensitive areas, as it is the case of Breast Cancer, in which early detections, effective screening and optimization of treatments have direct effects on the survival of patients 1, 2, 3 these systems take on a particular relevance for the specialists in the areas of treatment, teaching and scientific research, leading to optimization of the care for these patients32. The related data to the DICOM-SR can be used, not only in the improvement of the Imaging Reports, but also in the monitoring of critical and unexpected results and operations of correlation35, where the optimization techniques, detection and screening of Breast Cancer are optimized33. The acceptance of the Radiologists and non-Radiologists by FT vs. SR was evaluated by implementing a Questionnaire that allowed evaluating the degree of satisfaction of Physicians regarding various aspects of the FT and SR. This analysis revealed divided opinions about the SR. Schwartz et al.36 demonstrate in their study means of satisfaction of Clarity, which differ from those of this research. In the other hand, Johnson et al.9 showed a decrease in the accuracy and integrity of the SR compared with the FT in its research, corroborating the results in discussion. The trend by the FT can arise from excessive simplification of the SR in the reporting of complex cases and the rigidity inherent to the SR, as described in the study by Faggioni et al.37. The statistical analysis performed by medical specialty does not demonstrate a trend so evident by the FT and, effectively, statistically significant differences are not found between the means of FT vs. SR satisfaction for the specialties of Gynaecology/Obstetrics and GP. Therefore, the communication of Results through the SR, between Radiologists and requesting Physicians (Gynaecology/Obstetrics and GP), is performed successfully. The opposite occurs with the Radiologists. Krupinski et al.38 report that the Radiologists are most opposed to the non-traditional Reports, claiming that they never used the Reports and expressing its displeasure. In the Barbosa et al. investigation6, 66.7% of the Radiologists just preferred the SR if adjustments to the reports were made. The dissatisfaction of the FT SR Differences Mean (SD) Mean (SD) P value Structure 3,86 (0,91) 2,84 (0,59) 1,02 (1,05) 0,042 Clarity and assertiveness 3,92 (0,90) 2,94 (0,50) 0,98 (0,97) 0,037 Diagnostic / Recommendations 4,16 (0,71) 3,22 (0,39) 0,94 (0,99) 0,045 Easiness of reading 3,86 (0,91) 2,84 (0,59) 1,02 (1,05) 0,042 Ratio of evaluated answers with YES P value Full reading 1,00 0,80 0,082 Partially reading with BIRADS focus 0,16 0,20 0,569 Ambiguity 0,16 0,34 0,078 8 L Tribuna et al. / Procedia Computer Science 00 (2017) 000â€“000 Radiologists by the SR may be explained by the fear that they have to lose their professional autonomy and freedom with the inclusion of these documents in professional practice, as concluded Faggioni et al. 37 and Bosmans et al.28. In view of the obtained results on the acceptance of Physicians by the SR, strategies should be implemented for the acceptance of the same, especially with the Radiologists. These strategies can be, by involving the Radiologists in the creating process of the Templates as suggested by Faggioni et al.37 and conducted by Garcia et al.33. In addition, it is important that the implementation of the SR will always be an ongoing process7 and, to the majority of the surveyed professionals, this was the first contact with the SR. During the research, some limitations were identified such as the manual process and something long inherent to the structure of the Reports with the MamoCatalogue and the heterogeneity of the sample, both in the number of Radiologists (28%) vs. non-Radiologists (72%), which is not in the same ratio, as in the age of surveyed. 6. Conclusion This work implemented a DICOM-SR Repository, which is characterized as a searchable universe, where it is possible to study, consult and recover quickly data. This Repository may represent the beginning of a database in the area of Breast Imaging, where it is possible storing imaging studies and their Reports and conducting query and retrieve operations, including Imaging Reports, impractical tasks so far with traditional FT systems. The Physicians evaluation of FT vs. SR showed that for the Gynaecology/Obstetrics and GP specialties the differences between the FT vs. SR are not significant, allowing to conclude a good acceptance of the SR by these professionals and a satisfactory communication of Results. The opposite occurs with Radiologists, who still are the most satisfied with the Structure, Diagnosis and FT Recommendations and considerer these Reports clearer and more assertive than SR. Thus, improvements should be promoted to the SR, with the Radiologists involvement, and acceptance strategies should be developed to these documents, particularly among Radiology specialists, promoting the global communication in the Medical community and the optimization of patients healthcare. Acknowledgements This work was partly supported by EU/EFPIA Innovative Medicines Initiative Joint Undertaking (EMIF grant nÂ° 115372). References 1. Li H, Zhang S, Wang Q ZR. Clinical value of mammography in diagnosis and identification of breast mass.Pak J Med Sci.2016;32(4):1020â€“5. 2. Perry N, Broeders M, de Wolf C, TÃ¶rnberg S, Holland R, von Karsa L. European guidelines for quality assurance in breast cancer screening and diagnosis. Fourth edition--summary document. Vol. 19, Annals of oncologyâ€¯: official journal of the European Society for Medical Oncology / ESMO. 2008. 614-622 p. 3. Bulu H, Alpkocak A, Balci P. Uncertainty modeling for ontology-based mammography annotation with intelligent BI-RADS scoring. Vol. 43, Computers in Biology and Medicine. 2013. p. 301â€“11. 4. Guideline a CRP, Guideline a CRP. Acr practice guideline for communication of diagnostic imaging findings. Diagn Imaging. 2005;1076(Revised 2008):3â€“8. 5. Reiner BI, Knight N, Siegel EL. Radiology Reporting, Past, Present, and Future: The Radiologistâ€™s Perspective. J Am Coll Radiol. 2007;4(5):313â€“9. 6. Barbosa F, Maria L, Maciel Z, Vieira EM, Paulo M, Marques DA, et al. Clinical Science Radiological Reportsâ€¯: A comparation between the tranmission Efficiency of information in Free Text and in Structured Reports. Clinics. 2010;65(1):15â€“21. 7. Society E. Good practice for radiological reporting. Guidelines from the European Society of Radiology (ESR). Insights Imaging. 2011;2(2):93â€“ 6. 8. Weiss DL, Langlotz CP. Structured reporting: patient care enhancement or productivity nightmare? Radiology. 2008;249(3):739â€“47. 9. Johnson a. J, Chen MYM, Swan JS, Applegate KE, Littenberg B. Cohort Study of Structured Reporting Compared with Conventional Dictation. Radiology. 2009;253(1):74â€“80. 10. Larson DB, Towbin AJ, Pryor RM, Donnelly LF. Improving consistency in radiology reporting through the use of department-wide standardized structured reporting. Radiology [Internet]. 2013;267(1):240â€“50. Available from: 11. Kahn CE, Langlotz CP, Burnside ES, Carrino J a, Channin DS, Hovsepian DM, et al. Toward best practices in radiology reporting. Radiology. 2009;252(3):852â€“6. 12. Wang KC, Kohli M, Carrino JA. Technology Standards in Imagingâ€¯: A Practical Overview. J Am Coll Radiol. 2014;1251â€“9. 13. Clunie D a. DICOM structured reporting and cancer clinical trials results. Cancer Inform. 2007;4:33â€“56. Liliana Tribuna et al. / Procedia Computer Science 121 (2017) 672â€“680 679 L Tribuna et al. / Procedia Computer Science 00 (2017) 000â€“000 7 The interaction results between the Specialities and Type of Report were non-significant, meaning that the response patterns were identical (FT scores were higher than SR scores) for all the variables presented. Despite differences between FT vs. SR scores were significant only for the Radiologists. The influences of Age and Years of Service in the Results were non-significant. 5. Discussion For the execution of the research a mechanism for structuring Mammography and/or Breast Ultrasound Reports was developed, in the first instance and with the help of the EMIF Catalogue, which in the likeness to the developed by Johnson et al. 9 itâ€™s characterized by having section headers, consistent order of observations and terms for report reproduced from a controlled Lexicon, in our case the DICOM terminology. The integration of the Reports under this mechanism led to the creation of MamoCatalogue, where the introduction of the SR is performed according to the mechanism of checklist, which, as recommended by Marcovici et al. 29, allows the Radiologist is more focused on the important aspects of the images. 51 SR were introduced in the MamoCatalogue, that, a posteriori, were converted into DICOM-SR and integrated with the Dicoogle resulting in a DICOM-SR Repository, in line with the data bases developed in Wangenheim quetsche et al. 31, GarcÃ­a et al. 32 and Margolies et al. 33 investigations. The integration with the Dicoogle allowed the visualization of the Imaging study as a whole, watching Images and Reports on the same workstation, as described by Noumeir 15 and it allowed the realisation of query and retrieve operations to the data base. In addition, it is possible to study or withdraw elations of the population by statistical analysis operations. The constituted DICOM-SR Repository is the beginning of a data base, which once stronger, with the insertion of more studies in the context of the Breast Imaging, can play an important role in the areas of teaching, research and clinical decision support, making possible operations of data mining, as documented by Garcia et al. 34 and Margolies et al.33. In sensitive areas, as it is the case of Breast Cancer, in which early detections, effective screening and optimization of treatments have direct effects on the survival of patients 1, 2, 3 these systems take on a particular relevance for the specialists in the areas of treatment, teaching and scientific research, leading to optimization of the care for these patients32. The related data to the DICOM-SR can be used, not only in the improvement of the Imaging Reports, but also in the monitoring of critical and unexpected results and operations of correlation35, where the optimization techniques, detection and screening of Breast Cancer are optimized33. The acceptance of the Radiologists and non-Radiologists by FT vs. SR was evaluated by implementing a Questionnaire that allowed evaluating the degree of satisfaction of Physicians regarding various aspects of the FT and SR. This analysis revealed divided opinions about the SR. Schwartz et al.36 demonstrate in their study means of satisfaction of Clarity, which differ from those of this research. In the other hand, Johnson et al.9 showed a decrease in the accuracy and integrity of the SR compared with the FT in its research, corroborating the results in discussion. The trend by the FT can arise from excessive simplification of the SR in the reporting of complex cases and the rigidity inherent to the SR, as described in the study by Faggioni et al.37. The statistical analysis performed by medical specialty does not demonstrate a trend so evident by the FT and, effectively, statistically significant differences are not found between the means of FT vs. SR satisfaction for the specialties of Gynaecology/Obstetrics and GP. Therefore, the communication of Results through the SR, between Radiologists and requesting Physicians (Gynaecology/Obstetrics and GP), is performed successfully. The opposite occurs with the Radiologists. Krupinski et al.38 report that the Radiologists are most opposed to the non-traditional Reports, claiming that they never used the Reports and expressing its displeasure. In the Barbosa et al. investigation6, 66.7% of the Radiologists just preferred the SR if adjustments to the reports were made. The dissatisfaction of the FT SR Differences Mean (SD) Mean (SD) P value Structure 3,86 (0,91) 2,84 (0,59) 1,02 (1,05) 0,042 Clarity and assertiveness 3,92 (0,90) 2,94 (0,50) 0,98 (0,97) 0,037 Diagnostic / Recommendations 4,16 (0,71) 3,22 (0,39) 0,94 (0,99) 0,045 Easiness of reading 3,86 (0,91) 2,84 (0,59) 1,02 (1,05) 0,042 Ratio of evaluated answers with YES P value Full reading 1,00 0,80 0,082 Partially reading with BIRADS focus 0,16 0,20 0,569 Ambiguity 0,16 0,34 0,078 8 L Tribuna et al. / Procedia Computer Science 00 (2017) 000â€“000 Radiologists by the SR may be explained by the fear that they have to lose their professional autonomy and freedom with the inclusion of these documents in professional practice, as concluded Faggioni et al. 37 and Bosmans et al.28. In view of the obtained results on the acceptance of Physicians by the SR, strategies should be implemented for the acceptance of the same, especially with the Radiologists. These strategies can be, by involving the Radiologists in the creating process of the Templates as suggested by Faggioni et al.37 and conducted by Garcia et al.33. In addition, it is important that the implementation of the SR will always be an ongoing process7 and, to the majority of the surveyed professionals, this was the first contact with the SR. During the research, some limitations were identified such as the manual process and something long inherent to the structure of the Reports with the MamoCatalogue and the heterogeneity of the sample, both in the number of Radiologists (28%) vs. non-Radiologists (72%), which is not in the same ratio, as in the age of surveyed. 6. Conclusion This work implemented a DICOM-SR Repository, which is characterized as a searchable universe, where it is possible to study, consult and recover quickly data. This Repository may represent the beginning of a database in the area of Breast Imaging, where it is possible storing imaging studies and their Reports and conducting query and retrieve operations, including Imaging Reports, impractical tasks so far with traditional FT systems. The Physicians evaluation of FT vs. SR showed that for the Gynaecology/Obstetrics and GP specialties the differences between the FT vs. SR are not significant, allowing to conclude a good acceptance of the SR by these professionals and a satisfactory communication of Results. The opposite occurs with Radiologists, who still are the most satisfied with the Structure, Diagnosis and FT Recommendations and considerer these Reports clearer and more assertive than SR. Thus, improvements should be promoted to the SR, with the Radiologists involvement, and acceptance strategies should be developed to these documents, particularly among Radiology specialists, promoting the global communication in the Medical community and the optimization of patients healthcare. Acknowledgements This work was partly supported by EU/EFPIA Innovative Medicines Initiative Joint Undertaking (EMIF grant nÂ° 115372). References 1. Li H, Zhang S, Wang Q ZR. Clinical value of mammography in diagnosis and identification of breast mass.Pak J Med Sci.2016;32(4):1020â€“5. 2. Perry N, Broeders M, de Wolf C, TÃ¶rnberg S, Holland R, von Karsa L. European guidelines for quality assurance in breast cancer screening and diagnosis. Fourth edition--summary document. Vol. 19, Annals of oncologyâ€¯: official journal of the European Society for Medical Oncology / ESMO. 2008. 614-622 p. 3. Bulu H, Alpkocak A, Balci P. Uncertainty modeling for ontology-based mammography annotation with intelligent BI-RADS scoring. Vol. 43, Computers in Biology and Medicine. 2013. p. 301â€“11. 4. Guideline a CRP, Guideline a CRP. Acr practice guideline for communication of diagnostic imaging findings. Diagn Imaging. 2005;1076(Revised 2008):3â€“8. 5. Reiner BI, Knight N, Siegel EL. Radiology Reporting, Past, Present, and Future: The Radiologistâ€™s Perspective. J Am Coll Radiol. 2007;4(5):313â€“9. 6. Barbosa F, Maria L, Maciel Z, Vieira EM, Paulo M, Marques DA, et al. Clinical Science Radiological Reportsâ€¯: A comparation between the tranmission Efficiency of information in Free Text and in Structured Reports. Clinics. 2010;65(1):15â€“21. 7. Society E. Good practice for radiological reporting. Guidelines from the European Society of Radiology (ESR). Insights Imaging. 2011;2(2):93â€“ 6. 8. Weiss DL, Langlotz CP. Structured reporting: patient care enhancement or productivity nightmare? Radiology. 2008;249(3):739â€“47. 9. Johnson a. J, Chen MYM, Swan JS, Applegate KE, Littenberg B. Cohort Study of Structured Reporting Compared with Conventional Dictation. Radiology. 2009;253(1):74â€“80. 10. Larson DB, Towbin AJ, Pryor RM, Donnelly LF. Improving consistency in radiology reporting through the use of department-wide standardized structured reporting. Radiology [Internet]. 2013;267(1):240â€“50. Available from: 11. Kahn CE, Langlotz CP, Burnside ES, Carrino J a, Channin DS, Hovsepian DM, et al. Toward best practices in radiology reporting. Radiology. 2009;252(3):852â€“6. 12. Wang KC, Kohli M, Carrino JA. Technology Standards in Imagingâ€¯: A Practical Overview. J Am Coll Radiol. 2014;1251â€“9. 13. Clunie D a. DICOM structured reporting and cancer clinical trials results. Cancer Inform. 2007;4:33â€“56. 680 Liliana Tribuna et al. / Procedia Computer Science 121 (2017) 672â€“680 L Tribuna et al. / Procedia Computer Science 00 (2017) 000â€“000 9 14. Hussein R, Engelmann U, Schroeter A, Meinzer H-P. DICOM structured reporting: Part 1. Overview and characteristics. Radiographics. 2004;24(3):891â€“6. 15. Noumeir R. Benefits of the DICOM structured report. J Digit Imaging. 2006;19(4):295â€“306. 16. DICOM Standards Committee. Breast Imaging Report Templates [Internet]. dicom.nema.org. 2014. Available from: 17. Kahn CE, Langlotz CP, Channin DS, Rubin DL. Informatics in radiology: an information model of the DICOM standard. Radiographics. 2011;31(1):295â€“304. 18. Medical Imaging & Technology Alliance - a division of NEMA. DICOM Part 16: Content Mapping Resource [Internet]. NEMA. 2016. Available from: 19. Huang HK. PACS ans Imaging Informatics: Basic Principles and Applications. New Jersey: John Wiley & Sons, Inc; 2004. 175-187 p. 20. Valente F, Costa C, Silva A. Dicoogle, a Pacs Featuring Profiled Content Based Image Retrieval. PLoS One. 2013;8(5). 21. Matos P, Bastiao LA, Marques T. A Dynamic Approach to Support Interoperability for Medical Reports Using DICOM SR. 2016;0. 22. Costa C, Ferreira C, BastiÃ£o L. Dicoogle - an Open Source Peer-to-Peer PACS. J Digit Imaging. 2011;848â€“56. 23. BastiÃ£o LA, DÃ­as C, Lei J Van Der, Luis J. Architecture to summarize patient-level data across borders and countries. 24. Matos P, Bastiao LA, Marques T. A Dynamic Approach to Support Interoperability for Medical Reports Using DICOM SR. IOS Press. 2016;0. 25. Sickles, EA, Dâ€™Orsi CJ, Bassett LW E Al. ACR BI-RADSÂ® Mammography. ACR BI-RADSÂ® Atlas, Breast Imaging Report Data Syst. 2013;121â€“40. 26. Bi-rads ACR, Ultrasound B. Breast imaging reporting and data system (BI-RADS) Atlas- Ultrasound 5th edn. Am Coll Radiol. 2013;121â€“32. 27. Reis F. Como Elabobar uma DissertaÃ§Ã£o de Mestrado Segundo Bolonha. 2a EdiÃ§Ã£o. Pactor, editor. 2010. 91-106 p. 28. Bosmans JML, Peremans L, Menni M, de Schepper AM, Duyck PO, Parizel PM. Structured reporting: If, why, when, how-and at what expense? Results of a focus group meeting of radiology professionals from eight countries. Insights Imaging. 2012;3(3):295â€“302. 29. Marcovici PA, Taylor GA. Journal Club: Structured radiology reports are more complete and more effective than unstructured reports. AJR Am J Roentgenol. 2014;203(6):1265â€“71. 30. Hamburg M, Young P. Statistical Analysis for Decision Making. Six editio. Press TD, editor. Harcourt Brace College Publishers; 1994. 2,3, 319, 335-354, 646-651. 31. von Wangenheim A, Barcellos CL, Andrade R, de Carlos Back Giuliano I, Borgatto AF, de Andrade DF. Implementing DICOM structured reporting in a large-scale telemedicine network. Telemed J E Health [Internet]. 2013;19(7):535â€“41. Available from: 32. GarcÃ­a RM, Serrano ET, Quilis JDS, Espert IB, BonmatÃ­ LM, Cubells DA. A Systematic Approach for Using DICOM Structured Reports in Clinical Processesâ€¯: Focus on Breast Cancer. 2015;132â€“45. 33. Margolies LR, Pandey G, Horowitz ER, Mendelson DS. Breast Imaging in the Era of Big Data: Structured Reporting and Data Mining. AJR Am J Roentgenol. 2016;206(2):259â€“64. 34. Medina GarcÃ­a R, Torres Serrano E, Segrelles Quilis JD, Blanquer Espert I, MartÃ­ BonmatÃ­ L, Almenar Cubells D. A Systematic Approach for Using DICOM Structured Reports in Clinical Processes: Focus on Breast Cancer. J Digit Imaging [Internet]. 2015;28(2):132â€“45. Available from: 35. Morgan TA, Helibrun ME. Reporting Initiative of the Radiological Society of North Americaâ€¯: Progress and New. 2014;273(3). 36. Schwartz LH, Panicek DM, Berk AR. Improving Communication of through Structured Reporting. 2011;260(1). 37. Faggioni L, Coppola F, Ferrari R, Neri E, Regge D. Usage of structured reporting in radiological practice: results from an Italian online survey. Eur Radiol [Internet]. 2016; Available from: 38. Krupinski EA, Hall ET, Jaw S, Reiner B, Siegel E. Influence of radiology report format on reading time and comprehension. J Digit Imaging. 2012;25(1):63â€“9. nefits of the DICOM structured report. J Digit Imaging. 2006;19(4):295â€“306. 16. DICOM Standards Committee. Breast Imaging Report Templates [Internet]. dicom.nema.org. 2014. Available from: 17. Kahn CE, Langlotz CP, Channin DS, Rubin DL. Informatics in radiology: an information model of the DICOM standard. Radiographics. 2011;31(1):295â€“304. 18. Medical Imaging & Technology Alliance - a division of NEMA. DICOM Part 16: Content Mapping Resource [Internet]. NEMA. 2016. Available from: 19. Huang HK. PACS ans Imaging Informatics: Basic Principles and Applications. New Jersey: John Wiley & Sons, Inc; 2004. 175-187 p. 20. Valente F, Costa C, Silva A. Dicoogle, a Pacs Featuring Profiled Content Based Image Retrieval. PLoS One. 2013;8(5). 21. Matos P, Bastiao LA, Marques T. A Dynamic Approach to Support PROCS 12005 S1877-0509(17)32288-3 10.1016/j.procs.2017.11.088 A study to understand the acceptance of DICOM Structured Reports on Breast Imaging Liliana Tribuna a Augusto Silva b Pedro Sá Couto c Luis Bastião d a Department of Radiology, Hospital da Luz, Aveiro, Portugal Department of Radiology Hospital da Luz Aveiro Portugal b DETI/IEETA, University of Aveiro, Portugal DETI/IEETA University of Aveiro Portugal c CIDMA/DMAT, University of Aveiro, Portugal CIDMA/DMAT University of Aveiro Portugal d BMD Software, Lda. Portugal BMD Software Lda. Portugal Purpose: To create a Digital Imaging and Communication in Medicine Structured Reports (DICOM-SR) Repository and compare the acceptance of Free Text (FT) versus Structured Reports (SR) in communication of Breast Imaging findings. Materials and Methods: It was conceptualized the MamoCatalogue to the structuring of the Reports and the SR were converted into DICOM-SR and integrated with Dicoogle. After that, seven representative Breast Imaging Reports were selected and evaluated by a group of 25 Physicians. Each Physician evaluated the seven Reports, in FT and SR with a 3 months timelag, about their, Structure, Clarity and assertiveness, Diagnostic/Recommendations, Easiness of reading, Full reading, Partially reading with Breast Imaging Reporting and Data System (BI-RADS) focus and Ambiguity. Results: A DICOM-SR Repository was created and the assessment of the acceptance of the FT vs. SR revealed that there is a global trend favoring FT. Nevertheless, a group wise analysis revealed that for Gynaecologists and General Practitioners (GP) the differences between FT and SR weren’t significant, unlike what happens with Radiologists. Conclusion: The DICOM-SR Repository allows the query/retrieve data for Reports and the communication with Gynaecologists and GP by SR was satisfactory. Although, Radiologists acceptance must be reinforced upon global communication and management strategy. Keywords Breast cancer Free Text Structured Reports DICOM Structured Reports References 1 H Li S Zhang QZR Wang Clinical value of mammography in diagnosis and identification of breast mass Pak J Med Sci. 32 4 2016 1020 1025 2 Perry N, Broeders M, de Wolf C, Törnberg S, Holland R, von Karsa L. European guidelines for quality assurance in breast cancer screening and diagnosis. Fourth edition--summary document. Vol. 19, Annals of oncology : official journal of the European Society for Medical Oncology/ESMO. 2008. 614-622 p. 3 Bulu H, Alpkocak A, Balci P. Uncertainty modeling for ontology-based mammography annotation with intelligent BI-RADS scoring. Vol. 43, Computers in Biology and Medicine. 2013. p. 301–11. 4 ACRP Guideline CRP Guideline A Acr practice guideline for communication of diagnostic imaging findings Diagn Imaging. 1076 Revised 2008 2005 3 8 5 BI Reiner N Knight EL Siegel Radiology Reporting, Past, Present, and Future: The Radiologist’s Perspective J Am Coll Radiol. 4 5 2007 313 319 6 F Barbosa L Maria Z Maciel EM Vieira M Paulo DA Marques Clinical Science Radiological Reports : A comparation between the tranmission Efficiency of information in Free Text and in Structured Reports Clinics. 65 1 2010 15 21 7 E Society Good practice for radiological reporting Guidelines from the European Society of Radiology (ESR). Insights Imaging. 2 2 2011 93 96 8 DL Weiss CP Langlotz Structured reporting: patient care enhancement or productivity nightmare? Radiology. 249 3 2008 739 747 9 A.J. Johnson MYM Chen JS Swan KE Applegate B Littenberg Cohort Study of Structured Reporting Compared with Conventional Dictation Radiology. 253 1 2009 74 80 10 Larson DB, Towbin AJ, Pryor RM, Donnelly LF. Improving consistency in radiology reporting through the use of department-wide standardized structured reporting. Radiology [Internet]. 2013;267(1):240–50. Available from: 11 CE Kahn CP Langlotz ES Burnside JA Carrino DS Channin DM Hovsepian Toward best practices in radiology reporting Radiology. 252 3 2009 852 856 12 KC Wang M Kohli JA Carrino Technology Standards in Imaging : A Practical Overview J Am Coll Radiol. 2014 1251 1259 13 DA Clunie DICOM structured reporting and cancer clinical trials results Cancer Inform. 4 2007 33 56 14 R Hussein U Engelmann A Schroeter H-P Meinzer DICOM structured reporting: Part 1 Overview and characteristics. Radiographics. 24 3 2004 891 896 15 R Noumeir Benefits of the DICOM structured report J Digit Imaging. 19 4 2006 295 306 16 DICOM Standards Committee. Breast Imaging Report Templates [Internet]. dicom.nema.org. 2014. Available from: 17 CE Kahn CP Langlotz DS Channin DL Rubin Informatics in radiology: an information model of the DICOM standard Radiographics. 31 1 2011 295 304 18 Medical Imaging & Technology Alliance - a division of NEMA. DICOM Part 16: Content Mapping Resource [Internet]. NEMA. 2016. Available from: 19 HK Huang PACS ans Imaging Informatics: Basic Principles and Applications. 2004 John Wiley & Sons, Inc; 175 187 20 Valente F, Costa C, Silva A. Dicoogle, a Pacs Featuring Profiled Content Based Image Retrieval. PLoS One. 2013;8(5). 21 Matos P, Bastiao LA, Marques T. A Dynamic Approach to Support Interoperability for Medical Reports Using DICOM SR. 2016;0. 22 C Costa C Ferreira L Bastião Dicoogle - an Open Source Peer-to-Peer PACS J Digit Imaging. 2011 848 856 23 Bastião LA, Días C, Lei J Van Der, Luis J. Architecture to summarize patient-level data across borders and countries. 24 P Matos LA Bastiao T Marques A Dynamic Approach to Support Interoperability for Medical Reports Using DICOM SR. 2016 IOS Press 0 25 EA Sickles CJ D’Orsi LW Bassett E Al ACR BI-RADS® Mammography ACR BI-RADS® Atlas, Breast Imaging Report Data Syst. 2013 121 140 26 ACR Bi-rads B Ultrasound Breast imaging reporting and data system (BI-RADS) Atlas- Ultrasound 5th edn Am Coll Radiol. 2013 121 132 27 Reis F. Como Elabobar uma Dissertação de Mestrado Segundo Bolonha. 2a Edição. Pactor, editor. 2010. 91-106 p. 28 JML Bosmans L Peremans M Menni AM de Schepper PO Duyck PM Parizel Structured reporting: If, why, when, how-and at what expense? Results of a focus group meeting of radiology professionals from eight countries Insights Imaging. 3 3 2012 295 302 29 PA Marcovici GA Taylor Journal Club: Structured radiology reports are more complete and more effective than unstructured reports AJR Am J Roentgenol. 203 6 2014 1265 1271 30 Hamburg M, Young P. Statistical Analysis for Decision Making. Six editio. Press TD, editor. Harcourt Brace College Publishers; 1994. 2,3, 319, 335-354, 646-651. 31 von Wangenheim A, Barcellos CL, Andrade R, de Carlos Back Giuliano I, Borgatto AF, de Andrade DF. Implementing DICOM structured reporting in a large-scale telemedicine network. Telemed J E Health [Internet]. 2013;19(7):535–41. Available from: 32 RM García ET Serrano JDS Quilis IB Espert LM Bonmatí DA Cubells A Systematic Approach for Using DICOM Structured Reports in Clinical Processes  Focus on Breast Cancer 2015 132 145 33 LR Margolies G Pandey ER Horowitz DS Mendelson Breast Imaging in the Era of Big Data: Structured Reporting and Data Mining AJR Am J Roentgenol. 206 2 2016 259 264 34 Medina García R, Torres Serrano E, Segrelles Quilis JD, Blanquer Espert I, Martí Bonmatí L, Almenar Cubells D. A Systematic Approach for Using DICOM Structured Reports in Clinical Processes: Focus on Breast Cancer. J Digit Imaging [Internet]. 2015;28(2):132–45. Available from: 35 TA Morgan ME Helibrun Reporting Initiative of the Radiological Society of North America  Progress and New 273 3 2014 36 LH Schwartz DM Panicek AR Berk Improving Communication of through Structured Reporting. 260 1 2011 37 Faggioni L, Coppola F, Ferrari R, Neri E, Regge D. Usage of structured reporting in radiological practice: results from an Italian online survey. Eur Radiol [Internet]. 2016; Available from: 38 EA Krupinski ET Hall S Jaw B Reiner E Siegel Influence of radiology report format on reading time and comprehension J Digit Imaging. 25 1 2012 63 69 "
    },
    {
        "doc_title": "Characterization of the stakeholders of medical imaging based on an image repository",
        "doc_scopus_id": "85018575978",
        "doc_doi": "10.1007/978-3-319-56538-5_81",
        "doc_eid": "2-s2.0-85018575978",
        "doc_date": "2017-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Control and Systems Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2207"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Digital imaging and communication in medicines",
            "Image repository",
            "Imaging modality",
            "Information quality",
            "Medium size"
        ],
        "doc_abstract": "© Springer International Publishing AG 2017.Background: The optimization of the performance of medical imaging departments should be supported by the quality of the available information, namely the characterization of the involved stakeholders. Objective: The study reported in this paper aimed to assess the quality of Digital Imaging and Communication in Medicine (DICOM) metadata related to the characterization of the stakeholders of medical imaging, particularly in terms of the availability of the attributes and their usage trends. Methods: The authors analysed the DICOM metadata related to all the imaging studies carried out by all medical imaging modalities and stored in the PACS of a medium size hospital during one year period (i.e. 5153870 images, corresponding to 97612 studies performed on 61256 patients). Results: It was identified a considerable variation in terms of the number of DICOM attributes available for each medical imaging modality (between 10 and 20), and how these attributes are used to characterize medical imaging stakeholders. Conclusion: A better use of DICOM metadata can be achieved, namely to characterize the stakeholders of medical imaging and to promote the communication between them.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "DICOM Metadata Analysis for Population Characterization: A Feasibility Study",
        "doc_scopus_id": "85006857526",
        "doc_doi": "10.1016/j.procs.2016.09.169",
        "doc_eid": "2-s2.0-85006857526",
        "doc_date": "2016-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Clinical environments",
            "Computed radiography",
            "Feasibility studies",
            "Picture archiving and communication systems (PACS)",
            "Radiographic studies",
            "Radiology departments",
            "Resources utilizations",
            "Software applications"
        ],
        "doc_abstract": "© 2016 The Authors.In clinical environments the information resulting from the provision of healthcare is increasingly used to improve the delivery of healthcare. In the radiology context, the data analysis used to characterize the population that accesses different radiology departments is often supported by software applications from different manufacturers, which makes data integration very difficult. And it makes very difficult to characterize, in a centralized manner, the studies performed on each patient. In this context, is there a way to perform population characterization and patient centered studies by analyzing the DICOM metadata stored on Picture Archiving and Communication Systems (PACS) from different healthcare facilities? This paper presents the results of population characterization with chest radiographic studies performed on Computed Radiography (CR) and Digital Radiography (DX) modalities in three healthcare facilities. It also identifies the studies conducted on the patient that, in each healthcare facility, in addition to chest radiographic studies, had a higher number of radiological studies involving ionizing radiation. The final sample consists of 95.433 images, corresponding to 89.980 studies belonging to 56.547 patients. The methodology used made it possible to characterize the population by age group, gender and modality, the average number of studies per patient in each age group, as well as the patient with the highest number of chest radiographic studies per modality in each of the healthcare facilities. The results clearly demonstrate the relevance of the use of DICOM metadata stored in disperse PACS archives for population characterization, as well as to identify resources utilization trends and situations that may represent patient radiation over-exposure.",
        "available": true,
        "clean_text": "serial JL 280203 291210 291871 31 90 Procedia Computer Science PROCEDIACOMPUTERSCIENCE 2016-10-04 2016-10-04 2016-10-04 2016-10-04 2016-10-04T18:39:36 S1877-0509(16)32337-7 S1877050916323377 10.1016/j.procs.2016.09.169 S300 S300.1 HEAD-AND-TAIL 2016-10-04T14:31:54.49151-04:00 0 0 20160101 20161231 2016 2016-10-04T19:31:54.49151Z rawtext articleinfo articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids confeditor contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid hubeid indexeddate issn issnnorm itemstage itemtransactionid itemweight oauserlicense openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sortorder srctitle srctitlenorm srctype ssids alllist content oa subj suppl tomb vol volfirst volissue volumelist yearnav affil articletitle auth authfirstini authfull authkeywords authlast primabst ref 1877-0509 18770509 true 100 100 C Volume 100 45 355 361 355 361 2016 2016 2016-01-01 2016-12-31 2016 International Conference on ENTERprise Information Systems/International Conference on Project MANagement/International Conference on Health and Social Care Information Systems and Technologies, CENTERIS/ProjMAN / HCist 2016 Dr. João Eduardo Quintela Varajão Dr. Maria Manuela Cruz-Cunha Dr. Ricardo Martinho Dr. Rui Rijo Dr. Niels Bjørn-Andersen Dr. Rodney Turner Dr. Domingos Alves article fla © 2016 The Author(s). Published by Elsevier B.V. DICOMMETADATAANALYSISFORPOPULATIONCHARACTERIZATIONAFEASIBILITYSTUDY SANTOS M DEVOE 2011 597 604 J WAGNER 1996 234 244 M VERSCHUUREN 2008 550 551 M HUANG 2010 H PACSIMAGINGINFORMATICSBASICPRINCIPLESAPPLICATIONS TSALAFOUTAS 2011 236 243 I NAGY 2009 1897 1906 P ONDATEGUIPARRA 2004 716 722 S THRALL 2009 133 134 J HILLMAN 2008 689 690 B AMIS 2007 272 284 E TEUNEN 1998 133 D NOL 2006 159 166 J PRIETO 2009 393 399 C SANTOS 2015 651 658 M SANTOSX2016X355 SANTOSX2016X355X361 SANTOSX2016X355XM SANTOSX2016X355X361XM Full 2016-09-17T00:42:14Z ElsevierWaived OA-Window This is an open access article under the CC BY-NC-ND license. © 2016 The Author(s). Published by Elsevier B.V. item S1877-0509(16)32337-7 S1877050916323377 10.1016/j.procs.2016.09.169 280203 2016-10-04T14:31:54.49151-04:00 2016-01-01 2016-12-31 true 256608 MAIN 7 52724 849 656 IMAGE-WEB-PDF 1 Procedia Computer Science 100 ( 2016 ) 355 â€“ 361 Available online at www.sciencedirect.com 1877-0509 Â© 2016 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license Peer-review under responsibility of the organizing committee of CENTERIS 2016 doi: 10.1016/j.procs.2016.09.169 ScienceDirect &RQIHUHQFH RQ (17(5SULVH ,QIRUPDWLRQ 6\\VWHPV ,QWHUQDWLRQDO &RQIHUHQFH RQ 3URMHFW 0$1DJHPHQW &RQIHUHQFH RQ +HDOWK DQG 6RFLDO &DUH ,QIRUPDWLRQ 6\\VWHPV DQG 7HFKQRORJLHV &(17(5,6 3URM0$1 +&LVW 2FWREHU ',&20 0HWDGDWD DQDO\\VLV IRU SRSXODWLRQ FKDUDFWHUL]DWLRQ $ IHDVLELOLW\\ VWXG\\ 0LOWRQ 6DQWRVD E /XLV %DVWLmRF $XJXVWR 6LOYDG E 1HOVRQ 5RFKDH E aHealth Sciences School, University of Aveiro, Aveiro, Portugal, bIEETA, University of Aveiro, Aveiro, Portugal, c BMD software, Lda, Aveiro, Portugal, dDepartment of Electronics, Telecommunications and Informatics, University of Aveiro, Aveiro, Portugal, eHealth Sciences Department, University of Aveiro, Aveiro, Portugal $EVWUDFW ,Q FOLQLFDO HQYLURQPHQWV WKH LQIRUPDWLRQ UHVXOWLQJ IURP WKH SURYLVLRQ RI KHDOWKFDUH LV LQFUHDVLQJO\\ XVHG WR LPSURYH WKH GHOLYHU\\ RI KHDOWKFDUH ,Q WKH UDGLRORJ\\ FRQWH[W WKH GDWD DQDO\\VLV XVHG WR FKDUDFWHUL]H WKH SRSXODWLRQ WKDW DFFHVVHV GLIIHUHQW UDGLRORJ\\ GHSDUWPHQWV LV RIWHQ VXSSRUWHG E\\ VRIWZDUH DSSOLFDWLRQV IURP GLIIHUHQW PDQXIDFWXUHUV ZKLFK PDNHV GDWD LQWHJUDWLRQ YHU\\ GLIILFXOW $QG LW PDNHV YHU\\ GLIILFXOW WR FKDUDFWHUL]H LQ D FHQWUDOL]HG PDQQHU WKH VWXGLHV SHUIRUPHG RQ HDFK SDWLHQW ,Q WKLV FRQWH[W LV WKHUH D ZD\\ WR SHUIRUP SRSXODWLRQ FKDUDFWHUL]DWLRQ DQG SDWLHQW FHQWHUHG VWXGLHV E\\ DQDO\\]LQJ WKH ',&20 PHWDGDWD VWRUHG RQ 3LFWXUH $UFKLYLQJ DQG &RPPXQLFDWLRQ 6\\VWHPV 3$&6 IURP GLIIHUHQW KHDOWKFDUH IDFLOLWLHV\" 7KLV SDSHU SUHVHQWV WKH UHVXOWV RI SRSXODWLRQ FKDUDFWHUL]DWLRQ ZLWK FKHVW UDGLRJUDSKLF VWXGLHV SHUIRUPHG RQ &RPSXWHG 5DGLRJUDSK\\ &5 DQG 'LJLWDO 5DGLRJUDSK\\ '; PRGDOLWLHV LQ WKUHH KHDOWKFDUH IDFLOLWLHV ,W DOVR LGHQWLILHV WKH VWXGLHV FRQGXFWHG RQ WKH SDWLHQW WKDW LQ HDFK KHDOWKFDUH IDFLOLW\\ LQ DGGLWLRQ WR FKHVW UDGLRJUDSKLF VWXGLHV KDG D KLJKHU QXPEHU RI UDGLRORJLFDO VWXGLHV LQYROYLQJ LRQL]LQJ UDGLDWLRQ 7KH ILQDO VDPSOH FRQVLVWV RI LPDJHV FRUUHVSRQGLQJ WR VWXGLHV EHORQJLQJ WR SDWLHQWV 7KH PHWKRGRORJ\\ XVHG PDGH LW SRVVLEOH WR FKDUDFWHUL]H WKH SRSXODWLRQ E\\ DJH JURXS JHQGHU DQG PRGDOLW\\ WKH DYHUDJH QXPEHU RI VWXGLHV SHU SDWLHQW LQ HDFK DJH JURXS DV ZHOO DV WKH SDWLHQW ZLWK WKH KLJKHVW QXPEHU RI FKHVW UDGLRJUDSKLF VWXGLHV SHU PRGDOLW\\ LQ HDFK RI WKH KHDOWKFDUH IDFLOLWLHV 7KH UHVXOWV FOHDUO\\ GHPRQVWUDWH WKH UHOHYDQFH RI WKH XVH RI ',&20 PHWDGDWD VWRUHG LQ GLVSHUVH 3$&6 DUFKLYHV IRU SRSXODWLRQ FKDUDFWHUL]DWLRQ DV ZHOO DV WR LGHQWLI\\ UHVRXUFHV XWLOL]DWLRQ WUHQGV DQG VLWXDWLRQV WKDW PD\\ UHSUHVHQW SDWLHQW UDGLDWLRQ RYHU H[SRVXUH &RUUHVSRQGLQJ DXWKRU 7HO ID[ E-mail address: PUV#XD SW 356 Milton Santos et al. / Procedia Computer Science 100 ( 2016 ) 355 â€“ 361 Â‹ 7KH $XWKRUV 3XEOLVKHG E\\ (OVHYLHU % 9 3HHU UHYLHZ XQGHU UHVSRQVLELOLW\\ RI 6FL.$ $VVRFLDWLRQ IRU 3URPRWLRQ DQG 'LVVHPLQDWLRQ RI 6FLHQWLILF .QRZOHGJH Keywords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Â© 2016 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license Peer-review under responsibility of the organizing committee of CENTERIS 2016 357 Milton Santos et al. / Procedia Computer Science 100 ( 2016 ) 355 â€“ 361 DUH UHODWHG WR SRSXODWLRQ DJLQJ ZKLFK FDXVHV WKH LQFUHDVHG SUHYDOHQFH RI FKURQLF FRQGLWLRQV EXW DUH DOVR UHODWHG ZLWK WHFKQRORJLFDO GHYHORSPHQWV GHIHQVLYH PHGLFLQH LQFUHDVHG QHHG IRU SUHVHQWDWLRQ RI UHVXOWV LQ VKRUWHU WLPHV DQG WKH QHHG WR SHUIRUP D ODUJH QXPEHU RI VWXGLHV 7KHVH DVSHFWV PD\\ EHFRPH UHOHYDQW ZKHQ WKH DQDO\\VLV RI KHDOWKFDUH LV IRFXVHG RQ WKH SDWLHQW ,Q DGGLWLRQ WR WKH VHOHFWLRQ RI H[SRVXUH IDFWRUV DVVRFLDWHG ZLWK WKH SHUIRUPDQFH RI UDGLRORJLFDO VWXGLHV DQRWKHU DVSHFW ZKLFK UHVXOWV LQ DQ LQFUHDVHG H[SRVXUH WR ; UDGLDWLRQ WR ZKLFK D SDWLHQW LV VXEMHFWHG LV WKH QXPEHU RI VWXGLHV FRQGXFWHG E\\ SDWLHQWV GXULQJ WKHLU OLIHWLPH ZKHUHE\\ WKH SDWLHQW V H[SRVXUH WR UDGLDWLRQ PXVW EH PLQLPL]HG ,Q WKLV FRQWH[W LQLWLDWLYHV FDQ EH WDNHQ WR LGHQWLI\\ WKH FDXVH RI UHSHDW UDGLDWLRQ H[SRVXUH ZLWKLQ UDGLRORJLF VWXGLHV 7KH LQIRUPDWLRQ WKDW LV SDUW RI WKH ',&20 PHWDGDWD PD\\ EH UHOHYDQW +RZHYHU WKH FKDUDFWHUL]DWLRQ RI WKH SRSXODWLRQ WKDW LV VXEMHFWHG WR UDGLRORJLFDO VWXGLHV LV RIWHQ FRQGXFWHG XVLQJ 5,6 LQIRUPDWLRQ RU VLPLODU DSSOLFDWLRQV 7KHVH VRIWZDUH VROXWLRQV DUH KLJKO\\ GHSHQGHQW RQ LQIRUPDWLRQ DFFHVV DQG DQDO\\VLV VWUDWHJLHV GHILQHG E\\ WKH +,6 DQG 5,6 PDQXIDFWXUHUV WKDW H[LVW LQ GLIIHUHQW LQVWLWXWLRQV 2Q WKH RWKHU KDQG +,6 DUH VXSSRUWHG E\\ FORVHG DUFKLWHFWXUHV WKDW GR QRW DOORZ WKH XVH RI QRQ SURSULHWDU\\ VRIWZDUH VROXWLRQV IRU DFFHVV H[WUDFWLRQ DQG GDWD DQDO\\VLV 7KLV UHDOLW\\ LV DQ REVWDFOH WR FKDUDFWHUL]LQJ WKH SRSXODWLRQ ZLWK UDGLRORJLFDO VWXGLHV SHUIRUPHG LQ PRUH WKDQ RQH KHDOWK IDFLOLW\\ RU ZKHQ ZH ZDQW WR DQDO\\]H WKH KLVWRU\\ RI LPDJLQJ VWXGLHV SHUIRUPHG RQ WKH SDWLHQWV 7KH ULVH RI QHZ PHWKRGV IRU DFFHVV H[WUDFWLRQ DQG DQDO\\VLV RI ',&20 PHWDGDWD EHORQJLQJ WR UDGLRORJLFDO VWXGLHV VWRUHG LQ PXOWLSOH 3$&6 DUFKLYHV FDQ EH DQ DOWHUQDWLYH ZD\\ WR DQDO\\]H WKH SURYLVLRQ RI UDGLRORJ\\ KHDOWKFDUH LQFOXGLQJ SRSXODWLRQ LQGLYLGXDO LPDJLQJ KLVWRU\\ ,Q WKLV FRQWH[W LV WKHUH D ZD\\ WR SHUIRUP SRSXODWLRQ FKDUDFWHUL]DWLRQ DQG SDWLHQW FHQWHUHG DQDO\\VLV E\\ DQDO\\]LQJ WKH ',&20 PHWDGDWD VWRUHG RQ 3LFWXUH $UFKLYLQJ DQG &RPPXQLFDWLRQ 6\\VWHPV 3$&6 IURP GLIIHUHQW KHDOWKFDUH IDFLOLWLHV\" 7KLV SDSHU SUHVHQWV WKH UHVXOWV RI WKH XVH RI ',&20 PHWDGDWD VWRUHG LQ WKH 3$&6 DUFKLYHV IURP WKUHH LQVWLWXWLRQV WR FKDUDFWHUL]H WKH SRSXODWLRQ ZLWK FKHVW UDGLRJUDSKLF VWXGLHV SHUIRUPHG ZLWK &RPSXWHG 5DGLRJUDSK\\ &5 DQG 'LJLWDO 5DGLRJUDSK\\ '; WKH DYHUDJH QXPEHU RI WKHVH VWXGLHV SHU SDWLHQW DQG SHU DJH JURXS DQG WKH LGHQWLILFDWLRQ RI VLWXDWLRQV WKDW PD\\ UHSUHVHQW D UDGLDWLRQ RYHUH[SRVXUH WKURXJK WKH DQDO\\VLV RI D SDWLHQWÂ�V UDGLDWLRQ H[SRVXUH KLVWRU\\ 0HWKRGV DQG 0DWHULDOV $FFHVV WR ',&20 PHWDGDWD ZDV KHOG LQ WKUHH KHDOWK XQLWV ZLWK GLIIHUHQW KHDOWKFDUH SURILOHV ,Q DOO LQVWLWXWLRQV SHUPLVVLRQ ZDV UHTXHVWHG RI KRVSLWDO DXWKRULWLHV DQG HWKLFV ERDUGV ZLWK DXWKRUL]HG GDWD DFFHVV 7KH GDWD FRQILGHQWLDOLW\\ DV ZHOO DV WKH LGHQWLILFDWLRQ RI KHDOWKFDUH SURIHVVLRQDOV SDWLHQWV DQG HTXLSPHQW PDQXIDFWXUHUV ZDV XSKHOG 7KH ',&20 PHWDGDWD DFFHVV LQGH[LQJ DQG H[SRUWLQJ SURFHVV ZDV DFKLHYHG XVLQJ 'LFRRJOH 7KH VWXGLHV VWRUHG LQ 3$&6 DUFKLYHV IURP WKUHH +HDOWKFDUH )DFLOLWLHV +&)B +&)B DQG +&)B ZHUH DQDO\\]HG )RU WKLV DFFHVV D SHUVRQDO FRPSXWHU ZDV XVHG DW +&)B DQG +&)B ZKLOH DW +&)B 'LFRRJOH ZDV LQVWDOOHG RQ D KHDOWK FDUH IDFLOLW\\ YLUWXDO PDFKLQH )RU WKH DQDO\\VLV RI WKH SRSXODWLRQ ZLWK VWXGLHV VWRUHG LQ 3$&6 DUFKLYHV D VDPSOH RI FKHVW UDGLRJUDSKLF VWXGLHV SHUIRUPHG LQ &5 DQG '; PRGDOLWLHV ZDV REWDLQHG 7KH VHOHFWLRQ RI WKLV VWXG\\ DQG PRGDOLW\\ LV GXH WR WKH IDFW WKDW WKH UDGLRJUDSK\\ RI WKH 7KRUD[ LV DPRQJ WKH PRVW IUHTXHQWO\\ SHUIRUPHG VWXGLHV DW QDWLRQDO DQG DOVR (XURSHDQ OHYHOV )RU WKH VWXGLHV FKDUDFWHUL]DWLRQ TXHULHV ZHUH GHILQHG ZLWK WKH IROORZLQJ ',&20 DWWULEXWHV 0RGDOLW\\ 6WXG\\ 'HVFULSWLRQ 6WXG\\ ,QVWDQFH 8,' 3DWLHQW 1DPH 3DWLHQW ,' 3DWLHQW 6H[ 3DWLHQW %LUWK 'DWH DQG ,QVWLWXWLRQ 1DPH 7KH H[SRUW RI GDWD LQ 06 ([FHO IRUPDW PDGH WKH VWDWLVWLFDO DQDO\\VLV XVLQJ 6WDWLVWLFDO 3DFNDJH IRU 6RFLDO 6FLHQFHV 6366 VRIWZDUH SRVVLEOH 7KH SRSXODWLRQ DQDO\\VLV ZDV SHUIRUPHG LGHQWLI\\LQJ WKH QXPEHU RI SDWLHQWV ZLWK SHUIRUPHG VWXGLHV E\\ DJH JURXS DQG JHQGHU DV ZHOO DV WKH DYHUDJH QXPEHU RI VWXGLHV E\\ SDWLHQW DJH JURXS DQG JHQGHU 7KH DQDO\\VLV RI SDWLHQWÂ�V UDGLDWLRQ H[SRVXUH KLVWRU\\ EHJDQ ZLWK WKH LGHQWLILFDWLRQ RI WKH SDWLHQW WKDW LQ HDFK +&) KDG SHUIRUPHG PRUH WKRUD[ UDGLRJUDSKLF VWXGLHV TXHULHV EDVHG RQ ',&20 DWWULEXWHV 3DWLHQW ,' 6WXG\\ 'HVFULSWLRQ DQG 6WXG\\ ,QVWDQFH 8,' 358 Milton Santos et al. / Procedia Computer Science 100 ( 2016 ) 355 â€“ 361 5HVXOWV 7KH WKUHH 3$&6 DUFKLYHV WRWDO LQGH[LQJ SURFHVV WRRN KRXUV 7KH ILQDO VDPSOH FRQVLVWHG RI ',&20 PHWDGDWD EHORQJLQJ WR FKHVW LPDJHV FRUUHVSRQGLQJ WR VWXGLHV FRQGXFWHG RQ SDWLHQWV 7DEOH 7DEOH 5HVXOWV IURP GH ',&20 PHWDGDWD LQGH[LQJ SURFHVV +HDOWK &DUH )DFLOLW\\ ,QGH[LQJ 7LPH K 3DWLHQWV 0RGDOLW\\ 6WXGLHV ,PDJHV $FWLYLW\\ WLPH ZLWK 3$&6 \\HDUV +&)B &5 +&)B &5 +&)B &5 '; 7RWDO $V FDQ EH VHHQ LQ 7DEOH +&)B KDV D ODUJHU QXPEHU RI VWXGLHV SHUIRUPHG LQ D VKRUWHU WLPH LQWHUYDO 2Q WKH RWKHU KDQG LW LV WKH RQO\\ +&) WKDW KDV WKH '; PRGDOLW\\ ZLWK VWXGLHV DQG KDYLQJ D OHVV QXPEHU RI &5 VWXGLHV 7KH VDPSOH GLVWULEXWLRQ RI FKHVW UDGLRJUDSKLF VWXGLHV FRQGXFWHG LQ WKUHH +&) SHU JHQGHU DJH JURXS DQG PRGDOLW\\ LV VKRZQ LQ )LJ )LJ 1XPEHU RI FKHVW UDGLRJUDSK\\ VWXGLHV SHUIRUPHG DW +&)B +&) B DQG +&) B )LJ VKRZV D KLJK QXPEHU RI VWXGLHV SHUIRUPHG LQ FKLOGUHQ SDUWLFXODUO\\ LQ WKH DJH JURXS IURP WR \\HDUV LQ +&)B ,Q DOO +&) WKHUH LV DQ LQFUHDVLQJ QXPEHU RI VWXGLHV DV WKH DJH LQFUHDVHV EHLQJ PRUH HYLGHQW LQ WKH DJH JURXSV DERYH \\HDUV ,Q WKH DJH JURXSV DERYH \\HDUV ZH KDYH LGHQWLILHG DQ LQFUHDVH LQ WKH DYHUDJH QXPEHU RI VWXGLHV SHU SDWLHQW )LJ 359 Milton Santos et al. / Procedia Computer Science 100 ( 2016 ) 355 â€“ 361 )LJ $YHUDJH QXPEHU RI FKHVW VWXGLHV E\\ SDWLHQW JHQGHU DQG DJH JURXS LQ +&)B +&)B DQG +&)B :H DOVR QRWH WKDW LQ +&) B LQ WKH DJH JURXSV RYHU \\HDUV WKH DYHUDJH QXPEHU RI VWXGLHV SHU SDWLHQW LQFUHDVHV VLJQLILFDQWO\\ ZKHQ FRPSDUHG WR +&) B DQG +&) B ,Q WKH FRQWH[W RI WKH FKDUDFWHUL]DWLRQ RI SDWLHQWÂ�V UDGLDWLRQ H[SRVXUH KLVWRU\\ WKH GDWD SUHVHQWHG LQ 7DEOH VKRZV WKH QXPEHU RI LPDJLQJ VWXGLHV SHUIRUPHG E\\ WKH SDWLHQW WKDW LQ HDFK +&) KDG WKH KLJKHVW QXPEHU RI FKHVW UDGLRJUDSKLF VWXGLHV FDUULHG RXW LQ &5 DQG '; PRGDOLWLHV WKXV WKH WLPH SHULRG EHWZHHQ WKH ILUVW DQG ODWHVW VWXG\\ GDWH $QDO\\]LQJ 7DEOH ZH FDQ VHH WKDW WKH SDWLHQW ZLWK PRUH FKHVW VWXGLHV SHUIRUPHG LQ '; PRGDOLW\\ PDGH VWXGLHV LQYROYLQJ LRQL]LQJ UDGLDWLRQ IRU D SHULRG RI PRQWKV %XW WKH SDWLHQW ZLWK PRUH FKHVW VWXGLHV SHUIRUPHG LQ &5 PRGDOLW\\ PDGH VWXGLHV LQYROYLQJ LRQL]LQJ UDGLDWLRQ RYHU D SHULRG RI DSSUR[LPDWHO\\ VHYHQ PRQWKV ,Q +&)B WKH SDWLHQW ZLWK PRUH FKHVW VWXGLHV LQ &5 PRGDOLW\\ PDGH VWXGLHV LQYROYLQJ LRQL]LQJ UDGLDWLRQ RYHU D SHULRG RI DSSUR[LPDWHO\\ VHYHQ \\HDUV DQG WZR PRQWKV ,Q WKH +&)B WKH SDWLHQW ZLWK PRUH FKHVW VWXGLHV LQ &5 PRGDOLW\\ FDUULHG RXW VWXGLHV LQYROYLQJ LRQL]LQJ UDGLDWLRQ RYHU D SHULRG RI DSSUR[LPDWHO\\ \\HDUV DQG PRQWKV 7DEOH 3DWLHQWÂ�V UDGLDWLRQ H[SRVXUH KLVWRU\\ 3DWLHQWV IURP +&) B +&) B H +&) B +HDOWK &DUH )DFLOLW\\ 3DWLHQW ,' ,QLWLDO TXHU\\ PRGDOLW\\ 3DWLHQW 6H[ 3DWLHQW $JH 6WXG\\ 0RGDOLW\\ 1Âž RI VWXGLHV 7LPH 3HULRG +&)B Â«Â« '; 0 725$; 21( 352-(&7,21 '; WR 725$; 7:2 352-(&7,216 '; +($' &7 &7 7RUD[ &5 5,*+7 *5,' 21( 352-(&7,21 '; /()7 *5,' 21( 352-(&7,21 '; Â« Â« &5 ) 7RUD[ &5 WR +($' &7 &7 725$; &7 &7 725$; &7 +,*+ 5(62/ &7 725$; 7:2 352-(&7,216 '; 725$; 21( 352-(&7,21 '; +&)B Â«Â« &5 ) 725$; 21( 352-(&7,21 &5 WR 6NXOO &5 $%'20(1 21( 352-(&7,21 &5 +HDG &7 &7 +&)B Â« &5 ) 725$; &5 WR 725$; 3$ &5 3(/9,6 &5 )e085 &5 +80(586 &5 ',&20 DWWULEXWH YDOXHV LQ DFFRUGDQFH ZLWK VWRUDJH VWUDWHJ\\ i.e.XVH RI XSSHU DQG ORZHU FDVH 360 Milton Santos et al. / Procedia Computer Science 100 ( 2016 ) 355 â€“ 361 'LVFXVVLRQ 7KH FKHVW UDGLRJUDSKLF VWXGLHV DQDO\\VLV VWRUHG LQ GLIIHUHQW 3$&6 DUFKLYHV KDV VKRZQ WKDW WKH FRQWULEXWLRQ RI HDFK +&) IRU WKH ILQDO VWXGLHV VDPSOH YDULHV DFFRUGLQJ WR WKH KHDOWKFDUH GHOLYHU\\ SURILOH DQG H[LVWLQJ LPDJLQJ PRGDOLWLHV )RU H[DPSOH DW +&)B &5 DQG '; PRGDOLW\\ VWXGLHV ZHUH FDUULHG RXW $W +&)B DQG +&)B DQG WKHUH LV RQO\\ WKH &5 PRGDOLW\\ ,Q WKH SRSXODWLRQ FRQWH[W FKDUDFWHUL]DWLRQ LW ZDV SRVVLEOH WR FKDUDFWHUL]H E\\ JHQGHU DQG DJH JURXS 2Q WKH RWKHU KDQG LW ZDV DOVR SRVVLEOH WR NQRZ WKH QXPEHU RI VWXGLHV E\\ DJH JURXS JHQGHU DQG PRGDOLW\\ ,W ZDV DOVR SRVVLEOH WR LGHQWLI\\ DQ LQFUHDVLQJ QXPEHU RI VWXGLHV DFFRUGLQJ WR WKH DJH GHFUHDVLQJ WR \\RXQJHU DJH JURXSV H[FHSW IRU WKH DJH JURXS IURP WR \\HDUV LQ +&)B +RZHYHU WKH GLIIHUHQFHV LGHQWLILHG LQ GLIIHUHQW +&) VKRXOG EH LQWHUSUHWHG WDNLQJ LQWR DFFRXQW IDFWRUV VXFK DV WKH WLPH SHULRG FRYHUHG RU WKH KHDOWK FDUH GHOLYHU\\ SURILOH RI HDFK +&) e.g. SRSXODWLRQ VHUYLQJ RU H[LVWLQJ PHGLFDO VHUYLFHV )RU H[DPSOH LQ +&)B PRUH WKDQ FKHVW UDGLRJUDSKLF VWXGLHV DUH SHUIRUPHG RQ SDWLHQWV DJHG EHWZHHQ DQG \\HDUV 'HVSLWH WKLV IDFW WKHUH PD\\ EH DVVRFLDWHG ZLWK WKH +&) SURILOH e.g H[LVWHQFH RI 3HGLDWULFV VHUYLFHV D ODUJH QXPEHU RI FKHVW VWXGLHV LQ YHU\\ \\RXQJ SDWLHQWV GHVHUYHV D FORVHU ORRN E\\ KHDOWK SURIHVVLRQDOV QDPHO\\ VHHNLQJ WR LGHQWLI\\ WKH FDXVHV WLPH SHULRGV EHWZHHQ VWXGLHV DQG WKH QXPEHU RI VWXGLHV SHUIRUPHG SHU SDWLHQW :KHQ ZH DQDO\\]H WKH QXPEHU RI VWXGLHV SHUIRUPHG LQ HDFK RI WKH +&) LV LPSRUWDQW WR NQRZ WKDW WKH VWXG\\ VDPSOH LV UHODWHG ZLWK GLIIHUHQW WLPHOLQHV )RU H[DPSOH WKH JUHDWHU QXPEHU RI FKHVW VWXGLHV SHU SDWLHQW LQ HDFK DJH JURXS LQ +&)B LV HYLGHQW )LJ 7KLV DVSHFW FDQ LQIOXHQFH WKH QXPEHU RI VWXGLHV SHUIRUPHG E\\ D SDWLHQW VLQFH WKH JUHDWHU WKH WLPH LQWHUYDO WKH JUHDWHU WKH OLNHOLKRRG RI D SDWLHQW SHUIRUPLQJ LPDJLQJ VWXGLHV SDUWLFXODUO\\ LQ ROGHU DJHV :KHQ DQDO\\]LQJ )LJ ZH LGHQWLI\\ DJH JURXSV ZKHUH WKHUH LV D ODUJHU QXPEHU RI VWXGLHV SHUIRUPHG E\\ SDWLHQWV ZKLFK PD\\ KDYH LPSOLFDWLRQV IRU WKH SDWLHQWÂ�V UDGLDWLRQ H[SRVXUH KLVWRU\\ ,Q WKH OLJKW RI WKH UHVXOWV REWDLQHG LQ WKLV ZRUN DQG WDNLQJ LQWR DFFRXQW WKDW RQH VKRXOG PLQLPL]H H[SRVXUH WR UDGLDWLRQ LQFOXGLQJ PLQLPL]LQJ WKH UHSHWLWLRQ QXPEHU RI LPDJLQJ VWXGLHV LW LV HVVHQWLDO WR LGHQWLI\\ SURFHGXUHV WKDW SURWHFW WKH PRVW YXOQHUDEOH SDWLHQWV IURP WKH ULVNV RI H[FHVVLYH UDGLDWLRQ H[SRVXUH 7KLV FDQ EH DFKLHYHG WKURXJK WKH PRQLWRULQJ RI WKH LQGLYLGXDO SDWLHQWÂ�V UDGLDWLRQ H[SRVXUH KLVWRU\\ 7DEOH VKRZV WKDW LQ WKH FDVH RI +&)B WKH SDWLHQW LGHQWLILHG ZLWK D JUHDWHU QXPEHU RI FKHVW UDGLRJUDSKLF VWXGLHV PDGH UDGLRJUDSKLF VWXGLHV RQ WKLV DQDWRPLFDO UHJLRQ RYHU D SHULRG RI WKUHH \\HDUV DQG IRXU PRQWKV $W +&)B VWXGLHV ZHUH FDUULHG RXW RQ D SDUWLFXODU SDWLHQW RYHU \\HDUV $W +&)B RQH SDWLHQW KHOG VWXGLHV LQFOXGLQJ FKHVW UDGLRJUDSKLF VWXGLHV DQG FKHVW &7 VWXGLHV RYHU DQG D KDOI \\HDUV 7KLV VFHQDULR FRXOG GHVHUYH VSHFLDO DWWHQWLRQ IURP KHDOWK FDUH SURIHVVLRQDOV SDUWLFXODUO\\ LQ WKH WKHUDSHXWLF HIILFLHQF\\ DQDO\\VLV UHVRXUFH RSWLPL]DWLRQ DQG SDWLHQW UDGLDWLRQ SURWHFWLRQ &RQFOXVLRQ DQG )XWXUH :RUN 7KH DQDO\\VLV RI WKH PHWDGDWD ',&20 LPDJLQJ VWXGLHV SHUIRUPHG E\\ D SRSXODWLRQ PDNHV WKHLU FKDUDFWHUL]DWLRQ SRVVLEOH EXW DOVR PDNHV LW SRVVLEOH WR NQRZ WKH VWXGLHV FDVXLVWU\\ LQ D WLPH LQWHUYDO LGHQWLI\\LQJ UHVRXUFH XVDJH WUHQGV DV ZHOO DV VLWXDWLRQV ZKLFK PD\\ UHVXOW IURP D OHVV VXLWDEOH LPDJLQJ VWUDWHJ\\ ,Q WKLV SDSHU DUH SUHVHQWHG WKH UHVXOWV FRQFHUQLQJ D VSHFLILF FDVH VWXG\\ IRU &5 PRGDOLW\\ +RZHYHU LQ IXWXUH ZRUN ZLOO EH LQWHUHVWLQJ WR UHSOLFDWH WKLV DQDO\\VLV ZLWK RWKHU NLQGV RI PRGDOLWLHV LQ D ZLGHU SRSXODWLRQ DQG DQDO\\]H KRZ XVHIXO FRXOG EH IRU WKH PDQDJHU RI WKH KRVSLWDO WR H[SORUH V\\VWHPDWLFDOO\\ WKLV LQIRUPDWLRQ LQ RUGHU WR LGHQWLI\\ RYHUVDWXUDWHG VHUYLFHV $FFHVV WR WKLV LQIRUPDWLRQ PD\\ EH UHOHYDQW WR WKH LGHQWLILFDWLRQ RI VLWXDWLRQV WKDW MXVWLI\\ LPSURYHPHQW DFWLYLWLHV IRU SURYLVLRQ RI KHDOWK FDUH SURFHVVHV RSWLPL]DWLRQ +RZHYHU WKH ',&20 PHWDGDWD DQDO\\VLV SHU VH GRHV QRW DOORZ WKH FKDUDFWHUL]DWLRQ RI DOO FOLQLFDO VLWXDWLRQV DQG UDGLRORJ\\ ZRUN SURFHVVHV QHLWKHU GR HQDEOH XV WR NQRZ WKH UHDVRQ IRU WKH VWXG\\ FRPSOHWLRQ 7KXV IRU IXWXUH ZRUN ZH DQWLFLSDWH WKH UHOHYDQFH RI LQWHJUDWLRQ RI LQIRUPDWLRQ UHVXOWLQJ IURP ',&20 PHWDGDWD DQDO\\VLV ZLWK LQIRUPDWLRQ IURP PHGLFDO UHFRUGV RU LQIRUPDWLRQ SURGXFHG DQG PDGH DYDLODEOH LQ RWKHU +,6 FRQWULEXWLQJ WR (+5 361 Milton Santos et al. / Procedia Computer Science 100 ( 2016 ) 355 â€“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xLJXH] $, $UHYDOR 1 HW DO ,PDJH 5HWDNH $QDO\\VLV LQ 'LJLWDO 5DGLRJUDSK\\ 8VLQJ ',&20 +HDGHU ,QIRUPDWLRQ - 'LJLW ,PDJLQJ 6DQWRV 0 %DVWLmR / &RVWD & 6LOYD $ 5RFKD 1 ',&20 DQG &OLQLFDO 'DWD 0LQLQJ LQ D 6PDOO +RVSLWDO 3$&6 $ 3LORW 6WXG\\ ,Q &UX] &XQKD 0 9DUDMmR - 3RZHOO 3 0DUWLQKR 5 HGLWRUV (17(5SULVH ,QIRUPDWLRQ 6\\VWHPV 6SULQJHU %HUOLQ +HLGHOEHUJ S 6DQWRV 0 %DVWLmR / 1HYHV 1 )UDQFLVFR ' 6LOYD $ 5RFKD 13 ',&20 0HWDGDWD $FFHVV &RQVROLGDWLRQ DQG 8VDJH LQ 5DGLRORJ\\ 'HSDUWPHQW 3HUIRUPDQFH $QDO\\VLV $ 1RQ SURSULHWDU\\ $SSURDFK 3URFHGLD &RPSXWHU 6FLHQFH 6DQWRV 0 )UDQFHVFR 6G 6LOYD /$% 6LOYD $ &RVWD & 5RFKD 1 HGLWRUV 0XOWL YHQGRU ',&20 PHWDGDWD DFFHVV D PXOWL VLWH KRVSLWDO DSSURDFK XVLQJ 'LFRRJOH ,QIRUPDWLRQ 6\\VWHPV DQG 7HFKQRORJLHV &,67, WK ,EHULDQ &RQIHUHQFH RQ - &RVWD & )HUUHLUD & %DVWLmR / 5LEHLUR / 6LOYD $ 2OLYHLUD - 'LFRRJOH DQ 2SHQ 6RXUFH 3HHU WR 3HHU 3$&6 - 'LJLW ,PDJLQJ 6WXG\\ RQ (XURSHDQ 3RSXODWLRQ 'RVHV IURP 0HGLFDO ([SRVXUH 'RVH 'DWDPHG >GDWDEDVH RQ WKH ,QWHUQHW@ +HDOWK 3URWHFWLRQ $JHQF\\ $YDLODEOH IURP KWWS GGPHG HX BPHGLD QHZV GGP BSURMHFWBUHSRUWBSDUWB B BPD\\B BILQDO SGI $FFHVVHG 5HODWyULR 6REUH RV 5HVXOWDGRV GR 3URMHFWR 'RVH 'DWDPHG 3RUWXJDO >GDWDEDVH RQ WKH ,QWHUQHW@ ,QVWLWXWR 7HFQROyJLFR H 1XFOHDU $YDLODEOH IURP KWWS ZZZ LWQ SW SURMV GGP SRUWXJDO 5HODWRULRB'RVHB'DWDPHG B3RUWXJDO SGI $FFHVVHG R - *LVVOHU 0 $VFLDN 53 6DNNHXV / HW DO 7KH (XURSHDQ 'DWD 3URWHFWLRQ /HJLVODWLRQ DQG LWV &RQVHTXHQFHV IRU 3XEOLF +HDOWK 0RQLWRULQJ D 3OHD IRU $FWLRQ 7KH (XURSHDQ -RXUQDO RI 3XEOLF +HDOWK +XDQJ +. 3$&6 DQG ,PDJLQJ ,QIRUPDWLFV %DVLF 3ULQFLSOHV DQG $SSOLFDWLRQV 6HFRQ HG 1HZ -HUVH\\ -RKQ :LOH\\ 6RQV ,QF 0F(YR\\ ) 6YDODVWRJD ( 6HFXULW\\ RI 3DWLHQW DQG 6WXG\\ 'DWD $VVRFLDWHG ZLWK ',&20 ,PDJHV ZKHQ 7UDQVIHUUHG 8VLQJ &RPSDFW 'LVF 0HGLD - 'LJLW ,PDJLQJ 7VDODIRXWDV ,$ 0HWDOOLGLV 6, $ 0HWKRG IRU &DOFXODWLQJ WKH 'RVH /HQJWK 3URGXFW )URP &7 ',&20 ,PDJHV 7KH %ULWLVK -RXUQDO RI 5DGLRORJ\\ 9DQR ( 3DGRYDQL 5 %HUQDUGL * 7HQ -, 3HWHU]RO $ 'RZOLQJ $ HW DO 2Q WKH 8VH RI ',&20 &LQH +HDGHU ,QIRUPDWLRQ IRU 2SWLPLVDWLRQ 5HVXOWV IURP WKH (XURSHDQ ',021' &DUGLRORJ\\ 6XUYH\\ 5DGLDW 3URW 'RVLPHWU\\ 'HFHPEHU 1DJ\\ 3* :DUQRFN 0- 'DO\\ 0 7RODQG & 0HHQDQ &' 0H]ULFK 56 ,QIRUPDWLFV LQ 5DGLRORJ\\ $XWRPDWHG :HE EDVHG *UDSKLFDO 'DVKERDUG IRU 5DGLRORJ\\ 2SHUDWLRQDO %XVLQHVV ,QWHOOLJHQFH 5DGLRJUDSKLFV 1RYHPEHU 2QGDWHJXL 3DUUD 6 %KDJZDW -* =RX .+ *RJDWH $ ,QWULHUH /$ .HOO\\ 3 HW DO 3UDFWLFH 0DQDJHPHQW 3HUIRUPDQFH ,QGLFDWRUV LQ $FDGHPLF 5DGLRORJ\\ 'HSDUWPHQWV 5DGLRORJ\\ 7KUDOO -+ 5DGLDWLRQ ([SRVXUH 3ROLWLFV DQG 2SLQLRQ YV 6FLHQFH DQG 3UDJPDWLVP -RXUQDO RI WKH $PHULFDQ &ROOHJH RI 5DGLRORJ\\ +LOOPDQ %- 5DGLDWLRQ ([SRVXUH DQG ,PDJLQJ 8WLOL]DWLRQ -RXUQDO RI WKH $PHULFDQ &ROOHJH RI 5DGLRORJ\\ $PLV (6 -U %XWOHU 3) $SSOHJDWH .( %LUQEDXP 6% %UDWHPDQ /) +HYH]L -0 HW DO $PHULFDQ &ROOHJH RI 5DGLRORJ\\ :KLWH 3DSHU RQ 5DGLDWLRQ 'RVH LQ 0HGLFLQH -RXUQDO RI WKH $PHULFDQ &ROOHJH RI 5DGLRORJ\\ %XVKRQJ 6& 5DGLRORJLF 6FLHQFH IRU 7HFKQRORJLVWV 3K\\VLFV %LRORJ\\ DQG 3URWHFWLRQ WK HG 6W /RXLV 0RVE\\ 7HXQHQ ' 7KH (XURSHDQ 'LUHFWLYH RQ +HDOWK PROCS 9874 S1877-0509(16)32337-7 10.1016/j.procs.2016.09.169 The Authors ☆ Peer-review under responsibility of the organizing committee of CENTERIS 2016. DICOM Metadata Analysis for Population Characterization: A Feasibility Study Milton Santos a b ⁎ Luis Bastião c Augusto Silva d b Nelson Rocha e b a Health Sciences School, University of Aveiro, Aveiro, Portugal Health Sciences School, University of Aveiro, Aveiro Portugal b IEETA, University of Aveiro, Aveiro, Portugal IEETA, University of Aveiro, Aveiro Portugal c BMD software, Lda, Aveiro, Portugal BMD software, Lda, Aveiro Portugal d Department of Electronics, Telecommunications and Informatics, University of Aveiro, Aveiro, Portugal Department of Electronics, Telecommunications and Informatics, University of Aveiro, Aveiro Portugal e Health Sciences Department, University of Aveiro, Aveiro, Portugal Health Sciences Department, University of Aveiro, Aveiro Portugal ⁎ Corresponding author. Tel.: +351 234 247 110; fax: +351 234401597. In clinical environments the information resulting from the provision of healthcare is increasingly used to improve the delivery of healthcare. In the radiology context, the data analysis used to characterize the population that accesses different radiology departments is often supported by software applications from different manufacturers, which makes data integration very difficult. And it makes very difficult to characterize, in a centralized manner, the studies performed on each patient. In this context, is there a way to perform population characterization and patient centered studies by analyzing the DICOM metadata stored on Picture Archiving and Communication Systems (PACS) from different healthcare facilities? This paper presents the results of population characterization with chest radiographic studies performed on Computed Radiography (CR) and Digital Radiography (DX) modalities in three healthcare facilities. It also identifies the studies conducted on the patient that, in each healthcare facility, in addition to chest radiographic studies, had a higher number of radiological studies involving ionizing radiation. The final sample consists of 95.433 images, corresponding to 89.980 studies belonging to 56.547 patients. The methodology used made it possible to characterize the population by age group, gender and modality, the average number of studies per patient in each age group, as well as the patient with the highest number of chest radiographic studies per modality in each of the healthcare facilities. The results clearly demonstrate the relevance of the use of DICOM metadata stored in disperse PACS archives for population characterization, as well as to identify resources utilization trends and situations that may represent patient radiation over-exposure. Keywords DICOM metadata Radiology Population Characterization References [1] Hasan S, Padman R. Analyzing the Effect of Data Quality on the Accuracy of Clinical Decision Support Systems: A Computer Simulation Approach. CORD Conference Proceedings. 2006:324-8. [2] J.E. DeVoe R. Gold M. Spofford S. Chauvie J. Muench A. Turner Developing a Network of Community Health Centers With a Common Electronic Health Record: Description of the Safety Net West Practice-based Research Network (SNW-PBRN) The Journal of the American Board of Family Medicine 24 5 2011 597 604 [3] M.M. Wagner W.R. Hogan The Accuracy of Medication Data in an Outpatient Electronic Medical Record Journal of the American Medical Informatics Association 3 3 1996 234 244 [4] M. Verschuuren G. Badeyan J. Carnicero M. Gissler R.P. Asciak L. Sakkeus The European Data Protection Legislation and its Consequences for Public Health Monitoring: a Plea for Action The European Journal of Public Health 18 6 2008 550 551 [5] H.K. Huang PACS and Imaging Informatics. Basic Principles and Applications Secon ed. 2010 John Wiley & Sons, Inc New Jersey [6] McEvoy F, Svalastoga E. Security of Patient and Study Data Associated with DICOM Images when Transferred Using Compact Disc Media. J Digit Imaging. 2009 2009/02/01;22(1):65-70. [7] I.A. Tsalafoutas S.I. Metallidis A Method for Calculating the Dose Length Product From CT DICOM Images The British Journal of Radiology 84 999 2011 236 243 [8] Vano E, Padovani R, Bernardi G, Ten JI, Peterzol A, Dowling A, et al. On the Use of DICOM Cine Header Information for Optimisation: Results from the 2002 European DIMOND Cardiology Survey. Radiat Prot Dosimetry. 2005 December 1, 2005; 117(1-3):162-5. [9] P.G. Nagy M.J. Warnock M. Daly C. Toland C.D. Meenan R.S. Mezrich Informatics in Radiology: Automated Web-based Graphical Dashboard for Radiology Operational Business Intelligence1 Radiographics 29 7 2009 1897 1906 2009 November 1 [10] S. Ondategui-Parra J.G. Bhagwat K.H. Zou A. Gogate L.A. Intriere P. Kelly Practice Management Performance Indicators in Academic Radiology Departments1 Radiology. 233 3 2004 716 722 [11] J.H. Thrall Radiation Exposure: Politics and Opinion vs Science and Pragmatism Journal of the American College of Radiology. 6 3 2009 133 134 [12] B.J. Hillman Radiation Exposure and Imaging Utilization Journal of the American College of Radiology. 5 6 2008 689 690 [13] E.S. Amis Jr. P.F. Butler K.E. Applegate S.B. Birnbaum L.F. Brateman J.M. Hevezi American College of Radiology White Paper on Radiation Dose in Medicine Journal of the American College of Radiology. 4 5 2007 272 284 [14] Bushong SC. Radiologic Science for Technologists. Physics, Biology, and Protection. 7th ed. St.Louis: Mosby; 2001. [15] D. Teunen The European Directive on Health Protection of Individuals Against the Dangers of Ionising Radiation in Relation to Medical Exposures (97/43/EURATOM) Journal of Radiological Protection. 18 2 1998 133 [16] J. Nol G. Isouard J. Mirecki Digital Repeat Analysis; Setup and Operation J Digit Imaging. 19 2 2006 159 166 [17] C. Prieto E. Vano J.I. Ten J.M. Fernandez A.I. Iñiguez N. Arevalo Image Retake Analysis in Digital Radiography Using DICOM Header Information J Digit Imaging. 22 4 2009 393 399 [18] Santos M, Bastião L, Costa C, Silva A, Rocha N. DICOM and Clinical Data Mining in a Small Hospital PACS: A Pilot Study. In: Cruz-Cunha M, Varajão J, Powell P, Martinho R, editors. ENTERprise Information Systems: Springer Berlin Heidelberg; 2011. p. 254-63. [19] M. Santos L. Bastião N. Neves D. Francisco A. Silva N.P. Rocha DICOM Metadata Access, Consolidation and Usage in Radiology Department Performance Analysis. A Non-proprietary Approach Procedia Computer Science 64 2015 651 658 [20] Santos M, Francesco Sd, Silva LAB, Silva A, Costa C, Rocha N, editors. Multi vendor DICOM metadata access a multi site hospital approach using Dicoogle. Information Systems and Technologies (CISTI), 2013 8th Iberian Conference on; 2013 19-22 J. [21] Costa C, Ferreira C, Bastião L, Ribeiro L, Silva A, Oliveira J. Dicoogle - an Open Source Peer-to-Peer PACS. J Digit Imaging. 2011;24(5):848-56. [22] Study on European Population Doses from Medical Exposure: Dose Datamed 2 [database on the Internet]. Health Protection Agency. 2014. Available from: Accessed: 2015-01-31. [23] Relatório Sobre os Resultados do Projecto Dose Datamed 2 Portugal [database on the Internet]. Instituto Tecnológico e Nuclear. 2012. Available from: Accessed: 2015-01-31. "
    },
    {
        "doc_title": "DICOM Metadata Access, Consolidation and Usage in Radiology Department Performance Analysis. A Non-proprietary Approach",
        "doc_scopus_id": "84962787127",
        "doc_doi": "10.1016/j.procs.2015.08.579",
        "doc_eid": "2-s2.0-84962787127",
        "doc_date": "2015-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Clinical environments",
            "Efficient analysis",
            "PACS archive",
            "Performance analysis",
            "Production data",
            "Radiology departments"
        ],
        "doc_abstract": "© 2015 The Authors. Published by Elsevier B.V.In a clinical environment are produced on daily basis huge volumes of information. In the radiology context, the realization of an increasing number of studies, in particular those associated with modalities that produce huge amounts of images, has given rise to large PACS archives. Proprietary tools available for the analysis of the stored information are limited and usually do not allow efficient analysis of the radiology department performance. In this work we demonstrate that with seamless access to DICOM metadata we can provide a consolidated view of departmental production data regardless of the heterogeneous imaging sources and subsidiary information systems. With our non-proprietary approach it is therefore feasible to conceive indicators that may be included in wider scope institutional performance evaluation. The results from the consolidated DICOM information analysis of more than 20 million images, belonging to more than 467 thousand studies performed on more than 162 thousand patients, justify the relevance of the implementation of similar methodologies in order to optimize the management of Radiology departments.",
        "available": true,
        "clean_text": "serial JL 280203 291210 291871 31 90 Procedia Computer Science PROCEDIACOMPUTERSCIENCE 2015-09-15 2015-09-15 2015-09-15 2015-09-15 2016-03-16T16:55:20 S1877-0509(15)02714-3 S1877050915027143 10.1016/j.procs.2015.08.579 S300 S300.5 HEAD-AND-TAIL 2016-03-16T13:28:00.421176-04:00 0 0 20150101 20151231 2015 2015-09-15T04:43:01.029579Z rawtext articleinfo articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids confeditor contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid hubeid indexeddate issn issnnorm itemstage itemtransactionid itemweight oauserlicense openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sortorder srctitle srctitlenorm srctype ssids alllist content oa subj suppl tomb vol volfirst volissue volumelist yearnav affil articletitle auth authfirstini authfull authkeywords authlast primabst ref 1877-0509 18770509 true 64 64 C Volume 64 83 651 658 651 658 2015 2015 2015-01-01 2015-12-31 2015 Conference on ENTERprise Information Systems/International Conference on Project MANagement/Conference on Health and Social Care Information Systems and Technologies, CENTERIS/ProjMAN / HCist 2015 October 7-9, 2015 Maria Manuela Cruz-Cunha João Varajão Rui Rijo Ricardo Martinho Petra Schubert Albert Boonstra Ricardo Correia Alexander Berler article fla Copyright © 2015 The Authors. Published by Elsevier B.V. DICOMMETADATAACCESSCONSOLIDATIONUSAGEINRADIOLOGYDEPARTMENTPERFORMANCEANALYSISANONPROPRIETARYAPPROACH SANTOS M SANTOSX2015X651 SANTOSX2015X651X658 SANTOSX2015X651XM SANTOSX2015X651X658XM Full 2015-08-21T00:47:13Z ElsevierWaived OA-Window item S1877-0509(15)02714-3 S1877050915027143 10.1016/j.procs.2015.08.579 280203 2016-03-16T13:28:00.421176-04:00 2015-01-01 2015-12-31 true 440101 MAIN 8 51626 849 656 IMAGE-WEB-PDF 1 Procedia Computer Science 64 ( 2015 ) 651 â€“ 658 Available online at www.sciencedirect.com 1877-0509 Â© 2015 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license Peer-review under responsibility of SciKA - Association for Promotion and Dissemination of Scientific Knowledge doi: 10.1016/j.procs.2015.08.579 ScienceDirect Conference on ENTERprise Information Systems / International Conference on Project MANagement / Conference on Health and Social Care Information Systems and Technologies, CENTERIS / ProjMAN / HCist 2015 October 7-9, 2015 DICOM metadata Access, Consolidation and Usage in Radiology Department Performance Analysis. A non-proprietary approach Milton Santosa,b*, Luis BastiÃ£ob, Nuno Nevesc, Dulce Franciscoc, Augusto Silvab,d, Nelson Pacheco Rochab,e aHealth Sciences School, University of Aveiro, Aveiro, Portugal bIEETA, University of Aveiro, Aveiro, Portugal cCentro Hospitalar do Baixo Vouga, Aveiro, Portugal dDepartment of Electronics, Telecommunications and Informatics, University of Aveiro, Aveiro, Portugal eHealth Sciences Department, University of Aveiro, Aveiro, Portugal Abstract In a clinical environment are produced on daily basis huge volumes of information. In the radiology context, the realization of an increasing number of studies, in particular those associated with modalities that produce huge amounts of images, has given rise to large PACS archives. Proprietary tools available for the analysis of the stored information are limited and usually do not allow efficient analysis of the radiology department performance. In this work we demonstrate that with seamless access to DICOM metadata we can provide a consolidated view of departmental production data regardless of the heterogeneous imaging sources and subsidiary information systems. With our non-proprietary approach it is therefore feasible to conceive indicators that may be included in wider scope institutional performance evaluation. The results from the consolidated DICOM information analysis of more than 20 million images, belonging to more than 467 thousand studies performed on more than 162 thousand patients, justify the relevance of the implementation of similar methodologies in order to optimize the management of Radiology departments. Â© 2015 The Authors. Published by Elsevier B.V. Peer-review under responsibility of SciKA - Association for Promotion and Dissemination of Scientific Knowledge. * Corresponding author. Tel.: +351 234 247 110. fax: +351 234401597. E-mail address: mrs@ua.pt 2015 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license Peer-review under responsibility of SciKA - Association for Promotion and Dissemination of Scientific Knowledge 652 Milton Santos et al. / Procedia Computer Science 64 ( 2015 ) 651 â€“ 658 Keywords: Radiology, PACS, DICOM Metadata, Performance Analysis. 1. Introduction The existence of different information systems in clinical setting, as well as multiple imaging modalities and different manufacturers, together with the production of huge volumes of information, makes relevant the development of tools that can be used for the extraction, processing, delivery and analysis of large volumes of data. Such tools can be useful for the professional practice characterization, including through performance indicators definition1, which can be analyzed using dashboards in order to promote productivity, performance and other health care quality improvement initiatives2. This paper aims to demonstrate the Digital Imaging and Communication in Medicine (DICOM) metadata consolidation feasibility of images stored on a Picture Archiving and Communication System (PACS) archive for the production of indicators with different granularity levels, independently of medical imaging equipment manufacturers and information systems. The experimental study was conducted in a Hospital Center (HC) which resulted from the junction of three Health Care Facilities (HCF_01, HCF_2 and HCF_3). The imaging studies stores in two institutions PACS since 2009 (HCF_01 and HCF_2) were transferred to a central PACS archive installed in May 2011 and belonging to a third institution (HCF_3). The authors used Dicoogle application3 to build an index supported in the DICOM metadata contained in the HC PACS. This index, containing 92.6 GB, allows the information consolidation regarding to 20.595.967 images, bellowing to 467.243 studies, which is useful for retrospective studies. In particular, in this paper will explore the Index results for a macro characterization of the Radiology department who supported the study. This paper is organized as follows. In Section 2 are addressed some factors with influence in the production of high volumes of information associated with imaging studies and some existing limitations when analyzing the DICOM metadata stored in PACS archives. This section also provides a DICOM metadata indexing methodology, independent of equipment manufacturers and information systems, and its contribution within DICOM metadata mining initiatives. In section 3 is presented the methodology used for indexing and analysis of DICOM metadata existing in the CH PACS archive. In section 4 there are presented the results and in section 5 there are presented the discussion, some conclusions and future work initiatives. 2. Background The existence of inherently digital medical imaging modalities (eg, Computed Tomography - CT, Magnetic Resonance - MR) and the introduction of modalities such as Computed Radiography (CR) and Digital Radiography (DX) at Radiology departments, where they can generate 60-70% of the volume of images produced4 have made clear the need for the use of Information and Communication Technologies (ICT) for the daily information management. This led to the use of information systems such as PACS5-7 to access and use of relevant information to the Radiology departmentâ€™s activity. At this level, there has have been developed strategies for a more assertive management of large volume of studies performed daily. These strategies may comprise better definition of studies protocols, but also the optimization of existing PACS systems8, 9. In order to allow different users to create custom searches over the DICOM metadata that is part of the different modalities images, and according to the data that the user want to analyze, there are emerging IT solutions that complement the search functions normally provided by PACS10-15. An IT solution that enables the indexing, extraction and export of images and DICOM metadata, and that seeks to respond to the requirements mentioned above, is the Dicoogle3. The typically PACS Archive Server and Databases are general prepared to take maximum efficiency for clinical usage. Thus, the access to the information that typically are not used by the clinical or diagnosis is not typically implemented in the PACS Archive, or many of them supports the dump of all the DICOM fields in the screen, but they do not support a massive analyses of the field and do a statistical analyses from third party tools. General the 653 Milton Santos et al. / Procedia Computer Science 64 ( 2015 ) 651 â€“ 658 structure of the database is complex and depends on the manufacture. To tackle the issue, there is a tool called Dicoogle3, free and an open source that allows to easily access to a image archive over the file systems and massive extracts all the DICOM headers from the images. Dicoogle supports not only a powerful system to parse the DICOM headers but they can do it in hard-drives that can be remotely mounted in a local machine 16. On one hand, the process of the data gathering is named as â€œindexingâ€� and it allows to extract all the fields and store them in a data structure that is flexible and portable to move across locations. For instance, it is possible to index multiple locations in the same Dicoogle instance. On another hand, the process of query is really flexible compared with the traditional PACS. For instance, they restricted typically to the DIM (DICOM Information Model) fields, while in Dicoogle is possible to all the fields that contains the image and combine in an advanced and complex boolean query using range of values and wildcards. For instance, Dicoogle will be able to answer: â€œHow many patients have exams to the TORAX with ExposureTime between X and Y?â€�. Moreover, all of the results can be easily exported to an Excel spreadsheet. Finally, they also have an extension to analyze the index and easily extract global statistics, such as quality of the data, image per device and the most used terms in the DICOM fields. These results can be visualized graphically and also exported to a CSV file to be analyzed by third-party tools17. The DICOM metadata indexing process allows DICOM Meta Data Mining initiatives, and can be a very useful information resource for the professional practice characterization in radiology departments. For example, their use for the characterization of the actors involved in the provision of health care, or to analyze the exposure to X-radiation to which patients are subjected during radiological studies18-19, can help to identify situations that can represent a deficit of quality of health care, or can contribute to the definition of continuous quality improvement initiatives18. On the other hand, the DICOM metadata indexing process can occur over files from different modalities and health care facilities PACS archives since it is not dependent on the equipment manufacturer or information systems20. The different imaging modalities (eg, CT or MR) are supported by the DICOM standard for the studies acquisition and management, particularly when using PACS. In general, in these systems the users are always dependent on the provision by the manufacturer from a set of search functions. These are usually limited, that is, we can only use a limited number of DICOM fields for research activities. This promotes screening DICOM data in a standardized and inflexible manner3,15. This situation is mainly due to the fact that PACS do not make available all DICOM fields to support the DICOM Information Model Query & Retrieve (DIM Q / R), which means that a large amount of DICOM information is not searchable16. On the other hand, there is a need for tools and methodologies for the analysis of information produced in radiology department, including DICOM metadata, which can serve to support clinical decision-making and human and material resources management. 3. Material and Methods A retrospective study of the metadata stored in a Hospital PACS archive that stores studies performed in three Health Care institutions was done (HCF_1, HCF_2 and HCF_3). Access to studies stored in the PACS archive was conducted after approval by the ethics committee and the hospital administration. The confidentiality of patients and actors involved in the provision of health care was guaranteed The DICOM metadata indexing process occurred on the PACS archive using Dicoogle installed in a virtual machine bellowing to the Hospital domain and supported by an Intel (R) Xeon (R) E5540 with 2.53 GHz speed processor and 2 GB of RAM. Each of the 17 discs that form the PACS archive was indexed separately and merge in to a global index. The extraction of DICOM metadata was supported by specific queries, supported by the DICOM attributes Institution Name, Modality and Study Date. Data statistical analysis was supported by the statistical Dicoogle plugin22. In this context were analyzed: â€¢ The number of patients with studies, as well as the number of studies and images stored, â€¢ The contribution of each modality to the volume of information produced, â€¢ The contribution of each Health Care facility for the volume of studies stored at the PACS archive. 654 Milton Santos et al. / Procedia Computer Science 64 ( 2015 ) 651 â€“ 658 4. Results Within the HC, the PACS archive supports the storage of studies from three Health Care facilities (Fig. 1) bellowing to different modalities and conducted in different equipment. In this PACS, the images bellowing to a study are distributed across different disks, which imply having to index all existing records to ensure that all images belonging to a study is indexed. Fig. 1. Central PACS for the three Health Care facilities. At the time of DICOM metadata indexing process, de PACS archive consisted of 17 discs, with a total capacity of 8.626 GB, with 6.707 GB used and 1.934 GB free. The index of 17 disks held for 63 days (from October 6 to December 9, 2014), with an average speed indexing of 3.8 images/s, and resulted in an index of 92.6 GB, containing information on 467.243 studies, bellowing to 162.138 patients and comprising 20.595.967 images. The value of 308,336 patients in Table 1 arises from the fact that many patients went more than once to the Health Care facility between 2009 and 2014. In this table are also presented the queries structures used for the analysis of the number of patients with studies performed and the number of studies and images acquired and stored in different years . Table 1. Number of patients with studies performed per year and the number of studies and images stored at the PACS archive. Query structure Year Patients Studies Images StudyDate:[20090101 TO 20091231] 2009 1.119 1.383 9.783 StudyDate:[20100101 TO 20101231] 2010 15.026 19.847 211.824 StudyDate:[20110101 TO 20111231] 2011 58.358 88.514 3.432.894 StudyDate:[20120101 TO 20121231] 2012 80.046 124.038 5.973.930 StudyDate:[20130101 TO 20131231] 2013 77.436 116.457 5.095.546 StudyDate:[20140101 TO 20141231] 2014 76.351 117.004 5.871.990 âˆ‘ 308.336 467.243 20.595.967 In Table 1 we identify a gradual increase in the number of patients with studies performed each year, as well as the number of studies and images in 2012, being more significant between 2010 and 2011, but decreasing in 2013 and 2014. However, despite the decrease of the number of patients in 2014 compared to 2013, we see an increasing number of studies and images. 655 Milton Santos et al. / Procedia Computer Science 64 ( 2015 ) 651 â€“ 658 The number of acquired images has direct implications on storage space management. In this context, the disks that are part of the PACS archive have different levels of use, being noticeable values of about 400 GB (roughly 80%) of space used in most of them. However, there are two disks with lower space utilization (disk S and T with 200 GB) and two disks with fulfillment values slightly below 300 GB (disk U and V). Fig. 2 shows the capacity, used space and free space on each disk indexed. Fig. 2. Used an free space on each disk. The analysis of the contribution of different modalities to the information volume stored, and affecting the values shown in Figure 2, was supported by the queries presented in Table 1. In this context we analyzed the percentage of different values stored in the DICOM attribute â€œModality â€œ. These values range from 95,55% of images from CT modality in 2013 and 0,0% in other modalities such as Mammography (MG), Digital Radiography (DX) and Magnetic Resonance Imaging (MR) in some years (Table 2). In Table 2 we see a gradual increase in the percentage of CT and RF images existing in the PACS archive, decreasing in 2014. However, in this year we see a significant increase in MR images (6%) compared to previous years. The percentage of DX images decreases over the years. On the other hand, the percentage of US images gradually increases from 2011. From 2011 the percentage of CR images does not vary. When we look at Table 2 we also verify the existence of residual values of other modalities (eg, Other - OT and Angiography - XA), and values for Structured Reports (SR) and Presentation Layers (PR). Table 2. Percentage of images in the PACS archive by year and modality. Year/Modality CT CR US MG RF DX MR PR/XA/SR/ OT 2009 74,92% 14,43% 2,21% 0,00% 0,00% 0,00% 0,00% 8,44% 2010 81,06% 9,62% 2,66% 0,00% 0,02% 0,00% 0,00% 6,64% 2011 94,96% 0,74% 1,24% 0,02% 0,06% 2,41% 0,03% 1.56% 2012 95,12% 0,64% 1,60% 0,02% 0,10% 1,81% 0,00% 1.41% 2013 95,55% 0,67% 1,75% 0,02% 0,13% 1,6% 0,07% 0.41% 2014 89,81% 0,67% 1,99% 0,01% 0,12% 1,40% 6% 0% CT â€“ Computed Tomography, US â€“ Ultra Sound, RF - Radio-Fluoroscopy, MR â€“ Magnetic Resonance, OT â€“ Other, CR â€“ Computed Radiography, MG â€“ Mammography, DX â€“ Digital Radiography, XA â€“ Angiography, SR - Structured Report, PR - Presentation Layer. In Table 2 is also clear that there is 6% images belonging to the MR modality, a modality that does not exist at the HC, which could represent an increase in the number of studies conducted outside of CH and whose images were stored in the PACS archive, so it can be relevant to know the health care facility responsible for conducting these 656 Milton Santos et al. / Procedia Computer Science 64 ( 2015 ) 651 â€“ 658 studies. As a result, we identified 24 names for the outside health care facilities identification (Table 3) as well as 5,9% images with a numeric identification of the health care facility. On the other hand, it was evident the existence of different names to identify the same health care facility. For example, HCF_1 is identified with one designation in 0,07% images, and HCF_2 is identified with 9 different designations in 3,3% images (e.g. Hosp. XPTO, Hosp.xpto, HXPTO). The HCF_03 appears identified in 88,42% images but with 12 different designations. Furthermore, 5,90% images come with numerical values for the health care facility identification (eg, 11003, 11004, 11028). Table 3. Number of the Health Care facility designations and percentage of associated images. External HCF HCF _1 HCF _2 HCF- 3 Hospital Center Unknown (numeric values) Number of different designations (Institution Name DICOM attribute) 24 1 9 12 1 6 % 1,96 0,07 3,30 88,42 0,35 5,90 5. Discussion and Conclusions Most of the information stored in PACS archives was never accessed again by health care providers. However, the retrospective study of DICOM metadata, stored at the PACS archive, can be a very relevant source of information about the health care provision, but also for information management and information quality assessment, especially when the information results from the aggregation of data from different health care facilities. Despite the amount of information in the HC PACS archive, the merger indexing methodology of DICOM metadata stored on multiple disks, and from different health care facilities, was achieved within a time period which represents a considerable computational effort, especially if one takes into account the DICOM metadata indexing speed of 3.8 images/s. The 92.6 GB of data resulting from the indexing process allowed us to know the number of patients from three health care facilities with studies stored in the PACS archive. The DICOM metadata consolidation has provided an overall view of the Radiology department activity. However, the data interpretation should take into account the clinical environment from where they emerge. The definition of queries with specific structures, in accordance with the metadata to be extracted, allowed the collection of the data shown in Table 1. In this table we identified a significant increase in the number of patients, studies and images stored in the PACS archive in 2011 and went up again in 2012. These values result from the fact that the installation of the HCF_3 PACS occurred only on April 2011 and, on the other hand, the fact that only this health care facility have DX and MG modality, and two multi-slice CT equipment, which may explain the significant increase of studies and images stored in the PACS archive after 2011. However, when we analyze the 2014 data, we find that a smaller number of patients is associated with a greater number of studies and images stored (which can be explained by the fact that the indexing process was performed only until December 9). These values can be associated with a smaller number of images acquired in DX modality in 2014 and with an increased number of images in US and MR modalities (Table 2). In fact, the data analysis allow us to identify a decrease in the number of DX modality images associated with an increase of the number of images from US and MR modalities. In Table 2 we also found that in 2009 and 2010 there are no images from some modalities (eg, MG and DX), which is due to the fact that these modalities only exist in HCF_03 from the year 2011. Moreover, we found that a decrease in the number of CT images is associated with an increase in the number of MR images, in a very similar percentage. In this scenario it may be pertinent to study the existence of a cause-effect relationship. The identification of the health care facilities with studies stored in the PACS archive has proved a difficult task due to the poor information quality recorded in the DICOM attribute â€œInstitution Nameâ€�. This reality undermines the implementation of improvement initiatives in a clinical environment using existing resources, where the identification of the actors involved in the provision of health care is very important, starting with the identification of health care facilities. This identification can be diminished by multiple designation of the health care facilities and by the fact that 5,90% images are identified with numeric values. On the other hand, and as 657 Milton Santos et al. / Procedia Computer Science 64 ( 2015 ) 651 â€“ 658 an example, HCF_1 is uniquely identified in only 0,07% images, which can be associated to the migrating data process between HCF_1 PACS archive and HC PACS archive. The studies integration in HC PACS resulted in the possibility to analyze 8.626 GB of information, which allowed a better understanding of the evolution of the number of studies by the population covered by the three health care facilities. Knowing this reality makes it possible to anticipate hardware and software requirements that contribute to the proper management of information, including storage needs, or to the definition of strategies that result in optimizing performance, namely by optimizing studies protocols, particularly in the CT modality context. In fact, this modality comes to be responsible for over 95% of the information stored in the PACS archive (Table 2), aspect which may be associated with a large number of studies but also the use of multislice CT equipment and the inappropriate use of multiplanar image reformatting The knowledge of the data volume acquired over time can be relevant to the anticipation of needs in terms of information management and storage, in particular within the relevance to have 20% of disks storage capacity not used. In fact, and in average, every year has been produced more than 1.340 GB of metadata, and based on a retrospective analysis of information stored in the PACS archive, we expect that next year will be necessary to acquire 4 more disks for data storage. Within the quantity of information stored, in addition to the CT modality contribution, the MR modality emerges as the second modality with more images stored in the PACS archive. In this context, the existence of an increase in the number of images may be associated with an increased number of studies, which may represent an increase of financial burden for the institution whenever they are paid to health care facilities external to HC. On the other hand, MR studies may come from other health care facilities and does not represent a spending increase, it is, therefore, pertinent to identify these entities. In Radiology context, the production of a high data volume associated with imaging studies, and the constraints in accessing stored DICOM metadata supported by proprietary manufacturers tools for DICOM metadata analysis, emphasizes the need of new tools and methods for information analysis independently of manufacturers, stored information volume and information systems. The results of indexation and analysis of more than 20 million images, presented in this work, allows foreseeing the potential of the methodology used for the analysis of information stored in large PACS archives. The results of the work done and presented in this paper evidence the possibility of consolidation of a large volume of DICOM metadata, on the other hand, allows us to obtain relevant information to the provision of health care. In addition, allows us to identify usage trends of existing resources in different health care facilities, particularly in medical imaging equipment management context and DICOM information management, and makes it possible to audit the quality of the information stored in DICOM attributes. This aspect can be very important for the actors involved in the realization of the studies identification, but also in the identification and dissemination of good practices as well as for the definition of health care quality continuous improvement initiatives, particularly in the management of human and material resources scope. The flexibility that Dicoogle allows for conducting queries with different structures and according to user interests, and, by not using DICOM query & retrieve services for DICOM metadata access, leaves open the possibility of replication of the study presented in this paper in different professional realities, regardless different equipment manufacturers and information systems that exist in a clinical environment.. As future work, we foresee the possibility to carry out initiatives that enable the identification of situations that may represent opportunities for DICOM metadata quality improvement, as well as for the continuous improvement of health care provision at Radiology departments. This can be made through DICOM metadata indexing and analysis in a systematic way. References 1. Ondategui-Parra S, Bhagwat JG, Zou KH, Gogate A, Intriere LA, Kelly P, et al. Practice Management Performance Indicators in Academic Radiology Departments1. Radiology. 2004;233(3):716-22. 2. Nagy PG, Warnock MJ, Daly M, Toland C, Meenan CD, Mezrich RS. Informatics in Radiology: Automated Web-based Graphical Dashboard for Radiology Operational Business Intelligence1. Radiographics. 2009 November 1, 2009;29(7):1897-906. 658 Milton Santos et al. / Procedia Computer Science 64 ( 2015 ) 651 â€“ 658 3. Costa C, Ferreira C, BastiÃ£o L, Ribeiro L, Silva A, Oliveira J. Dicoogle - an Open Source Peer-to-Peer PACS. J Digit Imaging. 2011;24(5):848-56. 4. Samei E, Seibert JA, Andriole K, Badano A, Crawford J, Reiner B, et al. AAPM/RSNA Tutorial on Equipment Selection: PACS Equipment Overview: General Guidelines for Purchasing and Acceptance Testing of PACS Equipment. Radiographics. 2004;24(1):313-34. 5. Larsson W, Aspelin P, Bergquist M, HillergÃ¥rd K, Jacobsson B, LindskÃ¶ld L, et al. The effects of PACS on radiographer's work practice. Radiography. 2007;13(3):235-40. 6. Bick U, Lenzen H. PACS: the silent revolution. Eur Radiol. 1999;9(6):1152-60. 7. Reiner BI, Siegel EL. Technologists' Productivity When Using PACS: Comparison of Film-Based Versus Filmless Radiography. American Journal of Roentgenology. 2002;179(1):33-7. 8. Yoshinobu T, Abe K, Sasaki Y, Tabei M, Tanaka S, Takahashi M, et al. Data Management Solution for Large-Volume Computed Tomography in an Existing Picture Archiving and Communication System (PACS). J Digit Imaging. 2011;24(1):107-13. 9. Lee K, Lee H, Kim J, Kang H, Lee K, Hong H, et al. Managing the CT Data Explosion: Initial Experiences of Archiving Volumetric Datasets in a Mini-PACS. J Digit Imaging. 2005;18(3):188-95. 10. Vano E, Fernandez JM, Ten JI, Guibelalde E, Gonzalez L, Pedrosa CSA. Real-Time Measurement and Audit of Radiation Dose to Patients Undergoing Computed Radiography. Radiology. 2002;225(1):283-8. 11. Vano E, JM Fernandez S. Patient Dose Management in Digital Radiography. Biomed Imaging Interv 2007. 12. Vano E, Ten JI, Fernandez JM, Prieto C, Ordiales JM, Martinez D. Quality control and patient dosimetry in digital radiology. On line system: new features and transportability. Radiation Protection Dosimetry. 2008;129(1-3):144-6. 13. Stewart BK, Kanal KM, Perdue JR, Mann FA. Computed Radiography Dose Data Mining and Surveillance as an Ongoing Quality Assurance Improvement Process. Am J Roentgenol. 2007;189(1):7-11. 14. Vano E, Padovani R, Bernardi G, Ten JI, Peterzol A, Dowling A, et al. On the use of DICOM cine header information for optimisation: results from the 2002 European DIMOND cardiology survey. Radiat Prot Dosimetry. 2005;117(1-3):162-5. 15. KÃ¤llman H-E, Halsius E, Olsson M, StenstrÃ¶m M. DICOM Metadata repository for technical information in digital medical images. Acta Oncologica. 2009;48(2):285-8. 16. Costa C, Freitas F, Pereira M, Silva A, Oliveira J. Indexing and retrieving DICOM data in disperse and unstructured archives. International Journal of Computer Assisted Radiology and Surgery. 2009;4(1):71-7. 17. BastiÃ£o L, Santos M, Costa C, Oliveira JL, . Dicoogle statistics: analyzing efficiency and service quality of digital imaging laboratories. CARS 2013; Heidelberg, Germany. 18. Santos M, BastiÃ£o L, Costa C, Silva A, Rocha N. DICOM and Clinical Data Mining in a Small Hospital PACS: A Pilot Study. In: Cruz-Cunha M, VarajÃ£o J, Powell P, Martinho R, editors. ENTERprise Information Systems: Springer Berlin Heidelberg; 2011. p. 254-63. 19. Santos M, Couto P, Silva A, Rocha N. DICOM metadata-mining in PACS for Computed Radiography X-Ray Exposure Analysis. A Mammography Multisite Study. European Congress of Radiology. Viena, 2014. 20. Santos M, de Francesco S, Silva L, Silva A, Costa C, Rocha N, editors. Multi-vendor DICOM metadata access a multi-site hospital approach using Dicoogle. Information Systems and Technologies (CISTI), 8th Iberian Conference on Information Systems and Technologies. Lisboa, 2013. ematic way. References 1. Ondategui-Parra S, Bhagwat JG, Zou KH, Gogate A, Intriere LA, Kelly P, et al. Practice Management Performance Indicators in Academic Radiology Departments1. Radiology. 2004;233(3):716-22. 2. Nagy PG, Warnock MJ, Daly M, Toland C, Meenan CD, Mezrich RS. Informatics in Radiology: Automated Web-based Graphical Dashboard for Radiology Operational Business Intelligence1. Radiographics. 2009 November 1, 2009;29(7):1897-906. 658 Milton Santos et al. / Procedia Computer Science 64 ( 2015 ) 651 â€“ 658 3. Costa C, Ferreira C, BastiÃ£o L, Ribeiro L, Silva A, Oliveira J. Dicoogle - an Open Source Peer-to-Peer PACS. J Digit Imaging. 2011;24(5):848-56. 4. Samei E, Seibert JA, Andriole K, Badano A, Crawford J, Reiner B, et al. AAPM/RSNA Tutorial on Equipment Selection: PACS Equipment Overview: General Guidelines for Purchasing and Acceptance Testing of PACS Equipment. Radiographics. 2004;24(1):313-34. 5. Larsson W, Aspelin P, Bergquist M, HillergÃ¥rd K, Jacobsson B, LindskÃ¶ld L, et al. The effects of PACS on radiographer's work practice. Radiography. 2007;13(3):235-40. 6. Bick U, Lenzen H. PACS: the silent revolution. Eur Radiol. 1999;9(6):1152-60. 7. Reiner BI, Siegel EL. Technologists' Productivity When Using PACS: Comparison of Film-Based Versus Filmless Radiography. American Journal of Roentgenology. 2002;179(1):33-7. 8. Yoshinobu T, Abe K, Sasaki Y, Tabei M, Tanaka S, Takahashi M, et al. Data Management Solution for Large-Volume Computed Tomography in an Existing Picture Archiving and Communication System (PACS). J Digit Imaging. 2011;24(1):107-13. 9. Lee K, Lee H, Kim J, Kang H, Lee K, Hong H, et al. Managing the CT Data Explosion: Initial Experiences of Archiving Volumetric Datasets in a Mini-PACS. J Digit Imaging. 2005;18(3):188-95. 10. Vano E, Fernandez JM, Ten JI, Guibelalde E, Gonzalez L, Pedrosa CSA. Real-Time Measurement and Audit of Radiation Dose to Patients Undergoing Computed Radiography. Radiology. 2002;225(1):283-8. 11. Vano E, JM Fernandez S. Patient Dose Management in Digital Radiography. Biomed Imaging Interv 2007. 12. Vano E, Ten JI, Fernandez JM, Prieto C, Ordiales JM, Martinez D. Quality control and patient dosimetry in digital radiology. On line system: new features and transportability. Radiation Pro PROCS 6783 S1877-0509(15)02714-3 10.1016/j.procs.2015.08.579 The Authors ☆ Peer-review under responsibility of SciKA - Association for Promotion and Dissemination of Scientific Knowledge. DICOM Metadata Access, Consolidation and Usage in Radiology Department Performance Analysis. A Non-proprietary Approach Milton Santos a b ⁎ Luis Bastião b Nuno Neves c Dulce Francisco c Augusto Silva b d Nelson Pacheco Rocha b e a Health Sciences School, University of Aveiro, Aveiro, Portugal Health Sciences School, University of Aveiro Aveiro Portugal b IEETA, University of Aveiro, Aveiro, Portugal IEETA, University of Aveiro Aveiro Portugal c Centro Hospitalar do Baixo Vouga, Aveiro, Portugal Centro Hospitalar do Baixo Vouga Aveiro Portugal d Department of Electronics, Telecommunications and Informatics, University of Aveiro, Aveiro, Portugal Department of Electronics, Telecommunications and Informatics, University of Aveiro Aveiro Portugal e Health Sciences Department, University of Aveiro, Aveiro, Portugal Health Sciences Department, University of Aveiro Aveiro Portugal ⁎ Corresponding author. Tel.: +351 234 247 110. fax: +351 234401597. In a clinical environment are produced on daily basis huge volumes of information. In the radiology context, the realization of an increasing number of studies, in particular those associated with modalities that produce huge amounts of images, has given rise to large PACS archives. Proprietary tools available for the analysis of the stored information are limited and usually do not allow efficient analysis of the radiology department performance. In this work we demonstrate that with seamless access to DICOM metadata we can provide a consolidated view of departmental production data regardless of the heterogeneous imaging sources and subsidiary information systems. With our non-proprietary approach it is therefore feasible to conceive indicators that may be included in wider scope institutional performance evaluation. The results from the consolidated DICOM information analysis of more than 20 million images, belonging to more than 467 thousand studies performed on more than 162 thousand patients, justify the relevance of the implementation of similar methodologies in order to optimize the management of Radiology departments. Keywords Radiology PACS DICOM Metadata Performance Analysis. References [1] Ondategui-Parra S, Bhagwat JG, Zou KH, Gogate A, Intriere LA, Kelly P, et al. Practice Management Performance Indicators in Academic Radiology Departments1. Radiology. 2004;233(3):716-22. [2] Nagy PG, Warnock MJ, Daly M, Toland C, Meenan CD, Mezrich RS. Informatics in Radiology: Automated Web-based Graphical Dashboard for Radiology Operational Business Intelligence1. Radiographics. 2009 November 1, 2009;29(7):1897-906. [3] Costa C, Ferreira C, Bastião L, Ribeiro L, Silva A, Oliveira J. Dicoogle - an Open SourcePeer-to-Peer PACS. J Digit Imaging. 2011;24(5):848-56. [4] Samei E, Seibert JA, Andriole K, Badano A, Crawford J, Reiner B, et al. AAPM/RSNA Tutorial on Equipment Selection: PACS Equipment Overview: General Guidelines for Purchasing and Acceptance Testing of PACS Equipment. Radiographics. 2004;24(1):313-34. [5] Larsson W, Aspelin P, Bergquist M, Hillergård K, Jacobsson B, Lindsköld L, et al. The effects of PACS on radiographer's work practice. Radiography. 2007;13(3):235-40. [6] Bick U, Lenzen H. PACS: the silent revolution. EurRadiol. 1999;9(6):1152-60. [7] Reiner BI, Siegel EL. Technologists’ Productivity When Using PACS: Comparison of Film-Based Versus Filmless Radiography. American Journal of Roentgenology. 2002;179(1):33-7. [8] Yoshinobu T, Abe K, Sasaki Y, Tabei M, Tanaka S, Takahashi M, et al. Data Management Solution for Large-Volume Computed Tomography in an Existing Picture Archiving and Communication System (PACS). J Digit Imaging. 2011;24(1):107-13. [9] Lee K, Lee H, Kim J, Kang H, Lee K, Hong H, et al. Managing the CT Data Explosion: Initial Experiences of Archiving Volumetric Datasets in a Mini-PACS. J DigitImaging. 2005;18(3):188-95. [10] Vano E, Fernandez JM, Ten JI, Guibelalde E, Gonzalez L, Pedrosa CSA. Real-Time Measurement and Audit of Radiation Dose to Patients Undergoing Computed Radiography. Radiology. 2002;225(1):283-8. [11] Vano E, JM Fernandez S. Patient Dose Management in Digital Radiography. Biomed ImagingInterv 2007. [12] Vano E, Ten JI, Fernandez JM, Prieto C, Ordiales JM, Martinez D. Quality control and patient dosimetry in digital radiology. On line system: new features and transportability. Radiation Protection Dosimetry. 2008; 129(1-3):144-6. [13] Stewart BK, Kanal KM, Perdue JR, Mann FA. Computed Radiography Dose Data Mining and Surveillance as an Ongoing Quality Assurance Improvement Process. Am J Roentgenol. 2007;189(1):7-11. [14] Vano E, Padovani R, Bernardi G, Ten JI, Peterzol A, Dowling A, et al. On the use of DICOM cine header information for optimisation: results from the 2002 European DIMOND cardiology survey. RadiatProt Dosimetry. 2005; 117(1-3):162-5. [15] Källman H-E, Halsius E, Olsson M, Stenström M. DICOM Metadata repository for technical information in digital medical images. ActaOncologica. 2009;48(2):285-8. [16] Costa C, Freitas F, Pereira M, Silva A, Oliveira J. Indexing and retrieving DICOM data in disperse and unstructured archives. International Journal of Computer Assisted Radiology and Surgery. 2009;4(1):71-7. [17] Bastião L, Santos M, Costa C, Oliveira JL, .Dicoogle statistics: analyzing efficiency and service quality of digital imaging laboratories. CARS 2013; Heidelberg, Germany. [18] Santos M, Bastião L, Costa C, Silva A, Rocha N. DICOM and Clinical Data Mining in a Small Hospital PACS: A Pilot Study. In: Cruz-Cunha M, Varajão J, Powell P, Martinho R, editors. ENTERprise Information Systems: Springer Berlin Heidelberg; 2011. p. 254-63. [19] Santos M, Couto P, Silva A, Rocha N. DICOM metadata-mining in PACS for Computed Radiography X-Ray Exposure Analysis. A Mammography Multisite Study. European Congress of Radiology. Viena, 2014. [20] Santos M, de Francesco S, Silva L, Silva A, Costa C, Rocha N, editors. Multi-vendor DICOM metadata access a multi-site hospital approach using Dicoogle. Information Systems and Technologies (CISTI), 8 th Iberian Conference on Information Systems and Technologies.Lisboa, 2013. "
    },
    {
        "doc_title": "New insights in echocardiography based left-ventricle dynamics assessment",
        "doc_scopus_id": "84944463907",
        "doc_doi": "10.1007/978-3-319-16483-0_30",
        "doc_eid": "2-s2.0-84944463907",
        "doc_date": "2015-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Automatic systems",
            "Cardio-vascular disease",
            "Clinical diagnosis",
            "Echocardiogram",
            "Left ventricles",
            "Network classifiers",
            "Quantitative parameters",
            "Sensitivity and specificity"
        ],
        "doc_abstract": "© Springer International Publishing Switzerland 2015.Cardiovascular diseases affect a high percentage of people worldwide, being currently a major clinical concern. Echocardiograms are useful exams that allow monitoring the heart dynamics. However, their analysis depends on trained physicians with well-developed skills to recognize pathology from morphological and dynamical cues. Furthermore, these exams are often difficult to interpret due to image quality. Therefore, automatic systems able to analyze echocardiographic quantitative parameters in order to convey useful information will provide a great help in clinical diagnosis. A robust dataset was built, comprising variables associated with left-ventricle dynamics, which were studied in order to build a classifier able to discriminate between pathological and non-pathological records. To accomplish this goal, a network classifier based on decision tree was developed, using as input the left ventricle velocity over a complete cardiac cycle. This classifier revealed both sensitivity and specificity over 90% in discriminating non-pathological records, or pathological records (dilated or hypertrophic).",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Information model for radiology performance indicators based on DICOM",
        "doc_scopus_id": "84938884141",
        "doc_doi": "10.5220/0005286201820190",
        "doc_eid": "2-s2.0-84938884141",
        "doc_date": "2015-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Health Information Management",
                "area_abbreviation": "HEAL",
                "area_code": "3605"
            },
            {
                "area_name": "Computer Science Applications",
                "area_abbreviation": "COMP",
                "area_code": "1706"
            },
            {
                "area_name": "Electrical and Electronic Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2208"
            },
            {
                "area_name": "Health Informatics",
                "area_abbreviation": "MEDI",
                "area_code": "2718"
            },
            {
                "area_name": "Signal Processing",
                "area_abbreviation": "COMP",
                "area_code": "1711"
            }
        ],
        "doc_keywords": [
            "Comprehensive analysis",
            "Digital imaging and communication in medicines",
            "Digital radiography",
            "Healthcare facility",
            "Information Modeling",
            "Performance indicators",
            "Quality dimension",
            "Quality indicators"
        ],
        "doc_abstract": "The paper presents the information model of the DICOM - Radiology Performance Indicator (DICOM-RPI). This model can be used to aggregate information related to the characterization of medical imaging health care services, namely information incorporated in the studies according to the format of the Digital Imaging and Communication in Medicine (DICOM). The model comprises several components including the ones required to define the context of medical imaging health care services (e.g. the entities involved) and the context of use of the indicator (e.g. Quality Dimensions). For the validation of the proposed information model 51,277 Digital Radiography (DX) studies performed on 27,559 patients from a single health care facility were considered. The results of this validation within the scope of DX modality make possible to anticipate the DICOM-RPI relevance in other imaging modalities and its contribution for comprehensive analysis of medical imaging health care services.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Improving the Mann-Whitney statistical test for feature selection: An approach in breast cancer diagnosis on mammography",
        "doc_scopus_id": "84923943411",
        "doc_doi": "10.1016/j.artmed.2014.12.004",
        "doc_eid": "2-s2.0-84923943411",
        "doc_date": "2015-01-01",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Medicine (miscellaneous)",
                "area_abbreviation": "MEDI",
                "area_code": "2701"
            },
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            }
        ],
        "doc_keywords": [
            "Breast Cancer",
            "Feature selection methods",
            "Mann-Whitney U test",
            "Redundancy analysis",
            "UFilter method",
            "Algorithms",
            "Bayes Theorem",
            "Breast Neoplasms",
            "Chi-Square Distribution",
            "Databases, Factual",
            "Diagnosis, Computer-Assisted",
            "Discriminant Analysis",
            "Female",
            "Humans",
            "Linear Models",
            "Machine Learning",
            "Mammography",
            "Models, Statistical",
            "Predictive Value of Tests",
            "Radiographic Image Interpretation, Computer-Assisted",
            "Reproducibility of Results"
        ],
        "doc_abstract": "© 2014 Elsevier B.V.Objective: This work addresses the theoretical description and experimental evaluation of a new feature selection method (named uFilter). The uFilter improves the Mann-Whitney U-test for reducing dimensionality and ranking features in binary classification problems. Also, it presented a practical uFilter application on breast cancer computer-aided diagnosis (CADx). Materials and methods: A total of 720 datasets (ranked subsets of features) were formed by the application of the chi-square (CHI2) discretization, information-gain (IG), one-rule (1Rule), Relief, uFilter and its theoretical basis method (named U-test). Each produced dataset was used for training feed-forward backpropagation neural network, support vector machine, linear discriminant analysis and naive Bayes machine learning algorithms to produce classification scores for further statistical comparisons. Results: A head-to-head comparison based on the mean of area under receiver operating characteristics curve scores against the U-test method showed that the uFilter method significantly outperformed the U-test method for almost all classification schemes (p<. 0.05); it was superior in 50%; tied in a 37.5% and lost in a 12.5% of the 24 comparative scenarios. Also, the performance of the uFilter method, when compared with CHI2 discretization, IG, 1Rule and Relief methods, was superior or at least statistically similar on the explored datasets while requiring less number of features. Conclusions: The experimental results indicated that uFilter method statistically outperformed the U-test method and it demonstrated similar, but not superior, performance than traditional feature selection methods (CHI2 discretization, IG, 1Rule and Relief). The uFilter method revealed competitive and appealing cost-effectiveness results on selecting relevant features, as a support tool for breast cancer CADx methods especially in unbalanced datasets contexts. Finally, the redundancy analysis as a complementary step to the uFilter method provided us an effective way for finding optimal subsets of features without decreasing the classification performances.",
        "available": true,
        "clean_text": "serial JL 271219 291210 291682 291866 31 Artificial Intelligence in Medicine ARTIFICIALINTELLIGENCEINMEDICINE 2014-12-12 2014-12-12 2015-03-05T20:08:15 S0933-3657(14)00141-9 S0933365714001419 10.1016/j.artmed.2014.12.004 S300 S300.1 FULL-TEXT 2015-05-15T03:29:23.905283-04:00 0 0 20150101 20150131 2015 2014-12-12T17:12:46.553049Z articleinfo articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid hubeid indexeddate issfirst issn issnnorm issuelist itemstage itemtransactionid itemweight openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sectiontitle sortorder srctitle srctitlenorm srctype ssids alllist content subj subheadings tomb volfirst volissue volumelist yearnav figure table body mmlmath acknowledge affil appendices articletitle auth authfirstini authfull authkeywords authlast grantnumber grantsponsor highlightsabst primabst ref 0933-3657 09333657 true 63 63 1 1 Volume 63, Issue 1 4 19 31 19 31 201501 January 2015 2015-01-01 2015-01-31 2015 Research Articles article fla Copyright © 2014 Elsevier B.V. All rights reserved. IMPROVINGMANNWHITNEYSTATISTICALTESTFORFEATURESELECTIONAPPROACHINBREASTCANCERDIAGNOSISMAMMOGRAPHY PEREZ N 1 Introduction 2 Materials and methods 2.1 Databases 2.2 Considered features and datasets creation 2.3 Feature selection methods 2.4 Machine learning classifiers 2.5 The uFilter method 2.6 Experimental methodology 3 Results and discussions 3.1 Comparison between uFilter and U-test methods 3.1.1 Results on balanced datasets 3.1.2 Results on unbalanced datasets 3.2 Performance of uFilter versus classical feature selection methods 3.2.1 Results on balanced datasets 3.2.2 Results on unbalanced datasets 3.3 Feature relevance analysis 3.3.1 Features subset validation 4 Conclusions Conflict of interest Acknowledgments Algorithm 1 uFilter method References DEVIJVER 1982 P PATTERNRECOGNITIONASTATISTICALAPPROACH GUYON 2006 1 25 I FEATUREEXTRACTION INTRODUCTIONFEATUREEXTRACTION BLANCO 1998 135R 150R M KOEHN 2005 206 220 F HASHEMI 2008 863 871 H KAIFENG 2004 36 38 Y CHANWOO 2010 4574 4577 K 2010IEEEINTERNATIONALCONFERENCEACOUSTICSSPEECHSIGNALPROCESSINGICASSP FEATUREEXTRACTIONFORROBUSTSPEECHRECOGNITIONBASEDMAXIMIZINGSHARPNESSPOWERDISTRIBUTIONPOWERFLOORING PEI 2008 2001 2004 Y IEEEINTERNATIONALCONFERENCEACOUSTICSSPEECHSIGNALPROCESSINGICASSP2008 DISCRIMINATIVEFEATURESELECTIONFORHIDDENMARKOVMODELSUSINGSEGMENTALBOOSTING GUYON 2003 1157 1182 I YU 2004 1205 1224 L HOLMBERG 1998 319 324 M DUTTA 2002 4 R LOPEZ 2008 803 811 Y PROGRESSINPATTERNRECOGNITIONIMAGEANALYSISAPPLICATIONS BREASTCANCERDIAGNOSISBASEDASUITABLECOMBINATIONDEFORMABLEMODELSARTIFICIALNEURALNETWORKSTECHNIQUES GHAZAVI 2008 195 206 S SOLTANIANZADEH 2004 1973 1986 H WEI 2005 2827 2838 J LEE 2003 121 132 S SAEYS 2007 2507 2517 Y SETIONO 1995 388 391 R IEEEPROCEEDINGSSEVENTHINTERNATIONALCONFERENCETOOLSARTIFICIALINTELLIGENCE CHI2FEATURESELECTIONDISCRETIZATIONNUMERICATTRIBUTES LIU 2002 51 60 H PRESS 1988 W NUMERICALRECIPESINC JAIN 1982 835 855 A HANDBOOKSTATISTICS 39DIMENSIONALITYSAMPLESIZECONSIDERATIONSINPATTERNRECOGNITIONPRACTICE HALL 1999 M PROCEEDINGSTWELFTHINTERNATIONALFLORIDAARTIFICIALINTELLIGENCERESEARCHSOCIETYCONFERENCE FEATURESELECTIONFORMACHINELEARNINGCOMPARINGACORRELATIONBASEDFILTERAPPROACHWRAPPER KOLLER 1996 D TOWARDOPTIMALFEATURESELECTION KIRA 1992 249 256 K ML92PROCEEDINGSNINTHINTERNATIONALWORKSHOPMACHINELEARNING APRACTICALAPPROACHFEATURESELECTION PRADOS 2004 2320 2332 J KIRK 2007 R STATISTICSINTRODUCTION RAMOSPOLLAN 2012 2259 2269 R 2014 BREASTCANCERDIGITALREPOSITORY DEOLIVEIRA 2010 289 297 J HEATH 2001 212 218 M PROCEEDINGSFIFTHINTERNATIONALWORKSHOPDIGITALMAMMOGRAPHY DIGITALDATABASEFORSCREENINGMAMMOGRAPHY COMMITTEE 2003 ACRBREASTIMAGINGREPORTINGDATASYSTEMBREASTIMAGINGATLAS AMERICANCOLLEGERADIOLOGYACRACRBIRADSMAMMOGRAPHY HARALICK 1973 610 621 R LOPEZ 2008 453 460 Y PROGRESSINPATTERNRECOGNITIONIMAGEANALYSISAPPLICATIONS COMPUTERAIDEDDIAGNOSISSYSTEMDETECTBREASTCANCERPATHOLOGICALLESIONS DASH 1997 131 156 M HOLTE 1993 63 91 R MALAR 2012 898 905 E VERMA 2008 947 967 B INTELLIGENTINFORMATIONTECHNOLOGIESCONCEPTSMETHODOLOGIESTOOLSAPPLICATIONS NEURALNETWORKSFORCLASSIFICATIONBENIGNMALIGNANTPATTERSINDIGITALMAMMOGRAMS BELLOTTI 2006 3066 3075 R PAPADOPOULOS 2005 141 150 A PEREZ 2014 209 217 N IEEE2014FEDERATEDCONFERENCECOMPUTERSCIENCEINFORMATIONSYSTEMSFEDCSIS IMPROVINGPERFORMANCEMACHINELEARNINGCLASSIFIERSFORBREASTCANCERDIAGNOSISBASEDFEATURESELECTION PEREZ 2013 867022-1 867022-14 N SPIEMEDICALIMAGING2013 IMPROVINGBREASTCANCERCLASSIFICATIONMAMMOGRAPHYSUPPORTEDAPPROPRIATEVARIABLESELECTIONANALYSIS PING 2004 2303 2308 Z IEEEINTERNATIONALJOINTCONFERENCENEURALNETWORKSVOL3 ANEURALGENETICALGORITHMFORFEATURESELECTIONBREASTABNORMALITYCLASSIFICATIONINDIGITALMAMMOGRAPHY MAVROFORAKIS 2006 145 162 M PEREZ 2012 N 15THINTERNATIONALCONFERENCEEXPERIMENTALMECHANICSICEM15 EVALUATIONFEATURESSELECTIONMETHODSFORBREASTCANCERCLASSIFICATION FU 2005 419 429 J SHI 2008 280 290 J JESNECK 2007 390 398 J GUPTA 2006 1810 1817 S CATARIOUS 2004 1512 1520 D MOURA 2013 561 574 D SALAMA 2012 2 G CHRISTOBEL 2011 24 28 A KIM 2005 392 401 M FUZZYSYSTEMSKNOWLEDGEDISCOVERY OPTIMIZEDFUZZYCLASSIFICATIONUSINGGENETICALGORITHM ABONYI 2003 2195 2207 J XU 2004 953 958 W ADVANCESINNEURALNETWORKSISNN2004 APPLICATIONCMACBASEDNETWORKSMEDICALIMAGECLASSIFICATION SONG 2005 780 789 H ADVANCESINNEURALNETWORKSISNN2005 NEWMETHODOLOGYCOMPUTERAIDEDDIAGNOSTICSYSTEMBREASTCANCER HALL 2009 10 18 M GARCIALOPEZ 2006 477 489 F HWANG 2001 408 J HANDBOOKNEURALNETWORKSIGNALPROCESSING INTRODUCTIONNEURALNETWORKSFORSIGNALPROCESSING DUDA 2000 R PATTERNCLASSIFICATION WANG 2012 933 951 S 2007 81 109 ESTIMATINGDATAPARAMETERSAPPLIEDSTATISTICSUSINGSPSSSTATISTICAMATLABR HASTIE 2005 83 85 T MANN 1947 50 60 H DEMSAR 2006 1 30 J GIBBONS 2011 977 979 J INTERNATIONALENCYCLOPEDIASTATISTICALSCIENCE NONPARAMETRICSTATISTICALINFERENCE JOHN 1994 121 129 G MACHINELEARNINGPROCEEDINGSELEVENTHINTERNATIONALCONFERENCE IRRELEVANTFEATURESSUBSETSELECTIONPROBLEM HOLLANDER 2013 M NONPARAMETRICSTATISTICALMETHODS ABUBAKER 2007 896 899 A IEEEINTERNATIONALCONFERENCESIGNALPROCESSINGCOMMUNICATIONSICSPC2007 TEXTUREBASEDFEATUREEXTRACTIONFORMICROCALCIFICATIONDIGITALMAMMOGRAMIMAGES MOHANTY 2013 303 310 A PEREZX2015X19 PEREZX2015X19X31 PEREZX2015X19XN PEREZX2015X19X31XN item S0933-3657(14)00141-9 S0933365714001419 10.1016/j.artmed.2014.12.004 271219 2015-03-05T15:50:47.892466-05:00 2015-01-01 2015-01-31 true 1626851 MAIN 13 54214 849 656 IMAGE-WEB-PDF 1 si9 120 11 9 si8 805 58 169 si7 331 29 51 si6 481 15 99 si5 744 35 133 si4 120 11 9 si37 223 13 46 si36 203 15 25 si35 363 14 95 si34 1474 58 268 si33 128 11 10 si32 401 34 92 si31 424 34 83 si30 857 32 211 si3 1216 48 208 si29 700 32 194 si28 441 48 72 si27 458 48 69 si26 158 17 14 si25 158 17 14 si24 211 18 24 si23 211 18 24 si22 668 18 208 si21 759 32 162 si20 285 15 58 si2 120 11 9 si19 970 43 199 si18 477 45 87 si17 971 39 196 si16 796 37 168 si15 2421 87 398 si14 679 49 129 si13 969 49 209 si12 728 32 157 si11 927 32 201 si10 860 36 134 si1 1345 67 209 gr4 947311 2251 3333 gr3 618199 2467 3583 gr2 335890 1238 3000 gr1 146926 3590 3333 gr4 97476 509 753 gr3 98438 557 809 gr2 48263 280 678 gr1 18286 405 376 gr1 4400 164 152 gr4 5614 148 219 gr3 6351 151 219 gr2 3234 90 219 ARTMED 1376 S0933-3657(14)00141-9 10.1016/j.artmed.2014.12.004 Elsevier B.V. Fig. 1 Datasets creation; B and M represent benign and malignant class instances. Fig. 2 Applied experimental workflow; CV means cross-validation. Fig. 3 Head-to-head comparison between uFilter (uF) and U-test (UT) methods using the top 10 features of each ranking. Filled box represents significant difference (p <0.05) in the AUC performance. Fig. 4 Behavior of the best classification schemes when increasing the number of features on each dataset. Table 1 Summary of the Wilcoxon Statistical test among all classification schemes for BCDR1 and DDSM1 datasets. Dataset Best scheme AUC Other scheme AUC Wilcoxon (α =0.05) BCDR1 uFilter+SVM 0.8369 U-test+SVM 0.7995 p <0.01 uFilter+FFBP 0.8088 p <0.01 U-test+FFBP 0.7938 p <0.01 uFilter+LDA 0.7906 p <0.01 U-test+LDA 0.7968 p <0.01 uFilter+NB 0.7814 p <0.01 U-test+NB 0.7840 p <0.01 DDSM1 uFilter+SVM 0.80 U-test+SVM 0.7838 p =0.1390 uFilter+FFBP 0.7868 p =0.0986 U-test+FFBP 0.7925 p =0.5149 uFilter+LDA 0.7567 p <0.01 U-test+LDA 0.7832 p =0.0624 uFilter+NB 0.7277 p <0.01 U-test+NB 0.7288 p <0.01 Table 2 Summary of the Wilcoxon Statistical test among all classification schemes for BCDR2 and DDSM2 datasets. Dataset Best scheme AUC Other scheme AUC Wilcoxon (α =0.05) BCDR2 uFilter+FFBP 0.8350 U-test+FFBP 0.7578 p <0.01 uFilter+SVM 0.8332 p =0.6086 U-test+SVM 0.7482 p <0.01 uFilter+LDA 0.8296 p =0.5849 U-test+LDA 0.7613 p <0.01 uFilter+NB 0.8219 p =0.1546 U-test+NB 0.7246 p <0.01 DDSM2 uFilter+FFBP 0.8382 U-test+FFBP 0.8308 p =0.4923 uFilter+SVM 0.7782 p <0.01 U-test+SVM 0.7844 p <0.01 uFilter+LDA 0.8296 p =0.7031 U-test+LDA 0.7881 p <0.01 uFilter+NB 0.7511 p <0.01 U-test+NB 0.8057 p <0.01 Table 3 Summary of the Wilcoxon Statistical test among all classification schemes for BCDR3 and DDSM3 datasets. Dataset Best scheme AUC Other scheme AUC Wilcoxon (α =0.05) BCDR3 uFilter+FFBP 0.8850 U-test+FFBP 0.87 p <0.01 uFilter+SVM 0.8386 p <0.01 U-test+SVM 0.8207 p <0.01 uFilter+LDA 0.8621 p <0.01 U-test+LDA 0.8725 p =0.2131 uFilter+NB 0.8152 p <0.01 U-test+NB 0.8477 p <0.01 DDSM3 uFilter+LDA 0.7819 U-test+LDA 0.7328 p <0.01 uFilter+FFBP 0.7806 p =0.9386 U-test+FFBP 0.6266 p <0.01 uFilter+SVM 0.7795 p =0.8441 U-test+SVM 0.7393 p <0.01 uFilter+NB 0.7706 p =2047 U-test+NB 0.6467 p <0.01 Table 4 Summary of the redundancy analysis. Dataset Best subset of features Redundant features c-Pearson p-Value (α =0.05) Weakly relevant Strongly relevant BCDR1 f4, f12, f15, f21, f7, f10, f3, f6, f18, f8 f21 =f4 f10 =f7,f3 f3 =f7 f18 =f6 0.790.96, −0.92−0.84−0.62 p <0.01 f4, f15 (+), f7, f6, f8 f12 BCDR2 f14, f22, f21, f4, f12, f15, f6, f13, f11, f8 f14 =f22,f13, f11 f21 =f4 f13 =f22 f8 =f6 0.99, 0.56, 0.560.890.550.75 p <0.01 f22, f12 (+), f15 (+), f6, f11 f4 BCDR3 f7, f10, f3, f4, f12, f18, f15, f22, f19, f13 f10 =f7,f3, f22 f3 =f7,f22 f18 =f12 f13 =f7,f10,f3,f22 0.97, −0.94,0.56−0.85, −0.62−0.750.50, 0.57, −0.62, 0.99 p <0.01 f7, f4 (+), f12, f15 (+), f22 f19 DDSM1 f9, f16, f19, f23, f4, f12, f21, f6, f10, f15 f23 =f9,f16,f19 f21 =f4 f6 =f4, f15 f15 =f12 f16 =f19 0.85, 0.94, 0.940.930.56, −0.71−0.790.99 p <0.01 f9 (+), f4, f12, f10 (+), f19 – DDSM2 f7, f19, f16, f23, f9, f3, f1, f5, f12, f8 f23 =f19,f16,f9,f12,f8 f9 =f19,f16,f8 f12 =f9 0.97, 0.98, 0.89, 0.71, 0.510.92, 0.92, 0.610.68 p <0.01 f19, f16, f3 (+), f1 (+), f5 (+), f8 f7 DDSM3 f9, f4, f21, f23, f16, f10, f19, f12, f18, f6 f21 =f9 f23 =f9,f16,f19 f16 =f9,f19 f12 =f9,f4,f18,f6 0.840.78, 0.92, 0.910.85, 0.990.60, 0.56, 0.57, 0.76 p <0.01 f9, f10 (+), f19, f18, f6 f4 (+)Weakly relevant features but non-redundant; c-Pearson is the value of correlation of Pearson; p-value means whether the correlation value is significantly different from zero (i.e. are correlated). Table 5 AUC-based statistical comparisons between the best and optimal subset of features. Dataset Best subset of features AUC Weakly+strongly AUC Wilcoxon (α =0.05) BCDR1 f4, f12, f15, f21, f7, f10, f3, f6, f18, f8 0.839 f4, f15 (+), f7, f6, f8, f12 0.8315 p =0.811 BCDR2 f14, f22, f21, f4, f12, f15, f6, f13, f11, f8 0.835 f22, f12 (+), f15 (+), f6, f11, f4 0.8413 p =0.841 BCDR3 f7, f10, f3, f4, f12, f18, f15, f22, f19, f13 0.885 f7, f4 (+), f12, f15 (+), f22, f19 0.8821 p =0.918 DDSM1 f9, f16, f19, f23, f4, f12, f21, f6, f10, f15 0.8004 f9 (+), f4, f12, f10 (+), f19 0.8001 p =0.982 DDSM2 f7, f19, f16, f23, f9, f3, f1, f5, f12, f8 0.8382 f19, f16, f3 (+), f1 (+), f5 (+), f8, f7 0.8435 p =0.757 DDSM3 f9, f4, f21, f23, f16, f10, f19, f12, f18, f6 0.7806 f9, f10 (+), f19, f18, f6, f4 0.7759 p =0.685 (+)Weakly relevant features but non-redundant. Improving the Mann–Whitney statistical test for feature selection: An approach in breast cancer diagnosis on mammography Noel Pérez Pérez a ⁎ Miguel A. Guevara López b a Augusto Silva b Isabel Ramos c a Institute of Mechanical Engineering and Industrial Management (INEGI), Campus da FEUP, Rua Dr. Roberto Frias, 400, 4200-465 Porto, Portugal Institute of Mechanical Engineering and Industrial Management (INEGI) Campus da FEUP, Rua Dr. Roberto Frias, 400 Porto 4200-465 Portugal b Institute of Electronics and Telematics Engineering of Aveiro, Campus Universitário de Santiago, 3810-193 Aveiro, Portugal Institute of Electronics and Telematics Engineering of Aveiro Campus Universitário de Santiago Aveiro 3810-193 Portugal c Faculty of Medicine – Centro Hospitalar São Joao, Al. Prof. Hernâni Monteiro, 4200-319 Porto, Portugal Faculty of Medicine – Centro Hospitalar São Joao Al. Prof. Hernâni Monteiro Porto 4200-319 Portugal ⁎ Corresponding author. Tel.: +351 229578710; fax: +351 229537352. Objective This work addresses the theoretical description and experimental evaluation of a new feature selection method (named uFilter). The uFilter improves the Mann–Whitney U-test for reducing dimensionality and ranking features in binary classification problems. Also, it presented a practical uFilter application on breast cancer computer-aided diagnosis (CADx). Materials and methods A total of 720 datasets (ranked subsets of features) were formed by the application of the chi-square (CHI2) discretization, information-gain (IG), one-rule (1Rule), Relief, uFilter and its theoretical basis method (named U-test). Each produced dataset was used for training feed-forward backpropagation neural network, support vector machine, linear discriminant analysis and naive Bayes machine learning algorithms to produce classification scores for further statistical comparisons. Results A head-to-head comparison based on the mean of area under receiver operating characteristics curve scores against the U-test method showed that the uFilter method significantly outperformed the U-test method for almost all classification schemes (p <0.05); it was superior in 50%; tied in a 37.5% and lost in a 12.5% of the 24 comparative scenarios. Also, the performance of the uFilter method, when compared with CHI2 discretization, IG, 1Rule and Relief methods, was superior or at least statistically similar on the explored datasets while requiring less number of features. Conclusions The experimental results indicated that uFilter method statistically outperformed the U-test method and it demonstrated similar, but not superior, performance than traditional feature selection methods (CHI2 discretization, IG, 1Rule and Relief). The uFilter method revealed competitive and appealing cost-effectiveness results on selecting relevant features, as a support tool for breast cancer CADx methods especially in unbalanced datasets contexts. Finally, the redundancy analysis as a complementary step to the uFilter method provided us an effective way for finding optimal subsets of features without decreasing the classification performances. Keywords Feature selection methods Mann–Whitney U-test uFilter method Machine learning algorithms Redundancy analysis Breast cancer CADx 1 Introduction Devijver and Kittler define Feature Selection as the problem of “extracting from the raw data the information which is most relevant for classification purposes, in the sense of minimizing the within-class pattern variability while enhancing the between-class pattern variability” [1]. Guyon and Elisseeff consider that “feature selection addresses the problem of finding the most compact and informative set of features, to improve the efficiency or data storage and processing” [2]. During the last decade parallel efforts from researchers in statistics, machine learning, and knowledge discovery have been focused on the problem of feature selection and its influence in machine learning classifiers. The recent advances made in both sensing technologies and machine learning techniques make it possible to design recognition systems, which are capable of performing tasks that could not be performed in the past [2]. Feature selection lies at the center of these advances with applications in the pharmaceutical industry [3,4], oil industry [5,6], speech recognition [7,8], pattern recognition [9,10], biotechnology [11,12] and many other emerging fields with significant impact in health systems for cancer detection [13–17]. In contrast to other dimensionality reduction techniques like those based on projection (e.g. principal component analysis) or compression (e.g. using information theory), feature selection techniques do not alter the original representation of the variables, but merely select a subset of them. Thus, they preserve the original semantics of the variables, hence, offering the advantage of interpretation by a domain expert [18]. There are many potential benefits of feature selection: facilitating data visualization and data understanding, reducing the measurement and storage requirements, reducing training and utilization times, defining the curse of dimensionality to improve the predictions performance [9]. The objectives are related: to avoid overfitting and improve model performance; to provide faster and more cost-effective models, and to gain a deeper insight into the underlying processes that generated the data [18]. Although these benefits, the problem of finding or ranking relevant features is still a challenging task. Regarding their classification, feature selection techniques can be structured into three paradigms, depending on how they combine the feature selection search with the construction of the classification model: wrappers, embedded and filters methods (univariate and multivariate). Wrappers utilize machine learning classifiers as a black box to score subsets of features according to their predictive power. Embedded methods perform feature selection in the process of training and are usually specific to given machine learning classifiers. Filters methods (considered the earliest approaches) use heuristics based on general characteristics of the data rather than machine learning classifiers to evaluate the merit of features [2,9]. Therefore, filter methods in general present lower algorithm complexity and are much faster than wrapper or embedded methods [2,9]. Univariate filter methods, such as chi-square (CHI2) discretization [19], t-test [20], information gain (IG) [21] and gain ratio [22], present two main disadvantages: (1) ignoring the dependencies among features and (2) assuming a given distribution (Gaussian in most cases) from which the samples (observations) have been collected. In addition, to assume a Gaussian distribution includes the difficulties to validate distributional assumptions because of small sample sizes. On the other hand, multivariate filters methods such as: correlation based-feature selection [20,23], Markov blanket filter [24], fast correlation based-feature selection [10], ReliefF [25,26] overcome the problem of ignoring feature dependencies introducing redundancy analysis (models feature dependencies) at some degree, but the improvements are not always significant: domains with large numbers of input variables suffer from the curse of dimensionality and multivariate methods may overfit the data. Also, they are slower and less scalable than univariate methods [2,9]. To overcome these inconveniences we developed the uFilter method. uFilter is an innovative feature selection method for ranking relevant features that assess the relevance of features by computing the separability between class-data distribution of each feature. We address a theoretical description and experimental evaluation of the uFilter method, and it is described a formal framework for understanding the proposed algorithm, which is supported on the statistical model/theory of the non-parametric Mann–Whitney U-test [27]. A software prototype implementation of the uFilter method using these theoretical intuitions is also presented. The uFilter is an univariate filter method that solves some difficulties remaining on previous methods, such as: (1) it is effective in ranking relevant features independently of the samples sizes (tolerant to unbalanced training data); (2) it does not need any type of data normalization; and (3) the most important, it presents a low risk of data overfitting and does not incur the high computational cost of conducting a search through the space of feature subsets as in the wrapper or embedded methods. The remainder of the paper is organized as follows: Section 2 describes in detail the developed uFilter method as well as the experimental methodology for its evaluation in breast cancer databases; Section 3 presents and discusses the experimental results obtained both from the head-to-head statistical comparison between the proposed method and the theoretical basis (named U-test) method and from the global comparison with other well-known feature selection methods. Finally, in Section 4 we outline the principal achievements of the work. 2 Materials and methods 2.1 Databases This work considered two public databases: the Breast Cancer Digital Repository (BCDR) and the Digital Database for Screening Mammography (DDSM). The BCDR is the first wide-ranging annotated Portuguese breast cancer repository, with anonymous cases from medical historical archives supplied by Faculty of Medicine – Centro Hospitalar de São João at University of Porto, Portugal [28,29]. For convenience, the DDSM images used in this study were obtained from the Image Retrieval in Medical Applications (IRMA) project (courtesy of TM Deserno, Dept. of Medical Informatics, RWTH Aachen, Germany) where the original LJPEG images of DDSM were converted to 16 bits portable network graphics format [30,31]. BCDR is composed of 1734 patient cases with mammography and ultrasound images, clinical history, lesion segmentation and selected pre-computed image-based descriptors; each case may have one or more segmented (outlined) region of interest (ROI) associated to a pathological lesion, typically in mediolateral oblique (MLO) and craniocaudal (CC) images of the same breast [28,29]. We used the dataset BCDR-F01 available online at the BCDR website which is composed by 190 patient cases, biopsy proven. DDSM database is composed by 2620 patient cases divided into three categories: normal cases (12 volumes), cancer cases (15 volumes) and benign cases (14 volumes); each case may have one or more associated pathological lesion segmentations, usually in MLO and CC image views of the same breast [30,31]. Due to the wide range of information, we considered a dataset formed with 582 patient cases representing two volumes of cancer and benign cases (random selected). 2.2 Considered features and datasets creation Each instance of the datasets (above mentioned) is composed by a set of 23 image-based descriptors extracted both for the BCDR and DDSM databases. This rather extensive feature list builds upon the radiologists experience and previously reported feature lists embedded in breast cancer computer-aided diagnosis (CADx) systems. Selected descriptors included intensity statistics, shape and texture features computed from segmented pathological lesions in both MLO and CC mammography views. The intensity statistics and shape descriptors were selected according to the radiologists experience (similar to the clinician procedure) and the American College of Radiology (BIRADS-Mammography atlas) [32], which described in detail how to detect/classify pathological lesions. Additionally, texture descriptors were the Halarick's descriptors extracted from the gray-level co-occurrence matrices [33]. An overview of the mathematical formulation is presented below: • Skewness: f 1 = ( 1 / n ) ∑ i = 1 n ( x i − x ¯ ) 3 ( 1 / n ) ∑ i = 1 n ( x i − x ¯ ) 2 3 with x i being the ith-value and x ¯ the sample mean. • Kurtosis: f 2 = ( 1 / n ) ∑ i = 1 n ( x i − x ¯ ) 4 ( ( 1 / n ) ∑ i = 1 n ( x i − x ¯ ) 2 ) 2 − 3 with x i being the ith-value and x ¯ the sample mean. • Circularity: f 3 = 4 π area perimeter 2 • Perimeter: f 4 = length ( E ) with E ⊂ O being the edge pixels. • Elongation: f 5 = m M with m being the minor axis and M the major axis of the ellipse that has the same normalized second central moments as the region surrounded by the contour. • Standard deviation: f 6 = 1 n − 1 ∑ i = 1 n ( x i − x ¯ ) 2 with x i being the gray level intensity of the ith pixel and x ¯ the mean of intensity. • Roughness: f 7 = ( perimenter ) 2 4 π * area • Minimum (f 8 ) and maximum (f 9 ): the minimum and maximum intensity value in the region surrounded by the contour. • Shape: f 10 = perimeter * elongation 8 * area • X centroid: f 11 = min ( x ) + max ( x ) 2 with x being the set of X coordinates of the object's contour. • Entropy: f 12 = − ∑ i = 1 L ∑ j = 1 L p ( i , j ) log ( p ( i , j ) ) with p(i,j) being the probability of pixels with gray-level i occur together to pixels with gray-level j. • X center mass (f 13 ) and Y center mass (f 14 ): normalized X and Y coordinates of the center of mass of O • Angular second moment: f 15 = ∑ i = 1 L ∑ j = 1 L p ( i , j ) 2 with L being the number of gray-levels, and p being the gray-level co-occurrence matrix and, thus, p(i,j) is the probability of pixels with gray-level i occur together to pixels with gray-level j. • Median: f 16 = MED = n + 1 2 , if length ( X ) is odd MED = X n 2 + X n 2 + 1 2 , if length ( X ) is even with X being the set of intensities. • Contrast: f 17 = ∑ i ∑ j ( i − j ) 2 p ( i , j ) with p(i,j) being the probability of pixels with gray-level i occur together to pixels with gray-level j. • Correlation: f 18 = ∑ i ∑ j ( i j ) p ( i , j ) − μ x μ y σ x σ y with μ x , μ y , σ x and σ y being the means and standard deviations of the marginal distribution associated with p(i,j). • Mean: f 19 = 1 n ∑ i = 1 n x i with n being the number of pixels inside the region delimited by the contour and x i being the gray level intensity of the ith pixel inside the contour. • Inverse difference moment: f 20 = ∑ i ∑ j 1 1 + ( i − j ) 2 p ( i , j ) with p(i,j) being the probability of pixels with gray-level i occur together to pixels with gray-level j. • Area: f 21 = | O | with O being the set of pixels that belong to the segmented lesion. • Y centroid: f 22 = min ( Y ) + max ( Y ) 2 • with Y being the set of Y coordinates of the object's contour. • Statistical mode (f 23 ): most frequent intensity value in a segmented ROI (lesion). Taking as start point the two initially formed datasets from BCDR and DDSM, we created six new datasets (three from BCDR and three from DDSM respectively) representing three different configurations: (1) two balanced datasets (same quantity of benign and malignant instances), (2) two unbalanced datasets containing more benign than malignant instances and (3) two unbalanced datasets holding more malignant than benign instances. From the BCDR, we created the BCDR1 dataset comprising 362 features vectors, and the BCDR2 and BCDR3 datasets including a total of 281 features vectors (each one). Besides, from the DDSM database, we formed the DDSM1 dataset holding 582 features vectors, and the DDSM2 and DDSM3 datasets involving a total of 491 features vectors respectively. Fig. 1 shows a detail description of created datasets. 2.3 Feature selection methods Many types of extracted features (e.g. intensity statistics, shape and texture) from mammograms have been used to form subsets of features with significant information about different lesions [13,15,17,34]. However, selecting the most appropriate subset of features is still a very difficult task; usually a satisfactory instead of the optimal feature subset is searched. Dash and Liu in Ref. [35] stated that an optimal subset is always relative to a certain evaluation function. It is mean that an optimal subset chosen using one evaluation function may not be the same as that which uses another evaluation function. An example of this is the work of Ghazavi and Liao [14], which used different evaluation functions for feature selection purposes, including three modalities of mutual correlation, two variants of Welch t-statistic, two variants of Fisher correlation, the independently consistent expression discriminator, and two distance scores. These functions were evaluated on two binary class medical datasets available at UCI repository: the Wisconsin breast cancer and Pima Indians diabetes, and on a particular industrial dataset: the welding Flaw. The reported results highlighted the mutual correlation method as the best feature selector for the Wisconsin breast cancer and welding flaw datasets respectively. Meanwhile, the best result in the Pima Indians diabetes dataset was achieved by either one of the four statistical criteria. Usually, an evaluation function tries to measure the discriminating ability of a feature or a subset to distinguish the different class’ labels. Thus, the use of different evaluation function provides important information about the nature of each feature (respect to the class) in the features space. We selected different methods with different evaluation function, all of them derived from the filter paradigm (independent of classifiers): • CHI2 discretization: this method consists on a justified heuristic for supervised discretization [19]. Numerical features are initially sorted by placing each observed value into its own interval. Then the chi-square statistic is used to determine whether the relative frequencies of the classes in adjacent intervals are similar enough to justify merging. The extent of the merging process is controlled by an automatically set chi-square threshold. The threshold is determined through attempting to maintain the fidelity of the original data. • IG method: the IG measurement normalized with the symmetrical uncertainty coefficient [21] is a symmetrical measure in which the amount of information gained about Y after observing X is equal to the amount of information gained about X after observing Y (a measure of feature−feature intercorrelation). This model is used to estimate the value of an attribute Y for a novel sample (drawn from the same distribution as the training data) and compensates for information gain bias toward attributes with more values. • 1Rule: this method estimates the predictive accuracy of individual features building rules based on a single feature (can be thought of as single level decision trees) [36]. As it is used training and test datasets, it is possible to calculate a classification accuracy for each rule and hence each feature. Then, from the classification scores, a ranked list of features is obtained. Experiments with choosing a selected number of the highest ranked features and using them with common machine learning algorithms showed that, on average, the top three or more features are as accurate as using the original set. This approach is unusual due to the fact that no search is conducted. • Relief: this method uses instance based learning to assign a relevance weight to each feature [25]. Each feature weight reflects its ability to distinguish among the class values. The feature weight is updated according to how well its values distinguish the sampled instance from its nearest hit (instance of the same class) and nearest miss (instance of opposite class). The feature will receive a high weight if it differentiates between instances from different classes and has the same value for instances of the same class. For nominal features it is defined as either 1 (the values are different) or 0 (the values are the same), while for numeric features the difference is the actual difference normalized to the interval [0.1]. 2.4 Machine learning classifiers The discrimination of two different samples is a supervised learning problem, which is defined as the prediction of the value of a function for any valid input after training a learner using examples of input and target output pairs [27]. For the problem at hand, the function has only two discrete values: benign or malignant. Hence the problem of discriminating benign and malignant lesions can be modeled as a two-class classification problem. Among a wide variety of machine learning classifiers that have been applied in mammography-based CADx systems to solve the problem of breast cancer classification; artificial neural networks (ANN) [37–43], support vector machines (SVM) [40,44–46] and linear discriminant analysis (LDA) [16,41,42,47–50] seem to be the most commonly used type of classifiers. Other less used with high performance in breast cancer classification are the Naive Bayes (NB) classifier [37,51–53] and the fuzzy modeling methods [54–57]. However, the latter is very expensive in terms of CPU time consuming, because they are mainly based on rules. An example is the work of Ghazavi and Liao [14] where three fuzzy modeling methods for breast cancer classification were used, achieving a satisfactory AUC value (0.9587) when using the fuzzy k-nearest neighbor algorithm in the Wisconsin breast cancer dataset, but the CPU time consumed was high. We used the ANN, SVM, LDA and NB classifiers implemented and available on the Weka version 3.6 [58]. For all classifiers with the exception of the NB (which is parameterless), a 10-fold cross validation method [59] was applied on the training set for optimizing classifiers’ parameters. A brief description and configuration of employed machine learning classifiers is given here: • The feed forward back-propagation (FFBP) neural network is a particular model of ANN, which provides a nonlinear mapping between its input and output according to the back-propagation error learning algorithm [60]. We used this classifier with the following parameters: neurons on hidden layers were determined according to the equation (attributes+number of classes)/2; one output layer associated with the binary classification (benign or malignant); the sigmoid function was used as transfer function on all layers and the number of iterations (epochs) were optimized in the range of 100–1000 epochs (with an interval increment of 100 units). • SVMs are based on the definition of an optimal hyperplane, which linearly separates the training data. In comparison with other classification methods, a SVM aims to minimize the empirical risk and maximize the distances (geometric margin) of the data points from the corresponding linear decision boundary [60]. The SVM classifier was used with the following settings: the regularization parameter C (cost) was optimized in the range of 10−3–103 and the kernel type was based on a linear function, which provided better results respect to others kernel such as: radial basis, polynomial and sigmoid function (from our experimental experience). • LDA is a traditional method for classification [61]. The basic idea is to try to find an optimal projection (decision boundaries optimized by the error criterion), which can maximize the distances between samples from different classes and minimize the distances between samples from the same class. We used LDA for binary classification, thus, observations were classified by the following linear function: g i ( x ) = W i T * x − c i , 1 ≤ i ≤ 2 where W i T is the transpose of a coefficient vector, x is a feature vector and c i is a constant as the threshold. The values of W i T and c i are determined through the analysis of a training set. Once these values are determined, they can be used to classify the new observations (smallest g i (x) is preferred). • The NB classifier is based on probabilistic models with strong (Naive) independence assumptions, which assumes a class variable depending on the set of input features [62]. This classifier can be trained based on the relative frequencies shown in the training set to get an estimation of the class priors and feature probability distributions. For a test sample, the decision rule will be picking the most probable hypothesis, which is known as the maximum a posteriori decision rule. 2.5 The uFilter method We considered developing the new uFilter feature selection method based on the Mann–Whitney U-test [27], in a first approach, to be applied in binary classification problems. The uFilter algorithm is framed in the univariate filter paradigm since it requires only the computation of n scores and sorting them. Therefore, its time execution (faster) and complexity (lower) are beneficial when is compared to wrapper or embedded methods. The Mann–Whitney U-test is a non-parametric method used to test whether two independent samples of observations are drawn from the same or identical distributions. U-test is based on the idea that the particular pattern exhibited when m number of X random variables and n number of Y random variables are arranged together in increasing order of magnitude provides information about the relationship between their parent populations [27]. The Mann–Whitney test criterion is based on the magnitude of the Y's in relation to the X's (e.g. the position of Y's in the combined ordered sequence). A sample pattern of arrangement where most of the Y's are greater than most of the X's or vice versa would be evidence against random mixing. This would tend to discredit the null hypothesis of identical distribution [63]. An advantage of using this test is that the two samples under consideration may not necessarily have the same number of observations. However, samples with at least 25 instances would be more desirable for statistical analysis, since data distribution follows the normal distribution. For better understanding the theoretical description, we considered a binary class problem (benign and malignant classes) with more than 25 instances per class, thus: Let F ={f 1, f 2, …, f t } a set of features with size t, and let f i ={I c,1, I c,2, …, I c,n } an ordered set of instances (in ascending way) with size n belonging to the ith-feature under analysis, where I c,j represents the value of the feature f i for an individual instance j, and c denotes the class value: Benign (B) and Malignant (M). Then, the uFilter performs a tie analysis in the f i sequence according to the rule: if there are tie elements, their positions are updated by the resultant value of averaging the positions of tied elements; the output sequence is saved in f ′ i . Consequently, summation of benign (S B ) and malignant (S M ) instance positions in the f ′ i sequence was defined by: (1) S B = ∑ j = 1 n B f ′ j (2) S M = ∑ j = 1 n M f ′ j where n B and n M are the totals of benign and malignant instances respectively. Thus, u-values (according to the Mann–Whitney U-test [27]) for each sample are computed as: (3) u B = n B n M + n B ( n B + 1 ) 2 − S B (4) u M = n B n M + n M ( n M + 1 ) 2 − S M As the sample size exceeds 25 instances per class, the original Mann–Whitney U-test [27] selected the minimum between both computed u-values (from Eqs. (3) to (4)) for the calculation of the Z-indicator (see Eqs. (5) or (6)). In this case, only one Z-indicator will be analyzed to accept or reject the null hypothesis at a given level of significance (α =0.05). In contrast with the original U-test, the proposed uFilter method computes both Z-indicators (one by each class) in the following way: (5) Z B = u B − u ¯ σ u (6) Z M = u M − u ¯ σ u where u ¯ is the mean of the sample and the standard deviation is defined as: σ u = n B n M n ( n − 1 ) n 3 − n 12 − ∑ i = 1 k l i 3 − l i 12 where k denotes the total of range having tied elements in f i sequence and l i means the quantity of elements within each kth-range. Finally, the score/weight of the feature f i is calculated as the absolute value of the numerical difference between Z scores (see Eq. (7)). (7) w i = | Z B − Z M | The uFilter algorithm is applied to the whole feature space and the output of the algorithm is the ranking of features established by sorting in descendant way the random sequence of weights ( w ) . In this approach, higher values in Eq. (7) are preferred, because it means the feature has better separability of class-data distributions and therefore higher discrimination power. Otherwise, the class-data distributions is overlapping and finding the decision boundary for future classifications becomes more difficult. Algorithm 1 summarizes the uFilter steps. 2.6 Experimental methodology This section outlines the experimental evaluation of the proposed uFilter method when compared to four well known (classical) feature selection methods on breast cancer diagnosis. Since this research is a multistep modeling procedure, the application of the k-fold cross validation method [59] to the entire sequence of modeling steps guarantees reliable results [64]. In particular, we applied ten times the 10-fold cross validation method before to establish a ranking of features (to avoid giving an unfair advantage to predictors) and classification steps respectively (to prevent overfitting of classifiers to the training set [59]) (see Fig. 2 ). Thus, no samples appear simultaneously in training and test (disjoint test partitions). In this way, individual classifiers will be trained on different training sets, leading to different representations of the input space. Testing on these different input space representations leads to diversity in the resultant classifications for individual samples. The overall procedure for the uFilter evaluation involves five main steps: • Applying the classical Mann–Whitney U-test (U-test), the new proposed uFilter method and four well known feature selection methods: CHI2 discretization [19], IG [21], 1Rule [36] and Relief [25] to the six previously formed breast cancer datasets (see Fig. 2 step 2); • Creating several ranked subset of features using increasing quantities of features. The top N features of each ranking (resultant from the previous step) were used for feeding different classifiers, with N varying from 5 to the total number of features of the dataset, with increments of 5 (see Fig. 2 step 3). • Classifying the generated ranked subset of features using FFBP neural network [60], SVM [60], LDA [61] and NB [62] classifiers for a comparative analysis of AUC scores. All comparisons were using the Wilcoxon statistical test [65,66] to assess the meaningfulness of differences between classification schemes (see Fig. 2 step 3); • Selecting the best classification scheme on datasets (BCDR1, BCDR2, BCDR3, DDSM1, DDSM2 and DDSM3), and thus the best subset of features. In the last step of the experiment, we determined the feature relevance analysis using a two-step procedure involving (1) selecting the best subset of features for each dataset, and (2) performing a redundancy analysis based on the Pearson correlation [67], to determine and eliminate redundant features from relevant ones, and thus to produce the final subset of features. In contrast to the work of Ghazavi and Liao [14], we decided to employ the correlation analysis as a complementary step to the uFilter procedure, instead to an evaluation function for features selection, because in real domains many features have high correlations and thus many are (weakly) relevant and should not be removed [68]. Also, some variables may have a low rank because they are redundant and yet be highly relevant [9]. 3 Results and discussions 3.1 Comparison between uFilter and U-test methods The statistical comparison between uFilter and U-test methods considered only features subsets formed by the top 10 features (empirical threshold) of each ranking. We used a total of 48 ranked subsets of image-based features for feeding four machine learning classifiers. With this, a head-to-head statistical comparison based on the mean of AUC performances over 100 runs produced inspiring results. Fig. 3 shows a boxplot graph representing the statistical comparison (p <0.05) based on the mean of AUC scores between both methods for all classification schemes. 3.1.1 Results on balanced datasets The best classification scheme for BCDR1 dataset was formed by the uFilter method and the SVM classifier (see Fig. 3b). The AUC value of 0.8369 was statistically superior to the best AUC value (0.7995) obtained by the U-test method when combined with the SVM classifier. Also, this combination was statistically better than the remaining classification schemes in the BCDR1 dataset (see Table 1 ). For DDSM1 dataset, the best classification scheme was formed by the uFilter method and the SVM classifier, reaching an AUC score of 0.80. However, this result did not provide statistical evidence to be better than the combination of the U-test method and the SVM classifier, which reached an AUC score of 0.7838 (see Fig. 3b). This combination statistically outperformed only three classification schemes for DDSM1 dataset (see Table 1). 3.1.2 Results on unbalanced datasets The best classification scheme for BCDR2 dataset was formed by the uFilter method and the FFBP neural network, reaching an AUC score of 0.8350. This result was statistically superior to the obtained result by the combination of the U-test method with the FFBP neural network, which provided an AUC score of 0.7578 (see Fig. 3e). In this dataset other classification schemes using the uFilter method stretched satisfactory results with no statistical difference respect to the best scheme (see Table 2 ). Besides, for DDSM2 dataset the best classification performance was obtained by the combination of the uFilter and the FFBP neural network classifier; reaching AUC value of 0.8382 (see Fig. 3e). However, this result did not statistically outperform the obtained result by the combination of the U-test method and the FFBP neural network (AUC value of 0.8308). The comparison among all classification schemes for DDSM2 dataset indicated that the best combination (higher AUC value) was almost statistically superior in all cases (see Table 2). The best classification performance for BCDR3 dataset was provided by the combination of the uFilter method and the FFBP neural network classifier that attained, an AUC score of 0.8850 (see Fig. 3i). This result was statistically superior to the obtained result by the combination of the U-test method and the FFBP neural network, which achieved an AUC score of 0.87. With the exception of the scheme formed by the U-test method and the LDA classifier, which attained a similar AUC performance (0.8725), the best scheme statistically outperformed the remaining classification schemes (see Table 3 ). In the DDSM3 dataset, the best classification scheme was formed by the combination of the uFilter method and the LDA classifier for an AUC value of 0.7819. This classification result showed significant difference with respect to the classification result provided by the combination of the U-test method with the LDA classifier, which reached an AUC value of 0.7328 (see Fig. 3k). Also, the best combination statistically outperformed other obtained results using the U-test method in the classification scheme, and does not indicated statistical evidences of being better than other uFilter combinations (see Table 3). A head-to-head comparison between the proposed uFilter method and the classical Mann Withney U-test [27] (U-test) is well demonstrated in the experiments reported here. As it is shown in Tables 1–3, the uFilter method statistically outperformed the U-test method in a 50%; tied in a 37.5% and lost in a 12.5% of the 24 considered scenarios (see Fig. 3). This circumstance could be related with the assigned weights to each feature in the ranking, e.g. in the BCDR1 dataset, the uFilter method considered the f4 feature (perimeter) as the most relevant feature, meanwhile the U-test method considered it as irrelevant. A similar situation occurs with the f21 feature (area), which was ranked in the top five features by the uFilter and irrelevant by the U-test method respectively. According to the American College of Radiology [32], microcalcification lesions are tiny bright dots in the breast, and masses are very often obscure and greater than microcalcifications. Hence the perimeter and area are important features for discriminating between both lesions. It is clear that the U-test method underestimated both features on unbalanced datasets. In addition, for unbalanced datasets this fact could be associated to the Mann–Whitney test criterion [27], which is based on the magnitude of the relationship between both samples (benign and malignant instances). In the BCDR2, DDSM2, BCDR3 and DDSM3 datasets most of the benign instances are greater than most of the malignant instances or vice versa and this would be evidence against random mixing. Therefore, the U-test method would tend to discredit the null hypothesis of identical distribution [63] and underrate the features weight (like in the balanced datasets). The opposite occur with the uFilter method, which computes the separability between both samples, independently of the number of benign and malignant instances. 3.2 Performance of uFilter versus classical feature selection methods This section aims to compare the new developed uFilter method against four well known (established) feature selection methods. A total of 720 ranked subsets of image-based features were analyzed and the straightforward statistical comparison based on the mean of AUC performances over 100 runs highlighted interesting results for balanced and unbalanced datasets (see Fig. 4 ). 3.2.1 Results on balanced datasets On the BCDR1 dataset, the best classification scheme was obtained when we combine the uFilter method and the SVM classifier using 10 features, obtaining an AUC score of 0.8369. The statistical comparison against the other feature selection methods did not provide significant difference in term of AUC scores: CHI2 discretization (AUC=0.8325, p =0.6717), IG (AUC=0.8324, p =0.6725), 1Rule (AUC=0.8310, p =0.6053) and Relief (AUC=0.8316, p =0.6190). However, the uFilter method reached this result using the top 10 features, while the other methods required a total of 20 features (see Fig. 4a). On the DDSM1 dataset, the combination of the uFilter method and the SVM classifier using the top 10 features provided the best classification performance obtaining an AUC value of 0.8004. This result was not statistically superior to the obtained result by the CHI2 discretization (AUC=0.7893, p =0.2684), IG (AUC=0.7893, p =0.2840) and 1Rule methods (AUC=0.79, p =0.3450), but it was better than the Relief method (AUC=0.7821, p <0.05). Similar to the BCDR1 dataset, the uFilter method reached this result using the top 10 features, while the other methods required a total of 20 features. 3.2.2 Results on unbalanced datasets The higher classification performance in the BCDR2 dataset was achieved by the combination of the uFilter method and the FFBP neural network classifier with a total of 10 features, obtaining an AUC value of 0.8350. However, this result was not statistically superior to the obtained results by the remaining feature selection methods using the same number of features (see Fig. 4b): CHI2 discretization (AUC=0.8342, p =0.7590), IG (AUC=0.8320, p =0.8022), 1Rule (AUC=0.8259, p =0.8259) and Relief (AUC=0.8344, p =0.8402). Similar to the BCDR2 dataset, the higher classification performance in the DDSM2 dataset was obtained by the combination of the uFilter method and the FFBP neural network classifier using a total of 10 features, accomplishment an AUC of 0.8382 (see Fig. 4e). This result did not provide statistical evidences of an AUC improvement respect to the CHI2 discretization (AUC=0.8301, p =8079), IG (AUC=0.8374, p =0.9076), 1Rule (AUC=0.8326, p =0.7470) and Relief methods (AUC=0.8315, p =0.3884). On the other hand, the best classification scheme for the BCDR3 dataset was formed by the combination of the uFilter method and the FFBP neural network using a total of 10 features (see Fig. 4c). The AUC value of 0.8850 was statistically superior respect to the obtained result by the CHI2 discretization (AUC=0.8444, p <0.01), IG (AUC=0.8465, p <0.01), 1Rule (AUC=0.8454, p <0.01) and Relief methods (AUC=0.8347, p <0.01). On the DDSM3 dataset, the best classification performance was obtained by the combination of the IG method and the FFBP neural network classifier using 15 features (AUC value of 0.7945). The AUC-based comparison against the other classification schemes using less number of features (10) indicated no significant difference in the classification performance (see Fig. 4f): CHI2 discretization (AUC=0.7798, p =0.0729), 1Rule (AUC=0.7776, p =0.0551), Relief (AUC=0.7933, p =0.9717) and uFilter (AUC=0.7806, p =0.0796). The global comparison demonstrated that uFilter method statistically outperformed the CHI2 discretization, IG, 1Rule and Relief methods on BCDR1, DDSM1 and BCDR3 datasets, and it was statistically similar on BCDR2, DDSM2 and DDSM3 datasets while requiring less number of features. This circumstance could be related to the particular nature of employed feature selection methods and datasets respectively. We used datasets without any type of data normalization, and some methods could lead to non-reliable results e.g. the CHI2 discretization (which used the chi-square statistical test as the main evaluation function), IG (which is an entropy-based feature evaluation), and 1Rule (which is not likely to enhance the performance of classification schemes that require a search space of greater complexity) methods provided the worst results on BCDR1, DDSM1 and BCDR3 datasets (see Fig. 4). In contrast, the Relief method computes the feature's weight based on a different semantic independent of data normalization (distance to nearest hit and nearest miss), and this explains the good performance of the Relief method in almost all datasets (see Fig. 4). The satisfactory results obtained by the uFilter were expected since it is a non-parametric method and thus is tolerant to non-normalized data. Concerning classifiers performance, results show that the selection of the most appropriate classifier is dependent on the dataset and the feature selection method (see Fig. 4). For balanced datasets, the best results were obtained with de SVM classifier; meanwhile for unbalanced datasets were obtained with the FFBP neural network classifier (see Fig. 4). These results were expected since the SVM classifier is based on the definition of an optimal hyperplane [60], and for a less complex features space (e.g. balanced datasets), it could easily find the corresponding linear decision boundary. On the other hand, for a more complex features space such as those presented on unbalanced datasets, the FFBP neural network demonstrated better capabilities of generalizing [60]. 3.3 Feature relevance analysis The results showed in previous section clearly provide experimental evidence that the uFilter method provided ranked subsets of features with higher discriminant potential. It approximates the set of relevant features by selecting a subset from the top 10 features of each ranking list. According to its linear time complexity in terms of the dimensionality N (total of features), the uFilter method is efficient for high-dimensional data. However, it is incapable of removing redundant features because it is an individual evaluator of features (i.e. it assigns weights according to their degrees of relevance [9]) and as long as features are considered relevant to the class, they will all be selected even though many of them are highly correlated to each other (redundant). In this case, a validation of features’ subsets through a redundancy analysis is convenient. 3.3.1 Features subset validation To efficiently find an optimal subset of features we introduced an analysis of redundancy to decrease the size of the subset of features and keeping prediction accuracy. We achieved this goal using a two-step procedure involving: (1) selecting the best subset of features for each dataset, and (2) performing the redundancy analysis based on the Pearson correlation [67] to determine and eliminate redundant features from relevant ones, and thus to produce a final optimal subset of features. In order to correctly interpret the results, John and Kohavi in [68] defined two degrees of relevance: strong and weak. Strong relevance implies that the feature is indispensable in the sense that it cannot be removed without loss prediction accuracy. Weak relevance (redundant and non-redundant) implies that the feature can sometimes contribute to prediction accuracy. Thus, features are relevant if they are both strongly or weakly relevant and irrelevant otherwise. Irrelevant features can never contribute to prediction accuracy, by definition. As it is shown in Fig. 4 and described in previous section, the relevance analysis based on the proposed uFilter method provided discriminant subsets of features by removing irrelevant ones. Hence, these subsets of features were used as the starting point for the redundancy analysis. Table 4 summarizes the redundancy analysis based on the Pearson correlation [67] for each selected subset of features. It should be pointed out that only higher correlation values were considered in this analysis (more than 0.5 on both positive and negative direction). Correlated features are considered redundant (see Table 4). Therefore, only one of them in the correlated pair is selected together with the non-correlated features to form the weakly relevant subset of features. Hence each weakly relevant subset of features was used for selecting the strongly relevant ones. In the BCDR1 dataset, the entropy (f12) feature was selected as the strongly relevant feature because its absence in the final subset of features significantly decreased the AUC performance from 0.8315 to 0.791 (p <0.01). In the BCDR2 and DDSM3 datasets, the perimeter (f4) feature constituted the strongly relevant feature. Its participation in the final subset significantly increased the AUC performance from 0.81 to 0.835 (p <0.01) and 0.7521 to 0.7806 (p <0.01) respectively. For the BCDR3 dataset, the mean (f19) feature was considered as the strongly relevant feature because its absence significantly reduced the classification performance from an AUC value of 0.885 to 0.8395 (p <0.01). Besides, in the DDSM2 dataset, the strongly relevant feature was the roughness (f7); this feature contributed to a significantly increment of 0.07 (p <0.01) in the AUC performance when it is included in the final subset (AUC value of 0.8382 versus 0.7727 when is left out). Only in the DDSM1 dataset no feature appears as strongly relevant, which means that all features in this subset contributed with similar effort in the classification model. It should be pointed out that removed features can be inferred from Table 4. According to the relevant definition of John and Kohavi [68], we put together both weakly and strongly relevant features to form the optimal subset of features. These subsets were evaluated using the same machine learning classifier employed in the evaluation of its precedent subsets of features (for further comparison). Therefore, optimal subset of features for BCDR1 and DDSM1 datasets used the SVM classifier, and for BCDR2, BCDR3, DDSM2 and DDSM3 datasets used the FFBP neural network respectively. Table 5 summarizes the AUC-based statistical comparison (using the Wilcoxon statistical test [66,69]) between the best subset of features selected by the uFilter method, and its corresponding optimal subset of features after the redundancy analysis. From Table 5, it is possible to conclude that only two optimal subsets of features provided a slight increment in terms of AUC performance, but these results were not significantly superior. Furthermore, the remaining optimal subsets of features did not provide significance difference in the AUC performance. Concerning redundancy analysis, redundant features were detected on every dataset, which means there are some variables providing similar information to the classifier, and thus it is unnecessarily increasing the complexity of the classification model. With the exception of the DDSM1 dataset, it was possible to find the most relevant feature for all the datasets. In the case of the BCDR2 dataset, the perimeter (f4) feature was selected as the most appropriated strongly relevant feature, however it has a unique correlation with the area (f21) feature (c-Pearson value of 0.89). In this case, it is possible to interchange both features (f4 or f21) and select only one of them as the most relevant feature (see Table 4). Likewise, in the DDSM3, the perimeter (f4) feature was selected as the most relevant feature and is correlated with the entropy (f12) feature (c-Pearson value of 0.56), but the entropy (f12) feature is also correlated with others features: maximum (f9), correlation (f18) and standard deviation (f6); under this situation, the selected perimeter (f4) feature is the only one which can be elected as the most relevant feature. This particular effect on both datasets could be explained by the c-Pearson values; the correlation value between perimeter (f4) and area (f21) was high (unique correlation) meanwhile the correlation value between perimeter (f4) and entropy (f12) was low (multi-correlation). It means that it is possible interchanging most relevant features only if there is a unique and strong correlation between them. We considered strongly relevant features as the most important features: perimeter (f4), entropy (f12), mean (f19) and roughness (f7). They consistently appeared at least 3 times (each one) on the six optimal features subsets (see Table 5). This result was expected due to the binary classification problem (benign–malignant classes) investigated in this work. The perimeter and roughness features are considered significant shape descriptors for masses classification i.e. benign masses possess smooth, round, or oval shapes with possible macrolobulations, as opposed to malignant tumors which typically exhibit rough contours with microlobulations, spiculations, and concavities [32]. On the other hand, the entropy and mean features are more likely to be employed for microcalcification classification i.e. the entropy is a feature that represents the texture of the background tissue where the calcifications are embedded in [15,70]; meanwhile, the mean is an intensity statistics descriptor used with higher frequency [46,71] because microcalcifications are tiny brighter dots [32]. Regarding classification performances, the proposed uFilter method was able to produce subsets of features with higher discriminant potential and the redundancy analysis did not improve the prediction accuracy, but decreased the size of the subset of features without significantly decreasing the performance. This result was expected since the uFilter method is an individual evaluator of features (filter paradigm) and it ignores the feature dependencies. This is the main drawback of individual features evaluator methods as is the case of uFilter. 4 Conclusions The new developed uFilter method performed better than the Mann–Whitney U-test (U-test) when applied to reduce and ranking features in binary classification problems. uFilter was validated using several machine learning algorithms such as FFBP neural network, SVM, LDA and NB classifiers over six different (balanced and unbalanced) datasets representative of two different breast cancer repositories. A head-to-head comparison proved that the uFilter method significantly outperformed the U-test method for almost all of the classification schemes. It was superior in 50%; tied in a 37.5% and lost in a 12.5% of the 24 comparative scenarios. Moreover, a global comparison against other four well known feature selection methods (CHI2 discretization, IG, 1Rule and Relief) demonstrated that uFilter statistically outperformed the remaining methods on several datasets (BCDR1, DDSM1 and BCDR3), and it was statistically similar on the BCDR2, DDSM2 and DDSM3 datasets while requiring less number of features. The uFilter method revealed competitive and appealing cost-effectiveness results on selecting relevant features, as a support tool for breast cancer CADx methods especially in unbalanced datasets contexts. Finally, the redundancy analysis as a complementary step to the uFilter method provided us an effective way for finding optimal subsets of features without decreasing the classification performances. Future work will be aimed to: (1) increasing the number of features in benchmarking breast cancer datasets; (2) exploring the performance of uFilter in other knowledge domains and (3) extending uFilter allowing it to be used on multiclass classification problems. Conflict of interest The authors declare that they do not have any conflict of interest. Acknowledgments MSc. Pérez acknowledges “Fundação para a Ciência e a Tecnologia (grant SFRH/BD/48896/2008)” for financial support. Prof. Guevara acknowledges the Cloud Thinking project (CENTRO-07-ST24-FEDER-002031), co-funded by QREN, “Mais Centro” program. Algorithm 1 uFilter method 1. Let F ={f 1, f 2, …, f t } a set of features with size t; 2. Let f i ={I c,1, I c,2, …, I c,n } a set of instances with size n, where I c,j is the value of the feature f i for the instance j, and c denotes the class value (B or M); 3. For each f i a. Initial weight of the feature w i = 0 ; b. Sort (f i ′, ascendant’); c. Perform the tie analysis of resultant in b: f i ′=avg(position of tied elements); d. Compute the summation of benign and malignant instances based on Eqs. (1) and (2); e. Compute u-values based on Eqs. (3) and (4) f. Compute Z-indicators based on Eqs. (5) and (6) g. Updating the weight of the feature based on Eq. (7) 4. End for 5. Output ranking Sort(w,′ descendant’); References [1] P.A. Devijver J. Kittler Pattern recognition: a statistical approach 1982 Prentice/Hall International London, UK [2] I. Guyon A. Elisseeff An introduction to feature extraction I. Guyon M. Nikravesh S. Gunn L. Zadeh Feature extraction vol. 207 2006 Springer Berlin/Heidelberg 1 25 10.1007/978-3-540-35488-8_1 [3] M. Blanco J. Coello H. Iturriaga S. Maspoch C. de la Pezuela Near-infrared spectroscopy in the pharmaceutical industry Analyst 123 1998 135R 150R 10.1039/a802531b [4] F.E. Koehn G.T. Carter The evolving role of natural products in drug discovery Nat Rev Drug Discov 4 2005 206 220 10.1038/nrd1657 [5] H. Hashemi D.M.J. Tax R.P.W. Duin A. Javaherian P. de Groot Gas chimney detection based on improving the performance of combined multilayer perceptron and support vector classifier Nonlinear Process Geophys 15 2008 863 871 10.5194/npg-15-863-2008 [6] Y. Kaifeng L. Wenkai D. Wenlong Z. Shanwen X. Huanqin L. Yanda Hydrocarbon prediction method based on Svm feature selection Nat Gas Ind 24 2004 36 38 [7] K. Chanwoo R.M. Stern Feature extraction for robust speech recognition based on maximizing the sharpness of the power distribution and on power flooring 2010 IEEE International Conference on Acoustics Speech and Signal Processing (ICASSP) Dallas, TX 2010 4574 4577 10.1109/ICASSP.2010.5495570 [8] Y. Pei I. Essa T. Starner J.M. Rehg Discriminative feature selection for hidden Markov models using Segmental Boosting IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP 2008) Las Vegas, NV, USA 2008 2001 2004 10.1109/ICASSP.2008.4518031 [9] I. Guyon A. Elisseeff An introduction to variable and feature selection J Mach Learn Res 3 2003 1157 1182 [10] L. Yu H. Liu Efficient feature selection via analysis of relevance and redundancy J Mach Learn Res 5 2004 1205 1224 [11] M. Holmberg F. Gustafsson E.G. Hornsten F. Winquist L.E. Nilsson L. Ljung Bacteria classification based on feature extraction from sensor data Biotechnol Tech 12 1998 319 324 10.1023/A:1008862617082 [12] R. Dutta E.L. Hines J.W. Gardner P. Boilot Bacteria classification using Cyranose 320 electronic nose BioMed Eng Online 1 2002 4 10.1186/1475-925x-1-4 [13] Y. López A. Novoa M. Guevara A. Silva Breast cancer diagnosis based on a suitable combination of deformable models and artificial neural networks techniques L. Rueda D. Mery J. Kittler Progress in pattern recognition image analysis and applications vol. 4756/2008 2008 Springer Berlin/Heidelberg 803 811 10.1007/978-3-540-76725-1_83 [14] S.N. Ghazavi T.W. Liao Medical data mining by fuzzy modeling with selected features Artif Intell Med 43 2008 195 206 10.1016/j.artmed.2008.04.004 [15] H. Soltanian-Zadeh F. Rafiee-Rad S.D. Pourabdollah-Nejad Comparison of multiwavelet, wavelet, haralick, and shape features for microcalcification classification in mammograms Pattern Recognit 37 2004 1973 1986 10.1016/j.patcog.2003.03.001 [16] J. Wei B. Sahiner L.M. Hadjiiski H.-P. Chan N. Petrick M.A. Helvie Computer-aided detection of breast masses on full field digital mammograms Med Phys 32 2005 2827 2838 10.1118/1.1997327 [17] S.K. Lee P.C. Chung C.I. Chang C.S. Lo T. Lee G.C. Hsu Classification of clustered microcalcifications using a Shape Cognitron neural network Neural Netw 16 2003 121 132 10.1016/S0893-6080(02)00164-8 [18] Y. Saeys I. Inza P. Larranaga A review of feature selection techniques in bioinformatics Bioinformatics 23 2007 2507 2517 10.1093/bioinformatics/btm344 [19] R. Setiono H. Liu CHI2: feature selection and discretization of numeric attributes IEEE Proceedings of the Seventh International Conference on Tools with Artificial Intelligence Herndon, VA 1995 388 391 10.1109/TAI.1995.479783 [20] H. Liu J. Li L. Wong A comparative study on feature selection and classification methods using gene expression profiles and proteomic patterns Genome Inform 13 2002 51 60 [21] W.H. Press B.P. Flannery S.A. Teukolsky W.T. Vetterling Numerical recipes in C 1988 Cambridge University Press Cambridge [22] A.K. Jain B. Chandrasekaran 39 Dimensionality and sample size considerations in pattern recognition practice P.R. Krishnaiah L.N. Kanal Handbook of statistics vol. 2 1982 Elsevier 835 855 10.1016/S0169-7161(82)02042-2 [23] M.A. Hall L.A. Smith Feature selection for machine learning: comparing a correlation-based filter approach to the wrapper Proceedings of the Twelfth International Florida Artificial Intelligence Research Society Conference AAAI Press, Orlando Florida, USA 1999 [24] D. Koller M. Sahami Toward optimal feature selection 1996 Stanford InfoLab, Technical report 1996–77 [25] K. Kira L.A. Rendell A practical approach to feature selection D. Sleeman P. Edwards ML92 Proceedings of the ninth international workshop on Machine learning 1992 Morgan Kaufmann Publishers Inc. San Francisco, CA, USA 249 256 [26] J. Prados A. Kalousis J.C. Sanchez L. Allard O. Carrette M. Hilario Mining mass spectra for diagnosis and biomarker discovery of cerebral accidents Proteomics 4 2004 2320 2332 10.1002/pmic.200400857 [27] R.E. Kirk Statistics: an introduction fifth ed. 2007 Thomson/Wadsworth Belmont, CA, USA [28] R. Ramos-Pollan M.A. Guevara-Lopez C. Suarez-Ortega G. Diaz-Herrero J.M. Franco-Valiente M. Rubio-Del-Solar Discovering mammography-based machine learning classifiers for breast cancer diagnosis J Med Syst 36 2012 2259 2269 10.1007/s10916-011-9693-2 [29] Breast cancer digital repository 2014 [accessed 02.01.14] [30] J.E. de Oliveira A.M. Machado G.C. Chavez A.P. Lopes T.M. Deserno A. Araujo Ade MammoSys: a content-based image retrieval system using breast density patterns Comput Methods Progr Biomed 99 2010 289 297 10.1016/j.cmpb.2010.01.005 [31] M. Heath K. Bowyer D. Kopans R. Moore W.P. Kegelmeyer The digital database for screening mammography M.J. Yaffe Proceedings of the Fifth International Workshop on Digital Mammography 2001 Medical Physics Publishing 212 218 [32] Committee American College of Radiology (ACR) ACR BIRADS – mammography A.C.o. Radiology ACR breast imaging reporting and data system, breast imaging atlas 2003 American College of Radiology Reston, VA [33] R.M. Haralick K. Shanmuga I. Dinstein Textural features for image classification IEEE Trans Syst Man Cybern Smc3 1973 610 621 10.1109/Tsmc.1973.4309314 [34] Y. López A. Novoa M. Guevara N. Quintana A. Silva Computer aided diagnosis system to detect breast cancer pathological lesions J. Ruiz-Shulcloper W. Kropatsch Progress in pattern recognition, image analysis and applications vol. 5197 2008 Springer Berlin/Heidelberg 453 460 10.1007/978-3-540-85920-8_56 [35] M. Dash H. Liu Feature selection for classification Intell Data Anal 1 1997 131 156 10.3233/IDA-1997-1302 [36] R.C. Holte Very simple classification rules perform well on most commonly used datasets Mach Learn 11 1993 63 91 10.1023/A:1022631118932 [37] E. Malar A. Kandaswamy D. Chakravarthy A. Giri Dharan A novel approach for detection and classification of mammographic microcalcifications using wavelet analysis and extreme learning machine Comput Biol Med 42 2012 898 905 10.1016/j.compbiomed.2012.07.001 [38] B. Verma R. Panchal Neural networks for the classification of benign and malignant patters in digital mammograms V. Sugumaran Intelligent information technologies: concepts, methodologies, tools, and applications 2008 IGI Global Hershey, NY, USA 947 967 10.4018/978-1-59904-941-0.ch056 [39] R. Bellotti F. De Carlo S. Tangaro G. Gargano G. Maggipinto M. Castellano A completely automated CAD system for mass detection in a large mammographic database Med Phys 33 2006 3066 3075 [40] A. Papadopoulos D.I. Fotiadis A. Likas Characterization of clustered microcalcifications in digitized mammograms using neural networks and support vector machines Artif Intell Med 34 2005 141 150 10.1016/j.artmed.2004.10.001 [41] N. Pérez M.A. Guevara A. Silva I. Ramos J. Loureiro Improving the performance of machine learning classifiers for Breast Cancer diagnosis based on feature selection M. Ganzha L. Maciaszek M. Paprzycki IEEE 2014 Federated Conference on Computer Science and Information Systems (FedCSIS) Warsaw, Poland 2014 209 217 10.15439/2014F249 [42] N. Pérez M.A. Guevara A. Silva Improving breast cancer classification with mammography, supported on an appropriate variable selection analysis C.L. Novak S. Aylward SPIE medical imaging 2013 2013 International Society for Optics and Photonics Lake Buena Vista (Orlando Area), Florida, USA 867022-1 867022-14 10.1117/12.2007912 [43] Z. Ping B. Verma K. Kuldeep A neural-genetic algorithm for feature selection and breast abnormality classification in digital mammography IEEE International Joint Conference on Neural Networks, vol. 3 2004 2303 2308 10.1109/IJCNN.2004.1380985 [44] M.E. Mavroforakis H.V. Georgiou N. Dimitropoulos D. Cavouras S. Theodoridis Mammographic masses characterization based on localized texture and dataset fractal analysis using linear, neural and support vector machine classifiers Artif Intell Med 37 2006 145 162 10.1016/j.artmed.2006.03.002 [45] N. Pérez M.A. Guevara A. Silva Evaluation of features selection methods for breast cancer classification J. Silva M. Vaz 15th International Conference on Experimental Mechanics (ICEM15) 2012 Porto Portugal [46] J.C. Fu S.K. Lee S.T. Wong J.Y. Yeh A.H. Wang H.K. Wu Image segmentation feature selection and pattern classification for mammographic microcalcifications Comput Med Imaging Graphics 29 2005 419 429 10.1016/j.compmedimag.2005.03.002 [47] J. Shi B. Sahiner H.P. Chan J. Ge L. Hadjiiski M.A. Helvie Characterization of mammographic masses based on level set segmentation with new image features and patient information Med Phys 35 2008 280 290 10.1118/1.2820630 [48] J.L. Jesneck J.Y. Lo J.A. Baker Breast mass lesions: computer-aided diagnosis models with mammographic and sonographic descriptors Radiology 244 2007 390 398 10.1148/radiol.2442060712 [49] S. Gupta P.F. Chyn M.K. Markey Breast cancer CADx based on BI-RAds descriptors from two mammographic views Med Phys 33 2006 1810 1817 [50] D.M. Catarious Jr. A.H. Baydush C.E. Floyd Jr. Incorporation of an iterative, linear segmentation routine into a mammographic mass CAD system Med Phys 31 2004 1512 1520 [51] D. Moura M. Guevara López An evaluation of image descriptors combined with clinical data for breast cancer diagnosis Int J Comput Assist Radiol Surg 8 2013 561 574 10.1007/s11548-013-0838-2 [52] G.I. Salama M. Abdelhalim M.A.-e. Zeid Breast cancer diagnosis on three different datasets using multi-classifiers Breast Cancer (WDBC) 32 2012 2 [53] A. Christobel An empirical comparison of data mining classification methods Int J Comput Inf Syst 3 2 2011 24 28 [54] M. Kim J. Ryu Optimized fuzzy classification using genetic algorithm L. Wang Y. Jin Fuzzy systems and knowledge discovery vol. 3613 2005 Springer Berlin Heidelberg 392 401 10.1007/11539506_51 [55] J. Abonyi F. Szeifert Supervised fuzzy clustering for the identification of fuzzy classifiers Pattern Recognit Lett 24 2003 2195 2207 10.1016/S0167-8655(03)00047-3 [56] W. Xu S. Xia H. Xie Application of CMAC-based networks on medical image classification F.-L. Yin J. Wang C. Guo Advances in neural networks – ISNN 2004 vol. 3173 2004 Springer Berlin Heidelberg 953 958 10.1007/978-3-540-28647-9_157 [57] H. Song S. Lee D. Kim G. Park New methodology of computer aided diagnostic system on breast cancer J. Wang X.-F. Liao Z. Yi Advances in neural networks – ISNN 2005 vol. 3498 2005 Springer Berlin Heidelberg 780 789 10.1007/11427469_124 [58] M. Hall E. Frank G. Holmes B. Pfahringer P. Reutemann I.H. Witten The WEKA data mining software: an update ACM SIGKDD Explor Newslett 11 2009 10 18 10.1145/1656274.1656278 [59] F. Garcı́a López M. Garcı́a Torres B. Melián Batista J.A. Moreno Pérez J.M. Moreno-Vega Solving feature subset selection problem by a Parallel Scatter Search Eur J Oper Res 169 2006 477 489 10.1016/j.ejor.2004.08.010 [60] J.-N. Hwang Introduction to neural networks for signal processing Y.H. Hu J.-N. Hwang Handbook of neural network signal processing 2001 CRC Press Boca Raton, Florida, USA 408 [61] R.O. Duda P.E. Hart D.G. Stork Pattern classification 2nd ed. 2000 Wiley-Interscience New York, NY, USA [62] S. Wang R.M. Summers Machine learning and radiology Med Image Anal 16 2012 933 951 10.1016/j.media.2012.02.005 [63] J.P. Marques de Sá Estimating data parameters applied statistics using SPSS, STATISTICA, MATLAB and R 2007 Springer Berlin/Heidelberg 81 109 10.1007/978-3-540-71972-4_3 [64] T. Hastie R. Tibshirani J. Friedman J. Franklin The elements of statistical learning: data mining, inference and prediction Math Intell 27 2005 83 85 [65] H.B. Mann D.R. Whitney On a test of whether one of two random variables is stochastically larger than the other Ann Math Stat 18 1947 50 60 10.1214/aoms/1177730491 [66] J. Demsar Statistical comparisons of classifiers over multiple data sets J Mach Learn Res 7 2006 1 30 [67] J. Gibbons S. Chakraborti Nonparametric statistical inference M. Lovric International encyclopedia of statistical science 2011 Springer Berlin Heidelberg 977 979 10.1007/978-3-642-04898-2_420 [68] G.H. John R. Kohavi K. Pfleger Irrelevant features and the subset selection problem W.W. Cohen H. Hirsh Machine Learning, Proceedings of the Eleventh International Conference 1994 Morgan Kaufmann, Rutgers University New Brunswick, NJ, USA 121 129 [69] M. Hollander D. Wolfe Nonparametric statistical methods 3rd ed. 2013 John Wiley & Sons Hoboken, New Jersey, USA [70] A. AbuBaker R. Qahwaji S. Ipson Texture-based feature extraction for the microcalcification from digital mammogram images IEEE International Conference on Signal Processing and Communications (ICSPC 2007) Dubai, United Arab Emirates 2007 896 899 10.1109/ICSPC.2007.4728464 [71] A. Mohanty M. Senapati S. Lenka An improved data mining technique for classification and detection of breast cancer from mammograms Neural Comput Appl 22 2013 303 310 10.1007/s00521-012-0834-4 "
    },
    {
        "doc_title": "Improving the performance of machine learning classifiers for Breast Cancer diagnosis based on feature selection",
        "doc_scopus_id": "84912103556",
        "doc_doi": "10.15439/2014F249",
        "doc_eid": "2-s2.0-84912103556",
        "doc_date": "2014-10-21",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Information Systems",
                "area_abbreviation": "COMP",
                "area_code": "1710"
            }
        ],
        "doc_keywords": [
            "Breast cancer classifications",
            "Breast cancer diagnosis",
            "Building machines",
            "Feature selection methods",
            "Feeding machines",
            "Image-based features",
            "Receiver operating characteristic curves",
            "Search spaces"
        ],
        "doc_abstract": "© 2014 Polish Information Processing Society.This paper proposed a comprehensive algorithm for building machine learning classifiers for Breast Cancer diagnosis based on the suitable combination of feature selection methods that provide high performance over the Area Under receiver operating characteristic Curve (AUC). The new developed method allows both for exploring and ranking search spaces of image-based features, and selecting subsets of optimal features for feeding Machine Learning Classifiers (MLCs). The method was evaluated using six mammography-based datasets (containing calcifications and masses lesions) with different configurations extracted from two public Breast Cancer databases. According to the Wilcoxon Statistical Test, the proposed method demonstrated to provide competitive Breast Cancer classification schemes reducing the number of employed features for each experimental dataset.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Clinical data mining in small hospital PACS: Contributions for radiology department improvement",
        "doc_scopus_id": "84945432008",
        "doc_doi": "10.4018/978-1-4666-6339-8.ch003",
        "doc_eid": "2-s2.0-84945432008",
        "doc_date": "2014-08-31",
        "doc_type": "Book Chapter",
        "doc_areas": [
            {
                "area_name": "Medicine (all)",
                "area_abbreviation": "MEDI",
                "area_code": "2700"
            }
        ],
        "doc_keywords": [],
        "doc_abstract": "© 2015 by IGI Global. All rights reserved.Technological developments in the medical imaging acquisition and storage process have triggered the use of PACS (Picture Archiving and Communication Systems) with gradually larger archives. Nowadays, there is data stored in the DICOM (Digital Imaging and Communication in Medicine) file that is not searchable using the traditional PACS database. However, it may represent an important source of information for continuous professional practice improvement. The use of DICOM Data Mining tools has been a valuable asset to analyze the information stored in the DICOM file and can result in gathering important data for the professional practice improvement. These tools can also contribute to the PACS information audit and facilitate access to relevant clinical data within programs for quality continuous improvement. By allowing the construction of multiple views over data repository in a flexible and quickly way and with the possibility to export data for further statistical analysis, Dicoogle permits the identification of data and process inconsistencies that can contribute to radiology department improvement, such as in dose surveillance and patient safety programs and image quality control initiatives. However, the assessment of relevant data for practice improvement must take into account several factors related to the informational environment, professional reality, and healthcare goals and mission. This chapter describes a method to examine and perform studies over a medical imaging repository. Moreover, a case study of a small hospital where the obtained results are discussed is shown.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Content-based image retrieval for clinical applications: An overview of current approaches and challenges",
        "doc_scopus_id": "84893496321",
        "doc_doi": "10.2174/15734056091310281214",
        "doc_eid": "2-s2.0-84893496321",
        "doc_date": "2013-12-01",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Internal Medicine",
                "area_abbreviation": "MEDI",
                "area_code": "2724"
            },
            {
                "area_name": "Radiology, Nuclear Medicine and Imaging",
                "area_abbreviation": "MEDI",
                "area_code": "2741"
            }
        ],
        "doc_keywords": [],
        "doc_abstract": "Digital medical imaging has become one of the most important tools for medical diagnosis. However, the ongoing evolution in both storage and modality devices has had as consequence that enormous amounts of imaging data are being produced. The existence of large sets of data coupled with the limited query capabilities provided by the standard tools and protocols poses problems for radiologists and has shifted the research focus from data availability towards data accessibility. Content-based image retrieval (CBIR) systems have been heralded as a solution that is able to cope with the increasingly larger volumes of information present in medical repositories and assist radiologists with decision support. While generic, extensible CBIR frameworks that work natively with Picture Archive and Communication Systems (PACS) are scarce, developments are happening at a fast pace and several systems have been implemented with some degree of success. Based on the literature available, we provide an overview of such CBIR systems, architecture and implementation techniques, with an emphasis on systems oriented towards usage in a clinical domain. We conclude with an analysis of some of the challenges that still need to be overcome in order to bring this technology to a medical audience. © 2013 Bentham Science Publishers.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Multi vendor DICOM metadata access: A multi site hospital approach using Dicoogle",
        "doc_scopus_id": "84887886530",
        "doc_doi": null,
        "doc_eid": "2-s2.0-84887886530",
        "doc_date": "2013-11-25",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Computer Networks and Communications",
                "area_abbreviation": "COMP",
                "area_code": "1705"
            },
            {
                "area_name": "Information Systems",
                "area_abbreviation": "COMP",
                "area_code": "1710"
            }
        ],
        "doc_keywords": [
            "DICOM",
            "Digital imaging and communication in medicines",
            "Healthcare facility",
            "Heterogeneous database",
            "PACS",
            "Picture archiving and communication systems (PACS)",
            "Quality initiatives",
            "Radiology departments"
        ],
        "doc_abstract": "The Radiology departments are increasingly taking advantage of Information Technologies (IT) to enhance the efficiency and quality of patient care services. These IT systems are normally able to handle huge amounts of digital data and to extract relevant fingerprints useful to improve the quality of clinical practice. However, they provide multiple and heterogeneous databases and informational environments, namely regarding to the information stored in Picture Archiving and Communication Systems (PACS). The heterogeneous of environments make the access to the information a challenge to extract relevant data. This paper presents the deployment and validation process of the Dicoogle system in two health care facilities. This system represents a new approach able to collect and index information from distinct PACS archives, developed on top of Dicoogle, which allow the construction of multiple views over data repositories according to the standard Digital Imaging and Communication in Medicine (DICOM), in a flexible and fast way. The developed methodology can contribute to improve the use of DICOM metadata, stored over disperse PACS of radiology departments, which otherwise not be used in productivity, efficiency and quality initiatives at radiology departments. © 2013 AISTI.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Improving breast cancer classification with mammography, supported on an appropriate variable selection analysis",
        "doc_scopus_id": "84878404694",
        "doc_doi": "10.1117/12.2007912",
        "doc_eid": "2-s2.0-84878404694",
        "doc_date": "2013-06-05",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Electronic, Optical and Magnetic Materials",
                "area_abbreviation": "MATE",
                "area_code": "2504"
            },
            {
                "area_name": "Condensed Matter Physics",
                "area_abbreviation": "PHYS",
                "area_code": "3104"
            },
            {
                "area_name": "Computer Science Applications",
                "area_abbreviation": "COMP",
                "area_code": "1706"
            },
            {
                "area_name": "Applied Mathematics",
                "area_abbreviation": "MATH",
                "area_code": "2604"
            },
            {
                "area_name": "Electrical and Electronic Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2208"
            }
        ],
        "doc_keywords": [
            "Back propagation neural networks",
            "Breast cancer classifications",
            "Classification performance",
            "Classification scheme",
            "Comparative performance",
            "Descriptors",
            "Receiver operating characteristics",
            "Variable selection"
        ],
        "doc_abstract": "This work addresses the issue of variable selection within the context of breast cancer classification with mammography. A comprehensive repository of feature vectors was used including a hybrid subset gathering image-based and clinical features. It aimed to gather experimental evidence of variable selection in terms of cardinality, type and find a classification scheme that provides the best performance over the Area Under Receiver Operating Characteristics Curve (AUC) scores using the ranked features subset. We evaluated and classified a total of 300 subsets of features formed by the application of Chi-Square Discretization, Information-Gain, One-Rule and RELIEF methods in association with Feed-Forward Backpropagation Neural Network (FFBP), Support Vector Machine (SVM) and Decision Tree J48 (DTJ48) Machine Learning Algorithms (MLA) for a comparative performance evaluation based on AUC scores. A variable selection analysis was performed for Single-View Ranking and Multi-View Ranking groups of features. Features subsets representing Microcalcifications (MCs), Masses and both MCs and Masses lesions achieved AUC scores of 0.91, 0.954 and 0.934 respectively. Experimental evidence demonstrated that classification performance was improved by combining image-based and clinical features. The most important clinical and image-based features were StromaDistortion and Circularity respectively. Other less important but worth to use due to its consistency were Contrast, Perimeter, Microcalcification, Correlation and Elongation. © 2013 SPIE.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Digital imaging systems for plain radiography",
        "doc_scopus_id": "84949180458",
        "doc_doi": "10.1007/978-1-4614-5067-2",
        "doc_eid": "2-s2.0-84949180458",
        "doc_date": "2013-06-01",
        "doc_type": "Book",
        "doc_areas": [
            {
                "area_name": "Medicine (all)",
                "area_abbreviation": "MEDI",
                "area_code": "2700"
            },
            {
                "area_name": "Biochemistry, Genetics and Molecular Biology (all)",
                "area_abbreviation": "BIOC",
                "area_code": "1300"
            }
        ],
        "doc_keywords": [
            "Computed radiography",
            "Digital imaging system",
            "Digital radiography",
            "Digital technologies",
            "Digital x-ray detector",
            "Exposure parameters",
            "Radiological process",
            "Technological methods"
        ],
        "doc_abstract": "© Springer Science+Business Media New York 2013. All rights are reserved.Advances in digital technology led to the development of digital x-ray detectors that are currently in wide use for projection radiography, including Computed Radiography (CR) and Digital Radiography (DR). Digital Imaging Systems for Plain Radiography addresses the current technological methods available to medical imaging professionals to ensure the optimization of the radiological process concerning image quality and reduction of patient exposure. Based on extensive research by the authors and reference to the current literature, the book addresses how exposure parameters influence the diagnostic quality in digital systems, what the current acceptable radiation doses are for useful diagnostic images, and at what level the dose could be reduced to maintain an accurate diagnosis. The book is a valuable resource for both students learning the field and for imaging professionals to apply to their own practice while performing radiological examinations with digital systems.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Dicoogle, a Pacs Featuring Profiled Content Based Image Retrieval",
        "doc_scopus_id": "84877095473",
        "doc_doi": "10.1371/journal.pone.0061888",
        "doc_eid": "2-s2.0-84877095473",
        "doc_date": "2013-05-06",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Biochemistry, Genetics and Molecular Biology (all)",
                "area_abbreviation": "BIOC",
                "area_code": "1300"
            },
            {
                "area_name": "Agricultural and Biological Sciences (all)",
                "area_abbreviation": "AGRI",
                "area_code": "1100"
            },
            {
                "area_name": "Multidisciplinary",
                "area_abbreviation": "MULT",
                "area_code": "1000"
            }
        ],
        "doc_keywords": [],
        "doc_abstract": "Content-based image retrieval (CBIR) has been heralded as a mechanism to cope with the increasingly larger volumes of information present in medical imaging repositories. However, generic, extensible CBIR frameworks that work natively with Picture Archive and Communication Systems (PACS) are scarce. In this article we propose a methodology for parametric CBIR based on similarity profiles. The architecture and implementation of a profiled CBIR system, based on query by example, atop Dicoogle, an open-source, full-fletched PACS is also presented and discussed. In this solution, CBIR profiles allow the specification of both a distance function to be applied and the feature set that must be present for that function to operate. The presented framework provides the basis for a CBIR expansion mechanism and the solution developed integrates with DICOM based PACS networks where it provides CBIR functionality in a seamless manner. © 2013 Valente et al.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Clinical data mining in small hospital PACS: Contributions for radiology department improvement",
        "doc_scopus_id": "84898329665",
        "doc_doi": "10.4018/978-1-4666-3667-5.ch016",
        "doc_eid": "2-s2.0-84898329665",
        "doc_date": "2013-03-31",
        "doc_type": "Book Chapter",
        "doc_areas": [
            {
                "area_name": "Medicine (all)",
                "area_abbreviation": "MEDI",
                "area_code": "2700"
            },
            {
                "area_name": "Health Professions (all)",
                "area_abbreviation": "HEAL",
                "area_code": "3600"
            }
        ],
        "doc_keywords": [
            "Clinical data minings",
            "Continuous improvements",
            "Data-mining tools",
            "Digital imaging and communication in medicines",
            "Information audit",
            "Professional practices",
            "Radiology departments",
            "Technological development"
        ],
        "doc_abstract": "© 2013, IGI Global.Technological developments in the medical imaging acquisition and storage process have triggered the use of PACS (Picture Archiving and Communication Systems) with gradually larger archives. Nowadays, there is data stored in the DICOM (Digital Imaging and Communication in Medicine) file that is not searchable using the traditional PACS database. However, it may represent an important source of information for continuous professional practice improvement. The use of DICOM Data Mining tools has been a valuable asset to analyze the information stored in the DICOM file and can result in gathering important data for the professional practice improvement. These tools can also contribute to the PACS information audit and facilitate access to relevant clinical data within programs for quality continuous improvement. By allowing the construction of multiple views over data repository in a flexible and quickly way and with the possibility to export data for further statistical analysis, Dicoogle permits the identification of data and process inconsistencies that can contribute to radiology department improvement, such as in dose surveillance and patient safety programs and image quality control initiatives. However, the assessment of relevant data for practice improvement must take into account several factors related to the informational environment, professional reality, and healthcare goals and mission. This chapter describes a method to examine and perform studies over a medical imaging repository. Moreover, a case study of a small hospital where the obtained results are discussed is shown.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Validation of a dental image-analyzer tool to measure the radiographic defect angle of the intrabony defect in periodontitis patients",
        "doc_scopus_id": "84867231804",
        "doc_doi": "10.1111/j.1600-0765.2012.01483.x",
        "doc_eid": "2-s2.0-84867231804",
        "doc_date": "2012-12-01",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Periodontics",
                "area_abbreviation": "DENT",
                "area_code": "3506"
            }
        ],
        "doc_keywords": [],
        "doc_abstract": "Background and Objective: A report describing the software Dental Image Analyzer (DIA) was published in this journal in 2009. A new function - measurement of the periodontal intrabony defect angle - was added to the software in 2010. The purpose of this study was to investigate whether measurements of the radiographic intrabony defect angle using digital radiographs and the newly developed DIA tool were comparable with measurements obtained using the conventional protractor method. Material and Methods: The baseline radiographic defect angle of intrabony defects was measured conventionally, using a protractor, in 60 selected teeth from 47 patients and then digitally using the newly developed DIA tool. The measurements were made independently by four experienced dentists. The radiographic defect angle of intrabony defects was measured after the three anatomical landmarks were identified, namely the cemento-enamel junction, the top of the crest and the bottom of the defect. Results: Both methods showed a high interexaminer reliability for measurements of the radiographic defect angle of intrabony defects (intraclass correlation coefficient >0.97). Moreover, both methods showed high reliability (intraclass correlation coefficient >0.96). On the other hand, the new DIA tool, compared with the conventional method, exhibited high sensitivity (0.92) and high specificity (0.91) in selecting defects of ≥37° or <37°. Analysis of the time taken for measurements revealed significant differences between the two methods, with the protractor method being more time consuming. Conclusions: This study provided evidence for the lack of a significant difference between the conventional method and the DIA tool for radiographic measurement of intrabony defects. However, digital analysis was significantly faster. © 2012 John Wiley & Sons A/S.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Segmentation and analysis of the oral and nasal cavities from MR time sequences",
        "doc_scopus_id": "84864125184",
        "doc_doi": "10.1007/978-3-642-31298-4_26",
        "doc_eid": "2-s2.0-84864125184",
        "doc_date": "2012-07-27",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Dynamic aspects",
            "Large images",
            "MR images",
            "Nasal cavity",
            "Nasal vowels",
            "Oral cavity",
            "Real-Time MRI",
            "Segmentation tool",
            "Speech production",
            "Temporal resolution",
            "Time sequences",
            "Time-consuming tasks",
            "Vocal-tracts"
        ],
        "doc_abstract": "The study of dynamic aspects of speech production in Portuguese is very important to characterize vowel nasalization. In this context, the analysis of velum movement remains a challenging task and only a few studies present articulatory descriptions of Portuguese nasal vowels. Advances in real-time MRI (magnetic resonance imaging) allow the acquisition of vocal tract images with reasonable spatial and temporal resolution to enable observation and quantification of articulatory movements. The resulting data consists of large image sequences and the structures of interest (e.g., oral cavity) have to be identified (segmented) throughout to enable analysis which can be a time consuming task. This article presents a segmentation tool for real-time MR image sequences of the oral and nasal cavities. The proposed tool has been implemented using MevisLab and provides features for the analysis of the resulting data. © 2012 Springer-Verlag.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Production and modeling of the European Portuguese palatal lateral",
        "doc_scopus_id": "84858404691",
        "doc_doi": "10.1007/978-3-642-28885-2_36",
        "doc_eid": "2-s2.0-84858404691",
        "doc_date": "2012-03-22",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Acoustic modeling",
            "Area function",
            "Convex shapes",
            "Cross sectional area",
            "European Portuguese",
            "Frequency ranges",
            "Lateral compression",
            "magnetic ressonance",
            "MRI Image",
            "palatal lateral",
            "Pole-zero",
            "Vocal-tracts"
        ],
        "doc_abstract": "In this study, an articulatory characterization of the palatal lateral is provided, using MRI images of the vocal tract acquired during the production of /L/ by several speakers of European Portuguese. The production of this sound involves: a complete linguo-alveolopalatal closure; inward lateral compression of the tongue and a convex shape of the posterior tongue body, allowing airflow around the sides of the tongue; large cross-sectional areas in the upper pharyngeal and velar regions. The lengths and area functions derived from MRI are analysed and used to model the articulatory-acoustic relations involved in the production of /L/. The results obtained in the first simulations show that the vocal-tract model (VTAR) is reasonably able to estimate the frequencies of the first formants and zeros. The lateral channels combined with the supralingual cavity create pole-zero clusters around and above F3, in the frequency range of 2-4.5 kHz. © 2012 Springer-Verlag.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Real-time MRI for Portuguese: Database, methods and applications",
        "doc_scopus_id": "84858377622",
        "doc_doi": "10.1007/978-3-642-28885-2_35",
        "doc_eid": "2-s2.0-84858377622",
        "doc_date": "2012-03-22",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "European Portuguese",
            "laterals",
            "nasal vowels",
            "Real-Time MRI",
            "trills"
        ],
        "doc_abstract": "In this paper, we present a database of synchronized audio and Real-Time Magnetic Resonance Imaging (RT-MRI) in order to study dynamic aspects of the production of European Portuguese (EP) sounds. Currently, data have been acquired from one native speaker of European Portuguese. The speech corpus was primarily designed to investigate nasal vowels in a wide range of phonological contexts, but also includes examples of other EP sounds. The RT-MRI protocol developed for the acquisition of the data is detailed. Midsagittal and oblique images were acquired with a frame rate of 14 frames/s, resulting in a temporal resolution of 72 ms. Different image processing tools (automatic and semi-automatic) applied for inspection and analysis of the data are described. We demonstrate the potential of this database and processing techniques with some illustrative examples of Portuguese nasal vowels, taps, trills and laterals. © 2012 Springer-Verlag.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Tongue segmentation from MRI images using ITK-SNAP: Preliminary evaluation",
        "doc_scopus_id": "84864986322",
        "doc_doi": null,
        "doc_eid": "2-s2.0-84864986322",
        "doc_date": "2011-12-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Computer Graphics and Computer-Aided Design",
                "area_abbreviation": "COMP",
                "area_code": "1704"
            },
            {
                "area_name": "Computer Vision and Pattern Recognition",
                "area_abbreviation": "COMP",
                "area_code": "1707"
            },
            {
                "area_name": "Information Systems",
                "area_abbreviation": "COMP",
                "area_code": "1710"
            }
        ],
        "doc_keywords": [
            "3D Visualization",
            "European Portuguese",
            "Jaccard coefficients",
            "Magnetic resonance images",
            "Manual segmentation",
            "MRI Image",
            "Region competition",
            "Semi-automatic segmentation",
            "Semi-automatics",
            "Semiautomatic methods",
            "Similarity metrics",
            "Speech production",
            "Speech synthesizer",
            "Tongue segmentation",
            "Validation",
            "Volumetric data"
        ],
        "doc_abstract": "The purpose of this study was to evaluate and compare the efficiency, reliability and accuracy of manual and semiautomatic segmentation techniques to segment tongue images. This work is included in a vast framework (HERON II) that aims to improve an articulatory-based speech synthesizer (SAP-Windows), for European Portuguese (EP). Volumetric data from Magnetic resonance images (MRI) were used to extract tongue configurations from several speakers uttering different EP sounds, or the same sound produced in different contexts or syllabic positions, in a speech production study. Segmentations were performed manually and using a semi-automatic approach implemented in ITK-SNAP (Region Competition Snakes). Results from similarity metrics (Jaccard coefficient and voxelwise comparison) revealed that the semi-automatic (SA) method presents good agreement with the manual segmentation method (Jaccard=0.9002 and 10.495 voxel error). Furthermore, the semi-automatic method is more reproducible (Jaccard=0.9382 and 6.388 voxel error) than manual segmentation method (Jaccard= 0.9170 and 8.662 voxel error). The semi-automatic approach provides an efficient and reliable method to segment tongue images providing 3D visualizations that allows description and comparison of tongue configurations during the production of different sounds. This information is of great relevance in speech production field contributing to a better understanding of speech production mechanisms. © 2011 IADIS.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "DICOM and clinical data mining in a small hospital PACS: A pilot study",
        "doc_scopus_id": "80054063236",
        "doc_doi": "10.1007/978-3-642-24352-3_27",
        "doc_eid": "2-s2.0-80054063236",
        "doc_date": "2011-10-19",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            },
            {
                "area_name": "Mathematics (all)",
                "area_abbreviation": "MATH",
                "area_code": "2600"
            }
        ],
        "doc_keywords": [
            "Clinical data",
            "Data fields",
            "Data-mining tools",
            "DICOM Data Mining",
            "PACS",
            "Picture archiving",
            "Pilot studies",
            "Technological development"
        ],
        "doc_abstract": "Technological developments in the medical imaging acquisition and storage process have triggered the use of Picture Archiving and Communication Systems (PACS) with gradually larger archives. This paper aims to exploit advantages of using a DICOM Data Mining Tool in a hospital PACS. The results showed the tool reliability and performance to obtain and index clinical data, as well as the possibility of conducting flexible research on DICOM data fields, providing means for continuous improved practices at the Radiology Departments. © 2011 Springer-Verlag.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Dicoogle - An open source peer-to-peer PACS",
        "doc_scopus_id": "84855567679",
        "doc_doi": "10.1007/s10278-010-9347-9",
        "doc_eid": "2-s2.0-84855567679",
        "doc_date": "2011-10-01",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Radiological and Ultrasound Technology",
                "area_abbreviation": "HEAL",
                "area_code": "3614"
            },
            {
                "area_name": "Radiology, Nuclear Medicine and Imaging",
                "area_abbreviation": "MEDI",
                "area_code": "2741"
            },
            {
                "area_name": "Computer Science Applications",
                "area_abbreviation": "COMP",
                "area_code": "1706"
            }
        ],
        "doc_keywords": [
            "Computer communication networks",
            "Digital imaging and communications in medicines",
            "Information storage and retrieval",
            "Open sources",
            "PACS",
            "PACS implementation",
            "Peer to peer"
        ],
        "doc_abstract": "Picture Archiving and Communication Systems (PACS) have been widely deployed in healthcare institutions, and they now constitute a normal commodity for practitioners. However, its installation, maintenance, and utilization are still a burden due to their heavy structures, typically supported by centralized computational solutions. In this paper, we present Dicoogle, a PACS archive supported by a document-based indexing system and by peer-to-peer (P2P) protocols. Replacing the traditional database storage (RDBMS) by a documental organization permits gathering and indexing data from file-based repositories, which allows searching the archive through free text queries. As a direct result of this strategy, more information can be extracted from medical imaging repositories, which clearly increases flexibility when compared with current query and retrieval DICOM services. The inclusion of P2P features allows PACS internetworking without the need for a central management framework. Moreover, Dicoogle is easy to install, manage, and use, and it maintains full interoperability with standard DICOM services. © Society for Imaging Informatics in Medicine 2010.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "A PACS gateway to the cloud",
        "doc_scopus_id": "80052507826",
        "doc_doi": null,
        "doc_eid": "2-s2.0-80052507826",
        "doc_date": "2011-09-12",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Management of Technology and Innovation",
                "area_abbreviation": "BUSI",
                "area_code": "1405"
            },
            {
                "area_name": "Information Systems",
                "area_abbreviation": "COMP",
                "area_code": "1710"
            }
        ],
        "doc_keywords": [
            "Cloud providers",
            "Concept-based",
            "Data availability",
            "Data flow",
            "DICOM",
            "High security levels",
            "Medical images",
            "Outsource",
            "PACS",
            "Pay-as-you-go",
            "Universal access",
            "Work-flows"
        ],
        "doc_abstract": "The amount of medical images has increased significantly over the last decade as result of the increase of number and quality of studies. Following some researchers, this trend will continue over the next years. Cloud computing is a new concept based on a well-know model named \"pay-as-you-go\". There is a new concept dubbed PACS Cloud, which the fundamental idea is to do PACS outsourcing taking advantages of the clouds elasticity and scalability, avoiding hardware obsolescence, providing universal access to the information anywhere, anytime and increase the data availability. This paper presents a module of PACS Cloud architecture to grant interoperability with DICOM devices. PACS Cloud Gateway is a component of PACS Cloud, which focuses mainly on the translation from DICOM commands to non-DICOM and vice-versa. While data outsource to the cloud can relieve users from the burden of local storage and maintenance, it also brings new security concerns. This paper presents a secure PACS Cloud Gateway to access PACS Cloud archive, which provides a high security level and without cloud's provider dependence. The workflows of each process was described carefully, specifying data flows since that Gateway is contacted by DICOM device, until it releases the process. Finally, the platform was instantiated in biggest Internet Cloud providers and the solution's results was analysed. © 2011 AISTI.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Image denoising methods for tumor discrimination in high-resolution computed tomography",
        "doc_scopus_id": "80052901081",
        "doc_doi": "10.1007/s10278-010-9305-6",
        "doc_eid": "2-s2.0-80052901081",
        "doc_date": "2011-06-01",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Radiological and Ultrasound Technology",
                "area_abbreviation": "HEAL",
                "area_code": "3614"
            },
            {
                "area_name": "Radiology, Nuclear Medicine and Imaging",
                "area_abbreviation": "MEDI",
                "area_code": "2741"
            },
            {
                "area_name": "Computer Science Applications",
                "area_abbreviation": "COMP",
                "area_code": "1706"
            }
        ],
        "doc_keywords": [
            "Computed Tomography",
            "Denoising methods",
            "Figures of merits",
            "Geometric mean",
            "High-resolution computed tomography",
            "HRCT images",
            "Image denoising methods",
            "Intensity analysis",
            "Poisson noise",
            "Reconstruction error",
            "Tomographic reconstruction",
            "Visual analysis",
            "Visual inspection",
            "Wavelet denoising",
            "Wiener filtering"
        ],
        "doc_abstract": "Pixel accuracy in images from high-resolution computed tomography (HRCT) is ultimately limited by reconstruction error and noise. While for visual analysis this may not be relevant, for computer-aided quantitative analysis in either densitometric, or shape studies aiming at accurate results, the impact of pixel uncertainty must be taken into consideration. In this work, we study several denoising methods: geometric mean filter, Wiener filtering, and wavelet denoising. The performance of each method was assessed through visual inspection, profile region intensity analysis, and global figures of merit, using images from brain and thoracic phantoms, as well as several real thoracic HRCT images. Copyright © 2010 by Society for Imaging Informatics in Medicine.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "An MRI study of consonantal coarticulation resistance in Portuguese",
        "doc_scopus_id": "84926296637",
        "doc_doi": null,
        "doc_eid": "2-s2.0-84926296637",
        "doc_date": "2011-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Language and Linguistics",
                "area_abbreviation": "ARTS",
                "area_code": "1203"
            },
            {
                "area_name": "Linguistics and Language",
                "area_abbreviation": "SOCI",
                "area_code": "3310"
            },
            {
                "area_name": "Computer Science Applications",
                "area_abbreviation": "COMP",
                "area_code": "1706"
            }
        ],
        "doc_keywords": [
            "Co-articulation",
            "MR images",
            "Qualitative evaluations",
            "Quantitative evaluation",
            "Quantitative result",
            "Semi-automatic segmentation",
            "Similarity metrics"
        ],
        "doc_abstract": "This study aimed to evaluate the effect of vocalic context, particularly at tongue level, on the articulation of European Portuguese (EP) consonants. Magnetic Resonance (MR) images were acquired for three speakers (two male and one female) during the production of consonants in a symmetric VCV context, with the cardinal vowels [i,a,u], Midsagittal contours of the tongue were extracted from MR images (by using a semi-automatic segmentation technique) and superimposed in order to allow a qualitative evaluation. Furthermore, a quantitative evaluation using a similarity metric (Pratt Index) was also conducted. Qualitative and quantitative results showed that stop consonants and nasals were especially sensitive to the vocalic context. Also, labial consonants were clearly more influenced by surrounding vowels than alveolars and dorsals. In comparison with all the consonantal segments analyzed, the fricatives [3 ∫] and the lateral [γ] were minimally affected by vowel context.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "3D MRI and semi-automatic segmentation techniques applied to the study of European Portuguese lateral sounds",
        "doc_scopus_id": "84910077128",
        "doc_doi": null,
        "doc_eid": "2-s2.0-84910077128",
        "doc_date": "2011-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Language and Linguistics",
                "area_abbreviation": "ARTS",
                "area_code": "1203"
            },
            {
                "area_name": "Linguistics and Language",
                "area_abbreviation": "SOCI",
                "area_code": "3310"
            },
            {
                "area_name": "Computer Science Applications",
                "area_abbreviation": "COMP",
                "area_code": "1706"
            }
        ],
        "doc_keywords": [
            "Common property",
            "Context effects",
            "Lateral compression",
            "MR images",
            "Reliable methods",
            "Semi-automatic segmentation",
            "Semi-automatics",
            "Vocal-tracts"
        ],
        "doc_abstract": "This study used 3D MR images and explored semi-automatic segmentation techniques to investigate the articulatory characteristics of European Portuguese (EP) laterals. Syllabic position and vowel context effects were also evaluated. Seven speakers of EP were scanned while uttering the consonants /I, U in the context of the cardinal vowels/i, a, u/. The semi-automatic approach provided an efficient and reliable method to segment tongue and vocal tract images. The analysis of MR images revealed several common properties for both /l/ and /U: lateral compression of the tongue and a convex tongue body, which enables the creation of lateral channels. However, /U exhibited greater lateral compression, when compared to /I/, and also larger lateral channels. The EP laterals were also distinguished from each other by means of the extension of constriction. For most of the speakers, /// exhibited a similar tongue body configuration at the word edges, with small pharyngeal/velar areas due to tongue-root retraction and/or raising the tongue dorsum. Vocalic effects were more evident in the alveolar lateral than in /IV. c.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "A preparatory study to choose similarity metrics for left-ventricle segmentations comparison",
        "doc_scopus_id": "79955785537",
        "doc_doi": "10.1117/12.878294",
        "doc_eid": "2-s2.0-79955785537",
        "doc_date": "2011-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Electronic, Optical and Magnetic Materials",
                "area_abbreviation": "MATE",
                "area_code": "2504"
            },
            {
                "area_name": "Atomic and Molecular Physics, and Optics",
                "area_abbreviation": "PHYS",
                "area_code": "3107"
            },
            {
                "area_name": "Biomaterials",
                "area_abbreviation": "MATE",
                "area_code": "2502"
            },
            {
                "area_name": "Radiology, Nuclear Medicine and Imaging",
                "area_abbreviation": "MEDI",
                "area_code": "2741"
            }
        ],
        "doc_keywords": [
            "Computational costs",
            "Ground truth",
            "Image processing and analysis",
            "Left ventricles",
            "preparatory studies",
            "Quantitative measures",
            "Segmentation methods",
            "Similarity metrics"
        ],
        "doc_abstract": "In medical image processing and analysis it is often required to perform segmentation for quantitative measures of extent, volume and shape. The validation of new segmentation methods and tools usually implies comparing their various outputs among themselves (or with a ground truth), using similarity metrics. Several such metrics are proposed in the literature but it is important to select those which are relevant for a particular task as opposed to using all metrics and therefore avoiding additional computational cost and redundancy. A methodology is proposed which enables the assessment of how different similarity and discrepancy metrics behave for a particular comparison and the selection of those which provide relevant data. © 2011 SPIE.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "CardioAnalyser: A software tool for segmentation and analysis of the left ventricle from 4D MDCT images of the heart",
        "doc_scopus_id": "78449288239",
        "doc_doi": "10.1109/IV.2010.91",
        "doc_eid": "2-s2.0-78449288239",
        "doc_date": "2010-11-24",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Software",
                "area_abbreviation": "COMP",
                "area_code": "1712"
            },
            {
                "area_name": "Signal Processing",
                "area_abbreviation": "COMP",
                "area_code": "1711"
            },
            {
                "area_name": "Computer Vision and Pattern Recognition",
                "area_abbreviation": "COMP",
                "area_code": "1707"
            }
        ],
        "doc_keywords": [
            "4D",
            "Left ventricles",
            "MDCT",
            "Segmentation",
            "Software tool"
        ],
        "doc_abstract": "Cardiac angiography using multiple detector row computerized tomography (MDCT) scanners provides 3D data concerning the heart and, in particular, the left ventricle (LV), for different cardiac phases along one cardiac cycle. Exploring this data for LV function analysis is not an easy task, given the amount of data and time involved in segmenting (or revising results provided by automatic segmentation methods) up to 12 cardiac phases. CardioAnalyser, a tool for 4D LV segmentation from MDCT data which provides a protocol to help perform LV segmentation of all cardiac phases available is presented. It uses an automatic segmentation algorithm along with a procedure which guides the user through the process. Its main goal is to reuse as much information as possible from one cardiac phase to the next in order to reduce segmentation time and the amount of user interaction. © 2010 IEEE.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "A 3D tool for left ventricle segmentation editing",
        "doc_scopus_id": "77955377969",
        "doc_doi": "10.1007/978-3-642-13775-4_9",
        "doc_eid": "2-s2.0-77955377969",
        "doc_date": "2010-08-13",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "3-D image",
            "3D segmentation",
            "Anatomical structures",
            "Application area",
            "Automatic method",
            "CT scanners",
            "Editing tools",
            "Left ventricles",
            "Quantitative measurement",
            "Robust segmentation",
            "Time instances"
        ],
        "doc_abstract": "Image segmentation has a very important role in many application areas, such as medical imaging. Even robust segmentation methods cannot deal with the wide range of variation observed, for example, in shape and orientation of an anatomical structure. Given the need to accomplish accurate segmentations in order to perform quantitative measurements or compare structures in different time instances, it is important to have tools which allow easy segmentation editing/correction by experts. In 3D images (e.g., obtained using CT scanners) performing segmentation editing of regions which span several slices might be a tiresome task if it has to be done slice-by-slice with a 2D tool. This article presents a 3D segmentation editing tool, to be applied to left ventricle segmentations, which enables radiographers to correct segmentations provided by an automatic method. © 2010 Springer-Verlag.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Semantic image search and subset selection for classifier training in object recognition",
        "doc_scopus_id": "71049160418",
        "doc_doi": "10.1007/978-3-642-04686-5_28",
        "doc_eid": "2-s2.0-71049160418",
        "doc_date": "2009-11-16",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Classifier training",
            "Digital collections",
            "Image clustering",
            "Local feature",
            "Object extraction",
            "Ranking methods",
            "Semantic images",
            "Semantic search",
            "Shape contexts",
            "Subset selection",
            "Training objects"
        ],
        "doc_abstract": "Robots need to ground their external vocabulary and internal symbols in observations of the world. In recent works, this problem has been approached through combinations of open-ended category learning and interaction with other agents acting as teachers. In this paper, a complementary path is explored, in which robots also resort to semantic searches in digital collections of text and images, or more generally in the Internet, to ground vocabulary about objects. Drawing on a distinction between broad and narrow (or general and specific) categories, different methods are applied, namely global shape contexts to represent broad categories, and SIFT local features to represent narrow categories. An unsupervised image clustering and ranking method is proposed that, starting from a set of images automatically fetched on the web for a given category name, selects a subset of images suitable for building a model of the category. In the case of broad categories, image segmentation and object extraction enhance the chances of finding suitable training objects. We demonstrate that the proposed approach indeed improves the quality of the training object collections. © 2009 Springer Berlin Heidelberg.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Processing, visualization and analysis of medical images of the heart: An example of fast prototyping using MeVisLab",
        "doc_scopus_id": "70350558556",
        "doc_doi": "10.1109/VIZ.2009.40",
        "doc_eid": "2-s2.0-70350558556",
        "doc_date": "2009-11-05",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Computer Vision and Pattern Recognition",
                "area_abbreviation": "COMP",
                "area_code": "1707"
            },
            {
                "area_name": "Information Systems",
                "area_abbreviation": "COMP",
                "area_code": "1710"
            },
            {
                "area_name": "Software",
                "area_abbreviation": "COMP",
                "area_code": "1712"
            }
        ],
        "doc_keywords": [
            "Fast prototyping",
            "Left ventricles",
            "MDCT images",
            "Medical images",
            "MeVisLab",
            "Prototyping platform",
            "Real problems",
            "Semi-automatic segmentation",
            "Visualization and analysis"
        ],
        "doc_abstract": "Developing and testing new algorithms for medical imaging processing can be a tiresome task as it often requires an additional set of tools to visualize the data and results and perform validation steps along the development. The integration among all these tools is also very important as it speeds all the process allowing the developer to concentrate on the real problems. This article briefly presents how MeVisLab is being used as a prototyping platform to develop a semi-automatic segmentation algorithm to extract the left ventricle from 4D MDCT images of the heart and then build a simple framework to perform a preliminary evaluation of the obtained results. © 2009 IEEE.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Left ventricle segmentation from heart MDCT",
        "doc_scopus_id": "68749088804",
        "doc_doi": "10.1007/978-3-642-02172-5_40",
        "doc_eid": "2-s2.0-68749088804",
        "doc_date": "2009-08-20",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Left ventricles",
            "Qualitative evaluations",
            "Semiautomatic methods"
        ],
        "doc_abstract": "A semi-automatic method for left ventricle segmentation from MDCT exams is presented. It was developed using ITK and custom modules integrated in the MeVisLab platform. A preliminary qualitative evaluation shows that the provided segmentation, without any tweaking or manual edition, is reasonably close to the ideal segmentation as judged by experienced radiology technicians. © 2009 Springer Berlin Heidelberg.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Digital radiography detectors - A technical overview: Part 2",
        "doc_scopus_id": "62949161539",
        "doc_doi": "10.1016/j.radi.2008.02.005",
        "doc_eid": "2-s2.0-62949161539",
        "doc_date": "2009-05-01",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Radiology, Nuclear Medicine and Imaging",
                "area_abbreviation": "MEDI",
                "area_code": "2741"
            }
        ],
        "doc_keywords": [],
        "doc_abstract": "Digital X-ray detector technologies provide several advantages when compared with screen-film (SF) systems: better diagnostic quality of the radiographic image, increased dose efficiency, better dynamic range and possible reduction of radiation exposure to the patient. The transition from traditional SF systems to digital technology-based systems highlights the importance of the discussion around technical factors such as image acquisition, the management of patient dose and diagnostic image quality. Radiographers should be aware of these aspects concerning their clinical practice regarding the advantages and limitations of digital detectors. New digital technologies require an up-to-date of scientific knowledge concerning their use in projection radiography. This is the second of a two-part review article focused on a technical overview of digital radiography detectors. This article provides a discussion about the issues related to the image acquisition requirements and advantages of digital technologies, the management of patient dose and the diagnostic image quality. © 2008 The College of Radiographers.",
        "available": true,
        "clean_text": "serial JL 272334 291210 291703 291926 31 Radiography RADIOGRAPHY 2008-04-01 2008-04-01 2011-07-22T23:07:15 S1078-8174(08)00011-4 S1078817408000114 10.1016/j.radi.2008.02.005 S300 S300.2 FULL-TEXT 2015-05-15T05:05:43.622236-04:00 0 0 20090501 20090531 2009 2008-04-01T00:00:00Z articleinfo crossmark dco dateupdated tomb dateloaded datesearch indexeddate issuelist volumelist yearnav articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright dateloadedtxt docsubtype doctype doi eid ewtransactionid hubeid issfirst issn issnnorm itemstage itemtransactionid itemweight openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sectiontitle sortorder srctitle srctitlenorm srctype subheadings volfirst volissue figure table body affil articletitle auth authfirstini authfull authkeywords authlast primabst ref alllist content subj ssids 1078-8174 10788174 15 15 2 2 Volume 15, Issue 2 8 134 138 134 138 200905 May 2009 2009-05-01 2009-05-31 2009 Original Articles article fla Copyright © 2008 The College of Radiographers. Published by Elsevier Ltd. All rights reserved. DIGITALRADIOGRAPHYDETECTORSATECHNICALOVERVIEWPART2 LANCA L Introduction Image acquisition requirements and advantages of digital technologies for projection radiography Management of patient dose Image quality in diagnostic radiology Primary physical image quality parameters Objective image quality measurements Observer performance methods Conclusions Conflict of interest References CHOTAS 1999 595 599 H NEITZEL 2005 32 38 U SAMEI 2003 49 61 E ADVANCESINDIGITALRADIOGRAPHY PERFORMANCEDIGITALRADIOGRAPHICDETECTORSFACTORSAFFECTINGSHARPNESSNOISE KORNER 2007 675 686 M INTERNATIONALCOMMISSIONONRADIOLOGICALPROTECTION 2004 STROTZER 2002 169 171 M VOLK 2004 827 834 M STROTZER 1998 52 57 M BACHER 2003 923 929 K ALKHALIFAH 2004 119 125 K VANO 2007 461 466 E BUSCH 2004 H DIMOND IMAGEQUALITYDOSEMANAGEMENTFORDIGITALRADIOGRAPHYFINALREPORT PASCOAL 2005 273 277 A TAPIOVAARA 2006 M STUKRADIATIONNUCLEARSAFETYAUTHORITY RELATIONSHIPSBETWEENPHYSICALMEASUREMENTSUSEREVALUATIONIMAGEQUALITYINMEDICALRADIOLOGYAREVIEW JESSEN 2004 9 18 K MARSH 2001 37 42 D INTERNATIONALELECTROTECHNICALCOMMISSION 2003 INTERNATIONALSTANDARDIEC62201 MEDICALELECTRICALEQUIPMENTCHARACTERISTICSDIGITALXRAYIMAGINGDEVICESPART1DETERMINATIONDETECTIVEQUANTUMEFFICIENCY RANGER 2007 785 795 N CUNNINGHAM 2000 79 159 I HANDBOOKMEDICALIMAGING APPLIEDLINEARSYSTEMSTHEORY DOBBINS 2000 161 222 J HANDBOOKMEDICALIMAGING IMAGEQUALITYMETRICSFORDIGITALSYSTEMS SAMEI 2003 37 47 E ADVANCESINDIGITALRADIOGRAPHY PERFORMANCEDIGITALRADIOGRAPHICDETECTORSQUANTIFICATIONASSESSMENTMETHODS DOBBINS 2006 1466 1475 J HANSON 1998 243 250 K PHYSICSMEDICALIMAGING ASIMPLIFIEDMETHODESTIMATINGNOISEPOWERSPECTRA BUADES 2006 57 67 M SAMEI 2004 313 334 E OBUCHOWSKI 2003 3 8 N CHAKRABORTY 1990 873 881 D METZ 2006 413 422 C LANHEDE 2002 38 49 B LANCAX2009X134 LANCAX2009X134X138 LANCAX2009X134XL LANCAX2009X134X138XL item S1078-8174(08)00011-4 S1078817408000114 10.1016/j.radi.2008.02.005 272334 2011-10-05T22:36:06.039444-04:00 2009-05-01 2009-05-31 true 314550 MAIN 5 73742 849 656 IMAGE-WEB-PDF 1 gr1 43011 453 371 gr1 7492 164 134 gr1 371230 2009 1645 gr2 20225 356 318 gr2 4640 163 146 gr2 113486 1579 1411 YRADI 784 S1078-8174(08)00011-4 10.1016/j.radi.2008.02.005 The College of Radiographers Figure 1 Dynamic Range in digital and SF systems. Figure 2 Image quality triangle: relationships between image quality parameters and physical image measurements (adapted 17 ). Table 1 Methods for quality evaluation of diagnostic imaging procedures 14 Level of ambition Investigation Measurement Lowest Radiographic technique • Equipment characteristics • Exposure parameters Primary physical characteristics • Contrast • Spatial resolution (MTF) • Noise (WS) • Signal-to-noise ratio (SNR) Overall system performance • DQE • Image quality index (IQI) • Contrast-detail resolution Images of anthropomorphic phantoms • ROC • ROC related methods • Visual grading analysis (VGA) Highest Images of patients • ROC • ROC related methods • Visual grading analysis (VGA) • Image criteria (IC) Digital radiography detectors – A technical overview: Part 2 Luís Lança a ∗ Augusto Silva b a School of Health Technology, Lisbon Polytechnics, Lisbon, Portugal b Department of Electronic, Telecommunications and Informatics, Aveiro University, Aveiro, Portugal ∗ Corresponding author. Digital X-ray detector technologies provide several advantages when compared with screen-film (SF) systems: better diagnostic quality of the radiographic image, increased dose efficiency, better dynamic range and possible reduction of radiation exposure to the patient. The transition from traditional SF systems to digital technology-based systems highlights the importance of the discussion around technical factors such as image acquisition, the management of patient dose and diagnostic image quality. Radiographers should be aware of these aspects concerning their clinical practice regarding the advantages and limitations of digital detectors. New digital technologies require an up-to-date of scientific knowledge concerning their use in projection radiography. This is the second of a two-part review article focused on a technical overview of digital radiography detectors. This article provides a discussion about the issues related to the image acquisition requirements and advantages of digital technologies, the management of patient dose and the diagnostic image quality. Keywords CR DR X-ray detectors Digital technologies Introduction The transition from traditional screen-film (SF) systems to digital technology-based systems highlights the importance of the discussion around technical factors such as image acquisition, the management of patient dose and diagnostic image quality. Radiographers should be aware of these aspects concerning their clinical practice. New digital technologies require an up-to-date of scientific knowledge concerning their use in projection radiography. This is the second of a two-part review article focused on a technical overview of digital radiography detectors. This article provides a discussion about the issues related to the image acquisition requirements and advantages of digital technologies, the management of patient dose and the diagnostic image quality. Image acquisition requirements and advantages of digital technologies for projection radiography A digital X-ray detector is the key component of a digital radiography system. It has to fulfil several requirements 1,2 concerning field size, pixel size, sensitivity, dynamic range, internal noise and readout. In DR (Digital Radiography), the field or detector size must be large enough for all radiographic examinations. Ideally, it should have an active area of at least 43×43cm to allow both vertical and horizontal imaging orientations without detector rotation. In CR (Computed Radiography), different cassette sizes with standard dimensions for typical plain radiography are available (e.g. 18×24; 24×30; 35×43). These cassettes contain the correspondent IP which is used for the appropriate region to be examined. The maximum spatial resolution of an image is defined by pixel size and spacing (i.e., the pitch or the distance between centres of pixels). Pixel size affects the system resolution and ranges typically from 100–200μm in CR (depending on the cassette detector size) and 127–200μm in DR detectors. In SF systems, spatial resolution is higher (25–80μm) but these systems are limited in their sensitivity and dynamic range, when compared with digital systems. Sensitivity or latitude must be high enough to allow low-dose operation. Digital detectors that have higher sensitivity or higher detective quantum efficiency values, allows better image quality at all frequencies showing the ability to represent both small and large image structures. The dynamic range must be enough to cover a wide range of intensities. Typically, digital detectors have a dynamic range of 1:10.000 which is considerably higher than SF systems (1:30). This wide dynamic range allows the digital systems to maximize the number of grey values on the digital image ( Fig. 1). This characteristic is a key feature concerning exposure errors. A marked reduction of repeated radiographs and consequent reduced radiation exposure to the patient 2 is a positive consequence of wide dynamic range in digital detectors. Internal noise sources must be small enough to preserve image quality. These noise sources could be related, for example with the capture element, the coupling element, and the collection element of the digital detector. 3 The readout time must be fast enough to allow efficient workflow and this will depend on the type of technology: in CR, bigger IPs will have a slower readout than smaller IPs (e.g. 30–40s); in DR, the readout process could take about 1.3s. 4 These requirements are very important in digital X-ray technology because they will affect image quality, dose efficiency and workflow. In fact, digital technologies for projection radiography can offer several advantages when compared with SF systems. The fundamentals and advantages of digital systems are stated by ICRP 5 and were discussed before in this review. Management of patient dose The development of an adequate radiographic technique involves the management of the exposure parameters, the patient's radiation exposure and the exposure on the imaging detector to produce the most accurate diagnosis. This should be accomplished with an optimization of exposures and image quality. When a new digital system or post-processing software is introduced, an optimization programme (for radiation dose) and continuing training should be conducted in parallel. 5 Exposure optimization should contribute to protect patients from unnecessary exposures and ALARP (As Low As Reasonable Practicable) principle should be always kept in mind. This is an important principle because in digital radiology – both CR and DR – examinations can be performed over a wide range of doses and the best images (low noise) are obtained with higher doses. 5 DR technology based on solid state detectors can achieve a dose reduction in chest and skeletal radiography of up to 33–50% without loss of image quality when compared with a traditional screen-film radiography system 6,7 due to its high detective quantum efficiency and wide dynamic range. In the field of thoracic and skeletal radiography, flat-panel detectors have the potential for dose reduction compared with conventional SF systems with the same imaging quality. 8 In a study comparing radiation dose delivered to patients undergoing clinical chest imaging in three different detector technologies, significant differences in the patient radiation dose were found. 9 The flat-panel detector radiography system allowed an important and significant reduction in both entrance skin dose and effective dose compared with the film-screen radiography (×2.7 decrease) or computed radiography (×1.7 decrease) system. In addition, image quality produced by the flat-panel detector radiography system was significantly better than the image quality produced by the film-screen or computed radiography systems, confirming that the dose reduction was not detrimental to image quality. 9 With a reduction in mAs which is possible in CR systems rather than in FS systems, the CR systems will be able to produce quality diagnostic images with less patient dose than FS systems. 10 These results were recently confirmed in a study where digital techniques allowed diagnostically adequate images to be obtained with substantially lower patient doses than used for SF radiography. 11 Image quality in diagnostic radiology Digital detectors are often cited as offering higher sensitivity, lower intrinsic noise and greater dynamic range rather than traditional SF systems, which opens up new possibilities for dose reduction in clinical applications. 2 Beyond the characteristics of detectors, the imaging capabilities of digital systems are also determined by signal processing, digital image post-processing and documentation. 12 Although several advantages over SF systems are identified, considerable variations in image quality and effective dose can be achieved among different digital detectors. 13 Image quality could be evaluated combining the physical characteristics of the imaging system, the overall system performance and observer performance studies. 14 However, a recent review 15 states that the relationship between the results of physical measurements, phantom evaluations and clinical performance is not fully understood. Table 1 shows a wide spectrum of methods for image quality evaluation. 14 Some of these methods focus on the physical characteristics of the imaging systems and others on subjective assessment of image quality; some are used for the whole imaging chain including the human observer (observer performance) while others are used for parts of the system (typically physical measurements). This leads to the discussion of the image quality concept in diagnostic radiology. This concept could be virtually understood as a good quality image that fulfils its diagnostic purpose and comprises several methods for image quality evaluation. A good quality image is of major importance to assure an accurate diagnosis and this is – in general – determined by three primary physical image quality parameters 16 : contrast, spatial resolution and noise. These quality parameters can be evaluated by objective image quality measurements such as signal-to-noise ratio (SNR), modulation transfer function (MTF) and Wiener spectra (WS). Together they form a basis for the description of image quality which encompasses the three primary physical image quality parameters ( Fig. 2). 17 These factors contribute for the measurement of Detective Quantum Efficiency (DQE) which is well established as the most suitable parameter for describing the imaging performance of an X-ray digital imaging device. 18,19 DQE is the measure of the combined effect of the noise and contrast performance of an imaging system, expressed as a function of object detail. DQE combines spatial resolution (i.e., MTF) and image noise (i.e., WS) to provide a measure of the SNR of the various frequency components of the image. 1 Primary physical image quality parameters Contrast is defined as a measure of the relative brightness difference between two locations in an image. 20 The contrast of an imaging system is described by the characteristic response curve of the system. This curve has a typical S-shape for a SF system but in digital systems the characteristic curve is generally linear. SF systems have a characteristic curve that is in relation with the logarithm of incident intensity, while digital systems measure their characteristic response directly with respect to exposure (rather than the log of exposure as with film). 21 If the user is not properly trained, there is an obvious risk that the patient exposure can be unnecessarily high since a digital detector does not set the limit as film does with respect to film blackening 14,16 and thus the risk of over or underexposure could be present. The spatial resolution concept refers to the ability of the system to represent distinct anatomic features within the object being imaged. 22 It could be defined as the ability of the system to distinguish neighbouring features of an image from each other and is related with sharpness. Sharpness of an image is related to (a) the intrinsic sharpness of the detector employed; (b) the subject contrast, as determined by object characteristics, beam quality, and scatter, as well as the blur caused by the finite size of the X-ray focal spot; and (c) the patient motion during the acquisition. 3 The sharpness of an imaging detector or system is best characterised in terms of its MTF. Noise arises from a number of sources – such as quantum and electronic noise – that produces random variations of signal that can obscure useful information in a diagnostic image. Random noise means fluctuations of the signal over an image, as result of a uniform exposure, and can be characterised by the standard deviation of the signal variations over the image of a uniform object. Wiener spectrum has to be used to get a more complete description of the spatial correlation of the noise: it measures the noise power as a function of spatial frequency. 23 Noise is a major limiting factor in object detection because it remains constant in a given system unless dose is increased. The noise in images is recognized as an important factor in determining image quality. Image noise may be characterised by the WS – or noise power spectrum (NPS). WS provide the means of characterizing image noise and play a central role in the ultimate measure of image quality. 24 WS is the noise variance of the image, expressed as a function of spatial frequency, i.e., represents noise power at various spatial frequencies. Objective image quality measurements Physical measurements of signal-to-noise ratio (SNR), modulation transfer function (MTF) and Wiener spectra (WS) form together a basis for the description of image quality which encompasses the three primary physical image quality parameters. 17 Establishing a complete characterization of the physical properties of the digital image system requires the determination of MTF, SNR, WS and DQE. 25 Unlike analogical screen-film detectors, which are contrast limited in operation, digital acquisition devices are signal-to-noise ratio limited, which means that the image quality is usually dependent on the quantum statistics of the image formation process combined with contrast and spatial resolution enhancement methods. 26 DQE is the measure of the combined effect of the noise and contrast performance of an imaging system, expressed as a function of object detail. DQE combines MTF and WS to provide a measure of the SNR of the various frequency components of the image. 1 The MTF is a measure of the ability of an imaging detector to reproduce image contrast from subject contrast at various spatial frequencies. 22 In other words, MTF represents how well an imaging system reproduces high contrast objects of varying size in the resulting image, and, therefore, represents the relationship between contrast and spatial resolution. 17 Blurring and unsharpness introduced by the imaging system results in higher spatial frequencies not being transmitted as well as lower spatial frequency information. As a result, the MTF progressively decreases with increasing spatial frequency. 26 The SNR represents the relationship between contrast and noise in an image for large scale objects. 17 While signal sensitivity (contrast) and image noise properties are important by themselves, it is really the ratio between them that carries the most significance and constitutes the most significant indicator of image quality. 14,21 This relation shows that SNR needs to be a ratio of about 5:1 for a reliable detection by human observers. 21 In digital X-ray systems, as noise decreases and SNR increases, object detection increases very rapidly. The WS represents the noise power in an image as a function of spatial frequency. It, therefore, represents the relationship between noise and spatial resolution. 17 WS (or NPS) may be understood in several but equivalent ways 21 : it may be thought of as the variance of image intensity (i.e., image noise) distributed among the various frequency components of the image; or may be pictured as the variance of a given spatial frequency component in an ensemble of measurements of that spatial frequency. Observer performance methods Observer performance methods could be grouped in two categories 14 : observer performance methods based on lesion detection; and observer performance methods based on visibility of anatomical structures. Both methods are used to evaluate the whole imaging chain and give a measure of the clinical image quality of an imaging system. The first category includes the methods used to detect lesions either in real patients or in phantoms: receiver operating characteristic (ROC) analysis and ROC related methods, such as free-response ROC (FROC), alternative free-response ROC (AFROC) and free-response forced error (FFE). ROC analysis offers several advantages as a measure of the accuracy of a diagnostic test 27 : (a) it includes all possible cut points, (b) it shows the relationship between the sensitivity of a test and its specificity, (c) it is not affected by the prevalence of disease, and (d) from it we can compute several useful summary measures of test accuracy (e.g. ROC curve area, partial area). These methods were found to be in good agreement with one another. 28 ROC analysis provides the most comprehensive description of diagnostic accuracy available to date. 29 The second category includes the methods used to evaluate the visibility of anatomic structures such as visual grading analysis (VGA) and image criteria (IC). In VGA analysis, the aim is to compare the visibility of defined structures in the image to be evaluated with the same structures in a reference image. This evaluation is often based on a 5-level grading scale for image comparison. 14 In IC analysis, the aim is to decide if the image criterion – based on a reference frame – is present or not in the image giving a score for that purpose. The criteria can be used to highlight optimum radiographic technique in terms of image quality and patient dose. 30 Conclusions Digital detector technologies can offer several advantages when compared with SF systems. These advantages include better diagnostic image quality and better management of patient exposure. Also, a digital environment can offer better workflow and several other functionalities that are intrinsic to digital technology. Radiographers should be able to work with these technologies and specific training is needed. The transition from a SF environment to a digital environment requires the attention of radiographer's practices concerning the optimization of image quality and dose. This could be done through the implementation of dose management and clinical image evaluation programs for digital techniques. There is a considerable potential for the optimization and improvement of performance levels of digital detectors available at the present time. Conflict of interest No conflict of interest is declared. References 1 H.G. Chotas J.T. Dobbins III C.E. Ravin Principles of digital radiography with large-area, electronically readable detectors: a review of the basics Radiology 210 1999 595 599 2 U. Neitzel Status and prospects of digital detector technology for CR and DR Radiat Prot Dosimetry 114 2005 32 38 3 E. Samei Performance of digital radiographic detectors: factors affecting sharpness and noise Advances in digital radiography 2003 RSNA 49 61 4 M. Körner C.H. Weber S. Wirth K.J. Pfeifer M.F. Reiser M. Treitl Advances in digital radiography: physical principles and system overview Radiographics 27 2007 675 686 5 International Commission on Radiological Protection Managing patient dose in digital radiology ICRP Publication 93 Ann. ICRP 34 2004 6 M. Strotzer M. Völk R. Fründ O. Hamer N. Zorger S. Feuerbach Routine chest radiography using a flat-panel detector: image quality at standard detector dose and 33% dose reduction Am J Roentgenol 178 2002 169 171 7 M. Völk O. Hamer S. Feuerbach M. Strotzer Dose reduction in skeletal and chest radiography using a large-area flat-panel detector based on amorphous silicon and thallium-doped cesium iodide: technical background, basic image quality parameters, and review of the literature European Radiology 14 2004 827 834 8 M. Strotzer M. Völk S. Feuerbach Experimental examinations and initial clinical experience with a flat-panel detector in radiography Electromedica 2 1998 52 57 9 K. Bacher P. Smeets K. Bonnarens An De Hauwere K. Verstraete H. Thierens Dose reduction in patients undergoing chest imaging: digital amorphous silicon flat-panel detector radiography versus conventional film-screen radiography and phosphor-based computed radiography Am J Roentgenol 181 2003 923 929 10 K. Al Khalifah A. Brindhaban Comparison between conventional radiography and digital radiography for various kVp and mAs settings using a pelvic phantom Radiography 10 2004 119 125 11 E. Vaño J.M. Fernández J.I. Ten C. Prieto L. González R. Rodríguez Transition from screen-film to digital radiography: evolution of patient radiation doses at projection radiography Radiology 243 2007 461 466 10.1148/radiol.2432050930 12 H. Busch Image quality and dose management for digital radiography – final report Dimond 3rd ed. 2004 European Commission Available from: 13 A. Pascoal C.P. Lawinsky A. Mackenzie S. Tabakov C.A. Lewis Chest radiography: a comparison of image quality and effective dose using four digital systems Radiat Prot Dosimetry 114 2005 273 277 14 Tingberg A. Quantifying the quality of medical x-ray images: an evaluation based on normal anatomy lumbar spine and chest radiography. Doctoral Dissertation. Department of Radiation Physics: Lund University, Malmö; 2000. 15 M. Tapiovaara Relationships between physical measurements and user evaluation of image quality in medical radiology – a review Stuk – radiation and nuclear safety authority 2006 STUK A-219 Helsinki Available from: 16 K.A. Jessen Balancing image quality and dose in diagnostic radiology Eur Radiol Syllabus 14 2004 9 18 17 D.M. Marsh J.F. Malone Methods and materials for the measurement of subjective and objective measurements of image quality Radiat Prot Dosimetry 94 2001 37 42 18 International Electrotechnical Commission Medical electrical equipment – characteristics of digital x-ray imaging devices – part 1: Determination of the detective quantum efficiency International standard IEC6220-1 2003 IEC Geneva 19 N.T. Ranger E. Samei J.T. Dobbins III C.E. Ravin Assessment of detective quantum efficiency: intercomparison of a recently introduced international standard with prior methods Radiology 243 2007 785 795 20 I. Cunningham Applied linear-systems theory R.L. Van Metter Handbook of medical imaging 2000 Press SPIE Bellingham 79 159 21 J.T. Dobbins Image quality metrics for digital systems Handbook of medical imaging 2000 Press SPIE Bellingham 161 222 22 E. Samei Performance of digital radiographic detectors: quantification and assessment methods Advances in digital radiography 2003 RSNA 37 47 23 J.T. Dobbins E. Samei N.T. Ranger Y. Chen Intercomparison of methods for image quality characterization. II. Noise power spectrum Med Phys. 33 2006 1466 1475 24 K.M. Hanson A simplified method of estimating noise power spectra Physics of medical imaging Proc Soc Photo Opt Instrum Eng 3336 1998 243 250 25 M.J. Buades A. González B. Tobarra Implementación de un Programa Informático para la Determinación de la DQE de un Sistema de Radiología Digital Revista de Física Médica 7 2006 57 67 26 E. Samei J.A. Seibert K. Andriole A. Badano J. Crawford B. Reiner AAPM/RSNA tutorial on equipment selection: PACS equipment overview Radiographics 24 2004 313 334 27 N. Obuchowski Receiver operating characteristic curves and their use in radiology Radiology 229 2003 3 8 28 D. Chakraborty Free-response methodology: alternate analysis and a new observer-performance experiment Radiology 174 1990 873 881 29 C. Metz Receiver operating characteristic analysis: a tool for the quantitative evaluation of observer performance and imaging systems J Am Coll Radiol 3 2006 413 422 30 B. Lanhede M. Bath S. Kheddache P. Sund L. Bjorneld M. Widell The influence of different technique factors on image quality of chest radiographs as evaluated by modified CEC image quality criteria Br J Radiol 75 2002 38 49 "
    },
    {
        "doc_title": "Design, development, exploitation and assessment of a Cardiology Web PACS",
        "doc_scopus_id": "59149083992",
        "doc_doi": "10.1016/j.cmpb.2008.10.015",
        "doc_eid": "2-s2.0-59149083992",
        "doc_date": "2009-03-01",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Software",
                "area_abbreviation": "COMP",
                "area_code": "1712"
            },
            {
                "area_name": "Computer Science Applications",
                "area_abbreviation": "COMP",
                "area_code": "1706"
            },
            {
                "area_name": "Health Informatics",
                "area_abbreviation": "MEDI",
                "area_code": "2718"
            }
        ],
        "doc_keywords": [
            "Cardio-PACS",
            "DICOM",
            "PACS",
            "Telework",
            "Web-PACS"
        ],
        "doc_abstract": "Healthcare institutions are increasingly turning to digital medical imaging systems to promote better diagnosis and treatment of their patients. The implementation of the Picture Archiving and Communication System (PACS) clearly contributes to an increase in the productivity of health professionals. However, despite the amount of research that has been done in the past two decades, there are still several technological hurdles that hinder the wide adoption of PACS in the Web environment. In this paper, we present a Web-enabled PACS that through the inclusion of several DICOM services and compression methods promotes medical image availability and greater accessibility to users. © 2008 Elsevier Ireland Ltd. All rights reserved.",
        "available": true,
        "clean_text": "serial JL 271322 291210 291791 291871 291901 31 Computer Methods and Programs in Biomedicine COMPUTERMETHODSPROGRAMSINBIOMEDICINE 2008-12-30 2008-12-30 2011-01-20T10:46:36 S0169-2607(08)00260-5 S0169260708002605 10.1016/j.cmpb.2008.10.015 S300 S300.1 FULL-TEXT 2015-05-14T05:25:39.534626-04:00 0 0 20090301 20090331 2009 2008-12-30T00:00:00Z articleinfo crossmark dco dateupdated tomb dateloaded datesearch indexeddate issuelist volumelist yearnav articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright dateloadedtxt docsubtype doctype doi eid ewtransactionid hubeid issfirst issn issnnorm itemstage itemtransactionid itemweight openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sectiontitle sortorder srctitle srctitlenorm srctype subheadings volfirst volissue figure table body affil articletitle auth authfirstini authfull authkeywords authlast primabst ref alllist content subj ssids 0169-2607 01692607 93 93 3 3 Volume 93, Issue 3 7 273 282 273 282 200903 March 2009 2009-03-01 2009-03-31 2009 Section II. Systems and Programs article fla Copyright © 2008 Elsevier Ireland Ltd. All rights reserved. DESIGNDEVELOPMENTEXPLOITATIONASSESSMENTACARDIOLOGYWEBPACS COSTA C 1 Introduction 2 Methods and materials 2.1 Scenario 2.2 Image compression 2.3 DICOM private transfer syntax 3 Results 3.1 Software engineering 3.2 System workflow 3.3 Integration with a cardiovascular information system 3.4 Web-enabled interface 3.5 Exploitation 4 Discussion 5 Conclusions References HUANG 2004 H PACSIMAGINGINFORMATICSBASICPRINCIPLESAPPLICATIONS COSTA 2007 S322 S323 C CARS2007INTERNATIONALCONGRESSEXHIBITIONCOMPUTERASSISTEDRADIOLOGYSURGERY2 ENHANCEDPACSSUPPORTDEMANDINGTELEMEDICINETELEWORKSCENARIOS POLONIA 2008 D PROCEEDINGSSPIEVOLUME6919691906MEDICALIMAGING2008 BROKERAGEMECHANISMPROPOSALFORTELERADIOLOGYSTUDIESDISTRIBUTION OTERO 2008 834 841 H DALLESSIO 2007 34 35 K KALDOUDIA 2006 117 127 E SILVA 1998 A PROCEEDINGSSPIEMEDICALIMAGING ACARDIOLOGYORIENTEDPACS COSTA 2004 C PACSIMAGINGINFORMATICSPROCEEDINGSSPIE HIMAGEPACSANEWAPPROACHSTORAGEINTEGRATIONDISTRIBUTIONCARDIOLOGICIMAGES BRENNECKE 2000 1388 1397 R KERENSKY 2000 1370 1379 R TUINENBURG 2000 1380 1387 J UMEDA 2004 1297 1303 A SEGAR 1999 714 719 D KARSON 1996 769 778 T DICOMP 2004 DIGITALIMAGINGCOMMUNICATIONSINMEDICINEDICOMPART5DATASTRUCTURESENCODING ZHANGA 2003 J COMPUTERIZEDMEDICALIMAGINGGRAPHICS PACSWEBBASEDIMAGEDISTRIBUTIONDISPLAY MATSOPOULOS 2004 53 71 G MARCOS 2007 255 269 E DICOMP 2007 DIGITALIMAGINGCOMMUNICATIONSINMEDICINEDICOMPART4SERVICECLASSSPECIFICATIONS BOSWORTH 2003 A XMLSOAPBINARYDATAVERSION10 LEPANTO 2006 92 97 L REINER 2002 22 26 B MACKINNON 2008 796 804 A DICOMSUPL 2004 DIGITALIMAGINGCOMMUNICATIONSINMEDICINEDICOMSUPPLEMENT42MPEG2TRANSFERSYNTAX COSTAX2009X273 COSTAX2009X273X282 COSTAX2009X273XC COSTAX2009X273X282XC item S0169-2607(08)00260-5 S0169260708002605 10.1016/j.cmpb.2008.10.015 271322 2011-02-03T13:14:20.981783-05:00 2009-03-01 2009-03-31 true 2647107 MAIN 10 48258 849 656 IMAGE-WEB-PDF 1 gr1 104685 459 620 gr1 11739 162 219 gr2 32220 134 565 gr2 2373 52 219 gr3 67879 406 650 gr3 6824 137 219 gr4 27833 157 317 gr4 8334 109 219 gr5 95323 645 654 gr5 8754 164 166 gr6 75285 323 654 gr6 10920 108 219 gr7 107903 486 562 gr7 13899 163 189 gr8 108388 436 715 gr8 14170 134 219 gr9 103797 550 558 gr9 11491 164 166 gr10 117533 453 753 gr10 14321 132 219 COMM 2858 S0169-2607(08)00260-5 10.1016/j.cmpb.2008.10.015 Elsevier Ireland Ltd Fig. 1 A multimedia container that allows the introduction of a specific codec (MPEG4 in this case) inside the DICOM private transfer syntax. Fig. 2 An example of a DICOM dump: DICOM “default transfer syntax” vs. “private syntax”. Fig. 3 HIMAGE services and processes workflow. Fig. 4 HIMAGE Web components architecture. Fig. 5 HIMAGE main infra-structure inside the CHVNG cardiology department. Fig. 6 Himage Integration Engine (CIS+PACS). Fig. 7 Main interface of the Web HIMAGE. Fig. 8 Web HIMAGE–viewer window (Normal/Compare Mode). Fig. 9 Web HIMAGE–reporting module. Fig. 10 HIMAGE standalone DICOM viewer. Table 1 CHVNG cardiology department—US statistics. Number of procedures (exams) 36,418 Number of images (still+cine-loops) 856,215 Total size 230,984,532,254bytes (215GB) Average procedure size 6.05MB Average file size 263.5kB Average files/procedure 23.5 (majority of cine-loops) Design, development, exploitation and assessment of a Cardiology Web PACS Carlos Costa a ⁎ José L. Oliveira a Augusto Silva a Vasco Gama Ribeiro b José Ribeiro b a University of Aveiro – DETI/IEETA, 3810-193 Aveiro, Portugal b Centro Hospitalar de Vila Nova de Gaia, Portugal ⁎ Corresponding author. Tel.: +351 234370500. Healthcare institutions are increasingly turning to digital medical imaging systems to promote better diagnosis and treatment of their patients. The implementation of the Picture Archiving and Communication System (PACS) clearly contributes to an increase in the productivity of health professionals. However, despite the amount of research that has been done in the past two decades, there are still several technological hurdles that hinder the wide adoption of PACS in the Web environment. In this paper, we present a Web-enabled PACS that through the inclusion of several DICOM services and compression methods promotes medical image availability and greater accessibility to users. Keywords PACS DICOM Cardio-PACS Web-PACS Telemedicine Telework 1 Introduction A Picture Archiving and Communication System (PACS) is one of the most valuable tools supporting the medical profession both in decision-making and during treatment procedures. It encompasses several technologies that are used in the acquisition, archiving, distribution, and visualization of digital medical images [1]. The Digital Imaging and Communications in Medicine standard (DICOM) [2] was a major contribution to the facilitated exchange of structured medical imaging data, and is now a key component in PACS's success. Currently, almost all medical imaging equipment manufacturers provide DICOM digital output in their products. The deployment of PACS has enabled faster and broader access to medical image data. The movement from film-based processes to digital processes, allied to faster and more robust network infrastructure, reduced the costs associated with the storage and management of images, simplified data portability, and has paved the way for the development of new applications and working scenarios. A significant benefit of digital medical imaging is its availability, both within and between health institutions. Together with a new suite of Internet Protocol (IP)-based applications, such as IP phone and teleconference, PACS presents a tremendous opportunity for the introduction of telemedicine, telework, and collaborative teams, which will help to bridge frontiers and overcome the medical resource asymmetries found in several regions [3,4]. However, several problematic issues still remain, most of them related to the huge volume of data, and to the lack of interoperability between distinct PACS products. For instance, dynamic image modalities (films) such as cardiac ultrasound (US) and X-ray angiography (XA) typically generate hundreds of MB of data for each study. To keep these exams permanently available to practitioners it is necessary to create robust and efficient storage and communication infrastructures. There are no significant technical differences between the PACS used in cardiology and in radiology areas. However, they are often separate systems that tackle distinct user needs, namely related to visualization and reporting protocols [5]. Since almost all systems are DICOM compliant, it is possible from a radiology workstation to query and retrieve images located in a cardiology storage server, and vice-versa. The handicap is that an integrated system can lead to a more efficient workflow and improved access to images and data [6,7]. This paper presents a Web-enabled PACS framework, entitled HIMAGE, which is specially designed to support demanding cardiac imaging laboratories. HIMAGE enables the acquisition, storage, transmission, and visualization of DICOM cardiovascular sequences, providing a cost-efficient digital archive. The core of our approach is the implementation of a private DICOM transfer syntax that supports any video encoder that best suits the specificities of a particular imaging modality or working scenario. The major advantage of the proposed system stems from the high compression rate achieved by video encoding, while still maintaining diagnostic quality in the medical image sequences. This approach ensures full online availability of the studies and simplifies the transmission of medical data over the Internet 2 Methods and materials 2.1 Scenario HIMAGE was developed in the CHVNG cardiology department (Centro Hospitalar de Vila Nova de Gaia – Hospital of Gaia), which is supported by two imaging laboratories. The first implementation of HIMAGE was based on JPEG Baseline (Joint Photographic Experts Group) [8]. With this system, an echocardiography (US) study typically generates data between 20 and 30MB and an angiographic (XA) study between 40 and 60MB, depending on the technical characteristics of the equipment, on the operator expertise, and on the procedure type [9]. Although this volume can be easily transferred inside an institution Intranet or through the Internet, the latency, especially in the latter case, may be a drawback for some scenarios. One possible solution can be the exploitation of lossy compression techniques that still preserve the diagnostic quality of the existent JPEG solutions. Over the years, several studies have investigated the impact of various compression ratios on image quality, and on the observer performance for several diagnostic tasks. The general trend shown by the results of these studies is that optimal compression ratios for a modality are rarely achieved, as the observer's performance is tightly coupled with each particular diagnostic task. Currently, guidelines are published by international scientific and professional organizations, recommending suitable algorithms and compression ratios for a broad range of diagnostic tasks (see [10–12] for XA and [13–15] for US). 2.2 Image compression In cardiology, the majority of the data produced in the XA and US procedures is related to cine-loop sequences, which have a significant time-space redundancy, especially in ultrasound. Because the JPEG-based DICOM compression algorithms only explore the intra-frame image redundancy (space) [16], we decided to investigate the utilization of a more powerful video encoder that could also contemplate the inter-frame redundancy (time). In general, distinct digital video codecs produce significantly dissimilar results and medical image sequence types (modalities, cine/still, color/grayscale, etc.). This occurs because distinct sequences contain distinct kinds of information (motion, noise, etc.). As a result, it is not possible to select the very best among several codecs, to use for compression of all types of image/video. In the particular case of US cardiovascular images, after several trials and result evaluations with dynamic encoders [9], we realized that Moving Picture Experts Group (MPEG4) was the coding standard that provided the best tradeoff between image quality and storage requirements. The emergence of MPEG4 [17] as a coding standard for multimedia data with object-based and other enhanced encoding facilities appears to be a good alternative for the cost-effective storage and transmission of cardiac digital cine-loop sequences. With this new codec, a typical US file rarely exceeds 200–300kB [9]. At this order of magnitude, it is already feasible to envisage a pure online archive solution capable of handling all the registered procedures whatever their clinical or epidemiological life-cycle may be. Another immediate consequence of our encoding approach is that the reduced transmission times, either in Intranet mode or in Internet mode, may now be considered, in the worst cases, minor drawbacks in the overall imaging workflow. 2.3 DICOM private transfer syntax Since MPEG4 is not a DICOM native coding schema, subsequent image transmission, decoding and reviewing is accomplished through a specifically designed DICOM private transfer syntax. Moreover, to ensure that HIMAGE has the flexibility to support other modalities/encoders, it was decided not to insert the MPEG4 directly in the Tag Length Value (TLV) of the DICOM data structure [18]. Instead, we developed a multimedia container that dynamically supports several encoders (Fig. 1 ). The container includes a field that stores the encoder ID code, which is similar to the field used by the Audio Video Interleave (AVI) RIFF headers [19]. This approach represents the best modular software solution, as we simply need to change a single parameter in the HIMAGE conversion engine if a more efficient codec is developed. In Fig. 2 it is possible to compare parts of the DICOM representation of the “default transfer syntax” against our “private syntax,” in the specific case of a US 25-frame image sequence, with a RGB 576*768 matrix. Two important aspects are noticeable. First, the DICOM transfer syntax identifier is changed (from DefaultTransferSyntaxUID to PrivateTransferSyntaxUID). Second, the “PixelData” field size is reduced 120 times (from 33177600 to 275968). 3 Results 3.1 Software engineering In the initial versions of HIMAGE, the main objective was to reduce data volume through the implementation of a private transfer syntax that was capable of supporting multiple video encoders. In the current version herein described, another attained goal is the provisioning of a Web-based PACS that can be accessed easily and securely through a common Web browser with no further need for complex local installation of software. Web solutions can be created using one of the current available architectures [20–22]. Our approach is based on the .NET framework, which allows for smooth integration with existing code (in C, C++ and Visual Basic). All of the core functions used to manipulate the images and the DICOM structures were written in C++ and packed as Dynamic-link Library (DLL) components. We have developed a DICOM C++ SDK (Software Development Kit) that allows manipulation of the DICOM persistent object (i.e. structured files) and implements several HIMAGE (DICOM) network services such as Storage, Query/Retrieve and Modality Worklist (Fig. 3 ) [23]. The graphical components supporting all image-related tasks (visualization, reporting, etc.) were developed as Visual Basic plugins (ActiveX) and are directly embedded in the ASPX .NET pages (Fig. 4 ). The ActiveX viewer allows the direct integration of private DICOM files with the Web content. The communication between the dynamic HTML contents and the ActiveX binary is performed by JavaScript code. To be visualized or processed, the study images must be downloaded from the server to the client platform. All DICOM persistent object transfers (retrieves) are supported by a Web Service developed in C#. Though the Web Services are actually using XML-SOAP (Extensible Markup Language-Simple Object Access Protocol) [24] to transfer data, the XML [25] does not easily handle embedded binary data, which can create problems for DICOM file transfer. There are several issues, such as memory size and computation costs, that are associated with the conversion of binary data into base64 format (which is treated as a string). This encoding schema (base64) typically increases the original object size by 33% and also increases the processing time relative to binary-text-binary conversion [26]. To bypass this XML-SOAP drawback, it was necessary to develop a parallel gateway channel (HTTP encapsulated) to transfer DICOM files in a more efficient way. 3.2 System workflow Our clinical facility (CHVNG) is equipped with nine echocardiography machines distributed over three geographically dispersed hospital units. They have standard DICOM3.0 output interfaces and a configuration that ensures an automatic DICOM SCU (client) storage service at the end of each medical procedure. Daily output to the network typically reaches approximately 1200 DICOM files (both still and cine-loops). The ultrasound image data is sent to the Acquisition Processing Unit (APU) in DICOM default transfer syntax, i.e. uncompressed format (Fig. 5 ). The received procedures are analyzed (the alphanumeric data is extracted from DICOM headers) to detect eventual exam/patient ID errors and, if format conditions are verified, the exam is added to HIMAGE with the image data compressed and embedded in a new DICOM private syntax file. The result is then passed into the “Storage Server” that makes it permanently available to the PACS users. The original raw images are also saved, but they are only kept online for 6 months. The developed client application consists of a Web DICOM viewer (Fig. 7) that handles medical images and films available in the HIMAGE database, formatted in standard DICOM or in DICOM extended with our private syntax. Since the HIMAGE client solution is completely developed in Web technology, the access to the exams is controlled by appropriate security rules. Authentication is performed through a username/password pair and communication security is assured by an HTTPS connection. 3.3 Integration with a cardiovascular information system Implementation of an integrated healthcare access interface to patient clinical data represents the core element to accomplish new healthcare services with improved quality and efficiency. After the emergence of PACS as a fundamental infrastructure of any digital imaging department, the focus turned to the possibilities of integrating the medical image with other sources of information. Cardiologists need structured reports including images and related patient information. In our CHVNG scenario, a commercial Cardiovascular Information System (CIS) handles this additional information. Integration of the PACS with the existing CIS is an important feature for the healthcare professional. Besides the interface conformance, on network and application protocols, it is crucial to ensure data consistency among several systems. To implement this requirement, HIMAGE provides a DICOM Modality Worklist SCP service that is connected to the CIS database. It enables modalities (using C-FIND command) to query the server for patient and study-related information that will be thereafter inserted in the DICOM header. This process ensures consistency between both information systems and also that all PACS studies can be correctly referenced from the CIS. Concerning integrated access to information, the HIMAGE provides smooth integration of patient image data in the CIS environment. The inclusion of PACS images in other environments is easy due to DICOM private transfer syntax container portability. A “Himage Integration Engine” module (Fig. 6 ) was developed with two integration options: a. Multimedia AVI container: the engine can extract the MPEG4 encoded image data from the DICOM and encapsulate it in an AVI file to be, for instance, inserted in the CIS Web document; b. Plug-in module: an ActiveX application viewer is available, allowing the direct integration of the HIMAGE DICOM files in both Winforms and Web environments. This plug-in downloads the image data from HIMAGE archive and displays it. 3.4 Web-enabled interface During the last 5 years, the ubiquity of Web interfaces has pushed practically all PACS suppliers to develop client applications in which clinical practitioners can receive and analyze medical images using conventional personal computers and Web browsers [20,21]. Because of security and performance issues, use of these software packages has mostly been restricted to Intranets. Paradoxically, one of the most important advantages of digital imaging systems was to enable the widespread sharing and remote access to medical data between healthcare institutions. The HIMAGE Web version is fully operational, provides all the necessary functionality, and has the same performance and flexibility as the previous desktop version [9]. The application setup is very simple. It is downloaded from the Web server and is automatically installed when given explicit authorization by the user. Graphically, the HIMAGE main window includes a grid box with a list of patients and a movie preview of three sequences for the current selection (Fig. 7 ). The user can search all procedures using criteria such as patient name, patient ID, procedure ID/type/date, source institutions and equipment. A second graphical application layer provides interfaces to the system modules: communications to telecardiology, DICOM viewer (Fig. 8 ), report (Fig. 9 ) and export. In the DICOM viewer window (Fig. 8), it is possible to visualize the image sequences (still and cine-loops) and to select frames from various sequences that are then sent to the report area. Other traditional functions have been included such as image manipulation tools (contrast/brightness), printing capability, and the export of images in distinct formats (DICOM3.0 default transfer syntax, AVI, BMP, JPEG). It is also possible to copy a specific image to the clipboard and paste it onto some other external application. In the compare mode, the viewer window can work in either of two ways: automatic or manual. The automatic mode is used for a specific type of procedure—the “Stress eco” (Fig. 8). In this case, the visualization technique is based on the information stored in the DICOM file headers. HIMAGE provides a simultaneous and synchronized display of the several “Stages” of a heart “View.” The term “Stage” is defined as a phase in the stress echo exam protocol. The “View” is the result of a particular combination of the transducer position and orientation at the time of the image acquisition. Manual mode allows the user to select among distinct images of the same and/or different procedures that can then be displayed in a defined window matrix. In the report module (Fig. 9), the user can arrange the location of the image(s) or delete some frames using a drag-and-drop functionality. Finally, the output image matrix (2×3 or 3×3) is bundled with the clinical report to generate an Rich Text Format (RTF) file that is compatible with common text editors. The user can customize the base template used to generate the report file. For example, one could include the institution logo and report headers. The export module allows the procedure to be saved in a CDROM or DVD-ROM, using the uncompressed DICOM default transfer syntax format or the AVI format. A standalone fully compliant DICOM viewer application is also stored (Fig. 10 ), which starts automatically whenever the disk is used. 3.5 Exploitation The HIMAGE is installed in two central hospitals and three small diagnostic centers. Our main installation and research laboratory is the CHVNG cardiology department with approximately 65,000 patient records. In Table 1 it is possible to observe some general statistics relative to the CHVNG US data. Concerning transmission times, the Web HIMAGE images are downloaded in packs of 3 sequences (due to preview mode) based on the user selection. In a telework environment, supported by a 4Mbits ADSL (Asymmetric Digital Subscriber Line), a complete pack of 3 cine-loops takes typically less then 10s to download, decompress and display, including the overhead introduced with an encrypted SSL (Secure Sockets Layer) channel. 4 Discussion We have described a Web-enabled PACS software solution that is specially oriented to support demanding cardiac imaging laboratories. It provides a cost-efficient digital archive, ensures full online availability of studies and simplifies the transmission of medical data over the Internet. The benefits obtained from the availability of all historical image data in a simple, fast and integrated Web interface are unquestionable to practitioners and to patients, and are likely to induce a significant improvement in the overall quality of healthcare services. In our main installation, two years after the introduction of HIMAGE in the echocardiography laboratory, and maintaining the human resources, one realize an increase of procedures/year from 4000 to 7000, which is a good indication considering other reported results of PACS productivity improvements [27–29]. Although this result can be explained by several factors, to an increase on patient demand and on optimized workflow process, an informal and continuous assessment performed near the physicians suggest that HIMAGE was a major driving to this change: (a) the dead times and the information handling mistakes were considerably reduced; (b) since HIMAGE is ubiquitously available, the remote diagnostic can be easily performed without moving the patient or his records between several buildings; (c) the patient history (CIS reports and PACS images) is permanently available, which avoids the need for CD or other media storage manual handling. One main HIMAGE advantage is associated with its transfer rate efficiency. Healthcare professionals do not adopt telemedicine or telework platforms if they need to wait, for instance, 2–3h to receive/download a clinical image study with diagnostic quality. The advantage of the proposed system stems from the implementation of a private DICOM transfer syntax that supports any video encoder. In the cardiac US we are using a MPEG4 codec that provides high compression and maintains diagnostic quality. Qualitative assessments have been made of the previous HIMAGE Desktop version (no Web interface) [9]. In a simultaneous and blind display of the original against the compressed cine-loops, 37% of trials have selected the compressed sequence as the best image. This suggests that other factors related to visualization conditions are more likely to influence observer accuracy than the image compression itself. The interoperability of HIMAGE with other DICOM PACS implies the decompression of private MPEG4 images to an uncompressed normalized format like, for instance, the DICOM Default Transfer Syntax. However, we believe that, in the future, MPEG4 will be adopted by the DICOM standard that currently only supports MPEG-2 [30]. Finally, a major constraint of the presented solution is its dependency on Windows and on Internet Explorer browser. This has to do with the richness of the interface that requires a powerful platform to work (like ActiveX or Flash). The result will not be possible using pure web2.0 technologies. This decision provides a Web interface supporting all the requirements of a DICOM viewer. In the future, it is planned to update the HIMAGE platform to Microsoft .NET Silverlight technology, which is multi operating system compliant. 5 Conclusions In this paper, we have presented the Web HIMAGE software, a DICOM conformant Web PACS. Reducing the size of exam images, while preserving the diagnostic quality, is a major novel feature of this HIMAGE application. This is especially important for ensuring time-effective transmission through Internet connections. We successfully demonstrated the utility of HIMAGE (started with the HIMAGE desktop version) in a telemedicine project established between CHVNG (Portugal) and the Central Hospital of Maputo (Mozambique). The Web version of HIMAGE is currently being used in clinical environments with different requirements, from small private laboratories to public central hospitals. In the main installation, (CHVNG), we have made more than 36,000 US procedures permanently available through this system (850,000 cardiovascular digital sequences). References [1] H.K. Huang PACS and Imaging Informatics: Basic Principles and Applications 2004 Wiley [2] DICOM, Digital Imaging and Communications in Medicine version 3.0, ACR (the American College of Radiology) and NEMA (the National Electrical Manufacturers Association), [3] C. Costa J.L. Oliveira A. Silva V. Gama J. Ribeiro Enhanced PACS to support demanding telemedicine and telework scenarios CARS 2007-International Congress and Exhibition: Computer Assisted Radiology and Surgery 2 2007 S322 S323 [4] D. Polónia A. Silva C. Costa J.L. Oliveira Brokerage mechanism proposal for teleradiology studies distribution P.A. Katherine M.S. Khan Proceedings of SPIE-Volume 6919, 691906. Medical Imaging 2008 2008 PACS and Imaging Informatics San Diego, USA [5] H.J. Otero L. Nallamshetty F.J. Rybicki Interdepartmental conflict management and negotiation in cardiovascular imaging Journal of the American College of Radiology 5 2008 834 841 [6] K.M. Dallessio Integrating cardiology and radiology PACS Applied Radiology 36 2007 34 35 [7] E. Kaldoudia D. Karaiskakisb A service based approach for medical image distribution in healthcare Intranets Computer Methods and Programs in Biomedicine 81 2006 117 127 [8] A. Silva C. Costa P. Abrantes V. Gama A. Boer A cardiology oriented PACS Proceedings of SPIE: Medical Imaging San Diego, USA 1998 [9] C. Costa A. Silva J.L. Oliveira V. Ribeiro J. Ribeiro Himage PACS: a new approach to storage, integration and distribution of cardiologic images PACS and Imaging Informatics-Proceedings of SPIE San Diego, CA, USA 2004 [10] R.U. Brennecke U. Burgel R.U. Simon G. Rippin H.P. Fritsch T. Becker S.E. Nissen American College of Cardiology/European Society of Cardiology international study of angiographic data compression phase III: measurement of image quality differences at varying levels of data compression Journal of the American College of Cardiology 35 2000 1388 1397 [11] R.A. Kerensky J.T. Cusma P. Kubilis R.U. Simon T.M. Bashore J.W. Hirshfeld Jr. D.R. Holmes Jr. C.J. Pepine S.E. Nissen American College of Cardiology/European Society of Cardiology international study of angiographic data compression phase I: the effects of lossy data compression on recognition of diagnostic features in digital coronary angiography Journal of the American College of Cardiology 35 2000 1370 1379 [12] J.C. Tuinenburg G. Koning E. Hekking A.H. Zwinderman T. Becker R.U. Simon J.H.C. Reiber American College of Cardiology/European Society of Cardiology international study of angiographic data compression phase II: the effects of varying JPEG data compression levels on the quantitative assessment of the degree of stenosis in digital coronary angiography Journal of the American College of Cardiology 35 2000 1380 1387 [13] A. Umeda Y. Iwata Y. Okada M. Shimada A. Baba Y. Minatogawa T. Yamada M. Chino T. Watanabe M. Akaishi A low-cost digital filing system for echocardiography data with MPEG4 compression and its application to remote diagnosis Journal of the American Society of Echocardiography 17 2004 1297 1303 [14] D.S. Segar D. Skolnick S.G. Sawada G. Fitch D. Wagner D. Adams H. Feigenbaum A comparison of the interpretation of digitized and videotape recorded echocardiogram Journal of the American Society of Echocardiography 12 1999 714 719 [15] T.H. Karson R.C. Zepp S. Chandra A. Morchead J.D. Thomas Digital storage of echocardiograms offers superior image quality to analog storage, even with 20:1 digital compression: results of the digital echo record access study Journal of the American Society of Echocardiography 9 1996 769 778 [16] Joint Photographic Experts Group, JPEG standard (ITU-T T.81 | ISO/IEC 10918-1), 1994. [17] ISO/IEC Moving Picture Experts Group, MPEG-4 standard (ISO/IEC 14496), 1999. [18] DICOM-P5 Digital Imaging and Communications in Medicine (DICOM), Part 5: Data Structures and Encoding 2004 National Electrical Manufacturers Association [19] IBM Corporation and Microsoft Corporation, Multimedia Programming Interface and Data Specifications 1.0, 2001 (cited, available from: [20] J. Zhanga J. Suna J.N. Stahl PACS and Web-based image distribution and display Computerized Medical Imaging and Graphics vol. 27 2003 Elsevier pp. 197–206 [21] G.K. Matsopoulos V. Kouloulias P. Asvestas N. Mouravliansky K. Delibasis D. Demetriades MITIS: a WWW-based medical system for managing and processing gynecological–obstetrical–radiological data Computer Methods and Programs in Biomedicine 76 2004 53 71 [22] E. Marcos C.J. Acuña B. Vela J.M. Cavero J.A. Hernández A database for medical image management Computer Methods and Programs in Biomedicine 86 2007 255 269 [23] DICOM-P4 Digital Imaging and Communications in Medicine (DICOM), Part 4: Service Class Specifications 2007 National Electrical Manufacturers Association [24] World Wide Web Consortium (W3C), Web Services Architecture. 2004, W3C Working Group Note 11, 2004 (available from [25] World Wide Web Consortium (W3C), Extensible Markup Language (XML) 1.0, 4th ed., 2006, W3C Recommendation (available from [26] A. Bosworth D. Box M. Gudgin M. Nottingham D. Orchard J. Schlimmer XML, SOAP and Binary Data—Version 1.0 2003 BEA Systems, Microsoft Corporation [27] L. Lepanto G. Pare D. Aubry P. Robillard J. Lesage Impact of PACS on dictation turnaround time and productivity Journal of Digital Imaging 19 2006 92 97 [28] B. Reiner E. Siegel M. Scanlon Changes in technologist productivity with implementation of an enterprisewide PACS Journal of Digital Imaging 15 2002 22 26 [29] A.D. Mackinnon R.A. Billington E.J. Adam D.D. Dundas U. Patel Picture archiving and communication systems lead to sustained improvements in reporting times and productivity: results of a 5-year audit Clinical Radiology 63 2008 796 804 [30] DICOM-SUPL42 Digital Imaging and Communications in Medicine (DICOM), Supplement 42: MPEG2 Transfer Syntax 2004 National Electrical Manufacturers Association "
    },
    {
        "doc_title": "Validation of a dental image analyzer tool to measure alveolar bone loss in periodontitis patients",
        "doc_scopus_id": "58149345204",
        "doc_doi": "10.1111/j.1600-0765.2008.01111.x",
        "doc_eid": "2-s2.0-58149345204",
        "doc_date": "2009-02-01",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Periodontics",
                "area_abbreviation": "DENT",
                "area_code": "3506"
            }
        ],
        "doc_keywords": [],
        "doc_abstract": "Background and Objective: Radiographs are an essential adjunct to the clinical examination for periodontal diagnoses. Over the past few years, digital radiographs have become available for use in clinical practice. Therefore, the present study investigated whether measuring alveolar bone loss, using digital radiographs with a newly constructed dental image analyzer tool was comparable to the conventional method, using intra-oral radiographs on film, a light box and a Schei ruler. Material and Methods: Alveolar bone loss of the mesial and distal sites of 60 randomly selected teeth from 12 patients with periodontitis was measured using the conventional method, and then using the dental image analyzer tool, by five dentists. The conventional method scored bone loss in categories of 10% increments relative to the total root length, whereas the software dental image analyzer tool calculated bone loss in 0.1% increments relative to the total root length after crucial landmarks were identified. Results: Both methods showed a high interobserver reliability for bone loss measurements in nonmolar and molar sites (intraclass correlation coefficient ≥ 0.88). Also, a high reliability between both methods was demonstrated (intraclass correlation coefficient nonmolar sites, 0.98; intraclass correlation coefficient molar sites, 0.95). In addition, the new dental image analyzer tool showed a high sensitivity (1.00) and a high specificity (0.91) in selecting teeth with ≥ 50% or < 50% alveolar bone loss in comparison with the conventional method. Conclusion: This study provides evidence that, if digital radiographs are available, the dental image analyzer tool can reliably replace the conventional method for measuring alveolar bone loss in periodontitis patients. © 2008 The Authors.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Digital radiography detectors - A technical overview: Part 1",
        "doc_scopus_id": "57749195582",
        "doc_doi": "10.1016/j.radi.2008.02.004",
        "doc_eid": "2-s2.0-57749195582",
        "doc_date": "2009-02-01",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Radiology, Nuclear Medicine and Imaging",
                "area_abbreviation": "MEDI",
                "area_code": "2741"
            }
        ],
        "doc_keywords": [],
        "doc_abstract": "During the last two decades screen-film (SF) systems have been replaced by digital X-ray systems. The advent of digital technologies brought a number of digital solutions based on different detector and readout technologies. Improvements in technology allowed the development of new digital technologies for projection radiography such as computed radiography (CR) and digital radiography (DR). The large number of scientific papers concerning digital X-ray systems that have been published over the last 25 years indicates the relevance of these technologies in healthcare. There are important differences among different detector technologies that may affect system performance and image quality for diagnostic purposes. Radiographers are expected to have an effective understanding of digital X-ray technologies and a high level of knowledge and awareness concerning the capabilities of these systems. Patient safety and reliable diagnostic information are intrinsically linked to these factors. In this review article - which is the first of two parts - a global overview of the digital radiography systems (both CR and DR) currently available for clinical practice is provided. © 2008 The College of Radiographers.",
        "available": true,
        "clean_text": "serial JL 272334 291210 291703 291926 31 Radiography RADIOGRAPHY 2008-04-01 2008-04-01 2011-07-22T23:17:32 S1078-8174(08)00010-2 S1078817408000102 10.1016/j.radi.2008.02.004 S300 S300.2 FULL-TEXT 2015-05-15T05:05:43.622236-04:00 0 0 20090201 20090228 2009 2008-04-01T00:00:00Z articleinfo crossmark dco dateupdated tomb dateloaded datesearch indexeddate issuelist volumelist yearnav articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright dateloadedtxt docsubtype doctype doi eid ewtransactionid hubeid issfirst issn issnnorm itemstage itemtransactionid itemweight openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sectiontitle sortorder srctitle srctitlenorm srctype subheadings volfirst volissue figure table body affil articletitle auth authfirstini authfull authkeywords authlast primabst ref alllist content subj ssids 1078-8174 10788174 15 15 1 1 Volume 15, Issue 1 11 58 62 58 62 200902 February 2009 2009-02-01 2009-02-28 2009 Original Articles article fla Copyright © 2008 The College of Radiographers. Published by Elsevier Ltd. All rights reserved. DIGITALRADIOGRAPHYDETECTORSATECHNICALOVERVIEWPART1 LANCA L Introduction Overview of CR and DR detectors Computed radiography Digital radiography Large area direct conversion systems Large area indirect conversion systems Conclusions Conflict of interest References VANO 2007 461 466 E PERSLIDEN 2004 50 58 J BUSCH 2004 H DIMOND3 IMAGEQUALITYDOSEMANAGEMENTFORDIGITALRADIOGRAPHYFINALREPORT SAMEI 2004 313 334 E KORNER 2007 675 686 M SCHAETZING 2003 7 22 R ADVANCESINDIGITALRADIOGRAPHYRSNACATEGORICALCOURSEINDIAGNOSTICRADIOLOGYPHYSICS COMPUTEDRADIOGRAPHYTECHNOLOGY SAMEI 2003 49 61 E ADVANCESINDIGITALRADIOGRAPHY PERFORMANCEDIGITALRADIOGRAPHICDETECTORSFACTORSAFFECTINGSHARPNESSNOISE CHOTAS 1999 595 599 H CHOTAS 2001 679 682 H ROWLANDS 2002 R123 R166 J AMERICANASSOCIATIONOFPHYSICISTSINMEDICINE 2006 REPORTAAPMTASKGROUP10 ACCEPTANCETESTINGQUALITYCONTROLPHOTOSTIMULABLESTORAGEPHOSPHORIMAGINGSYSTEMS KOTTER 2002 2562 2570 E CULLEY 2000 J DIGITALRADIOGRAPHYSYSTEMSOVERVIEW LANCAX2009X58 LANCAX2009X58X62 LANCAX2009X58XL LANCAX2009X58X62XL item S1078-8174(08)00010-2 S1078817408000102 10.1016/j.radi.2008.02.004 272334 2011-10-05T15:54:30.209988-04:00 2009-02-01 2009-02-28 true 491842 MAIN 5 74427 849 656 IMAGE-WEB-PDF 1 gr1 33663 283 371 gr1 10094 164 215 gr1 237167 1254 1645 gr2 45062 356 354 gr2 4323 164 163 gr2 298285 1581 1570 gr3 18882 117 372 gr3 5387 69 219 gr3 104156 518 1649 gr4 51116 322 595 gr4 5968 118 219 gr4 387637 1424 2633 gr5 47595 457 369 gr5 5964 163 132 gr5 295947 2023 1635 gr6 37761 252 744 gr6 5886 74 219 gr6 298955 1114 3293 YRADI 783 S1078-8174(08)00010-2 10.1016/j.radi.2008.02.004 The College of Radiographers Figure 1 General description model for digital X-ray technologies (adapted from 8 ). Figure 2 SPS exposure and PSL. Figure 3 SPS scanning process. Figure 4 Flat-panel structure. Figure 5 TFT array. Figure 6 Unstructured or structured cintilator. Table 1 Three components of digital detectors 7 Detector technology Capture element Coupling element Charge readout CR BaFBr:Eu2+ phosphor Photostimulated luminescence (PSL) light-guide Photo-multiplier tube; signal digitization DR Direct conversion a-Se None TFT array Indirect conversion CsI or G2O2S phosphor Contact layer a-Si photodiode/TFT array Digital radiography detectors – A technical overview: Part 1 Luís Lança a ∗ Augusto Silva b a School of Health Technology, Lisbon Polytechnics, Lisbon, Portugal b Department of Electronic, Telecommunications and Informatics, Aveiro University, Aveiro, Portugal ∗ Corresponding author. During the last two decades screen-film (SF) systems have been replaced by digital X-ray systems. The advent of digital technologies brought a number of digital solutions based on different detector and readout technologies. Improvements in technology allowed the development of new digital technologies for projection radiography such as computed radiography (CR) and digital radiography (DR). The large number of scientific papers concerning digital X-ray systems that have been published over the last 25 years indicates the relevance of these technologies in healthcare. There are important differences among different detector technologies that may affect system performance and image quality for diagnostic purposes. Radiographers are expected to have an effective understanding of digital X-ray technologies and a high level of knowledge and awareness concerning the capabilities of these systems. Patient safety and reliable diagnostic information are intrinsically linked to these factors. In this review article – which is the first of two parts – a global overview of the digital radiography systems (both CR and DR) currently available for clinical practice is provided. Keywords CR DR X-ray detectors Digital technologies Introduction Advances in digital technology allowed the development of full digital X-ray detectors that are currently available for projection radiography. Computed radiography (CR) and Digital radiography (DR) are digital technologies widely spread in healthcare institutions nowadays. These technologies have been replacing traditional screen-film (SF) systems and this constitutes a challenge for radiographers and other healthcare staff. The transition from a SF environment to a digital environment is not a simple matter. Technical factors concerning image acquisition, the management of patient dose and diagnostic image quality are some issues that could influence this process. In a transition process from SF to digital, patient radiation doses could increase 40–103%. 1 When compared to SF, digital technology could increase patient radiation doses due to the wide dynamic range they have. However, the dynamic range is useful because it contributes for a better clinical image quality when compared to traditional SF systems. 2 This is an important difference among analogical and digital technologies. The risk of overexposure with no adverse effect on image quality could be present. Digital imaging systems could deliver over or under-exposure that influences patient's dose. Overexposure could provide good quality images, but may cause unnecessary patient dose. The management of patient dose and the quality of images involves the relationship between three core aspects of the imaging process. 3 These are determinants for the diagnostic quality of the radiographic image: (i) choice of radiographic technique; (ii) radiation dose to the patient and; (iii) diagnostic quality of the radiographic image. This is a challenge for radiographers because clinical advantages and limitations of digital technologies for projection radiography are also dependent on the radiographer's options for a particular patient examination. A technical overview about digital radiography detectors is provided in this two part review article. In this article – which is the first of two parts – a global overview of the digital radiography systems (both CR and DR) currently available for clinical practice is provided. Overview of CR and DR detectors Several digital systems are currently available for the acquisition of projection radiographs. These digital systems are traditionally split into two broadly defined categories: computed radiography (CR) and digital radiography (DR). 4,5 Although this taxonomy is commonly accepted other classifications are described: direct digital radiography and Indirect Digital Radiography technologies (including CR). 6 In this case, the detector classification is related with the conversion process of X-ray energy to electric charge. Despite charge-couple devices (CCDs) could be considered indirect conversion DR systems, they are not flat-panel detectors and studies dealing with CCD-based digital general radiography are rare. 5 This technology is mainly related to other applications such as mammography and digital dental radiography. 5 For this reason CCDs will be excluded from this review. Despite the taxonomy that is used the major difference among digital technology systems is how the process of X-ray detection and readout is performed. Concerning CR systems they use storage-phosphor image plates with a separate image readout process which means an indirect conversion process; DR technology converts X-rays into electrical charges by means of a direct readout process using TFT arrays. These systems can be further divided into direct and indirect conversion groups depending on the type of X-ray conversion used. 5 Table 1 shows the differences among detector technology concerning three components of digital detectors 7 : the capture element, the coupling element, and the charge readout element. DR detectors can use either a direct or indirect process for converting X-rays into electric charges. These detectors use direct readout by means of a Thin-film transistor (TFT) array despite the conversion process of the X-ray beam. Direct conversion detectors have a X-ray photoconductor – such as amorphous selenium (a-Se) – that converts directly at only one stage X-ray photons into electric charges. Indirect conversion systems use a two stage technique for conversion. They have a scintillator, such as Cesium Iodide (CsI) that converts X-rays into visible light at a first stage. That light is then converted – at a second stage – into an electric charge by means of an amorphous silicon photodiode array. 8 CR technology uses an indirect conversion process using a two stage technique. X-rays are captured at a storage-phosphor screen (SPS) (ex: BaFBr:Eu2+) and then a photodetector captures the light emitted from the SPS and converts the captured luminescence into a corresponding digital image. Fig. 1 show a general description model for digital X-ray technologies. Despite the process of X-ray detection and readout digital detectors offer several advantages when compared to SF systems. This includes wide dynamic range, adjustable image processing, better image quality, rapid image acquisition and image access at remote locations. 9 Computed radiography Computed radiography (CR) was the first available digital technology for projection radiography. CR technology is based in storage-phosphor screens (SPS) and its first clinical application by Fuji took place at the early 1980s. This technology uses a photostimulable detector replacing the traditional SF cassettes. The storage-phosphor plates are exposed inside the cassettes with standard dimensions for typical plain radiography and no change of generator, X-ray tube and Bucky wall or table mounted system is necessary. CR technology allows the radiographer to obtain plain radiography images like in a traditional SF system. The difference is how the latent image is created and how this image processing is done. The basic CR imaging cycle has three steps 6 : (i) expose, (ii) readout, and (iii) erase. Inside the radiography cassette an image plate (IP) – or SPS – having a detective layer of photostimulable crystals is available. The detective layer consists of a family of phosphors BaFX:Eu2+ where X can be any of the halogens Cl, Br or I (or an arbitrary mixture of them). 10 A typical SPS can store a latent image for a considerable period of time. However, it will lose about 25% of the stored signal between 10min to 8h after an exposure resulting in the loss of energy through spontaneous phosphorescence. 11 The phosphor crystals are usually cast into plates into resin material in an unstructured way (unstructured scintillators). 5 When the SPS is exposed to the X-ray the incident radiation excites electrons from the valence band to the conduction band ( Fig. 2a and b). These excited electrons absorb the X-ray energy and they are trapped at a stable energy level of the atom. The phosphor stores absorbed X-ray energy in crystal structure and a latent image is then created at these high-energy states giving a spatial distribution of these electrons at the SP detector. This trapped energy can be released if stimulated by additional light energy of the proper wavelength by the process of photostimulated luminescence (PSL). 11 After the X-ray exposure and the creation of the latent image, the SPS is scanned in a separate CR reader device. The readout is a process that follows exposure of the image plate and constitutes the second step of the CR imaging cycle. A red laser beam scans the photostimulable screen stimulating the emission of blue light photons under the excitation of the laser beam. When the detective layer of the IP is scanned pixel by pixel with a high-energy laser beam of a specific wave length, stored energy is set free as emitted light having a wave length different from that of the laser beam. 5 This triggers the process of photostimulated luminescence (PSL) resulting in the emission of blue light in an amount proportional to the original X-ray irradiation 10 and setting free the excited electrons to their lower energy level (Fig. 2c and d). This light is collected by photodiodes and converted into electric charge while an analog-to-digital device converts it into a corresponding digital image. Fig. 3 shows the SPS scanning process. Finally, the third step of the basic CR imaging cycle is the Residual Signal Erasure. Residual latent image electrons are still trapped on higher energy levels after readout. This energy is erased after the readout process using a high-intensity white light source that flushes the traps without reintroducing electrons from the ground energy level. 11 Digital radiography Digital radiography (DR) flat-panel systems with integrated readout mechanisms were introduced in the market at the end of the 1990s. 12 Flat-panel systems, also known as large area X-ray detectors, integrate an X-ray sensitive layer and an electronic readable system based on TFT arrays. Detectors using a scintillator layer and a light-sensitive TFT photodiode are called indirect conversion TFT detectors. Those using an X-ray sensitive photoconductor layer and a TFT charge collector are called direct conversion TFT detectors. 12 The reference to amorphous silicon (a-Si), which is used in TFT arrays to record the electronic signal, should not be confused with amorphous selenium (a-Se) the material used to capture X-ray energy in a direct digital detector. The structure of a DR flat-panel system is shown in Fig. 4. This electronic readable system allows an active readout process, also called active matrix readout, in opposition to the storage-phosphor systems where no active readout elements are integrated within the detector. The entire readout process is very fast, allowing further developments in digital real-time X-ray detectors. 12 TFT arrays ( Fig. 5) are typically deposited onto a glass substrate in multiple layers, with readout electronics at the lowest level, and charge collector arrays at higher levels. Depending on the type of detector being manufactured, charge collection electrodes or light sensing elements are deposited at the top layer of this “electronic sandwich.” 13 The advantages of this design include compact size and immediate access to digital images. The performance of DR systems greatly exceeds the performance of CR systems, which have efficiencies of 20–35%, and of screen-film systems for chest radiography, which have nominal efficiencies of 25%. 13 Large area direct conversion systems Large area direct conversion systems use amorphous selenium (a-Se) as the semiconductor material because of its X-ray absorption properties and extremely high intrinsic spatial resolution. 12,13 Before the flat-panel is exposed to X-rays an electric field is applied across the selenium layer. Then the X-ray exposure generates electrons and holes within the a-Se layer: the absorbed X-ray photons are transformed into electric charges and drawn directly to the charge-collecting electrodes due to the electric field. Those charges – proportional to the incident X-ray beam – are generated and migrate vertically to the both surfaces of the selenium layer, without much lateral diffusion. At the bottom of the a-Se layer, charges are drawn to the TFT charge collector, where they are stored until readout. The charge collected at each storage capacitor is amplified and quantified to a digital code value for the corresponding pixel. During the readout, the charge of the capacitors of every row is conducted by the transistors to the amplifiers. Large area indirect conversion systems Large area indirect conversion systems use cesium iodide (CsI) or gadolinium oxisulphide (Gd2O2S) as an X-ray detector. The scintillators and phosphors used in indirect conversion detectors can be either structured or unstructured ( Fig. 6). Unstructured scintillators scatter a large amount of light and this reduces spatial resolution. 7 Structured scintillators consist of phosphor material in a needlelike structure (the needles being perpendicular to the screen surface). This increases the number of X-ray photon interactions and reduces the lateral scattering of light photons. 7 When the scintillator layer is exposed to X-rays the beam is absorbed and converted into fluorescent light. At a second stage that light is converted into an electric charge by means of an a-Si photodiode array. 8 Indirect conversion detectors are constructed by adding an a-Si photodiode circuitry and a scintillator as the top layers of the TFT sandwich. These layers replace the X-ray semiconductor layer used in a direct conversion device. 13 The active area of the detector is divided into an integrated array of image elements – the pixel – and each element contains a photodiode and a TFT switch available for the readout process. Conclusions Different digital technologies are currently available for projection radiography. DR and CR constitute a remarkable improvement in detector technology over the last 25 years. Although SF and digital technology coexist at the present time the trends in the future seems to point to the digital technology. The new digital and technological solutions at the radiography field seem to represent the change and the challenges concerning the radiographer's work in a digital environment. Further developments in digital detector technology are expected in the near future. This is an opportunity for the continuous improvement and optimization concerning the technical factors of image acquisition, the management of patient dose and the diagnostic image quality. Conflict of interest No conflict of interest is declared. References 1 E. Vaño J.M. Fernández J.I. Ten C. Prieto L. González R. Rodríguez Transition from screen-film to digital radiography: evolution of patient radiation doses at projection radiography 10.1148/radiol.2432050930 Radiology 243 2007 461 466 2 J. Persliden Digital radiology and the radiological protection of the patient Eur Radiol Syllabus 14 2004 50 58 3 H. Busch Image quality and dose management for digital radiography – final report European Commission DIMOND3 2004 Available from 4 E. Samei J.A. Seibert K. Andriole A. Badano J. Crawford B. Reiner AAPM/RSNA Tutorial on equipment selection: PACS equipment overview Radiographics 24 2004 313 334 5 M. Körner C.H. Weber S. Wirth K.J. Pfeifer M.F. Reiser M. Treitl Advances in digital radiography: physical principles and system overview Radiographics 27 2007 675 686 6 R. Schaetzing Computed radiography technology Advances in digital radiography: RSNA categorical course in diagnostic radiology physics 2003 RSNA Chicago 7 22 7 E. Samei Performance of digital radiographic detectors: factors affecting sharpness and noise Advances in digital radiography 2003 RSNA 49 61 8 H.G. Chotas J.T. Dobbins III C.E. Ravin Principles of digital radiography with large-area, electronically readable detectors: a review of the basics Radiology 210 1999 595 599 9 H. Chotas C. Ravin Digital chest radiography with a solid-state flat-panel X-ray detector: contrast-detail evaluation with processed images printed on film hard copy Radiology 218 2001 679 682 10 J. Rowlands The physics of computed radiography Phys Med Biol 47 2002 R123 R166 11 American Association of Physicists in Medicine Acceptance testing and quality control of photostimulable storage phosphor imaging systems Report of AAPM task group 10 2006 AAPM 12 E. Kotter M. Langer Digital radiography with large-area flat-panel detectors Eur Radiol 12 2002 2562 2570 13 J.D. Culley G.F. Powell E.L. Gingold K. Reith Digital radiography systems: an overview 2000 Hologic Available from "
    },
    {
        "doc_title": "Spontaneous intracerebral hemorrhage image analysis methods: A survey",
        "doc_scopus_id": "84962900968",
        "doc_doi": "10.1007/978-1-4020-9086-8_14",
        "doc_eid": "2-s2.0-84962900968",
        "doc_date": "2009-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Civil and Structural Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2205"
            },
            {
                "area_name": "Modeling and Simulation",
                "area_abbreviation": "MATH",
                "area_code": "2611"
            },
            {
                "area_name": "Biomedical Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2204"
            },
            {
                "area_name": "Computer Science Applications",
                "area_abbreviation": "COMP",
                "area_code": "1706"
            },
            {
                "area_name": "Fluid Flow and Transfer Processes",
                "area_abbreviation": "CENG",
                "area_code": "1507"
            },
            {
                "area_name": "Computational Mathematics",
                "area_abbreviation": "MATH",
                "area_code": "2605"
            },
            {
                "area_name": "Electrical and Electronic Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2208"
            }
        ],
        "doc_keywords": [],
        "doc_abstract": "© Springer Science+Business Media B.V. 2009.Spontaneous intracerebral hemorrhages (ICH) account for 10-30% all strokes and are a result of acute bleeding into the brain by rupturing of small penetrating arteries. The societal impact of hemorrhage strokes are magnified by the fact that affected patients typically are a decade younger than those afflicted with ischemic strokes. The ICH continue to kill or disable most of their victims some studies show that those who suffer ICH have a 30-day mortality rate of 35-44% and a 6-month mortality rate approaching 50%. Diagnosis of ICH is based largely on clinical history and corroborative Computer Tomography (CT) scanning of the brain. The heat CT scan has a sensitivity and specificity that approach 100% for acute ICH. The hemorrhage volume is the most important predictor of clinical outcome after ICH and it can be approximated rapidly with a head CT. Contrast-enhanced CT scan that may now be readily accomplished on the latest-generation scanners. These images can exclude most gross vascular and tumor causes of hemorrhage rapidly and can have an impact on the therapeutic plan. We survey several available medical image analysis methods, which have been used in CAD systems for segmentation and tracking of ICH. These methods including diverse algorithms and techniques such as: MRI based techniques: susceptibility-weighted imaging (SWI), gradient-recalled echo imaging (GREI) and GRE-type single-shot echo-planar imaging (GRE-EPI), Artificial neural networks training based on the electrical impedance tomography signals, Statistical techniques as frequency histograms and k-means clustering, Labeling approaches based on the combination of maximum a-posteriori (MAP) estimation and Markov random fields (MRF) models, Quantitative measure of side to side of cerebral blood flow (CBF) asymmetry algorithm, Volume region extraction based on digital atlas, Hybrid approaches including the suitable combination of two or more methods such as Unsupervised fuzzy clustering and expert system-based labeling, Mathematical morphology and histogram based intensity analysis, Deformable models and similarity measures Spontaneous ICH segmentation, at present, is not a solved problem. Future work will be focused on the development of better automatic segmentation and tracking methods to gain in accuracy and precision in the ICH volume determination.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Nanoradioliposomes molecularly modulated to study the lung deep lymphatic drainage",
        "doc_scopus_id": "67650327279",
        "doc_doi": "10.1016/S0873-2159(15)30131-8",
        "doc_eid": "2-s2.0-67650327279",
        "doc_date": "2009-01-01",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Pulmonary and Respiratory Medicine",
                "area_abbreviation": "MEDI",
                "area_code": "2740"
            }
        ],
        "doc_keywords": [],
        "doc_abstract": "Lung deep lymphatic drainage (LDLD) plays an important role in the removal of foreign materials from lungs being alveolar macrophages the first line of phagocytic defence with high affinity for pathogenic microorganisms. Bacillus subtilis is a well-known genome-decoded saprophyte of the human respiratory tract used in research and in the biotechnology industry. Lung deep lymphatic chains (LDLC) constitute one of the first sites of lung tumours' dissemination. In this work we intended to develop and validate a non-invasive method for assessing LDLC by nanoradioliposomes aerosolised modulated on the Bacillus subtilis spore wall. The final goal was to produce a nanoradioliposome formulation that can mimics the dynamics of preferential removal of spores by LDLD and present the ideal properties as a tracer for molecular imaging studies. Seven different liposomal formulations were tested, and the formulation-F demonstrated physicochemical and radiopharmaceutical properties that make it an ideal candidate as an in vivo probe for molecular imaging studies of the LDLC. Nanoradioliposomes of the formulation-F after labelling with 99mTc-HMPAO were administered as aerosols to 20 Sus scrofa. Hilar and interpulmonary communications were visualized in first 5 minutes post-inhalation, infradiaphragmatic chains between 10 and 20 minutes, the ganglia of the aortic chain at 20 minutes and those of the renal hilar region at 30 minutes. Conclusion: the proposed method enables visualization of deep lymphatic lung network and lymph nodes. Besides, this technique involving the modulation of nanoradioliposomes targeting specific organs or tissues may be an important tool for diagnostic or even for therapeutic purposes.",
        "available": true,
        "clean_text": "serial JL 280303 291210 291683 291911 31 Revista Portuguesa de Pneumologia REVISTAPORTUGUESADEPNEUMOLOGIA 2015-05-09 2015-05-09 2015-05-09T02:14:39 S0873-2159(15)30131-8 S0873215915301318 10.1016/S0873-2159(15)30131-8 S350 S350.1 HEAD-AND-TAIL 2015-07-13T10:29:42.286915-04:00 0 0 20090301 20090430 2009 2015-05-09T04:04:55.713728Z rawtext articleinfo articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid hubeid indexeddate issfirst issn issnnorm issuelist itemstage itemtransactionid itemweight openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sectiontitle sortorder srctitle srctitlenorm srctype ssids alllist content subj tomb volfirst volissue volumelist yearnav affil altitemtitle articletitle auth authfirstini authfull authkeywords authlast nonengabst primabst pubtype ref 0873-2159 08732159 false 15 15 2 2 Volume 15, Issue 2 9 261 293 261 293 200903 200904 March–April 2009 2009-03-01 2009-04-30 2009 Artigos Originais simple-article fla Copyright © 2009 Sociedade Portuguesa de Pneumologia/SPP. Published by Elsevier España, S.L. NANORRADIOLIPOSSOMASMODULADOSMOLECULARMENTEPARAESTUDARADRENAGEMLINFATICAPULMONARPROFUNDA BOTELHO M BISHOP 1967 448 453 D 1969 298 303 MCPHERSON 2005 8278 8290 D LEAK 1997 779 786 V LUNGSCIENTIFICFOUNDATIONS LYMPHATICSLYMPHOIDTISSUE TAYLOR 1997 1147 1161 A LUNGSCIENTIFICFOUNDATIONS FLUIDBALANCE NAGAISHI 1980 901 908 C APFISHMANSPULMONARYDISEASEDISORDERS PULMONARYLYMPHATICSYSTEM FISHMAN 1980 919 952 A APFISHMANSPULMONARYDISEASEDISORDERS PULMONARYEDEMA LAUWERYNS 1977 625 683 J GRANT 1974 49 50 T LIUA 2006 377 386 J HANSON 1970 53 90 R ARONSON 1976 360 402 A PARKER 1987 150 159 J FINKELSTEIN 1979 202 216 M GREGORIADIS 1980 43 46 J ZALUSTRY 1986 269 276 M NAYAR 1989 200 206 R OUSSOREN 1998 39 44 C PHILLIPS 2000 309 313 W YAN 2007 329 344 W TYRRELL 1976 259 302 D KIRBY 1980 591 598 C MAUK 1979 302 307 M OSBORNE 1979 75 83 P PHILLIPS 1992 539 547 W JACQUIERSARLIER 1996 1413 1416 M GOINS 1996 1374 1379 B AWASHI 1998 155 160 V MACDONALD 1991 297 303 R OLSON 1979 9 23 F HOPE 1985 55 65 M HUANG 1969 344 351 C MCDOUGALL 1975 488 491 I MEDINA 2004 41 51 L PHILLIPS 2001 446 451 W AHKONG 1992 831 840 F KASI 1984 35 37 L GOINS 1994 1491 1498 B SAARI 1998 1573 1579 S SHURTENBERGER 1984 470 480 P PEREVUCNIK 1985 169 173 G MAYER 1986 161 168 L HNATOWICH 1980 662 669 D TAYLOR 1990 57 61 K NIVEN 1990 11271133 R LEUNG 1996 95 102 K THOMAS 1984 503 505 S 1988 INTERNATIONALCOMMISSIONRADIATIONPROTECTIONPUBLICATION30 CARIDE 1990 35 39 V GOINS 1993 2160 2168 B CROWE 1988 367 384 J GOODRICH 1988 143 154 R MCCALLION 1996 203 214 O PHALEN 1984 51 R BASICMORPHOLOGYPHYSIOLOGYRESPIRATORYTRACTININHALATIONSTUDIESFOUNDATIONSTECHNIQUES BOTELHOX2009X261 BOTELHOX2009X261X293 BOTELHOX2009X261XM BOTELHOX2009X261X293XM Full 2015-07-13T13:56:10Z OA-Window FundingBody Sociedade Portuguesa de Pneumologia item S0873-2159(15)30131-8 S0873215915301318 10.1016/S0873-2159(15)30131-8 280303 2015-05-08T23:04:55.713728-04:00 2009-03-01 2009-04-30 true 8493449 MAIN 33 63994 849 656 IMAGE-WEB-PDF 1 Nanorradiolipossomas modulados molecularmente para estudar a drenagem linfÃ¡tica pulmonar profunda Nanoradioliposomes molecularly modulated to study the lung deep lymphatic drainage Maria Filomena RabaÃ§a Roque Botelho, 1 * filomena@ibili.uc.pt Maria Alcide Tavares Marques, 2 CÃ©lia Maria Freitas Gomes, 1 Augusto Marques Ferreira da Silva, 3 Vasco AntÃ³nio Andrade Figueiredo Bairos, 4 Manuel Amaro de Matos Santos Rosa, 5 Antero Pena Abrunhosa, 1 JoÃ£o JosÃ© Pedroso de Lima, 1 1 Instituto de BiofÃ­sica e BiomatemÃ¡tica, Faculdade de Medicina, Universidade de Coimbra, Azinhaga de Santa Comba, Celas, 3000-548 Coimbra, Portugal Instituto de BiofÃ­sica e BiomatemÃ¡tica Faculdade de Medicina Universidade de Coimbra Azinhaga de Santa Comba Coimbra 3000-548 Portugal 2 Departmento de CiÃªncias PneumolÃ³gicas e AlergolÃ³gicas, Hospitais da Universidade de Coimbra, Praceta Mota Pinto, 3000-075 Coimbra, Portugal Departmento de CiÃªncias PneumolÃ³gicas e AlergolÃ³gicas Hospitais da Universidade de Coimbra Praceta Mota Pinto Coimbra 3000-075 Portugal 3 Departmento de ElectrÃ³nica e TelecomunicaÃ§Ãµes, Universidade de Aveiro, 3810-193 Aveiro, Portugal Departmento de ElectrÃ³nica e TelecomunicaÃ§Ãµes Universidade de Aveiro Aveiro 3810-193 Portugal 4 Instituto de Histologia e Embriologia, Faculdade de Medicina, Universidade de Coimbra, Rua Larga, 3004-504 Coimbra, Portugal Instituto de Histologia e Embriologia Faculdade de Medicina Universidade de Coimbra, Rua Larga Coimbra 3004-504 Portugal 5 Instituto de Imunologia, Faculdade de Medicina, Universidade de Coimbra, Rua Larga, 3004-504 Coimbra, Portugal Instituto de Imunologia Faculdade de Medicina Universidade de Coimbra, Rua Larga Coimbra 3004-504 Portugal * CorrespondÃªncia/Correspondence to: Maria Filomena Botelho, Instituto de BiofÃ­sica e BiomatemÃ¡tica, IBILI-Faculdade de Medicina, Azinhaga de Santa Comba, Celas 3000-548 Coimbra Portugal Tel: + 351 239 480240 FAX: + 351 239 480240 FAX: + 351 239 480258 Resumo A drenagem linfÃ¡tica pulmonar profunda (DLPP) desempenha um papel importante na remoÃ§Ã£o de materiais estranhos, constituindo os macrÃ³fagos alveolares a primeira linha de defesa fagocitÃ¡ria, dada a grande afinidade para microrganismos patogÃ©nicos. Os Bacillus subtilis sÃ£o saprÃ³fitas do tracto respiratÃ³rio humano com ampla utilizaÃ§Ã£o em investigaÃ§Ã£o e em biotecnologia.As cadeias linfÃ¡ticas pulmonares profundas (CLPP) constituem um dos primeiros locais de disseminaÃ§Ã£o de tumores pulmonares. Neste trabalho pretendeu-se desenvolver e validar um mÃ©todo nÃ£o invasivo para avaliar as CLPP atravÃ©s de nanorradiolipossomas aerosolisados e modulados pela parede do esporo do Bacillus subtilis . O objectivo final foi produzir uma formulaÃ§Ã£o de nanorradiolipossomas capaz de imitar a dinÃ¢mica da remoÃ§Ã£o de esporos pelas CLPP e simultaneamente ter propriedades ideais como traÃ§ador para imagiologia molecular. TestÃ¡mos sete diferentes formulaÃ§Ãµes lipossÃ³micas, tendo a formulaÃ§Ã£o F demonstrado possuir propriedades fisicoquÃ­micas e radiofarmacÃªuticas que a tornam o traÃ§ador ideal para imagiologia molecular in vivo das CLPP. Os nanorradiolipossomas da formulaÃ§Ã£o F apÃ³s marcaÃ§Ã£o com 99m Tc-HMPAO foram administrados sob a forma de aerossÃ³is a 20 Tc-HMPAO foram administrados sob a forma de aerossÃ³is a 20 Sus scrofa . Visualizaram-se comunicaÃ§Ãµes hilares e interpulmonares nos primeiros 5 minutos apÃ³s a inalaÃ§Ã£o, as cadeias infradiafragmÃ¡ticas entre os 10 e os 20 minutos, os gÃ¢nglios da cadeia aÃ³rtica aos 20 minutos e os da regiÃ£o hilar renal aos 30 minutos.Em conclusÃ£o, o mÃ©todo proposto visualiza os gÃ¢nglios linfÃ¡ticos e a rede linfÃ¡tica pulmonar profunda. A modulaÃ§Ã£o dos nanorradiolipossomas permite que eles atinjam Ã³rgÃ£os ou tecidos especÃ­ficos, conferindo-lhes importantes potencialidades no Ã¢mbito do diagnÃ³stico e/ou da terapÃªutica. Rev Port Pneumol 2009; XV (2): 261-293 Abstract Lung deep lymphatic drainage (LDLD) plays an important role in the removal of foreign materials from lungs being alveolar macrophages the first line of phagocytic defence with high affinity for pathogenic microorganisms. Bacillus subtilis is a well-known genome-decoded saprophyte of the human respiratory tract used in research and in the biotechnology industry. Lung deep lymphatic chains (LDLC) constitute one of the first sites of lung tumoursâ€™ dissemination. In this work we intended to develop and validate a non-invasive method for assessing LDLC by nanoradioliposomes aerosolised modulated on the Bacillus subtilis spore wall. The final goal was to produce a nanoradioliposome formulation that can mimics the dynamics of preferential removal of spores by LDLD and present the ideal properties as a tracer for molecular imaging studies. Seven different liposomal formulations were tested, and the formulation-F demonstrated physicochemical and radiopharmaceutical properties that make it an ideal candidate as an in vivo probe for molecular imaging studies of the LDLC. Nanoradioliposomes of the formulation-F after labelling with 99mTc-HMPAO were administered as aerosols to 20 Sus scrofa . Hilar and interpulmonary communications were visualized in first 5 minutes post-inhalation, infradiaphragmatic chains between 10 and 20 minutes, the ganglia of the aortic chain at 20 minutes and those of the renal hilar region at 30 minutes.Conclusion: the proposed method enables visualization of deep lymphatic lung network and lymph nodes. Besides, this technique involving the modulation of nanoradioliposomes targeting specific organs or tissues may be an important tool for diagnostic or even for therapeutic purposes. Rev Port Pneumol 2009; XV (2): 261-293 Palavras-chave Nanorradiolipossomas modulaÃ§Ã£o molecular drenagem linfÃ¡tica pulmonar imagem nuclear funcional Key-words Nanoradioliposomes molecular modulation lung lymphatic drainage functional nuclear imaging Bibliography 1. D.G. Bishop, L. Rutberg, B. Samuelsson, The chemical composition of the cytoplasmic membrane of Bacillus subtilis Eur J Biohem 2: (1967) 448-453 2. JAF Op der Kamp, I Redai, LLM van Deenen, Phosholipid composition of Bacillus subtilis J Bacteriol 99: (1969) 298-303 3. D.C. McPherson, H. Kim, M. Hahn, R. Wang, P. Grabowski, P. Eichenberger, A. Driks1, Characterization of the Bacillus subtilis spore morphogenetic coat ProteinCotO J Bacteriol 187: (2005) 8278-8290 4. V. Leak, V.J. Ferrans, Lymphatics and lymphoid tissue R.G. Crystal, J.B. West, The Lung: Scientific Foundations (1997) Raven Press Ltd New York 779-786 5. A.E. Taylor, J.W. Barnard, S.A. Barman, W.K. Adkins, Fluid Balance R.G. Crystal, J.B. West, The Lung: Scientific Foundations (1997) Raven Press Ltd New York 1147-1161 6. C. Nagaishi, Y. Okada, The pulmonary lymphatic system J.D. Dereck, M. Navrozov, AP Fishmanâ€™s Pulmonary Disease and Disorders 2: (1980) McGraw-Hill Inc London 901-908 7. A.P. Fishman, Pulmonary edema J.D. Dereck, M. Navrozov, AP Fishmanâ€™s Pulmonary Disease and Disorders 2: (1980) McGraw-Hill Inc London 919-952 8. J.M. Lauweryns, J.H. Baert, Alveolar clearance and the role of the pulmonary lymphatics Am Rev Respir Dis 115: (1977) 625-683 9. T. Grant, B. Levin, Lymphangiographic visualization of pleural and pulmonary lymphatics in a patient without chylothorax Radiology 113: (1974) 49-50 10. J. Liua, Ho-Lun Wong, B. Bowenc Moselhyc, X.Y. Wuc, M.R. Johnston, Targeting colloidal particulates to thoracic lymph nodes Lung Cancer 51: (2006) 377-386 11. R.S. Hanson, J.A. Peterson, A.A. Yousten, Unique bio chemical events in bacterial sporulation Annu Rev Microbiol 24: (1970) 53-90 12. A.I. Aronson, P. Fitz-James, Structure and morphogenesis of the bacterial spore coat Bacteriol Rev 40: (1976) 360-402 13. J.C. Parker, Transport and distribution of charged macromolecules in lung Adv Microcirc 13: (1987) 150-159 14. M.C. Finkelstein, G. Weissmann, Enzyme replacement via liposomes. Variations in lipid composition determine liposomal integrity in biological fluids Biochim Biophys Acta 587: (1979) 202-216 15. J. Gregoriadis, The phospholipid component of small unilamellar liposomes controls the rate of clearance of entrapped solutes from the circulation Senior FEBS Letters 119: (1980) 43-46 16. M.R. Zalustry, M.A. Noska, P.W. Gallagher, Properties of multilamellar liposomes containing 99mTcO4-: Effect of distearoylphosphatidylcholine to sphingomyelin ratio J Nucl Med 13: (1986) 269-276 17. R. Nayar, M.J. Hope, P.R. Cullis, Generation of large unilamellar vesicles from long-chain saturated phosphatidylcholines by extrusion techniques Biochim Biophys Acta 986: (1989) 200-206 18. C. Oussoren, G. Storm, Targeting to lymph nodes by subcutaneous administration of liposomes Inter J Pharma 162: (1998) 39-44 19. W.T. Phillips, R. Klipper, B. Goins, Novel method of greatly enhanced delivery of liposomes to lymph nodes1 JPET 295: (2000) 309-313 20. W. Yan, L. Huang, Recent advances in liposomebased nanoparticles for antigen delivery Polymer Reviews 47: (2007) 329-344 21. D.A. Tyrrell, T.D. Heath, C.M. Colley, B.E. Ryman, New aspects of liposomes Biochim Biophys Acta 457: (1976) 259-302 22. C. Kirby, J. Clarke, G. Gregoriadis, Effect of the cholesterol content of small unilamellar liposomes on their stability in vivo and in vitro Biochem J 186: (1980) 591-598 23. M.R. Mauk, R.C. Gamble, Preparation of lipid vesicles containing high levels of entrapped radioactive cations Anal Biochem 94: (1979) 302-307 24. P. Osborne, V.J. Richardson, K. Jeysingh, B.E. Ryman, Radionuclide-labelled liposomes â€“ A new lymph node imaging agent Int J Nucl Med 6: (1979) 75-83 25. W.T. Phillips, A.S. Rudolph, B. Goins, J.H. Timmons, R. Klipper, R. Blumhardt, A simple method for produc ing technetium-99 m-labeled liposome which is stable in vivoNucl Med Biol 19: (1992) 539-547 26. M.R. Jacquier-Sarlier, B.S. Polla, D.O. Slosman, Oxidoreductive state: the major determinant for cellular retention of technetium-99 m-HMPAOJ Nucl Med 37: (1996) 1413-1416 27. B. Goins, W.T. Phillips, R. Klipper, Blood-pool imaging using technetium-99 m-labeled liposomesJ Nucl Med 37: (1996) 1374-1379 28. V.D. Awashi, B. Goins, R. Klipper, W.T. Phillips, Dual radiolabeled liposomes: biodistribution studies and localization of focal sites of infection in rats Nucl Med Biol 25: (1998) 155-160 29. R.C. MacDonald, R.I. MacDonald, B.P.M. Menco, K. Takeshita, N.K. Subbarao, Hu. L-R, Small-volume extrusion apparatus for preparation of large unilamellar vesicles BiochimBiophys Acta 1061: (1991) 297-303 30. F. Olson, C.A. Hunt, F.C. Szoka, W.J. Vail, D. Papahadjopoulos, Preparation of liposomes of defined size and distribution by extrusion through polycarbonate membranes Biochim Biophys Acta 557: (1979) 9-23 31. M.J. Hope, M.B. Bally, G. Webb, P.R. Cullis, Production of large unilamellar vesicles by a rapid extrusion procedure: characterization of size distribution, trapped volume and ability to maintain a membrane potential Biochim Biophys Acta 812: (1985) 55-65 32. C. Huang, Studies on phosphatidylcholine vesicles. Formation and physical characteristics Biochemistry 8: (1969) 344-351 33. I.R. McDougall, J.K. Dunnick, M.L. Goris, J.P. Kriss, In vivo distribution of vesicles loads with radiopharmaceuticals: a study of different routes of administration J Nucl Med 16: (1975) 488-491 34. L.A. Medina, R. Klipper, W.T. Phillips, B. Goins, Pharmacokinetics and biodistribution of [111In]-avidin and [99mTc]-biotin-liposomes injected in the pleural space for the targeting of mediastinal nodes Nucl Med Biol 31: (2004) 41-51 35. W.T. Phillips, R. Klipper, B. Goins, Use of 99mTclabeled liposomes encapsulating blue dye for identification of the sentinel lymph node J Nucl Med 42: (2001) 446-451 36. F. Ahkong, C. Tilcock, Attachment of 99mTc to lipid vesicles containing the lipophilic chelate dipalmitoylphosphatidyl ethanolamine-DTTA Nucl Med Biol 19: (1992) 831-840 37. L.P. Kasi, G. Lopez-Berestein, K. Mehta, M. Rosenblum, H.J. Glenn, T.P. Haynie, G. Mavligit, E.M. Hersh, Distribution and pharmacology of intravenous 99mtclabeled multilamellar liposomes in rats and mice Int J Nucl Med Biol 11: (1984) 35-37 38. B. Goins, R. Klipper, A.S. Rudolph, W.T. Phillips, Use of technetium-99 m-liposomes in tumor imagingJ Nucl Med 35: (1994) 1491-1498 39. S.M. Saari, M.T. Vidgren, M.O. Koskinen, V.M.H. Turjanmaa, J.C. Waldrep, M.N. Nieminem, Regional lung deposition and clearance of 99mTc-labeled beclomethasone-DLPC liposomes in mild and severe asthma Chest 113: (1998) 1573-1579 40. P. Shurtenberger, H. Hauser, Characterization of the size distribution of unilamellar vesicles by gel filtration, quasi-elastic light scattering and electron microscopy Biochim Biophys Acta 778: (1984) 470-480 41. G. Perevucnik, P. Schurtenberger, H. Hauser, Size analysis of biological membrane vesicles by gel filtration, dynamic light scattering and electron microscopy Biochim Biophys Acta 821: (1985) 169-173 42. L.D. Mayer, M.J. Hope, P.R. Cullis, Vesicles of variable sizes produced by a rapid extrusion procedure Biochim Biophys Acta 858: (1986) 161-168 43. D.J. Hnatowich, B. Clancy, Investigations of a new, highly negative liposome with improved biodistribution for imaging J Nucl Med 21: (1980) 662-669 44. K.M.G. Taylor, G. Taylor, I.W. Kellaway, J. Stevens, The stability of liposomes to nebulization Int J Pharm 58: (1990) 57-61 45. R.W. Niven, H. Schreier, Nebulization of liposome. I. Effects of lipid composition Pharm Res 7: (1990) 11271133- 46. K.K.M. Leung, P.A. Bridges, K.M.G. Taylor, The stability of liposomes to ultrasonic nebulization Int J Pharm 145: (1996) 95-102 47. S. Thomas, H. Atkins, J. McAfee, M.D. Blaufox, M. Fernandez, P.T. Kirchner, R.C. Reba, Radiation absorbed dose from tc-99 m diethylenetriaminepentaacetic acid (DTPA)J Nucl Med 25: (1984) 503-505 48. International Commission of Radiation Protection Publication 30 (1988) Pergamon Press New York 49. V.J. Caride, Technical and biological considerations on the use of radiolabeled liposomes for diagnostic imaging Nucl Med Biol 17: (1990) 35-39 50. B. Goins, R. Klipper, A.S. Rudolph, R.O. Cliff, R. Blumhardt, W.T. Phillips, Biodistribution and ima ging studies of technetium-99 m-labeled liposomes in rats with focal infectionJ Nucl Med 34: (1993) 2160-2168 51. J.H. Crowe, L.M. Crowe, J.F. Carpenter, A.S. Rudolph, C.A. Wistrom, B.J. Spargo, T.J. Anchordoguy, Interactions of sugars with membranes Biochim Biophys Acta 947: (1988) 367-384 52. R.P. Goodrich, T.M. Handel, J.D. Baldeschwieler, Modification of lipid phase behavior with membrane bound cryoprotectants Biochim Biophys Acta 938: (1988) 143-154 53. O.N.M. Mc Callion, K.M.G. Taylor, M. Thomas, A.J. Taylor, Nebulization of monodisperse latex sphere suspensions in air-jet and ultrasonic nebulizers Int J Pharm 133: (1996) 203-214 54. R.F. Phalen, Basic morphology and physiology of the respiratory tract, in: Inhalation Studies: Foundations and techniques (1984) CRC Press Boca Raton, Florida 51- a membrane potential Biochim Biophys Acta 812: (1985) 55-65 32. C. Huang, Studies on phosphatidylcholine vesicles. Formation and physical characteristics Biochemistry 8: (1969) 344-351 33. I.R. McDougall, J.K. Dunnick, M.L. Goris, J.P. Kriss, In vivo distribution of vesicles loads with radiopharmaceuticals: a study of different routes of administration J Nucl Med 16: (1975) 488-491 34. L.A. Medina, R. Klipper, W.T. Phillips, B. Goins, Pharmacokinetics and biodistribution of [111In]-avidin and [99mTc]-biotin-liposomes injected in the pleural space for the targeting of mediastinal nodes Nucl Med Biol 31: (2004) 41-51 35. W.T. Phillips, R. Klipper, B. Goins, Use of 99mTclabeled liposomes encapsulating blue dye for identification of the sentinel lymph node J Nucl Med 42: (2001) 446-451 36. F. Ahkong, C. Tilcock, Attachment of 99mTc to lipid vesicles containing the lipophilic chelate dipalmitoylphosphatidyl ethanolamine-DTTA Nucl Med Biol 19: (1992) 831-840 37. L.P. Kasi, G. Lopez-Berestein, K. Mehta, M. Rosenblum, H.J. Glenn, T.P. Haynie, G. Mavligit, E.M. Hersh, Distribution and pharmacology of intravenous 99mtclabeled multilamellar liposomes in rats and mice Int J Nucl Med Biol 11: (1984) 35-37 38. RPPNEU 9 S0873-2159(15)30131-8 10.1016/S0873-2159(15)30131-8 Sociedade Portuguesa de Pneumologia/SPP © 2009 Sociedade Portuguesa de Pneumologia/SPP Artigo Original/Original Article Nanorradiolipossomas modulados molecularmente para estudar a drenagem linfática pulmonar profunda Nanoradioliposomes molecularly modulated to study the lung deep lymphatic drainage Maria Filomena Rabaça Roque Botelho 1 * Maria Alcide Tavares Marques 2 Célia Maria Freitas Gomes 1 Augusto Marques Ferreira da Silva 3 Vasco António Andrade Figueiredo Bairos 4 Manuel Amaro de Matos Santos Rosa 5 Antero Pena Abrunhosa 1 João José Pedroso de Lima 1 1 Instituto de Biofísica e Biomatemática, Faculdade de Medicina, Universidade de Coimbra, Azinhaga de Santa Comba, Celas, 3000-548 Coimbra, Portugal Instituto de Biofísica e Biomatemática Faculdade de Medicina Universidade de Coimbra Azinhaga de Santa Comba Coimbra 3000-548 Portugal 2 Departmento de Ciências Pneumológicas e Alergológicas, Hospitais da Universidade de Coimbra, Praceta Mota Pinto, 3000-075 Coimbra, Portugal Departmento de Ciências Pneumológicas e Alergológicas Hospitais da Universidade de Coimbra Praceta Mota Pinto Coimbra 3000-075 Portugal 3 Departmento de Electrónica e Telecomunicações, Universidade de Aveiro, 3810-193 Aveiro, Portugal Departmento de Electrónica e Telecomunicações Universidade de Aveiro Aveiro 3810-193 Portugal 4 Instituto de Histologia e Embriologia, Faculdade de Medicina, Universidade de Coimbra, Rua Larga, 3004-504 Coimbra, Portugal Instituto de Histologia e Embriologia Faculdade de Medicina Universidade de Coimbra, Rua Larga Coimbra 3004-504 Portugal 5 Instituto de Imunologia, Faculdade de Medicina, Universidade de Coimbra, Rua Larga, 3004-504 Coimbra, Portugal Instituto de Imunologia Faculdade de Medicina Universidade de Coimbra, Rua Larga Coimbra 3004-504 Portugal * Correspondência/Correspondence to: Maria Filomena Botelho, Instituto de Biofísica e Biomatemática, IBILI-Faculdade de Medicina, Azinhaga de Santa Comba, Celas 3000-548 Coimbra Portugal Tel: +351 239 480240 FAX: +351 239 480258 Resumo A drenagem linfática pulmonar profunda (DLPP) desempenha um papel importante na remoção de materiais estranhos, constituindo os macrófagos alveolares a primeira linha de defesa fagocitária, dada a grande afinidade para microrganismos patogénicos. Os Bacillus subtilis são saprófitas do tracto respiratório humano com ampla utilização em investigação e em biotecnologia. As cadeias linfáticas pulmonares profundas (CLPP) constituem um dos primeiros locais de disseminação de tumores pulmonares. Neste trabalho pretendeu-se desenvolver e validar um método não invasivo para avaliar as CLPP através de nanorradiolipossomas aerosolisados e modulados pela parede do esporo do Bacillus subtilis. O objectivo final foi produzir uma formulação de nanorradiolipossomas capaz de imitar a dinâmica da remoção de esporos pelas CLPP e simultaneamente ter propriedades ideais como traçador para imagiologia molecular. Testámos sete diferentes formulações lipossómicas, tendo a formulação F demonstrado possuir propriedades fisicoquímicas e radiofarmacêuticas que a tornam o traçador ideal para imagiologia molecular in vivo das CLPP. Os nanorradiolipossomas da formulação F após marcação com 99mTc-HMPAO foram administrados sob a forma de aerossóis a 20 Sus scrofa. Visualizaram-se comunicações hilares e interpulmonares nos primeiros 5 minutos após a inalação, as cadeias infradiafragmáticas entre os 10 e os 20 minutos, os gânglios da cadeia aórtica aos 20 minutos e os da região hilar renal aos 30 minutos. Em conclusão, o método proposto visualiza os gânglios linfáticos e a rede linfática pulmonar profunda. A modulação dos nanorradiolipossomas permite que eles atinjam órgãos ou tecidos específicos, conferindo-lhes importantes potencialidades no âmbito do diagnóstico e/ou da terapêutica. Rev Port Pneumol 2009; XV (2): 261-293 Lung deep lymphatic drainage (LDLD) plays an important role in the removal of foreign materials from lungs being alveolar macrophages the first line of phagocytic defence with high affinity for pathogenic microorganisms. Bacillus subtilis is a well-known genome-decoded saprophyte of the human respiratory tract used in research and in the biotechnology industry. Lung deep lymphatic chains (LDLC) constitute one of the first sites of lung tumours’ dissemination. In this work we intended to develop and validate a non-invasive method for assessing LDLC by nanoradioliposomes aerosolised modulated on the Bacillus subtilis spore wall. The final goal was to produce a nanoradioliposome formulation that can mimics the dynamics of preferential removal of spores by LDLD and present the ideal properties as a tracer for molecular imaging studies. Seven different liposomal formulations were tested, and the formulation-F demonstrated physicochemical and radiopharmaceutical properties that make it an ideal candidate as an in vivo probe for molecular imaging studies of the LDLC. Nanoradioliposomes of the formulation-F after labelling with 99mTc-HMPAO were administered as aerosols to 20 Sus scrofa. Hilar and interpulmonary communications were visualized in first 5 minutes post-inhalation, infradiaphragmatic chains between 10 and 20 minutes, the ganglia of the aortic chain at 20 minutes and those of the renal hilar region at 30 minutes. Conclusion: the proposed method enables visualization of deep lymphatic lung network and lymph nodes. Besides, this technique involving the modulation of nanoradioliposomes targeting specific organs or tissues may be an important tool for diagnostic or even for therapeutic purposes. Rev Port Pneumol 2009; XV (2): 261-293 Palavras-chave Nanorradiolipossomas modulação molecular drenagem linfática pulmonar imagem nuclear funcional Key-words Nanoradioliposomes molecular modulation lung lymphatic drainage functional nuclear imaging Bibliography 1. D.G. Bishop L. Rutberg B. Samuelsson The chemical composition of the cytoplasmic membrane of Bacillus subtilis Eur J Biohem 2 1967 448 453 2. JAF Op der Kamp, I Redai, LLM van Deenen, Phosholipid composition of Bacillus subtilis J Bacteriol 99 1969 298 303 3. D.C. McPherson H. Kim M. Hahn R. Wang P. Grabowski P. Eichenberger A. Driks1 Characterization of the Bacillus subtilis spore morphogenetic coat Protein CotO J Bacteriol 187 2005 8278 8290 4. V. Leak V.J. Ferrans Lymphatics and lymphoid tissue R.G. Crystal J.B. West The Lung: Scientific Foundations 1997 Raven Press Ltd New York 779 786 5. A.E. Taylor J.W. Barnard S.A. Barman W.K. Adkins Fluid Balance R.G. Crystal J.B. West The Lung: Scientific Foundations 1997 Raven Press Ltd New York 1147 1161 6. C. Nagaishi Y. Okada The pulmonary lymphatic system J.D. Dereck M. Navrozov AP Fishman’s Pulmonary Disease and Disorders 2 1980 McGraw-Hill Inc London 901 908 7. A.P. Fishman Pulmonary edema J.D. Dereck M. Navrozov AP Fishman’s Pulmonary Disease and Disorders 2 1980 McGraw-Hill Inc London 919 952 8. J.M. Lauweryns J.H. Baert Alveolar clearance and the role of the pulmonary lymphatics Am Rev Respir Dis 115 1977 625 683 9. T. Grant B. Levin Lymphangiographic visualization of pleural and pulmonary lymphatics in a patient without chylothorax Radiology 113 1974 49 50 10. J. Liua Ho-Lun Wong B. Bowenc Moselhyc X.Y. Wuc M.R. Johnston Targeting colloidal particulates to thoracic lymph nodes Lung Cancer 51 2006 377 386 11. R.S. Hanson J.A. Peterson A.A. Yousten Unique bio chemical events in bacterial sporulation Annu Rev Microbiol 24 1970 53 90 12. A.I. Aronson P. Fitz-James Structure and morphogenesis of the bacterial spore coat Bacteriol Rev 40 1976 360 402 13. J.C. Parker Transport and distribution of charged macromolecules in lung Adv Microcirc 13 1987 150 159 14. M.C. Finkelstein G. Weissmann Enzyme replacement via liposomes. Variations in lipid composition determine liposomal integrity in biological fluids Biochim Biophys Acta 587 1979 202 216 15. J. Gregoriadis The phospholipid component of small unilamellar liposomes controls the rate of clearance of entrapped solutes from the circulation Senior FEBS Letters 119 1980 43 46 16. M.R. Zalustry M.A. Noska P.W. Gallagher Properties of multilamellar liposomes containing 99mTcO4-: Effect of distearoylphosphatidylcholine to sphingomyelin ratio J Nucl Med 13 1986 269 276 17. R. Nayar M.J. Hope P.R. Cullis Generation of large unilamellar vesicles from long-chain saturated phosphatidylcholines by extrusion techniques Biochim Biophys Acta 986 1989 200 206 18. C. Oussoren G. Storm Targeting to lymph nodes by subcutaneous administration of liposomes Inter J Pharma 162 1998 39 44 19. W.T. Phillips R. Klipper B. Goins Novel method of greatly enhanced delivery of liposomes to lymph nodes1 JPET 295 2000 309 313 20. W. Yan L. Huang Recent advances in liposomebased nanoparticles for antigen delivery Polymer Reviews 47 2007 329 344 21. D.A. Tyrrell T.D. Heath C.M. Colley B.E. Ryman New aspects of liposomes Biochim Biophys Acta 457 1976 259 302 22. C. Kirby J. Clarke G. Gregoriadis Effect of the cholesterol content of small unilamellar liposomes on their stability in vivo and in vitro Biochem J 186 1980 591 598 23. M.R. Mauk R.C. Gamble Preparation of lipid vesicles containing high levels of entrapped radioactive cations Anal Biochem 94 1979 302 307 24. P. Osborne V.J. Richardson K. Jeysingh B.E. Ryman Radionuclide-labelled liposomes – A new lymph node imaging agent Int J Nucl Med 6 1979 75 83 25. W.T. Phillips A.S. Rudolph B. Goins J.H. Timmons R. Klipper R. Blumhardt A simple method for produc ing technetium-99m-labeled liposome which is stable in vivo Nucl Med Biol 19 1992 539 547 26. M.R. Jacquier-Sarlier B.S. Polla D.O. Slosman Oxidoreductive state: the major determinant for cellular retention of technetium-99m-HMPAO J Nucl Med 37 1996 1413 1416 27. B. Goins W.T. Phillips R. Klipper Blood-pool imaging using technetium-99m-labeled liposomes J Nucl Med 37 1996 1374 1379 28. V.D. Awashi B. Goins R. Klipper W.T. Phillips Dual radiolabeled liposomes: biodistribution studies and localization of focal sites of infection in rats Nucl Med Biol 25 1998 155 160 29. R.C. MacDonald R.I. MacDonald B.P.M. Menco K. Takeshita N.K. Subbarao L.-R. Hu Small-volume extrusion apparatus for preparation of large unilamellar vesicles BiochimBiophys Acta 1061 1991 297 303 30. F. Olson C.A. Hunt F.C. Szoka W.J. Vail D. Papahadjopoulos Preparation of liposomes of defined size and distribution by extrusion through polycarbonate membranes Biochim Biophys Acta 557 1979 9 23 31. M.J. Hope M.B. Bally G. Webb P.R. Cullis Production of large unilamellar vesicles by a rapid extrusion procedure: characterization of size distribution, trapped volume and ability to maintain a membrane potential Biochim Biophys Acta 812 1985 55 65 32. C. Huang Studies on phosphatidylcholine vesicles. Formation and physical characteristics Biochemistry 8 1969 344 351 33. I.R. McDougall J.K. Dunnick M.L. Goris J.P. Kriss In vivo distribution of vesicles loads with radiopharmaceuticals: a study of different routes of administration J Nucl Med 16 1975 488 491 34. L.A. Medina R. Klipper W.T. Phillips B. Goins Pharmacokinetics and biodistribution of [111In]-avidin and [99mTc]-biotin-liposomes injected in the pleural space for the targeting of mediastinal nodes Nucl Med Biol 31 2004 41 51 35. W.T. Phillips R. Klipper B. Goins Use of 99mTclabeled liposomes encapsulating blue dye for identification of the sentinel lymph node J Nucl Med 42 2001 446 451 36. F. Ahkong C. Tilcock Attachment of 99mTc to lipid vesicles containing the lipophilic chelate dipalmitoylphosphatidyl ethanolamine-DTTA Nucl Med Biol 19 1992 831 840 37. L.P. Kasi G. Lopez-Berestein K. Mehta M. Rosenblum H.J. Glenn T.P. Haynie G. Mavligit E.M. Hersh Distribution and pharmacology of intravenous 99mtclabeled multilamellar liposomes in rats and mice Int J Nucl Med Biol 11 1984 35 37 38. B. Goins R. Klipper A.S. Rudolph W.T. Phillips Use of technetium-99m-liposomes in tumor imaging J Nucl Med 35 1994 1491 1498 39. S.M. Saari M.T. Vidgren M.O. Koskinen V.M.H. Turjanmaa J.C. Waldrep M.N. Nieminem Regional lung deposition and clearance of 99mTc-labeled beclomethasone-DLPC liposomes in mild and severe asthma Chest 113 1998 1573 1579 40. P. Shurtenberger H. Hauser Characterization of the size distribution of unilamellar vesicles by gel filtration, quasi-elastic light scattering and electron microscopy Biochim Biophys Acta 778 1984 470 480 41. G. Perevucnik P. Schurtenberger H. Hauser Size analysis of biological membrane vesicles by gel filtration, dynamic light scattering and electron microscopy Biochim Biophys Acta 821 1985 169 173 42. L.D. Mayer M.J. Hope P.R. Cullis Vesicles of variable sizes produced by a rapid extrusion procedure Biochim Biophys Acta 858 1986 161 168 43. D.J. Hnatowich B. Clancy Investigations of a new, highly negative liposome with improved biodistribution for imaging J Nucl Med 21 1980 662 669 44. K.M.G. Taylor G. Taylor I.W. Kellaway J. Stevens The stability of liposomes to nebulization Int J Pharm 58 1990 57 61 45. R.W. Niven H. Schreier Nebulization of liposome. I. Effects of lipid composition Pharm Res 7 1990 11271133 46. K.K.M. Leung P.A. Bridges K.M.G. Taylor The stability of liposomes to ultrasonic nebulization Int J Pharm 145 1996 95 102 47. S. Thomas H. Atkins J. McAfee M.D. Blaufox M. Fernandez P.T. Kirchner R.C. Reba Radiation absorbed dose from tc-99m diethylenetriaminepentaacetic acid (DTPA) J Nucl Med 25 1984 503 505 48. International Commission of Radiation Protection Publication 30 1988 Pergamon Press New York 49. V.J. Caride Technical and biological considerations on the use of radiolabeled liposomes for diagnostic imaging Nucl Med Biol 17 1990 35 39 50. B. Goins R. Klipper A.S. Rudolph R.O. Cliff R. Blumhardt W.T. Phillips Biodistribution and ima ging studies of technetium-99m-labeled liposomes in rats with focal infection J Nucl Med 34 1993 2160 2168 51. J.H. Crowe L.M. Crowe J.F. Carpenter A.S. Rudolph C.A. Wistrom B.J. Spargo T.J. Anchordoguy Interactions of sugars with membranes Biochim Biophys Acta 947 1988 367 384 52. R.P. Goodrich T.M. Handel J.D. Baldeschwieler Modification of lipid phase behavior with membrane bound cryoprotectants Biochim Biophys Acta 938 1988 143 154 53. O.N.M. Mc Callion K.M.G. Taylor M. Thomas A.J. Taylor Nebulization of monodisperse latex sphere suspensions in air-jet and ultrasonic nebulizers Int J Pharm 133 1996 203 214 54. R.F. Phalen Basic morphology and physiology of the respiratory tract, in: Inhalation Studies: Foundations and techniques 1984 CRC Press Boca Raton, Florida 51 "
    },
    {
        "doc_title": "Indexing and retrieving DICOM data in disperse and unstructured archives",
        "doc_scopus_id": "63149146090",
        "doc_doi": "10.1007/s11548-008-0269-7",
        "doc_eid": "2-s2.0-63149146090",
        "doc_date": "2009-01-01",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Surgery",
                "area_abbreviation": "MEDI",
                "area_code": "2746"
            },
            {
                "area_name": "Biomedical Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2204"
            },
            {
                "area_name": "Radiology, Nuclear Medicine and Imaging",
                "area_abbreviation": "MEDI",
                "area_code": "2741"
            },
            {
                "area_name": "Computer Vision and Pattern Recognition",
                "area_abbreviation": "COMP",
                "area_code": "1707"
            },
            {
                "area_name": "Health Informatics",
                "area_abbreviation": "MEDI",
                "area_code": "2718"
            },
            {
                "area_name": "Computer Science Applications",
                "area_abbreviation": "COMP",
                "area_code": "1706"
            },
            {
                "area_name": "Computer Graphics and Computer-Aided Design",
                "area_abbreviation": "COMP",
                "area_code": "1704"
            }
        ],
        "doc_keywords": [],
        "doc_abstract": "Objective: This paper proposes an indexing and retrieval solution to gather information from distributed DICOM documents by allowing searches and access to the virtual data repository using a Google-like process. Methods and materials: The medical imaging modalities are becoming more powerful and less expensive. The result is the proliferation of equipment acquisition by imaging centers, including the small ones. With this dispersion of data, it is not easy to take advantage of all the information that can be retrieved from these studies. Furthermore, many of these small centers do not have large enough requirements to justify the acquisition of a traditional PACS. Results: A peer-to-peer PACS platform to index and query DICOM files over a set of distributed repositories that are logically viewed as a single federated unit. The solution is based on a public domain document-indexing engine and extends traditional PACS query and retrieval mechanisms. Conclusion: This proposal deals well with complex searching requirements, from a single desktop environment to distributed scenarios. The solution performance and robustness were demonstrated in trials. The characteristics of presented PACS platform make it particularly important for small institutions, including educational and research groups. © CARS 2008.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Evaluation of exposure parameters in plain radiography: A comparative study with European guidelines",
        "doc_scopus_id": "55249101494",
        "doc_doi": "10.1093/rpd/ncn144",
        "doc_eid": "2-s2.0-55249101494",
        "doc_date": "2008-12-22",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Radiation",
                "area_abbreviation": "PHYS",
                "area_code": "3108"
            },
            {
                "area_name": "Radiological and Ultrasound Technology",
                "area_abbreviation": "HEAL",
                "area_code": "3614"
            },
            {
                "area_name": "Radiology, Nuclear Medicine and Imaging",
                "area_abbreviation": "MEDI",
                "area_code": "2741"
            },
            {
                "area_name": "Public Health, Environmental and Occupational Health",
                "area_abbreviation": "MEDI",
                "area_code": "2739"
            }
        ],
        "doc_keywords": [],
        "doc_abstract": "Typical distribution of exposure parameters in plain radiography is unknown in Portugal. This study aims to identify exposure parameters that are being used in plain radiography in the Lisbon area and to compare the collected data with European references/Commission of European Communities (CEC) guidelines/. The results show that in four examinations (skull, chest, lumbar spine and pelvis), there is a strong tendency of using exposure times above the European recommendation. The X-ray tube potential values (in kV) are below the recommended values from CEC guidelines. This study shows that at a local level (Lisbon region), radiographic practice does not comply with CEC guidelines concerning exposure techniques. Further national/local studies are recommended with the objective to improve exposure optimisation and technical procedures in plain radiography. This study also suggests the need to establish national/local diagnostic reference levels and to proceed to effective measurements for exposure optimisation. © The Author 2008. Published by Oxford University Press. All rights reserved.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Evaluation of exposure index (IgM) in orthopaedic radiography",
        "doc_scopus_id": "55249092473",
        "doc_doi": "10.1093/rpd/ncn143",
        "doc_eid": "2-s2.0-55249092473",
        "doc_date": "2008-12-22",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Radiological and Ultrasound Technology",
                "area_abbreviation": "HEAL",
                "area_code": "3614"
            },
            {
                "area_name": "Radiation",
                "area_abbreviation": "PHYS",
                "area_code": "3108"
            },
            {
                "area_name": "Radiology, Nuclear Medicine and Imaging",
                "area_abbreviation": "MEDI",
                "area_code": "2741"
            },
            {
                "area_name": "Public Health, Environmental and Occupational Health",
                "area_abbreviation": "MEDI",
                "area_code": "2739"
            }
        ],
        "doc_keywords": [],
        "doc_abstract": "The exposure index (lgM) obtained from a radiographic image may be a useful feedback indicator to the radiographer about the appropriate exposure level in routine clinical practice. This study aims to evaluate lgM in orthopaedic radiography performed in the standard clinical environment. We analysed the lgM of 267 exposures performed with an AGFA CR system. The mean value of lgM in our sample is 2.14. A significant difference (P = 0.000 ≤0.05) from 1.96 lgM reference is shown. Data show that 72% of exposures are above the 1.96 lgM and 42% are above the limit of 2.26. Median values of lgM are above 1.96 and below 2.26 for Speed class (SC) 200 (2.16) and SC400 (2.13). The interquartile range is lower in SC400 than in SC200. Data seem to indicate that lgM values are above the manufacturer's reference of 1.96. Departmental exposure charts should be optimised to reduce the dose given to patients. © The Author 2008. Published by Oxford University Press. All rights reserved.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Computer aided diagnosis system to detect breast cancer pathological lesions",
        "doc_scopus_id": "55349108936",
        "doc_doi": "10.1007/978-3-540-85920-8_56",
        "doc_eid": "2-s2.0-55349108936",
        "doc_date": "2008-11-10",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Artificial neural networks",
            "Breast cancer",
            "CAD system",
            "Mammography images",
            "Pathological lesion"
        ],
        "doc_abstract": "Breast cancer is one of the most frequent forms of women's cancer over the world. Studies of the World Health Organization (WHO) reported 1,151,298 cases in 2002. A reliable Computer-Aided-Diagnosis (CAD) system for automated detection/classification of pathological lesions is very useful and helpful, providing a valuable \"second opinion\" to medical personnel. In this work, we describe a new CAD system to diagnose six mammography pathological lesions classes (calcifications, well-defined/circumscribed masses, spiculated masses, ill-defined masses, architectural distortions and asymmetries) as benign or malignant tissues. Two different Artificial Neural Networks models: Feedforward Backpropagation and Generalized Regression were tested statistically with a precision of 94.0% and 80.0% of true positives, respectively. This CAD system was validated successfully on the MiniMammographic Image Analysis Society (MiniMIAS) database, with a dataset formed by 100 images. The CAD system performance shows similar or better classification results compared with others available methods. © 2008 Springer-Verlag Berlin Heidelberg.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "European Portuguese MRI based speech production studies",
        "doc_scopus_id": "54149108753",
        "doc_doi": "10.1016/j.specom.2008.05.019",
        "doc_eid": "2-s2.0-54149108753",
        "doc_date": "2008-11-01",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Software",
                "area_abbreviation": "COMP",
                "area_code": "1712"
            },
            {
                "area_name": "Modeling and Simulation",
                "area_abbreviation": "MATH",
                "area_code": "2611"
            },
            {
                "area_name": "Communication",
                "area_abbreviation": "SOCI",
                "area_code": "3315"
            },
            {
                "area_name": "Language and Linguistics",
                "area_abbreviation": "ARTS",
                "area_code": "1203"
            },
            {
                "area_name": "Linguistics and Language",
                "area_abbreviation": "SOCI",
                "area_code": "3310"
            },
            {
                "area_name": "Computer Vision and Pattern Recognition",
                "area_abbreviation": "COMP",
                "area_code": "1707"
            },
            {
                "area_name": "Computer Science Applications",
                "area_abbreviation": "COMP",
                "area_code": "1706"
            }
        ],
        "doc_keywords": [
            "2d images",
            "Area functions",
            "Articulatory synthesis",
            "Coarticulation",
            "European",
            "European Portuguese",
            "High qualities",
            "Image processing techniques",
            "Key features",
            "Nasal vowels",
            "Nasals",
            "Pharyngeal cavities",
            "Reasonable times",
            "Soft tissues",
            "Speech production",
            "Speech production models",
            "Speech productions",
            "Vocal tracts"
        ],
        "doc_abstract": "Knowledge of the speech production mechanism is essential for the development of speech production models and theories. Magnetic resonance imaging delivers high quality images of soft tissues, has multiplanar capacity and allows for the visualization of the entire vocal tract. To our knowledge, there are no complete and systematic magnetic resonance imaging studies of European Portuguese production. In this study, a recently acquired magnetic resonance imaging database including almost all classes of European Portuguese sounds, excluding taps and trills, is presented and analyzed. Our work contemplated not only image acquisition but also the utilization of image processing techniques to allow the exploration of the entire database in a reasonable time. Contours extracted from 2D images, articulatory measures (2D) and area functions are explored and represent valuable information for articulatory synthesis and articulatory phonetics descriptions. Some European Portuguese distinctive characteristics, such as nasality are addressed in more detail. Results relative to oral vowels, nasal vowels and a comparison between both classes are presented. The more detailed information on tract configuration supports results obtained with other techniques, such as EMMA, and allows the comparison of European Portuguese and French nasal vowels articulation, with differences detected at pharyngeal cavity level and velum port opening quotient. A detailed characterization of the central vowels, particularly the [{A figure is presented}], is presented and compared with classical descriptions. Results for consonants point to the existence of a single positional dark allophone for [l], a more palato-alveolar place of articulation for [y{turned}], a more anterior place of articulation for [y{turned}] relative to [n{left tail at left}], and the use, by our speaker, of a palatal place of articulation for [k]. Some preliminary results concerning coarticulation are also reported. European Portuguese stops revealed less resistant to coarticulatory effects than fricatives. Among all the sounds studied, [sh{phonetic}] and [z] present the highest resistance to coarticulation. These results follow the main key features found in other studies performed for different languages. © 2008 Elsevier B.V. All rights reserved.",
        "available": true,
        "clean_text": "serial JL 271578 291210 291718 291723 291743 291782 291874 31 Speech Communication SPEECHCOMMUNICATION 2008-06-13 2008-06-13 2010-11-19T11:27:02 S0167-6393(08)00080-0 S0167639308000800 10.1016/j.specom.2008.05.019 S300 S300.1 FULL-TEXT 2015-05-14T05:01:34.741028-04:00 0 0 20081101 20081231 2008 2008-06-13T00:00:00Z articleinfo crossmark dco dateupdated tomb dateloaded datesearch indexeddate issuelist volumelist yearnav absattachment articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids confeditor contenttype copyright dateloadedtxt docsubtype doctype doi eid ewtransactionid hubeid issfirst issn issnnorm itemstage itemtransactionid itemweight openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sortorder srctitle srctitlenorm srctype subheadings vol volfirst volissue figure table body mmlmath acknowledge affil articletitle auth authfirstini authfull authkeywords authlast nomenclature primabst ref alllist content subj ssids 0167-6393 01676393 50 50 11 12 11 12 Volume 50, Issues 11–12 8 925 952 925 952 200811 200812 November–December 2008 2008-11-01 2008-12-31 2008 Iberian Languages Isabel Trancoso Nestor Becerra-Yoma Plínio Barbosa Rubén San-Segundo Kuldip Paliwal article fla Copyright © 2008 Elsevier B.V. All rights reserved. EUROPEANPORTUGUESEMRIBASEDSPEECHPRODUCTIONSTUDIES MARTINS P Nomenclature 1 Introduction 1.1 Measurement methods 1.2 European Portuguese 1.3 Coarticulation 1.4 MRI in speech production studies: an overview 2 Image acquisition 2.1 MRI acquisition 2.2 Corpus 2.2.1 2D corpus 2.2.2 3D corpus 2.3 Speaker 3 Image processing 3.1 2D corpus 3.2 3D Corpus 4 Results I: vowels 4.1 Oral vowels 4.1.1 Anterior oral vowels 4.1.2 Central oral vowels 4.1.3 Posterior oral vowels 4.2 Nasal vowels 4.2.1 Nasal vs. Oral vowels 4.2.2 VPOQ 5 Results II: consonants 5.1 Nasals 5.2 Stops 5.3 Fricatives 5.4 Laterals 6 Discussion 6.1 Corpus, MRI acquisition and image processing 6.2 Oral vowels 6.3 Nasals 6.4 Stops and fricatives 6.5 Laterals 6.6 Coarticulation 7 Conclusions 7.1 Future Acknowledgements References ADAMS 1994 641 647 R ALWAN 1997 1078 1089 A BAER 1991 799 828 T BRYMAN 2001 A QUANTITATIVEDATAANALYSISSPSSRELEASE10FORWINDOWSAGUIDEFORSOCIALSCIENTISTS DANG 1994 1765 J DANG 1994 2088 2100 J DEMOLIN 2003 454 467 D FARNETANI 1999 371 404 E HANDBOOKPHONETICSCIENCES COARTICULATIONCONNECTEDSPEECHPROCESSES GICK 2002 357 371 B HARDCASTLE 1976 W PHYSIOLOGYSPEECHPRODUCTIONINTRODUCTIONFORSPEECHSCIENTISTS HARDCASTLE 1999 W COARTICULATIONTHEORYDATATECHNIQUES HOOLE 1993 43 64 P HOOLE 1999 260 269 P COARTICULATIONTHEORYDATATECHNIQUES ELECTROMAGNETICARTICULOGRAPHY JESUS 2002 437 464 L KIM 2004 234 251 H KIRITANI 1986 119 140 S KUHNERT 1999 B COARTICULATIONTHEORYDATATECHNIQUES ORIGINSCOARTICULATION LADEFOGED 1996 P SOUNDSWORLDSLANGUAGES MAGEN 1997 187 205 H MANUEL 1999 179 198 S COARTICULATIONTHEORYDATATECHNIQUES CROSSLANGUAGESTUDIESRELATINGLANGUAGEPARTICULARCOARTICULATIONPATTERNSOTHERLANGUAGEPARTICULARFACTS MATHIAK 2000 419 425 K MORAISBARBOSA 1994 A INTRODUCAOAOESTUDODAFONOLOGIAEMORFOLOGIAPORTUGUES NARAYANAN 1995 2511 2524 S NARAYANAN 2000 328 344 S NARAYANAN 1995 1325 1347 S NARAYANAN 1997 1064 1077 S NARAYANAN 2004 1771 1776 S PERKELL 1969 J PHYSIOLOGYSPEECHPRODUCTIONRESULTSIMPLICATIONSAQUANTITATIVECINERADIOGRAPHICSTUDY RECASENS 1999 D COARTICULATION LINGUALCOARTICULATION RECASENS 2005 1 25 D RECASENS 2006 295 318 D RECASENS 1997 544 561 D SACHS 1984 L APPLIEDSTATISTICSAHANDBOOKTECHNIQUES SANOGUEIRA 1938 R ELEMENTOSPARAUMTRATADODEFONETICAPORTUGUESA SANTOS 2004 868 878 B SERRURIER 2005 195 211 A SHADLE 1996 C MRISTUDYEFFECTSVOWELCONTEXTFRICATIVES STONE 1999 11 32 M HANDBOOKPHONETICSCIENCES LABORATORYTECHNIQUESFORINVESTIGATINGSPEECHARTICULATION STONE 2001 1026 1040 M STORY 1996 537 554 B STREVENS 1954 5 29 P TAKEMOTO 2004 468 474 H TEIXEIRA 2005 1435 1448 A TIEDE 1996 399 421 M TULLER 1981 175 188 E VIANA 1996 113 167 M INTRODUCAOALINGUISTICAGERALEPORTUGUESA FONETICA MARTINSX2008X925 MARTINSX2008X925X952 MARTINSX2008X925XP MARTINSX2008X925X952XP item S0167-6393(08)00080-0 S0167639308000800 10.1016/j.specom.2008.05.019 271578 2010-12-28T19:56:56.229472-05:00 2008-11-01 2008-12-31 true 3258794 MAIN 28 69155 849 656 IMAGE-WEB-PDF 1 si9 325 17 35 si8 194 13 9 si7 245 16 23 si6 270 13 27 si5 125 2 8 si43 194 13 9 si42 125 2 8 si41 125 2 8 si40 125 2 8 si4 194 13 9 si39 125 2 8 si38 125 2 8 si37 125 2 8 si36 125 2 8 si35 125 2 8 si34 194 13 9 si33 194 13 9 si32 194 13 9 si31 194 13 9 si30 194 13 9 si3 125 2 8 si29 194 13 9 si28 194 13 9 si27 194 13 9 si26 194 13 9 si25 125 2 8 si24 488 17 78 si23 488 17 78 si22 488 17 78 si21 1052 19 219 si20 1072 19 220 si2 194 13 9 si19 337 17 55 si18 217 15 14 si17 633 26 120 si16 125 2 8 si15 194 13 9 si14 125 2 8 si13 194 13 9 si12 333 17 37 si11 125 2 8 si10 125 2 8 si1 270 13 27 gr1 13645 141 577 gr1 1420 31 125 gr10 51458 556 575 gr10 2359 93 96 gr11 84510 846 579 gr11 2033 93 64 gr12 18115 170 566 gr12 1605 38 125 gr13 88749 671 610 gr13 3504 93 85 gr14 26193 269 574 gr14 2048 59 125 gr15 73164 851 564 gr15 1989 94 62 gr16 117074 725 486 gr16 3863 93 62 gr17 71026 851 564 gr17 1998 94 62 gr18 80348 734 539 gr18 2258 93 68 gr19 86568 745 580 gr19 2902 94 73 gr2 8250 142 571 gr2 1237 31 125 gr20 21045 184 600 gr20 1649 38 125 gr3 23129 306 306 gr3 4735 93 93 gr4 33560 295 300 gr4 5567 93 95 gr5 45413 298 609 gr5 2831 61 125 gr6 108311 619 555 gr6 4476 94 84 gr7 100582 902 610 gr7 1828 93 63 gr8 63007 774 600 gr8 1921 93 72 gr9 101006 897 513 gr9 2634 93 53 fx1 true 378 8 3 fx1 true 977 41 16 SPECOM 1722 S0167-6393(08)00080-0 10.1016/j.specom.2008.05.019 Elsevier B.V. Fig. 1 Boxplots of the Pratt Index differences obtained by using different starting points (seeds). Results for oral vowels, nasal vowels and nasal consonants are presented. Fig. 2 Boxplots comparing Pratt Index of all contours obtained with different starting points for a fixed image (intra) and contours of different EP sounds (inter). In the calculation, part of 2D corpus was used: all oral vowels, all five nasal vowels and the consonants [m], [s] and [l]. Fig. 3 Midsagittal profile obtained during the production of a sustained [ ] by PAA, as in the word (devi) [ d i vi ], showing measured articulatory points. Articulatory points used for this work are: highest tongue dorsum point (TD), tongue tip (TT), tongue root position at C3–C4 level (TR), jaw height (JH) and lower (LL) and upper lip (UL) spatial coordinates. Fig. 4 Example of a resliced midsagittal cut, for [a], obtained from the volumetric information (between a few centimeters above hard palate to C5 vertebral level). Superimposed, the generated adaptative grid is shown. With this procedure all obtained slices are orthogonal to the vocal tract centerline. Fig. 5 Examples of coronal oblique views obtained from nasal consonants 3D data: [m] at left and [ɲ] at right. The cut passes through the velum (orthogonal to the vocal tract centerline). Two passages can be observed: one (at the top) refers to nasal cavity and the other to oral cavity (bottom). Fig. 6 Midsagittal images with superimposed contours for the EP oral vowels: from the top, [i], [ ], [u], [e], [ɐ], [o], [ε], [a] and [ɔ]. Fig. 7 Six articulatory measures for EP vowels. From the top left: Tongue dorsum highest position (TD), tongue root at C3–C4 level (TR), tongue tip (TT), jaw height (JH), and lower (LL) and upper (UL) lip. Fig. 8 Area functions for seven of the EP oral vowels. They were grouped in anterior, central and posterior, with higher vowels at the top. From the top, [i], [e], [ɐ], [a], [u], [o] and [ɔ]. In the area functions, information regarding the constriction point (distance from reference, at basis of C5 vertebra, and area) is included. Note the difference in y-axis scale for the three last area functions, with a maximum twice of what was used in the others. Fig. 9 Results for the 5 EP nasal vowels: from the top, [ĩ], [ e ˜ ], [ ɐ ˜ ], [ũ] and [õ]. In each row, are presented, from left, the midsagittal image with superimposed contour and area function. In the area functions, information regarding constriction point (distance from reference point and area) is included. Fig. 10 Midsagittal vocal tract profiles comparisons for nasal vowels and their possible oral counterparts: (a) superimposition of [i] (solid line) and [ĩ] (dash-dotted); (b) superimposition of [e] (solid line), [ e ˜ ] (dash-dotted) and [ε] (dotted); (c) superimposition of [a] (solid line), [ ɐ ˜ ] (dash-dotted) and [ɐ] (dotted) and (d) superimposition of [o] (solid line), [õ] (dash-dotted) and [ɔ] (dotted). Fig. 11 Area functions comparison between EP nasal and oral vowels. On the left, a plot of area functions; on the right the absolute differences between nasal vowel and oral counterparts. Fig. 12 Boxplots of VPOQ for oral vowels, nasal vowels, and consonants. Dots represent the VPOQ average value. Fig. 13 Results for the EP nasal consonants. From the top, bilabial [m], dental [n] and palatal [ɲ]. All the three sounds were sustained having a reference word with the same symmetric vocalic context, the oral vowel [ɐ]. In each row the following are presented: the image with superimposed contour (at left) and area function. In the area functions, information regarding occlusion point (distance from reference point and area) is included. Fig. 14 Midsagittal contour superimposition for nasal consonants and stops with the same place of articulation. At the left, bilabials [p] and [m]; at the right the dentals [t] and [n]. The two nasal consonants were sustained having an example word with the same symmetric vocalic context, oral vowel [ɐ]. The stops are the ones produced in the [aCa] context. Fig. 15 Midsagittal contours relative to stop consonants, obtained in VCV context with the point vowels [a] (dashed), [i] (solid line) and [u] (dash-dotted). At the top row appears the bilabial unvoiced [p] (left) and the voiced [b] (right); at center appear the dental unvoiced [t] (left) and the voiced stop [d] (right); at bottom the velar stops: the unvoiced [k] (left) and voiced [g] (right). Fig. 16 Midsagittal MRI images with superimposed contour relative to EP fricative sounds. At the top row the labiodental fricatives [f] and [v]; at the center the alveolar fricatives [s] and [z] and at bottom the palato-alveolar fricatives [ʃ] and [ʒ]. All were sustained having an example word with the fricative at the beginning and followed by the oral vowel [a]. Fig. 17 Midsagittal contours relative to fricatives, obtained in VCV context with the vowels [a] (dashed), [i] (solid line) and [u] (dash-dotted). At the top appears the labiodental unvoiced [f] (left) and the voiced [v] (right); in the middle row appear the alveolar unvoiced [s] (left) and alveolar voiced [z] (right); at bottom the palato-alveolar fricatives: the unvoiced [ʃ] (left) and the voiced [ʒ] (right). Fig. 18 Area functions for the fricatives [f], [s], and [ʃ] in three vocalic contexts (left) and absolute differences (right). Fig. 19 MRI images (with contours) and area functions for the EP laterals. Top 3 rows presents results for [l]: top row [l] in [lasu]; second row [ɫ] in [maɫ]; third row a comparison of the contours previously presented, on the left, and right, area function for a third context with only 3D data available, intervocalic position [palɐ]. Finally, on the bottom row, image and area function for [ʎ]. Fig. 20 Comparison of the three area functions obtained for EP lateral [l]. Three contexts are represented: beginning of word and syllable (solid), end of word or syllable (dash-dotted) and in syllable onset but intervocalic (dotted). Table 1 MRI sequence parameters used in imaging acquisition Parameter TSE T1 weighted (2D) 3D flash VIBE TR (time to repeat) 400ms 4.89ms TE (time to echo) 8.3ms 2.44ms ETL 15 1 FA 180° 10° FOV(x, y) [mm] 200×200 270×216 Slabs – 1 Slices per slab – 60 Slice thickness 5mm 2mm Orientation Sagittal Axial Distance factor – 0.2mm Base resolution 256mm 256mm Phase resolution 75% 60% Phase direction Anterior–posterior Right–left Phase partial Fourier – 6/8 BW (Hz/pixel) 235 350 Acquisition time 5.6s 18s NEX 1 1 Image size (x, y) [pixels] 256×256 512×416 Pixel size (x, y) [mm] 0.78×0.78 0.53×0.53 Number of measurements 1 1 Table 2 2D and 3D corpus contents including target phone and reference words (in Portuguese and respective phonetic transcription using IPA phonetic alphabet) used in instructing speaker Phone Word Transcr. 2D 3D Oral vowels [i] pipo [pipu] X X [e] pêca [pekɐ] X X [ε] leva [lεvɐ] X [i] devi [ d i vi ] X [ɐ] cada [kɐdɐ] X X [a] pato [patu] X X [u] buda [budɐ] X X [o] tôpo [topu] X X [ɔ] pote [ p ɔ t i ̶ ] X X Nasal vowels [ĩ] pinta [pĩtɐ] X X [ e ˜ ] pente [ p e ˜ t i ̶ ] X X [ ɐ ˜ ] canto [k ɐ ˜ tu] X X [ũ] punto [pũtu] X X [õ] ponte [ p o ˜ t i ̶ ] X X Stops [p] [apa], [ipi], [upu] X [t] [ata], [iti], [utu] X [k] [aka], [iki], [uku] X [b] [aba], [ibi], [ubu] X [d] [ada], [idi], [udu] X [g] [aga], [igi], [ugu] X Nasal consonants [m] cama [kɐmɐ] X X [n] cana [kɐnɐ] X X [ɲ] canha [kɐɲɐ] X X Fricatives [f] fala [falɐ] X [s] sala [salɐ] X [ʃ] chá [ʃa] X [v] vaca [vakɐ] X [z] zarpa [zarpɐ] X [ʒ] jacto [ʒatu] X [f] [afa], [ifi], [ufu] X X [s] [asa], [isi], [usu] X X [ʃ] [aʃa], [iʃi], [uʃu] X X [v] [ava], [ivi], [uvu] X [z] [aza], [izi], [uzu] X [ʒ] [aʒa], [iʒi], [uʒu] X Laterals [l] laço [lasu] X X [l] pála [palɐ] X [ɫ] mal [maɫ] X X [ʎ] falha [faʎɐ] X [ʎ] palha [paʎɐ] X ☆ Part of the work reported, particularly on nasals, was accepted for presentation at Interspeech 2007. Paper is entitled “An MRI study of European Portuguese nasals. European Portuguese MRI based speech production studies Paula Martins a Inês Carbone b Alda Pinto c Augusto Silva b António Teixeira b ⁎ a Escola Superior de Saúde, Universidade de Aveiro, Portugal b Dep. Electrónica Telec. Informática/IEETA, Universidade de Aveiro, 3810 Aveiro, Portugal c Dep. de Radiologia, Hospital da Universidade de Coimbra, Portugal ⁎ Corresponding author. Tel.: +351 234370500; fax: +351 234370545. Knowledge of the speech production mechanism is essential for the development of speech production models and theories. Magnetic resonance imaging delivers high quality images of soft tissues, has multiplanar capacity and allows for the visualization of the entire vocal tract. To our knowledge, there are no complete and systematic magnetic resonance imaging studies of European Portuguese production. In this study, a recently acquired magnetic resonance imaging database including almost all classes of European Portuguese sounds, excluding taps and trills, is presented and analyzed. Our work contemplated not only image acquisition but also the utilization of image processing techniques to allow the exploration of the entire database in a reasonable time. Contours extracted from 2D images, articulatory measures (2D) and area functions are explored and represent valuable information for articulatory synthesis and articulatory phonetics descriptions. Some European Portuguese distinctive characteristics, such as nasality are addressed in more detail. Results relative to oral vowels, nasal vowels and a comparison between both classes are presented. The more detailed information on tract configuration supports results obtained with other techniques, such as EMMA, and allows the comparison of European Portuguese and French nasal vowels articulation, with differences detected at pharyngeal cavity level and velum port opening quotient. A detailed characterization of the central vowels, particularly the [ ], is presented and compared with classical descriptions. Results for consonants point to the existence of a single positional dark allophone for [l], a more palato-alveolar place of articulation for [ʎ], a more anterior place of articulation for [ʎ] relative to [ɲ], and the use, by our speaker, of a palatal place of articulation for [k]. Some preliminary results concerning coarticulation are also reported. European Portuguese stops revealed less resistant to coarticulatory effects than fricatives. Among all the sounds studied, [ʃ] and [ʒ] present the highest resistance to coarticulation. These results follow the main key features found in other studies performed for different languages. Keywords Speech production European Portuguese Magnetic resonance imaging Nasals Coarticulation Nomenclature ETL echo train length FOV field of view MRI magnetic resonance imaging SSFP steady state free precession TR time to repeat VIBE volume interpolated breath hold examination FLASH fast low angle shot MPRAGE magnetization prepared rapid acquisition gradient echo NEX number of excitations TE time to echo TSE turbo spin echo (sequence) VPOQ velum port opening quotient 1 Introduction Mankind’s knowledge about human speech production and perception is still incomplete. More information is definitely needed. Recently, better techniques for measuring vocal tract configurations have become an increased research interest. Building phonetic information databases has had great relevance in fields such as speech synthesis, speech recognition, speech disorder studies, learning of new languages, etc. An area where production data are very important is articulatory synthesis, where we have been involved for more than a decade (Teixeira et al., 2005). These anthropomorphic synthesizers demand large amounts of detailed anatomic-physiological information, if possible in 3D, and their variation in time (dynamic information). For European Portuguese (EP), not much information is available. To compensate this lack of information, the objectives of the present study are: (1) to provide vocal tract configurations during (sustained) production of all the EP sounds (excluding taps and trills); (2) to perform comparisons between different sound classes; (3) to obtain direct area functions from a great part of the EP sounds; (4) to have a preliminary approach on coarticulation in stops and fricatives and, (5) due to the nature of the research team, to develop acquisition and segmentation techniques with application in the field of speech production. This paper is structured as follows: this first section introduces the problem, presents the most common anatomic-physiological measurement methods for speech production studies, describes the EP relevant specificities, coarticulation and related work in MRI application to speech production studies; Section 2 describes image acquisition and corpus; Section 3 describes image processing; Sections 4 and 5 present our results, separated into vowels and consonants. All the phonetic considerations made in this paper rely on static articulations that might be different from continuous speech articulations. The paper ends with a discussion of the results presented in earlier sections, and with the main conclusions that can be extracted from them. 1.1 Measurement methods Nowadays, the common methods found in the speech research literature to acquire anatomic-physiological information directly are: electromagnetic midsagittal articulography (EMMA), electropalatography (EPG), and magnetic resonance imaging (MRI). EMMA provides valuable kinematic data relative to different articulators (lips, tongue, jaw, velum) with good temporal resolution. However, some drawbacks can be pointed out: the acquired data are, in the majority of available systems, two dimensional and limited to the trajectories of some articulator fleshpoints (Hoole, 1993; Hoole and Nguyen, 1999); the process is invasive and articulation may be affected by the sensors. EPG measures only the linguopalatal contact and its variation on time, being difficult to make well-fitted pseudo-palates, which in turn interfere to some extent with speech production (Stone, 1999). MRI, the technique on which we will focus in this study, has some potential advantages: it provides a good contrast between soft tissues, allows 3D modeling and covers the vocal tract in all of its extension (Baer et al., 1991; Alwan et al., 1997; Narayanan et al., 1997; Narayanan et al., 2004). This last advantage is of special interest in the study of the pharyngeal cavity, as it is not accessible through EMMA or EPG. Moreover, it is non-invasive and considered as safe. Its disadvantages are related to the absence of the teeth in the images, due to their lack of hydrogen protons; the acquisition technique, in which the speaker must be lying down during speech production. This position can have some influence, for instance, on the tongue posture (Tiede et al., 2000; Engwall, 2003), but this drawback can be considered acceptable. The relatively low temporal resolution achieved, even with the fastest acquisition techniques, is a limiting factor (Narayanan et al., 2004). The noisy acquisition environment and the reduced acoustic feedback, due to the use of headphones, are also MRI disadvantages. The MRI technique has already been used for the study of several languages: British English (Baer et al., 1991), American English (Narayanan and Alwan, 1995; Stone et al., 1997; Narayanan et al., 1997; Narayanan et al., 2004), French (Demolin et al., 1996; Badin et al., 1998; Serrurier and Badin, 2005), Swedish (Engwall and Badin, 1999; Ericsdotter, 2005), Japanese (Takemoto et al., 2004), German (Kröger et al., 2000; Hoole et al., 2000; Mathiak et al., 2000), Tamil (Narayanan et al., 2004), and Akan (Tiede, 1996). For EP, one of the authors was involved in the creation of the first and, to the best of our knowledge, unique EMMA database focused on nasals (Teixeira and Vaz, 2001). Also, there are no EPG databases for EP, and there is only one partial MRI study (Rua and Freitas, 2006). For Brazilian Portuguese this information is also scarce. An MRI based study of nasals was performed recently by Gregio (2006). 1.2 European Portuguese “The characteristics which at first hearing distinguish the pronunciation of Portuguese from that of the other Western Romance languages [are]: (a) the very large number of diphthongs (…); (b) the large number of nasal vowels and nasal diphthongs; (c) frequent alveolar and palatal fricatives (…); (d) the extremely ‘dark’ quality of the common variety of l-sound” (Strevens, 1954, p. 6). Despite its similarities to Spanish, both in vocabulary and grammatical structure, Portuguese differs considerably in its pronunciation (Strevens, 1954). In EP there is a maximum of nine oral vowels and 10 oral diphthongs (Cruz-Ferreira, 1999). Oral vowels are usually divided into: anterior ([i], [e], and [ε]); central ([a], [ɐ], and [ ]); and posterior ([u], [o], and [ɔ]). The most problematic vowel is [ ] with descriptions going from the schwa to a high central vowel or even, as proposed by Cruz-Ferreira (1999), a configuration close to [u]. EP has five nasal vowels ([ĩ], [ e ˜ ], [ ɐ ˜ ], [õ], and [ũ]); three nasal consonants ([m], [n], and [ɲ]); and several nasal diphthongs and triphthongs. Despite nasality being present in most of the languages of the world, only about 20% of such languages have nasal vowels (Rossato et al., 2006). There is some uncertainty in the actual configurations assumed by the tongue and other articulators during EP nasals production, namely nasal vowels. This is particularly relevant for mid vowels where the opposition between mid-low and mid-high, present in the oral vowels set, is neutralized (Teixeira et al., 2003). This neutralization allows the oral articulators to rearrange, leading to associate each nasal vowel to several possible oral counterparts (Teixeira et al., 2003): nasal vowel [ e ˜ ] relates to [e] and [ε]; [õ] relates to [o] and [ɔ]; and [ ɐ ˜ ] can be more open than [ɐ] or produced with an oral configuration similar to [a]. Note that [i] and [u] are considered to be the oral counterparts of [ĩ] and [ũ]. Also, some phonetic studies point to the existence of differences related with production of EP nasals relative to French (Teixeira et al., 1999; Teixeira and Vaz, 2001). In this work, we return to the same challenging topic, using MRI as the data acquisition method. In EP six fricative consonants are described (Jesus and Shadle, 2002). Three are produced with vocal fold vibration (voiced fricatives [v], [z] and [ʒ]) and three produced without vibration (unvoiced fricatives [f], [s] and [ʃ]). Sounds [v] and [f] are produced with a constriction point induced by the contact of the lower lip and upper incisor (labiodental), [s] and [z] are fricatives produced with approximation of the tongue tip or blade to the alveolar region. Finally, [ʃ] and [ʒ] are produced in the palato-alveolar area. Phonologically EP has two laterals, /l/ and /ʎ/. The former is produced with contact of tongue tip or blade in the alveolar ridge, the latter produced with a central occlusion between the most anterior tongue dorsum and the anterior palate (palatal consonant). For the apical lateral /l/, in accordance with EP most frequent descriptions, two allophones are considered: one, non-velarized light or clear [l], occurring in syllable onset; the second, occurring in coda or in absolute word-final position, considered a “velarized” [ɫ] and corresponding to the descriptions of the English dark [l]. During the production of this dark allophone, a second and posterior constriction, originated by tongue back raising towards the velum, is considered (Ladefoged and Maddieson, 1996). However, Andrade (1999) found in three Lisbon speakers, evidence that this “velarization” can also occur in syllable onset. This was also described, much earlier, in older EP phonetic descriptions (Strevens, 1954). Also, Recasens and Espinosa (2005), based on acoustic data stated that EP, together with Russian and Leeds British English, belong to a group of sound systems where /l/ presents the same realization in word initially and word finally. 1.3 Coarticulation The term coarticulation has been introduced by Menzerath and Lacerda – a Portuguese Phoneticist – in 1933 (Kühnert and Nolan, 1999). Although it could be simply defined as “the articulatory or acoustic influence of one segment or phone on another” (Magen, 1997) it is a complex and difficult subject. Many theories and models have emerged to explain coarticulation but some doubts still persist. There are, however, some accepted facts: coarticulation was observed in almost all languages, being a universal phenomenon, but coarticulatory effects vary from one language to another Manuel (1999, p. 180). Recent theories of speech production consider that coarticulation plays a central role and that is essential to take coarticulatory effects into account in both speech production models and speech synthesis. Important concepts such as “coarticulation resistance” and “degree of articulatory constraint” (DAC) were introduced to explain why coarticulatory effects are different in different sounds (Recasens et al., 1997). To give a complete picture of coarticulation one should consider lingual, jaw, labial, and laryngeal coarticulation. An extensive review of the subject can be found in (Hardcastle and Hewlett, 1999). Several exploratory techniques are referred as important tools when studying coarticulation, such as EMMA (Hoole, 1993; Hoole and Nguyen, 1999) or EPG (West, 2000). MRI has also been used for the same purpose as described in (Stone et al., 1997; Engwall and Badin, 2000; Stone et al., 2001; Engwall, 2003). We are not aware of any MRI coarticulation study for EP. 1.4 MRI in speech production studies: an overview MRI evaluation of the vocal tract configuration is definitely not a recent issue in the field of speech production. One of the pioneer studies in this field was performed by Baer et al. (1991) for British English. Although it is not the first study that employs MRI as an imaging tool, it was the first that allowed extraction of valuable 3D information related with English vocalic sounds (Engwall, 2002). Traditionally, studies involving MRI were called static (2D and 3D), or dynamic/real-time, although different terminology has been used by different authors, as has been pointed out and explained by Narayanan et al. (2004). From static (2D and 3D) studies, with images acquired during sustained production of sounds, midsagittal profiles and distances, cross sectional areas, articulatory measures, vocal tract area functions, and 3D visualizations were obtained (Baer et al., 1991; Story et al., 1996; Engwall and Badin, 1999). The acquisition time, during which articulation must be sustained, is nowadays substantially shorter in most recent studies, when compared with the first MRI evaluations, which reflect technical advances in the field of MRI technology. This fact leads to a better image quality, since image artifacts, due to movements, contributes negatively to the sharpness and image contrast in a MRI image. For real-time studies, recent improvements in temporal resolution are encouraging, but not yet enough to obtain dynamic information relative to some articulators (e.g. tongue tip or velum opening/closure during nasals sounds), or to study more demanding sounds in terms of temporal resolution as happens with stops (Mathiak et al., 2000). The number of speakers participating in studies with published results is not high, varying between one (Greenwood et al., 1992; Story et al., 1996; Yang, 1999; Engwall and Badin, 1999; Shadle et al., 1999; Kröger et al., 2000; Serrurier and Badin, 2005), two (Baer et al., 1991; Tiede, 1996; Ericsdotter, 2005), four (Narayanan et al., 1995; Narayanan et al., 1997; Alwan et al., 1997; Demolin et al., 1996; Demolin et al., 2003) and five (Dang and Honda, 1994). This fact reflects the high costs of MRI equipment and the access constraints imposed by the use, in the majority of the studies, of hospital diagnostic equipment. There are studies for different languages and for different classes of sounds. In the next paragraphs, one for each class of sounds contemplated in the present study, a brief review of studies, having a phonetical speech production point of view, is made. Oral vowels were studied for American English (Story et al., 1996), British English (Baer et al., 1991), Akan (Tiede, 1996), Japanese (Dang and Honda, 1996), French (Demolin et al., 1996), German (Hoole et al., 2000) and Swedish (Engwall, 1999; Ericsdotter, 2005). Common results are MRI images, distances, segmentations, 3D vocal tract and tongue visualizations, and area functions. Nasal vowels were mainly considered for French (Demolin et al., 1998; Demolin et al., 2003; Engwall et al., 2006). In (Demolin et al., 1998) the results presented are transversal MRI images, cross sectional areas, comparisons between oral and nasal vowels, and 3D reconstructions of the pharynx and of the nasal tract. In 2002, Delvaux et al. (2002), obtained from MRI images the articulatory contours. Recently, Engwall et al. (2006) published MRI images, nasal and oral areas and a relative measure for the velum port opening, VPOQ. Dang and his colleagues (Dang et al., 1994; Dang and Honda, 1994) studied nasal consonants for Japanese (Story et al., 1996) for (American) English, and (Hoole et al., 2000) for German. Japanese studies presented several measurements of the three-dimensional geometry of the vocal tract. In (Story et al., 1996) area functions and vocal tract visualizations are presented. Hoole and coworkers provided tongue contours and respective deformations based on a two-factor tongue model. The study lead by Story et al. (1996), included some investigation on American English stops, through the observation of 3D vocal tract visualizations and respective area functions. Hoole et al. (2000), in 2000, acquired MRI coronal, axial and sagittal volumes of long German vowels and alveolar consonants. Kim (2004) studied Korean coronal stops and affricates. She presented midsagittal MRI images, tongue contours, and some measurements of movements, distances, and widths. Fricatives were studied for a broad number of languages, such as English (British and American), Swedish, German. The oldest study, by Shadle et al. (1996) in 1996, showed only midsagittal MRI images. Mohammad et al. (1997) developed a new method to acquire MRI dynamic images. Jackson (2000), in his work on acoustic modeling, used MRI to draw contours and area functions. Narayanan and Alwan (2000) used vocal tract area functions obtained from MRI images of voiced and unvoiced English fricatives to delineate hybrid source models for fricative consonants. Engwall and Badin (2000) presented midsagittal contours, 3D vocal tract shapes and investigated coarticulatory effects in Swedish fricatives. Hoole and his team (Hoole et al., 2000) focused on the study of the tongue. To gather data on laterals, and to the best of our knowledge (Bangayan et al., 1996; Narayanan et al., 1997; Gick et al., 2002) (for American English) and (Hoole et al., 2000) (for German) used MRI. They presented coronal MRI images, midsagittal segmentations of the vocal tract, area functions, 3D vocal tract and tongue visualizations. 2 Image acquisition 2.1 MRI acquisition The MRI images were acquired using a 1.5T (Magneton Simphony, Maestro Class, Siemens, Erlangen, Germany) scanner equipped with Quantum gradients (maximum amplitude=30mT/m; rise time=240μs; slew rate=125T/m/s; FOV=50cm). Neck and brain phased array coils were used. Two different types of acquisitions were performed, 2D static and 3D static, whose acquisition sequence parameters are shown in Table 1 . For 3D, instead of exciting a series of 2D slices in different planes (coronal, coronal oblique and axial) as reported by other authors in the field (e.g. Badin et al., 1998; Engwall and Badin, 1999) we performed a volumetric acquisition, by exciting a volume of spins in the axial plane (from above hard palate level to C5–C6 level), using a three-dimensional Fourier Transform (3DFT) sequence. This acquisition has some advantages when compared with 2D acquisitions: the possibility of having a reduced slice thickness (in our study we obtained an effective slice thickness of 2mm) contributing to obtain high resolution images with a reduced acquisition time; signal to noise ratio (SNR) is usually high with a 3D excitation; possibility of reslicing in any direction with different slice thickness, a variable number of slices and different orientation with a quality superior that can be obtained with 2D acquisitions. When 3D visualizations are required, this method allows the utilization of faster and direct segmentation tools (e.g. itk-SNAP) to extract tract configuration. Establishing some trade-offs, we obtained at least the same amount of data as reported in the referenced studies, with a reasonable spatial resolution, but decreasing to less than half the acquisition time (18s). Bidimensional acquisitions resulted in images of 256×256pixels and a resolution of 0.78mm/pixel in both directions. For 3D, the volume has 512×416×60 voxels and resolution of 0.53mm/pixel in plane and 2mm resolution in the z-direction. 2.2 Corpus The corpus comprises two subsets, 2D and 3D corpus, acquired using two different acquisition techniques. In both sets, the sounds are artificially sustained (vowels) or holding the articulation (stops) during the period of image acquisition, as already done in a similar way for other languages (Story et al., 1996; Demolin et al., 1996; Engwall and Badin, 1999). Although with some technical differences, our 2D and 3D corpus were inspired by the studies of (Demolin et al., 1996) for French, Badin et al. (1998) also for French, and Engwall and Badin (1999) for Swedish. As in Engwall and Badin (1999), we decided to obtain a large corpus with only one speaker rather than to obtain a small set of items relative to vowels or classes of consonantal sounds with a higher number of speakers. The reason for this option relies on the scarcity of MRI information for EP. Both approaches present advantages and limitations as emphasized by Engwall and Badin (1999). 2.2.1 2D corpus The main goals were: to obtain MRI static images of the vocal tract during the production of all EP vowels and consonants allowing to extract midsagittal contours; to have articulatory measures; and to measure midsagittal distances. Each sound of the 2D corpus (Table 2 ) was pronounced and sustained during the acquisition time (5.6s). To help the speaker, a reference word, containing the target phone, was presented before launching the sequence, using the intercom (e.g. “please say [a] as pronounced on [patu]”). This procedure was used for oral and nasal vowels, nasals, laterals and fricatives with one sample of each sound. For nasal vowels this process does not take into consideration the reported dynamic movement between an oral position towards a nasal position (see for example Teixeira and Vaz, 2001; Teixeira et al., 1999). The acquired image should be considered as more representative of nasal vowels when produced in isolation and of the initial and medial configuration during nasal vowel production. To allow a coarticulation study, stops and fricatives were also acquired on a vowel–consonant–vowel (VCV) symmetric context (non-sense words), with V being one of the cardinal vowels [a, i, u]. Note however that, due to recording duration constraints and the secondary role of coarticulation study in the present paper, only stops and fricatives were considered here. During this recording sequence the speaker was instructed to perform the VC-transition, then to sustain the consonant during acquisition time, and finally perform CV transition. Acquisition was started as soon as the speaker started producing the consonant; the speaker used the acquisition noise to make the final transition. The speaker had the opportunity of having a small training phase before the image acquisition session. 2.2.2 3D corpus For this corpus the main purposes were: (1) to obtain tridimensional information, such as vocal tract area functions, and (2) to complement the 2D information with lateral information. The main challenge with this corpus was to obtain a large volume of data within the smallest acquisition time. As already explained (Section 2.1), instead of choosing a set of directions and acquiring a fixed number of slices, we used a 3D sequence. Despite the reduction in acquisition time, each 3D item takes around 18s. To keep the recording session reasonably short (actual duration was of approximately 90min), in the 3D corpus we only contemplated the sounds for which 3D can provide new important information (as for the laterals) or are reported to be somehow characteristic of Portuguese. This explains the non-inclusion of stops. For oral vowels and fricatives, only a subset of the 2D corpus was considered. The procedures followed in this corpus were similar (excluding acquisition time) to the procedures already detailed for the 2D subset. The corpus actual content, using the IPA phonetic alphabet (International Phonetic Association, 1999) can be found in Table 2. Although Alwan et al. (1997) acquired sustained productions of American English rothics, EP taps and trills were not considered in this static study. We anticipated as particularly problematic to record information on [r,R] due to the several opening/closing movements involved. They have been included in a real-time MRI corpus (not presented in the paper). 3D high resolution sagittal images of the nasal and oral tracts of the speaker at rest (no phonation) were moreover acquired. Finally, as calcified structures such as bone and teeth are not observed on MRI images, dental arches were also obtained, according to the technique described by Takemoto et al. (2004), but using water as an oral MRI contrast agent. These images were however not exploited in this study and are planned to be used in following studies to improve our results (see Section 7.1). 2.3 Speaker For the 2D and 3D corpus subsets, analyzed in the present study, only one speaker was recorded (PAA). The speaker selected was an EP native speaker, male, 25years old, 180cm height, 70kg, from the north of the country, and with both vocal and singing training. The speaker had, at the time of the study, no history of speech or language disorders. During the acquisition of all the sequences involved in the study, the speaker used headphones to respect safety recommendations related with noise levels, and also to allow for better communication. The reduced auditory feedback due to the use of headphones represents a limitation to the study, with possible negative impact on speaker’s articulation. As far as positioning is concerned, the speaker was lying in a comfortable supine position. Head and neck phased array coils were used and the speaker’s head was fixed with regular foams and cushers. The speaker’s head movement was later evaluated, in the 2D corpus, by analysis of the coordinates of one manually marked point supposed to be fixed in the reference coordinate system, the anterior arch of C1. Maximum movement from average (including the error of the manual marking process) was 1pixel (corresponding to 0.78mm) in the anterior–posterior direction and 3pixels (2.34mm) in the other direction. These results support our assumption that speaker’s movements were negligible. 3 Image processing The viability of a large MRI database is determined by the existence of a reliable and fast segmentation method, with low human interaction. This is particularly relevant when using real-time MRI, where the number of images to process is very large. The study of the robustness of the segmentation method is also very important. We need to make sure that the contours generated are truthful enough to represent the vocal tract configuration of the sound being produced. The contours cannot contain errors that may lead to a misinterpretation and/or confusion of the sound with another one. This can be evaluated with a metric called the Pratt Index (Santos et al., 2004). All image analysis operations were performed in Matlab, version 7.0.1. The code used was specially implemented by one of the authors for use in this work. Exception is made for the live wire routine, developed by Chodorowski et al. (2005). We were able to obtain 2D contours, articulatory measures, area functions, quantification of the velum port opening, and 2D/3D visualizations of the vocal tract. To achieve these goals, the image analysis process included mainly: (1) 2D segmentation of the vocal tract, (2) 3D segmentation of the vocal tract and area extraction of the sections, and (3) computation of the velum port opening quotient (VPOQ). 3.1 2D corpus The 2D segmentations were made with the region growing method (Adams and Bischof, 1994). We started by manually placing a seed inside the vocal tract which expanded until it reaches the vocal tract wall. This expansion is based on grey level comparison between the mean grey level value of all the pixels already marked as inside the vocal tract and the neighbour pixels of the contour of the region already delimited. The stop criterion is based on a maximum difference threshold between the pixel being tested and the mean value of all the pixels assumed to belong to the region of interest. To assess reproducibility of the process, 100 contours were generated (each set takes about 35min with the current implementation) with a randomly placed seed inside the vocal tract, for each image. Each contour was compared with the mean contour (chosen as reference contour). Comparisons between contours were made with the Pratt Index (abbreviated as PI) (Santos et al., 2004), a distance between two contours defined by: PI = 1 N ∑ i = 1 N 1 1 + α d i 2 , where N is the number of corresponding points between contours, d i is the distance between two corresponding points, and α is related to the contour size. Based on one of the authors’ previous work on other types of images (Santos et al., 2004), α = 1 / 9 . Corresponding points between contours are obtained as follows: first contour with the smaller number of points is chosen; for each point of this contour, the closest point in the other contour is the correspondent point. This index has its range in the interval [0,1], where 1 means that the two contours are equal. The PI was also used to compare images of different sounds. In this case, we retained 101 PIs for each pair: the PI calculated between the two mean contours (resulting from the process described above) and the 100 PIs resulting from comparison of the contours corresponding to different seeds. As no order effect was anticipated, the 100 contours for each sound were compared with the contours of the other image by their order of calculation. Fig. 1 , presents, separately, the results obtained for oral vowels, nasal vowels and consonants, showing that the region growing segmentation method is robust to changes in the seed (low intra-variability). The corresponding PIs are close to 1, having as a minimum the value 0.84. Also interesting, for validating the process, is the comparison between the PIs calculated for the contours obtained for one sound (intra-variability) and the PIs obtained for different sounds (inter-variability). Fig. 2 presents these results. The 95 % confidence intervals (Sachs, 1984; Bryman and Cramer, 2001), calculated using SPSS, are: CI p [ 0.92 ⩽ Intra ⩽ 0.96 ] = 95 % for the intra-variability, and CI p [ 0.44 ⩽ Inter ⩽ 0.49 ] = 95 % for the inter-variability, resulting in a statistically significant difference between the variability due to the segmentation starting points and the differences due to different sounds. All 2D sagittal images were also manually marked with the following relevant points (Fig. 3 ): highest position of tongue dorsum (TD); tongue tip (TT); tongue root position at the C3–C4 vertebral level (TR); jaw height, using the root of lower incisors (JH); lower lip highest and most anterior position (LL); and upper lip lowest and most anterior position (UL). TR is the intersection with tongue contour of an horizontal line passing through C3–C4 level. Note that all TR measures have therefore the same vertical coordinate value and that the discrepancy observed in Fig. 7b is around 1mm and can be ascribed to the general process accuracy. We used as origin the lower left image point, and assumed that the speaker movement is not relevant. A different reference point could easily be chosen. 3.2 3D Corpus For the volumes, we first segmented the vocal tract in the midsagittal slice using the semiautomatic technique live wire (Chodorowski et al., 2005). Next a (fixed) gridline was applied and its intersections with the contour obtained. Middle points between the intersection in the two contour parts make our first approximation to the centerline. The centerline is then upsampled and smoothed. Then the volume was resliced according to a phoneme-adapted grid with planes oriented normally to the centerline. Each slice was also segmented using the live wire technique. We opted to use a number of slices similar to the used in other studies, 45 slices, covering all the oral tract. Although having a non-isotropic voxel, which is homogenized by a linear interpolation, we believe that with this method we will obtain more realistic data. The live wire segmentation approach is based on optimal search strategies over graphs built upon regional pixel maps defined on the neighbourhood of seed points determined by the user. This is a fully semiautomatic approach taking advantage of the unsurpassed human capacities for object recognition and delineation. Typically, the user starts segmentation by choosing an initial point (seed) on the boundary of the object of interest. Then, the algorithm computes the minimal cost path between the seed and the current position of a pointing device (mouse pointer). The criterion for minimal cost is often the integral of pixel intensities along a path. This minimal cost path is rendered continuously (the live wire paradigm) as a partial contour and if the user considers this partial contour as acceptable then he can proceed and define the next seed point. After a minimum set of seed points the boundary of the target object, not necessarily closed, should be completely delineated. Relying on the user pattern recognition capabilities, the live wire approach offers a sequence of locally optimal contours and it is often the segmentation technique of choice to deal with difficult images with diffuse targets and cluttered backgrounds. This segmentation technique was adopted due to its better performance in the lower image quality of the 3D resliced images, when compared with the region growing technique used for 2D Corpus. As can be observed in Fig. 4 , each resliced plane will have an orientation perpendicular to the centerline of the vocal tract. The bottom part of the vocal tract is usually easy to segment in these resliced planes, but some difficulties were found in the segmentation of the oral cavity. For validation purposes, a sample of the 3D segmentations was visually evaluated by two experts. Difficulties in observing larynx area, due to 3D aliasing, motivated the use of a reference point for our area functions at the basis of C5 vertebral body. Thus, in the obtained area functions, x-axis represents the distance from this reference level towards the lips, representing 0 the basis of C5 and not the larynx position. As the basis of C5 was marked separately from the process of area function determination, it is possible that area function started after this reference point. We also did not put much effort into improving segmentation of this lower part of the pharynx, not forcing the centerline to go as close as possible to the larynx position. We preferred to concentrate on the other parts of the area functions. However, this imprecision around glottis should be improved in the future, leading to more accurate area function lengths. The VPOQ was computed in a similar way to Engwall et al. (2006). In this method, we identified the first slice (from the glottis to the lips) where both the oral and nasal cavities can be seen. We then chose that slice and the next four and measured the area of the oral and nasal passages. Mean VPOQ was calculated as the mean of the quotients between the nasal and oral areas, for the five slices. In Fig. 5 the first oblique slice is shown (counting from the glottis to the lips) where both the oral and the nasal cavities are visible. 4 Results I: vowels We start this study with the analysis of the oral vowels. After we present our results for nasal vowels. At the end of the section a comparative study of nasal and oral vowels is also presented. 4.1 Oral vowels We present the MRI images with superimposed contours for the nine oral vowels in Fig. 6 . Vowels are arranged according to their phonetic description, high vowels at the top and posterior vowels to the right (in agreement with orientation of our images, with lips to the left). The corresponding articulatory measures (TD, TR, TT, JH, UL and LL) are presented in Fig. 7 . The area functions are presented, separately, in Fig. 8 . The following descriptions were based on all the information available, particularly in the parameters presented in Fig. 7. 4.1.1 Anterior oral vowels Regarding the tongue highest point (TD), [ε] is produced with the lowest position of TD; [i] with the most raised and anterior position; [e] in an intermediate position in both dimensions, being closer to [ε] in the anterior–posterior axis. Looking at the [i] and [e] area functions, Fig. 8, (corpus does not include 3D for [ε]) the point of smallest area is more anterior for [i], confirming TD parameter information. In the area functions it is possible to see that for [i] the constricted area is a few centimeters long while in [e] the obstruction zone is much more restricted. It has also been observed, that the most posterior tongue position (TR) is more anterior in [i] than in [ε], contributing to the increase of the pharyngeal cavity and the reduction of the oral cavity. The wide pharyngeal region for [i] is indeed clear on area functions. The JH is lower in [ε] and higher and more anterior in [i]. The TT vertical position increases from [ε] to [i], being [e] closer to the [i]. The distance between [e] and [ε] is almost twice the distance between [e] and [i]. In the horizontal direction differences are smaller: [i] and [ε] present very similar TT horizontal positions; [e] has a slightly posterior position. Regarding lip configuration, the results are different for the upper and lower lip. The three anterior vowels present quasi-identical UL parameter values. For lower lip (LL): [i] presents a higher position; protrusion (x-axis position) is not very different for the three vowels; differences are mainly in the vertical position, being [i]–[e] and [e]–[ε] distances similar. For each one of the three configurations, the velum is raised, not having a significative position alteration among the three vowels. In the region of the glottis there is no evidence, in the sagittal plan and for this speaker, of alterations between the three vowels. In terms of the similarity of contours, with the analysis of PI, [e] is closer to [i] (PI=0.76) than to [ε] (PI=0.72). Despite the very similar values of PI in both cases, non-parametric statistical tests (Mann–Whitney) confirm the difference as significative ( p < 0.001 ) . 4.1.2 Central oral vowels The vowel [ ] (high vowel) is produced with the tongue dorsum (TD) in the highest position inside of the series; followed by [ɐ] and [a] (low vowel). All three have similar x-coordinates for TD. Comparing with the anterior vowels, TD is always lower for central vowels. The highest value for central vowels (10.9) is clearly lower than the lowest position for anterior vowels (11.3). For this series of vowels, TD is not directly related with maximum constriction position, area function provides further insight. Our data show [a] as having its smallest area in the pharyngeal region. The tongue root (TR) is more anterior during the production of [ ] than of [ɐ] or [a]. [a] is also more posterior than all three anterior vowels. In terms of area function, major differences between [a] and [ɐ] are in the pharyngeal region. The jaw position (JH) is lower and posterior for [a] and higher and anterior for [ ]. There is an overlap of the opening values with anterior vowels. Nevertheless, [a] is produced with the lowest position in the combined anterior–central set of vowels. The tongue tip (TT) position follows the same pattern observed for TD, with a correlation between the points. The lower and upper lips positions can be considered as nearly similar for [ɐ] and [ ]. In [a], the lower lip is lower, around 7mm, and, also, more posterior (5mm). This may be related to mandibular position. From contours superimposition, not shown in this paper, the velum presents a more anterior position in the vowels [ɐ] and [ ] than in [a]. Non-parametric statistical tests (Mann–Whitney) showed: as non-significantly different the PIs obtained for the comparisons of [ɐ] with [ ] and [ɐ] with [a]; as significantly ( p < 0.001 ) higher the similarity of these two comparisons than similarity between [ ] and [a]. 4.1.3 Posterior oral vowels It can be observed in Figs. 6 and 7 that vowel [u] is produced with the highest TD position amongst the three posterior vowels, followed by [o] and [ɔ], with the lowest and more posterior position. Compared to anterior and central vowels, posterior vowels are produced with lower TD than the anterior series. Only [a] is produced with lower TD than the lowest posterior ([ɔ]), and only with 3mm difference. When compared with anterior vowels we observe that posterior vowels have, generally, lower TD position, except for [ε], which is slightly lower than [u]. Comparing posterior and central vowels, it can be observed that TD for [u] and [o] is higher than the value for the three central vowels. In the area functions, the point of maximum constriction follows the same tendency of TD parameter to lower from [u] to [ɔ], moving downward in the pharyngeal region. Tongue root position on sagittal images also confirms a more posterior position for [ɔ] than for [u] and [o]. The difference between [u] and [ɔ] is about 1cm. The tongue back position is closer to the velum in [u] and [o], while in [ɔ] is directed towards the pharyngeal wall. This dorsovelar orientation for [o] was an unexpected finding since this oral vowel is generally described as being produced with tongue back oriented towards the pharynx (e.g. Morais Barbosa, 1994, p. 53). From midsagittal profiles, corroborated from area functions values, an increase of oral cavity dimension from [u] to [ɔ] is evident, associated with a decrease of the pharyngeal cavity dimensions. Comparing TR positions for anterior and posterior vowels (Fig. 7b) we can observe a trend for anterior vowels to have more anterior TR positions, but with an overlap of the two classes (e.g. [ε] is more posterior than [o]). The jaw (JH) is lower in the production of [ɔ] than in the production of [o] and [u], these two vowels being produced with JH respectively 5mm and 8mm above. For tongue tip (TT) we notice a similarity between [u] and [o], both with TT more posterior and higher than [ɔ]. When comparing with the two previous series, in posterior vowels the range of values for TT is larger, both in the horizontal and vertical dimensions. While for central and anterior vowels TT has a maximum range of 0.4cm in the horizontal and 1.3cm for vertical, the ranges are 1.0cm and 1.8cm for posterior vowels. Also relevant to this series is the variation of lip position, particularly protrusion. Protrusion is important for [u] and [o]. For [ɔ], lower lip protrusion is smaller and similar to the highest value obtained in previous series (for [ ]). When compared with anterior and central vowels, the difference is marked, as expected, since in EP only posterior vowels are rounded. From the superimposition of contours (not included in the paper), it can be observed that the velum is in a lower position in the production of [ɔ] than in the other two posterior vowels. Area functions for [u] and [o] present a similar pattern, contrary to [ɔ]. Pattern differences are more pronounced at oral cavity level. Analyses of the PI, confirm this tendency, as PI between [u] and [o] mean contours is 0.77, being 0.73 between [o] and [ɔ], and 0.65 between [u] and [ɔ]. Statistical tests (Mann–Whitney) confirm as significantly higher the values of the PI for the pair [u] and [o] when compared with both other two pairs ( p < 0.001 ) . 4.2 Nasal vowels Fig. 9 show the images with superimposed contours and area functions for EP nasal vowels, complementing the information presented in Figs. 7 and 10. Based on these three figures, we can observe that: • Vowels [ĩ] and [e˜] are produced with the tongue (TD) in an anterior and raised position. • Vowel [ ɐ ˜ ] has a low TD position, occupying with [õ] the lowest TD positions measured for the five nasal vowels. • Vowels [õ] and [ũ] are more posterior in terms of TD. • The jaw position, in contrast with what happens in the production of the oral vowels, presents a more restricted range of variation. For the five nasal vowels, higher and lower JH measures differ of 0.7cm while for oral vowels the difference is more than the double, 1.5cm. • The velum is open for all nasal vowels, but its height is variable with the vowel. We will study these differences, below, using 3D information. • Labial protrusion is marked in the production of [ũ] and similar to the protrusion observed in the corresponding oral vowel ([u]). 4.2.1 Nasal vs. Oral vowels In this section comparisons between oral and nasal vowels are presented. They are based on the articulatory measures of Fig. 7, the superimposition of midsagittal contours for EP nasal vowels with their possible oral counterparts (Fig. 10 ) and area functions obtained from 3D acquisitions (Fig. 11 ). For mid and low nasal vowels two oral configurations are considered. With MRI 3D information we can, for the first time for EP, compare the area functions of oral and nasal vowels. Differences between two area functions were obtained as follows: both area functions were resampled at the same positions along the x-axis, resulting in two vectors with the same length; the difference is the result of subtracting the two vectors. The vowels [ĩ] and [i] present similar configurations, the nasal vowel being produced with a higher and posterior position of the tongue body and root when compared with the oral counterpart (Fig. 10a). The TD position is close for the two vowels, being (7.4cm, 11.7cm) for the oral and (7.7cm, 11.8cm) for the nasal (Fig. 7a). The nasal [ũ] is produced with a slightly posterior and lower TD than the oral counterpart [u] (Fig. 7a). Looking at Fig. 10b, comparison of [e], [ε] and [ e ˜ ], we can observe that the contours of the vowels [e] and [ e ˜ ] are closer (PI=0.86) than the contours of [ε] and [ e ˜ ] (PI=0.69). Specifically with respect to TD position, the nasal vowel [ e ˜ ] is produced with the highest TD (Fig. 7a), this difference being however more accentuated for [ε] than for [e]. The oral [e] and the nasal [ e ˜ ] present a similar pattern at pharynx level, which is not valid to [ε], more constricted than [ e ˜ ]. Differences at tongue tip level (TT) are small between [e] and [ e ˜ ] and more pronounced between [ε] and [ e ˜ ]. The velum although opened during the production of the nasal, seems to be in a higher position than in the other nasal vowels. This tendency is observable in contours superimposition not included in the paper. From 3D information (only relative to [e] and [ e ˜ ]), we confirmed that the nasal and the corresponding oral vowel [e], have a very similar pattern on area function. Analyzing Fig. 10c, we can detect some differences. The nasal vowel [ ɐ ˜ ] is produced with a TD in a higher position than for [ɐ] and [a]. In the anterior–posterior axis, [ ɐ ˜ ] has a TD more anterior than all three EP central oral vowels, in a position similar to anterior oral vowel [ε]. The tongue root (TR) is similar for [ ɐ ˜ ] and [ɐ] and more posterior for [a]. Observing Fig. 10d, we detected that, with respect to tongue height, the nasal vowel [õ] is produced between [o] and [ɔ]. In the tip/blade region, and looking at the TT parameter, the configuration of [õ] is closer to [o] than to [ɔ]. Regarding TR, [õ] is between [o] and [ɔ]. In these midsagittal images it is apparent that velum and uvula touch the tongue back during the production of back vowels [õ] and [ũ]. For the other nasal vowels this is not observed. Midsagittal distances in the pharyngeal cavity are different in nasal vowels and their oral counterparts. As an example, [ ɐ ˜ ] has a wider upper pharynx region relative to [ɐ]. During the production of EP oral and nasal vowels, there are not noticeable differences with respect to posterior wall of the pharynx. 4.2.2 VPOQ A particularly interesting parameter to study for the nasals is the VPOQ. The results obtained for EP are presented in Fig. 12 . We can observe that: • for this speaker, the average VPOQ is always higher in the nasal vowels than in the corresponding oral ones; • [ ɐ ˜ ] presents the highest VPOQ, followed by [ũ] and [õ]; • the largest oral/nasal VPOQ difference was observed in the pair [ɐ]/[ ɐ ˜ ]; • the smallest oral/nasal difference is between [u] and [ũ]. 5 Results II: consonants In this section, relative to consonantal sounds, we start with the description of the nasal consonants, to maintain continuity with the anterior section on nasal vowels. Next, stop consonants are briefly described as they are not generally considered as significantly different from other languages. They follow nasal consonants to allow a comparison between these two related classes. Then, we present results concerning fricatives, ending with a class with some EP particularities, the laterals. As the consonants depend on vocalic context, we are limited in the description of articulatory differences. Despite the use of similar vocalic context in the words used to instruct the speaker for the non-VCV parts of the corpus (in general an [a] follows the consonant), we avoided descriptions that could be more related to the production of the vowel than to the consonant we are studying. 5.1 Nasals In Fig. 13 midsagittal MRI images, contours and area functions for the EP nasal consonants are presented. In Fig. 14 a comparison between EP nasal and stop consonants contours is presented. In these images, the different places of articulation and the open position of the velum are clearly visible. The nasal [m] is produced with lip closure, [n] is produced with tongue tip occlusion at the superior incisors, and [ɲ] is clearly produced with tongue touching the hard palate. The tongue dorsum’s highest point (TD) is more anterior for [ɲ] being similar for [m] and [n]; higher, as expected, for [ɲ], followed by [n] and finally [m]. [ɲ] is only 1mm higher than [ĩ] and 2mm higher than [i], the highest vowel TD. The tongue tip (TT), involved in the articulation of [n] and affected in [ɲ] due to the overall raised tongue configuration, obviously presents very different positions. Looking at the contour comparisons for nasal consonants and stops with the same place of articulation, in Fig. 14, the main differences occur in the (upper) pharyngeal region with a more forward position of the tongue root for nasal consonants, associated with a lower position of the velum. EP stops have a narrower pharynx when compared with nasal consonants. This difference is more noticeable in the dentals ([n] vs [t]) than in the bilabials ([m] vs [p]). For the same place of articulation, nasal consonants present a more constricted larynx than stop consonants. VPOQ for nasal consonants was already included in Fig. 12. Nasal consonants present, on average (mean=0.75), intermediate values between the nasal vowels (mean=0.82) and oral vowels (mean=0.19). 5.2 Stops In Fig. 15 , left column, we can verify that in the production of [p] there is lip closure, as expected for a bilabial stop. In the production of [t] (although teeth contour is not visible) we see an approach of the tongue tip to the dental region. In the production of [k], the articulation point does not seem clearly velar, the constriction being in the transition between the palate and the velum. Also in Fig. 15, right column, we can observe that voiced stops present configurations that are close to the unvoiced, sharing the same articulation point. This was confirmed by contour superimposition and calculation of mean differences between contours and PIs, not included. For stops sharing the same place of articulation, the glottis is more constricted for voiced than for unvoiced cognates. Pharyngeal cavity, however, is larger in voiced when compared with unvoiced counterparts. For [p] the effect is observed through the entire pharynx, being for [t] and [k] differences more evident at oro-pharynx level. The effect of coarticulation for stops is evident. For [k] the differences are more significant in the tongue tip region, since this articulator is free for the production of the vowel. For [t], the region with less variation is the one close to the place of articulation (dental), while tongue back is affected by the production of the vowel. In [p], the tongue is free for the production of the vowel, since [p] has a bilabial articulation. 5.3 Fricatives The results for EP fricatives are presented in Fig. 16 . Despite the non-inclusion of the superior incisors in the images, we can infer, through the position of the lips, that the [f] is produced through the approximation of lower lip to the upper incisors (labiodental fricative). Despite the fact that they are quite similar, our results point to an alveolar place of constriction for [s] and [z], being fricatives [ʃ] and [ʒ] produced slightly posterior. The differences for TT horizontal position between these fricatives are of only 6mm, between [s] and [ʃ], and 4mm for the other pair. The [s] production involves the tongue blade while, [ʃ] presents an apical articulation. Other differences between [s] and [ʃ] are: [s] is produced with a slightly lower TD position; the back of the tongue is more posterior in the production of [s]. The same pattern and articulation places can be observed for [z] and [ʒ]. These facts were confirmed using the superimposition of [s,ʃ] and [z,ʒ] midsagittal contours (not included). Through the analysis of the contours (not included) and their PIs, we observed that differences in configuration, for the same place of articulation and vocalic context, are not significant (in the midsagittal plane) in the unvoiced–voiced pairs. However, at the glottis level, there is a higher constriction for voiced fricatives, as already observed for voiced stops. Regarding pharyngeal cavity, there is a tendency for voiced fricatives to have a larger pharynx, but being the difference less evident than for stops. We tested to see if our process was able to distinguish between the fricatives in three different VCV contexts, where V represents one of the vowels [a], [i], or [u]. The 2D results are presented in Fig. 17 and 3D results are shown in Fig. 18 . In Fig. 17, the effect of coarticulation is evident. In [f], a labiodental fricative, we observe differences both in tongue tip and tongue dorsum, the tongue being free for the production of the vowel. In [s], there are only differences in the posterior/back portion of the tongue. We do not observe the vowel effect on tongue tip or blade, used in the production of the consonant (apical alveolar). Relative to [ʃ], the effect of the vowel in the tongue is even less visible. This sound, when compared with others in this study, presents a higher resistance to coarticulation. For the voiced fricatives, the pattern of influence of the vowel in the production of the fricative consonant is similar to that observed for the unvoiced fricatives, being higher for the labiodental [v], smaller in the alveolar [z], and being [ʒ] production practically immune to the vowel effect. Comparing the area functions and the differences between two area functions (average and maximum values), in Fig. 18, coarticulatory effects are smaller for [ʃ]. About the two other unvoiced fricatives, the most affected regions are the pharyngeal region for [s] and the oral cavity for [f]. 5.4 Laterals The EP laterals, [l] and [ʎ], are shown in Fig. 19 . Figure presents 2D information for [ʎ] and the two variants of the l-sound: [l] as in [lasu] and [ɫ] as in [maɫ]. For 3D, a third context is also included, intervocalic position ([palɐ]). In Fig. 20 we compare the three area functions obtained for [l]. The first thing to note in Figs. 19 and 20 are the null areas in the area functions in the zone of partial occlusion. This is a result of the semiautomatic image processing, that was incapable of correctly segmenting the resliced images perpendicular to the centerline. Even with this limitation, 2D contours and area functions provide useful information on EP laterals. Comparing the midsagittal profiles of the lateral [l] and [ɫ], we can verify that the place of articulation is the same for both sounds, in the alveolar/dental region. This can be confirmed both in contour superimposition and at the first point with null area in the area functions, all presented in Fig. 19. It is clear that the active articulator is tongue tip for both sounds. Analyzing the area functions for [l] (Fig. 20), in the three contexts considered, we can observe a similar area variation pattern along the tract, without significant differences. We can report a constriction point beyond the lip region, corresponding to the alveolar area; upward in direction of the glottis an increase of area function is observed. This region corresponds to palatal area. A second constriction point is observed at uvular region, which is similar in the three positions. This second constriction is related with tongue dorsum raising. More detailed analyzes of tongue configurations on resliced coronal cuts, as in (Narayanan et al., 1997; Bangayan et al., 1996), are in progress. The [ʎ] is usually described as a palatal consonant. When compared with the palatal [ɲ], [ʎ] has its occlusion point more anterior. While in the area function the occlusion starts at 11.8cm for [ɲ] (Fig. 13), for [ʎ] occlusion starts at 15.0cm (Fig. 19). This points, at least for this speaker of EP, to a more palato-alveolar place of articulation for [ʎ]. It is produced with the tongue blade, the tongue dorsum not being in contact with the palate. 6 Discussion As our main objective is related to obtaining more data regarding EP production and not to exhaustively compare our results to published descriptions of EP, this discussion will not concentrate on pointing out all the agreements and disagreements between present work and EP common knowledge in articulatory phonetics. The availability of data for only one speaker also supports this option. 6.1 Corpus, MRI acquisition and image processing Our option to address as much as possible of EP sounds with only one speaker allowed us to cover, in a first study, what for other languages was produced incrementally. The existence of data regarding the several classes of EP sounds is particularly valuable to our work in articulatory synthesis. The disadvantage of only one speaker and the unique/reduced number of repetitions are, in our opinion, more than compensated by the advantages of the possibility of making direct comparison between different classes. This was particularly useful in the case of the comparative study of nasal vowels tract configuration relative to oral vowels; comparison of palatals [ɲ] and [ʎ] exact place of articulation and comparison of coarticulatory effects between stops and fricatives. With our option for the (semi)automatic processing, the use of a direct 3D acquisition was possible. As the acquired MRI data are in a volumic layout, image processing techniques were necessary and sufficient means to create the appropriate reformatted planes for further segmentation. This additional flexibility makes it possible to obtain data in planes defined after acquisition and tuned to the objectives of the analyses. Moreover, there was a gain in the acquisition time. With this, our speaker had a much easier task and overall acquisition time was substantially reduced. The choice for a trained speaker with vocal and singing practice also contributed positively to a faster and less error prone acquisition. Some points need however improvement in the acquisition: improvement on the larynx region, sometimes affected by aliasing problems, to allow a better characterization of this zone of the oral tract; improve overall quality of the coronal images for a better study of laterals. Semiautomatic image segmentation proved to be very useful and capable of attaining reproducible results. Nevertheless, there are areas where improvements are needed: segmentation of the images in the zone of partial obstruction for laterals (not completely successful in this first approach); addition to the images of the separately acquired information on speakers’ teeth. 6.2 Oral vowels One of the most relevant results obtained in this study, relative to EP oral vowels, is concerned with central vowels height. Contrary to traditional EP phonetic descriptions (e.g. Viana and Andrade, 1996), in which [ ] is considered as high as [i] (anterior) and [u] (posterior) high vowels, we found that [ ] has, in fact, the highest TD position among the central vowels, but not so high to be considered a high central vowel. Only looking at jaw height (JH) alone we could describe [ ] as a closed vowel, similar to [i]. From an articulatory view point, the differences between the three central vowels are mainly related with tongue dorsum position and shape, jaw height and pharyngeal cavity dimensions (particularly the upper part). Amongst the three central vowels the one that is produced with the highest TD position is the [ ], followed by [ɐ] and [a]. Pharyngeal cavity dimension is also high for [ ] as the tongue dorsum is more raised and advanced in the production of this vowel, when compared with the other central vowels. Important characteristics of [a] are the very low jaw, high lip aperture and posterior position of tongue (TD and TR). The last characteristic goes against its classic classification of [a] as a central vowel, being better described as a low pharyngeal vowel. The [ɐ] is more similar to [a] than [ ] in terms of tongue shape; has an intermediate jaw opening, and presents lip aperture similar to [ ]. The [ ] appears as distinctively different from the other two vowels in the upper pharyngeal region, not presenting the characteristic narrowing of the others. These articulatory differences and characteristics of each of the 3 central vowels can be useful in clarifying their descriptions, a point of discussion in EP Phonetics. However, it is hard to generalize as our data are limited to one speaker. The dorsovelar location of the maximum constriction for the posterior vowel [o] is not in agreement with the usual articulatory description (e.g. Morais Barbosa, 1994), reporting a pharyngeal location for the maximum constriction, as for [ɔ]. Obviously, due to corpus limitation to one speaker, we cannot clarify if this is a speaker characteristic, or a more general phenomenon. 6.3 Nasals As expected, differences between nasal and oral vowels do not only concern velum lowering, but also differences in the position of other articulators (Engwall et al., 2006). The 2D results show that, at least with this speaker of EP, [ ɐ ˜ ] is markedly higher than [a]; [õ] is produced with an articulatory configuration between [o] and [ɔ]; and [ĩ] and [ũ] are produced with a height similar to the oral counterparts. These results agree in general with the ones obtained using EMMA and acoustic inference from first formant values (Teixeira et al., 2003). When compared to French nasal vowels, some differences were detected, particularly at the pharyngeal cavity level. French nasal vowels seem to be produced with a more constricted pharyngeal region (Demolin et al., 1996; Demolin et al., 2003; Engwall et al., 2006; Delvaux et al., 2002). With the exception of [ ɐ ˜ ], a central vowel that presents the highest VPOQ, the posterior vowels ([ũ] and [õ]) have a slightly higher VPOQ than the anterior ones ([ĩ] and [ e ˜ ]). The oral area is always higher than the nasal for all the sounds contemplated in our study, which implies a VPOQ smaller than 1. Although the VPOQ is smaller in orals, in our measures it was always higher than zero due to the existence of a small passage to the nasal cavity even for the production of oral sounds. This is in agreement with the fact that nasal port opening is not sufficient to have a nasal sound. However, the VPOQ is an average value dependent of the sampling process, with possible failures in detecting nasal port closure. Comparing with recent results of (Engwall et al., 2006), we verify that: the average VPOQ follows, in general terms, a similar behaviour: superior in nasal vowels than in the correspondent orals; the VPOQ values for French are significantly higher than the obtained for EP, particularly for the nasal vowels. Relative to EP nasal consonants, the VPOQ results confirmed their relative position of velum aperture, between oral and nasal vowels. New 3D information contributed to validate previous work based on velum position only (Rossato et al., 2006; Teixeira et al., 2003). Also relevant is the close proximity of TD for [ɲ], [i] and [ĩ], consistent with the historic origin of the nasal consonant [ɲ]. 6.4 Stops and fricatives Another fact that also deserves to be mentioned is related to the place of articulation of the so-called “velar” stop [k]. Contrary to the classical descriptions of [k], we observe that [k], at least for this speaker of EP, was produced in the palatal area and does not seem to be dependent on the vocalic context. Although the place of articulation of velar stops could vary with context (Morais Barbosa, 1994), being more anterior when produced in the context of anterior vowels and more posterior in the context of back vowels, this is not observed in our study. In the different contexts studied, the place of articulation is always palatal, only with noticeable differences at tongue tip and blade level. In this area the effect of the vowel is clearly observed, the tip being more anterior in the context of [i] and more posterior in the context of [u]. Further studies are needed to clarify if this context independent point of constriction for [k] is (partially) related to the acquisition procedure, quite different from continuous speech. For fricatives, [ʃ,ʒ] have the point of maximum constriction produced with the tongue tip slightly posterior relative to [s,z], but, in our opinion and using (Ladefoged and Maddieson, 1996, p. 14) information on places of articulation, still in the alveolar region. This is not in accordance with what generally is described for [ʃ], as being produced by an approach of the tongue tip to the palato-alveolar or post-alveolar regions. A more detailed study of [ʃ] articulation point, using complementary techniques as EPG, should be considered. Relative to the stridents, a great similarity in the place of articulation for [s,z] and for [ʃ,ʒ] was evident, the most obvious difference being at the level of sub-laminal cavity which is larger for [ʃ] and [ʒ] than for [s] and [z]. This difference at the level of the sub-laminal cavity can be explained by the more apical articulation for [ʃ,ʒ], as the tongue tip is raised and slightly more posterior. These results are only partially in line with previous results reported for fricatives, but for a different language (Narayanan et al., 1995). The authors reported for [ʃ,ʒ] a high tendency for a laminal articulation rather than apical, and referred to a speaker dependent variability for [s,z] with respect to apical and laminal articulations. Our results regarding a more constricted glottis region together with a larger pharynx for voiced sounds are in line with what was reported by Narayanan et al. (1995), for fricatives: a tendency for larger pharyngeal areas for voiced sounds. This fact was also previously reported by Perkell (1969) for the sibilants [s] and [z] using X-ray techniques. This constriction at glottis level together with a larger pharynx might be explained by the necessity of having muscular adjustments and adequate pressure differences to produce phonation in voiced sounds. 6.5 Laterals In laterals, the differences between [l] and [ɫ] are not significant considering both 2D and 3D information. For American English, as reported by Narayanan et al. (1997) and Bangayan et al. (1996), there are differences in the back region for light and dark versions. For EP, we found /l/ velarization not only in syllable final position, as expected, but also in syllable initial position. EP area functions (for all the contexts considered for /l/) present a similar pattern in front and back regions, which means a second constriction point independent of position in the syllable (onset or coda). These facts point to the existence of only one positional allophone for /l/, a dark, which is in line with Andrade (1999) descriptions for EP: velarization occurs not only in syllable final position but also in initial position. This is also in agreement with older descriptions, see Strevens (1954) and Section 1.2. As far as [ʎ] is concerned, our results point to a more anterior place of articulation (alveolo-palatal) instead of palatal, which is not in line with EP most frequent descriptions, already referred to in the introduction. However, Sá Nogueira (1938) has already pointed to the possibility of this consonant having a more anterior place of articulation. Our finding is also in agreement with what was reported by Recasens and Espinosa (2006). These authors referred the fact that the lateral [ʎ] cannot be exclusively articulated in the palatal area. They pointed out that Romanic Languages also present a closure in the alveolo-palatal area, that could even be alveolar. When compared with the palatal [ɲ], it is evident a more anterior articulation point for [ʎ] and a “closure fronting decreasing in the progression [ʎ]>[ɲ]” as also reported by these authors Recasens and Espinosa (2006). 6.6 Coarticulation In general, EP stops are less resistant to coarticulatory effects than EP fricative. This is in agreement with the less constrained tongue body for stops, when compared to fricatives, reported for other languages by Farnetani (1999) and Recasens (1999). Comparing the labiodental fricative [f] with the bilabial stop [p] it is observed that the effect of the adjacent vowel is greater on the stop than on the fricative of the corresponding class. However, this difference is still sharper when we compare, by e.g., the alveolar fricative [z] with the dental stop [t]. In our study, concerning the tongue blade, for the stops [t,d] and the fricative [s] there is no significant effect of the vowel in this region, although the influence is evident in the production of the stops [k] and [g]. Recasens (1999) reports that the tongue region can present different articulatory behavior as a function of its evolvement in the production of a certain configuration. It is predicted that the blade must be more resistant to coarticulation during the production of alveolar consonants [t,d,s] than on the velar [k,g]. This is also verified in our study. Among all the sounds studied here, and not considering any articulator in particular, the sounds that have the highest resistance to coarticulation are [ʃ] and [ʒ]. This fact was already observed by Farnetani (1999) and can be connected with the complexity involved in the production of these sounds, Hardcastle (1976). Recasens et al. (1997) also refers to the fact that some sounds are more constrained than others. In accordance with Kiritani (1986), we can also consider the tongue-jaw system together. We verified that velar consonants [k] and [g] in [i] context present a more anterior position of tongue blade, but this anteriorization is not evident at jaw level. Tuller et al. (1981), also stated that the height of the jaw does not change in VCV context for [t] and [f], but suffers alterations due to the vowel in [p] and [k]. In our corpus, it was verified that for [t] there is no alteration in the height of the jaw, but this is seen in the production of [f]. 7 Conclusions In this paper we present new MRI data relative to the majority of the EP sounds. Both 2D and 3D MRI data are provided. In line with other studies in the field for other languages, we obtained volumetric MRI but using a different and faster acquisition technique. Unlike other studies in this field, we have used a semiautomatic segmentation method. MRI data obtained for one EP speaker, complemented by the utilization of imaging processing techniques and analyses, was determinant to improve our knowledge on EP oral and nasal sounds, laterals, fricatives and stops. With 2D MRI data, we compared oral and nasal vowels contours, leading to more detailed information than previously possible with other techniques such as EMMA. 3D information and area functions revealed very useful for palatal sounds [ɲ] and [ʎ], characteristic of EP. This is valuable information for evolution of articulatory synthesis of European Portuguese. Also, without claiming generalization due to the single speaker limitation of the data, some interesting findings were reported for palatal consonants, central vowels and laterals. It was possible to verify, for the EP, some facts related to coarticulation already reported for other languages. These results are also interesting due to the reduced use of MRI in coarticulation studies. 7.1 Future With this study, the capacities of MRI in providing useful information on speech production, particularly for EP or in general, is far from being exhausted. After this broad study, we consider as important the following possible continuations: • Perform a formal evaluation of 3D segmentation method, not yet performed due to time limitations; • Improve the area function computation regarding speed, accuracy in the laryngeal region, and taking in consideration the teeth. Only with an improved acquisition and segmentation of the tract near the larynx will be possible to solve the current limitations on area functions length and origin; • Process the nasal tract 3D acquisition to obtain nasal tract area function; • Complement the comparisons between nasal and oral vowels with real-time MRI information. Despite useful for the characterization of EP nasal vowels, the information available for this study suffers from two important limitations: only one speaker was recorded and the variation over time of vocal tract is not available. Real-time MRI, with adequate time resolution and from several speakers, is needed to reduce the remaining doubts regarding the nasal vowels tract configuration; • Conduct specific studies addressing a sound class or set of sounds in detail, with several repetitions and a reasonable number of speakers. This can be started by studying the EP laterals for which we had interesting results, needing more data to enable any generalization; • Repeat acquisition of the present corpus with more speakers. This is necessary to solve the speaker dependent nature of the reported results. Provision to include speakers from different dialects should be considered. With information regarding several speakers and the associated contours and area functions, a search for representative shape descriptors should be investigated; • Complement the study using real-time MRI. Real-time acquisition with a corpus mainly composed of nasal sounds and trills has already been carried out, but not yet fully analysed. In this preliminary and first approach we obtained a temporal resolution close to 200ms (5frames/s). We are particularly interested in improving temporal resolution and obtaining dynamic information on articulators movements, particularly for nasals, during actual production of EP words. Coarticulatory effects will greatly benefit from this line of research. Acknowledgements This work is part of project HERON (POSI/PLP/57680/2004), funded by FCT (Portuguese Research Agency). Authors thank Radiology Department, Coimbra University Hospital (HUC), particularly its Director Professor Filipe Caseiro Alves and its technical staff. We gratefully acknowledge the very important MRI technical support given by João Cunha Pires. We also thank our two speakers for their help and tolerance during the acquisition session. Our thanks to the three anonymous reviewers for their comments and suggestions, contributing to an overall improvement in the paper. References Adams and Bischof, 1994 R. Adams L. Bischof Seeded region growing IEEE Trans. Pattern Anal. Machine Intell. 16 6 1994 641 647 Alwan et al., 1997 A. Alwan S. Narayanan K. Haker Toward articulatory-acoustic models for liquid approximants based on MRI and EPG data. Part II. The rhotics J. Acoust. Soc. Amer. (JASA) 101 2 1997 1078 1089 Andrade, 1999 Andrade, A., 1999. On /l/ velarization in European Portuguese. In: Internat. Conf. of Phonetics (ICPhS), San Francisco. Badin et al., 1998 Badin, P., Bailly, G., Raybaudi, M., Segebarth, C., 1998. A three-dimensional linear articulatory model based on MRI data. In: 5th Internat. Conf. on Spoken Language Processing (ICSLP), pp. 417–420. Baer et al., 1991 T. Baer J.C. Gore L.C. Gracco P.W. Nye Analysis of vocal tract shape and dimensions using magnetic resonance imaging: vowels J. Acoust. Soc. Amer. (JASA) 90 2 1991 799 828 Bangayan et al., 1996 Bangayan, P., Alwan, A., Narayanan, S., 1996. From MRI and acoustic data to articulatory synthesis: a case study of the laterals. In: ICSLP, Philadelphia, pp. 793–796. Bryman and Cramer, 2001 A. Bryman D. Cramer Quantitative Data Analysis with SPSS Release 10 for Windows – A guide for Social Scientists 2001 Routledge Chodorowski et al., 2005 Chodorowski, A., Mattsson, U., Langille, M., Hamarneh, G., 2005. Color lesion boundary detection using live wire. In: SPIE. Cruz-Ferreira, 1999 Cruz-Ferreira, M., 1999. Portuguese (European). In: Handbook of the International Phonetic Association, The International Phonetic Association, Cambridge University Press, pp. 126–130. Dang and Honda, 1994 J. Dang K. Honda MRI measurements and acoustic of the nasal and paranasal cavities J. Acoust. Soc. Amer. (JASA) 94 3, Pt 2 1994 1765 Dang and Honda, 1996 Dang, J., Honda, K., 1996. An improved vocal tract model of vowel production implementing piriform resonance and transvelar nasal coupling. In: ICSLP. Dang et al., 1994 J. Dang K. Honda H. Suzuki Morphological and acoustical analysis of the nasal and the paranasal cavities J. Acoust. Soc. Amer. (JASA) 96 4 1994 2088 2100 Delvaux et al., 2002 Delvaux, V., Metens, T., Soquet, A., 2002. French nasal vowels: acoustic and articulatory properties. In: 7th Internat. Conf. on Spoken Language Processing (ICSLP), Vol. 1, Denver, pp. 53–56. Demolin et al., 1996 Demolin, D., George, M., Lecuit, V., Metens, T., Socquet, A., 1996. Détermination, par IRM, de l’ouverture au velum des voyelles nasales du Français. In: XXIémes Journées d’Etudes sur la Parole, Avignon, France, pp. 83–86. Demolin et al., 1996 Demolin, D., Metens, T., Soquet, A., 1996. Three-dimensional measurement of the vocal tract by MRI. In: 4th Internat. Conf. on Spoken Language Processing (ICSLP), Vol. 1, p. 272. Demolin et al., 1998 Demolin, D., Lecuit, V., Metens, T., Nazarian, B., Soquet, A., 1998. Magnetic resonance measurements of the velum port opening. In: 5th Internat. Conf. on Spoken Language Processing (ICSLP). Demolin et al., 2003 D. Demolin V. Delvaux T. Metens A. Soquet Determination of velum opening for French nasal vowels by magnetic resonance imaging J. Voice 17 4 2003 454 467 Engwall, 1999 Engwall, O., 1999. Modeling of the vocal tract in three dimensions. In: 6th Eur. Conf. on Speech Communication and Technology (Eurospeech), pp. 113–116. Engwall, 2002 Engwall, O., 2002. Tongue talking: studies in intraoral speech synthesis. Doctoral Thesis, KTH – Royal Institute of Technology. Engwall, 2003 Engwall, O., 2003. A revisit to the application of MRI to the analysis of speech production – testing our assumptions. In: 6th Seminar on Speech Production, pp. 43–48. Engwall and Badin, 1999 Engwall, O., Badin, P., 1999. Collecting and analysing two and three dimensional MRI data for Swedish, Speech Transmission Laboratory: Quarterly Progress and Status Report (STL-QPSR), pp. 11–38. Engwall and Badin, 2000 Engwall, O., Badin, P., 2000. An MRI study of Swedish fricatives: coarticulatory effects. In: 5th Seminar on Speech Production, Kloster Seeon, Germany, pp. 297–300. Engwall et al., 2006 Engwall, O., Delvaux, V., Metens, T., 2006. Interspeaker variation in the articulation of nasal vowels. In: 7th Internat. Seminar on Speech Production. Ericsdotter, 2005 Ericsdotter, C., 2005. Articulatory-acoustic relationships in Swedish vowel sounds, Doctoral dissertation, Stockholm University. Farnetani, 1999 E. Farnetani Coarticulation and connected speech processes W.J.H. Laver John The Handbook of Phonetic Sciences 1999 Blackwell Oxford 371 404 Gick et al., 2002 B. Gick A.M. Kang D.H. Whalen MRI evidence for commonality in the post-oral articulations of English vowels and liquids J. Phonetics 30 3 2002 357 371 Greenwood et al., 1992 Greenwood, A.R., Goodyear, C.C., Martin, P.A., 1992. Measurements of vocal tract shapes using magnetic resonance imaging. In: IEE Comm. Speech Vision, Vol. 139, pp. 553–560. Gregio, 2006 Gregio, F.N., 2006. Configuração do trato vocal supraglótico na produção das vogais do português brasileiro: dados de imagens de ressonância magnética, Dissertação de mestrado, Pontificia Universidade Católica de São Paulo. Hardcastle, 1976 W.J. Hardcastle Physiology of Speech Production: An Introduction for Speech Scientists 1976 Academic Press London Hardcastle and Hewlett, 1999 W. Hardcastle N. Hewlett Coarticulation: Theory, Data and Techniques 1999 Cambridge University Press Cambridge Hoole, 1993 P. Hoole Methodological considerations in the use of electromagnetic articulography in phonetic research FIPKM 31 1993 43 64 Hoole and Nguyen, 1999 P. Hoole N. Nguyen Electromagnetic articulography W. Hardcastle N. Hewlett Coarticulation: Theory, Data and Techniques 1999 Cambridge University Press Cambridge 260 269 Hoole et al., 2000 Hoole, P., Wismüller, A., Leinsinger, G., Kroos, C., Geumann, A., Inoue, M., 2000. Analysis of tongue configuration in multi-speaker, multi-volume MRI data. In: 5th Seminar on Speech Production, Kloster Seeon, Germany, pp. 157–160. International Phonetic Association, 1999 International Phonetic Association, 1999. Handbook of the International Phonetic Association: A Guide to the Use of the International Phonetic Alphabet. Cambridge University Press. Jackson, 2000 Jackson, P.J.B., 2000. Characterisation of plosive, fricative and aspiration components in speech production. Ph.D. Thesis, U. Southampton. Jesus and Shadle, 2002 L.M.T. Jesus C.H. Shadle A parametric study of the spectral characteristics of European Portuguese fricatives J. Phonetics 30 2002 437 464 Kim, 2004 H. Kim Stroboscopic-cine MRI data on Korean coronal plosives and affricates: implications for their place of articulation as alveolar Phonetica 61 4 2004 234 251 Kiritani, 1986 S. Kiritani X-ray microbeam method for measurement of articulatory dynamics-techniques and results Speech Comm. 5 2 1986 119 140 Kröger et al., 2000 Kröger, B.J., Winkler, R., Mooshammer, C., Pompino-Marschall, B., 2000. Estimation of vocal tract area function from magnetic resonance imaging: preliminary results. In: 5th Seminar on Speech Production, Kloster Seeon, Germany, pp. 333–336. Kühnert and Nolan, 1999 B. Kühnert F. Nolan The origins of coarticulation W.H. Hewlett Nigel Coarticulation: Theory, Data and Techniques 1999 Cambridge University Press Ladefoged and Maddieson, 1996 P. Ladefoged I. Maddieson The Sounds of the World’s Languages 1996 Blackwell Magen, 1997 H.S. Magen The extent of vowel-to-vowel coarticulation in English J. Phonetics 25 2 1997 187 205 Manuel, 1999 S. Manuel Cross-language studies: relating language-particular coarticulation patterns to other language-particular facts W.J.H. Hewlett Nigel Coarticulation: Theory Data and Techniques 1999 Cambridge University Press Cambridge 179 198 Chapter 8 Mathiak et al., 2000 K. Mathiak I. Hertrich W.E. Kincses U. Klose H. Ackermann W. Grodd Stroboscopic articulography using fast magnetic resonance imaging Internat. J. Lang. Comm. Disorders/Royal College Speech Lang. Therapists 35 3 2000 419 425 Mohammad et al., 1997 Mohammad, M., Moore, E., Carter, J.N., Shadle, C.H., Gunn, S.R., 1997. Using MRI to image the moving vocal tract during speech. In: 5th Eur. Conf. on Speech Communication and Technology (Eurospeech), Vol. 4, pp. 2027–2030. Morais Barbosa, 1994 A. Morais Barbosa Introdução ao Estudo da Fonologia e Morfologia do Português 1994 Almedina Coimbra Narayanan and Alwan, 1995 S. Narayanan A. Alwan A nonlinear dynamical systems analysis of fricative consonants J. Acoust. Soc. Amer. 97 1995 2511 2524 Narayanan and Alwan, 2000 S. Narayanan A. Alwan Noise source models for fricative consonants IEEE Trans. Speech Audio Process. 8 2 2000 328 344 Narayanan et al., 1995 S. Narayanan A. Alwan K. Haker An articulatory study of fricative consonants using MRI J. Acoust. Soc. Amer. (JASA) 98 3 1995 1325 1347 Narayanan et al., 1997 S. Narayanan A. Alwan K. Haker Toward articulatory-acoustic models for liquid approximants based on MRI and EPG data. Part I. The laterals J. Acoust. Soc. Amer. (JASA) 101 2 1997 1064 1077 Narayanan et al., 2004 S. Narayanan K. Nayak S. Lee D. Byrd An approach to real-time magnetic resonance imaging for speech production J. Acoust. Soc. Amer. (JASA) 115 4 2004 1771 1776 Perkell, 1969 J. Perkell Physiology of Speech Production: Results and Implications of a Quantitative Cineradiographic Study 1969 MIT Press Recasens, 1999 D. Recasens Lingual coarticulation W. Hardcastle N. Hewlett Coarticulation 1999 Cambridge University Press Cambridge Recasens and Espinosa, 2005 D. Recasens A. Espinosa Articulatory, positional and coarticulatory characteristics for clear /l/ and dark /l/: evidence from two catalan dialects J. Internat. Phonetic Assoc. 35 1 2005 1 25 Recasens and Espinosa, 2006 D. Recasens A. Espinosa Articulatory, positional and contextual characteristics of palatal consonants: evidence from Majorcan Catalan J. Phonetics 34 3 2006 295 318 Recasens et al., 1997 D. Recasens M.D. Pallarés J. Fontdevila A model of lingual coarticulation based on articulatory constraints J. Acoust. Soc. Amer. (JASA) 102 1997 544 561 Rossato et al., 2006 Rossato, S., Teixeira, A., Ferreira, L., 2006. Les nasales du Portugais et du Français: une étude comparative sur les données EMMA, in: XXVIes Journées détudes sur la parole, Dinard. Rua and Freitas, 2006 Rua, S., Freitas, D., 2006. Morphological dynamic study of human vocal tract. In: CompIMAGE – Computational Modelling of Objects Represented in Images: Fundamentals, Methods and Applications, Coimbra, Portugal. Sachs, 1984 L. Sachs Applied Statistics – A Handbook of Techniques second ed. 1984 Springer-Verlag Sá Nogueira, 1938 R. Sá Nogueira Elementos para um tratado de Fonética Portuguesa 1938 Impressa Nacional Lisbon Santos et al., 2004 B. Santos C. Ferreira J. Silva A. Silva L. Teixeira Quantitative evaluation of a pulmonary contour segmentation algorithm in X-ray computed tomography images Acad. Radiol. 11 8 2004 868 878 Serrurier and Badin, 2005 A. Serrurier P. Badin Towards a 3D articulatory model of the velum based on MRI and CT images ZAS Papers Linguist. 40 2005 195 211 Serrurier and Badin, 2005 Serrurier, A., Badin, P., 2005. A three-dimensional linear articulatory model of velum based on MRI data. In: Interspeech. Shadle et al., 1996 C.H. Shadle M. Tiede S. Masaki Y. Shimada I. Fujimoto An MRI Study of the Effects of Vowel Context on Fricatives Vol. 18 1996 Institute of Acoustics pp. 187–194 Shadle et al., 1999 Shadle, C.H., Mohammad, M., Carter, J.N., Jackson, P.J.B., 1999. Multi-planar dynamic magnetic resonance imaging: new tools for speech research. In: XIVth Internat. Congress of Phonetic Sciences (ICPhS), pp. 623–626. Stone, 1999 M. Stone Laboratory techniques for investigating speech articulation W.H. Laver John The Handbook of Phonetic Sciences 1999 Blackwell 11 32 Stone et al., 1997 Stone, M., Lundberg, A.J., Davis, E.P., Gullipalli, R., NessAiver, M., 1997. Three-dimensional coarticulatory strategies of tongue movement. In: 5th Eur. Conf. on Speech Communication and Technology (Eurospeech), pp. 1–31. Stone et al., 2001 M. Stone E.P. Davis A.S. Douglas M. NessAiver R. Gullipalli W.S. Levine A.J. Lundberg Modeling tongue surface contours from Cine-MRI images J. Speech Lang. Hear. Res. 44 2001 1026 1040 Story et al., 1996 B.H. Story I.R. Titze E.A. Hoffman Vocal tract area functions from magnetic resonance imaging J. Acoust. Soc. Amer. (JASA) 100 1 1996 537 554 Strevens, 1954 P. Strevens Some observations on the phonetics and pronunciation of modern Portuguese Rev. Laboratório Fonética Experimental Coimbra II 1954 5 29 Takemoto et al., 2004 H. Takemoto T. Kitamura H. Nishimoto K. Honda A method of tooth superimposition of MRI data for accurate measurement of vocal tract shape and dimensions Acoust. Sci. Technol. 25 6 2004 468 474 Teixeira and Vaz, 2001 Teixeira, A., Vaz, F., 2001. European Portuguese nasal vowels: an EMMA study. In: 7th Eur. Conf. on Speech Communication and Technology (EuroSpeech), Vol. 2, Scandinavia, pp. 1483–1486. Teixeira et al., 1999 Teixeira, A., Vaz, F., Príncipe, J.C., 1999. Influence of dynamics in the perceived naturalness of Portuguese nasal vowels. In: ICPhS, pp. 2557–2560. Teixeira et al., 2003 Teixeira, A., Castro Moutinho, L., Coimbra, R.L., 2003. Production, acoustic and perceptual studies on European Portuguese nasal vowels height. In: Internat. Congress Phonetic Sciences (ICPhS), pp. 3033–3036. Teixeira et al., 2005 A. Teixeira R. Martinez L.N. Silva L.M.T. Jesus J.C. Príncipe F. Vaz Simulation of human speech production applied to the study and synthesis of European Portuguese EURASIP J. Appl. Signal Process. 2005 9 2005 1435 1448 Tiede, 1996 M. Tiede An MRI-based study of pharyngeal volume contrasts in Akan and English J. Phonetics 24 4 1996 399 421 Tiede et al., 2000 Tiede, M., Masaki, S., Vatikiotis-Bateson, E., 2000. Contrasts in speech articulation observed in sitting and supine conditions. In: 5th Seminar on Speech Production, Kloster Seeon, Germany, pp. 25–28. Tuller et al., 1981 E. Tuller K.S. Harris R. Gross Electromyographic study of the jaw muscles during speech J. Phonetics 9 1981 175 188 Viana and Andrade, 1996 M.d.C. Viana A. Andrade Fonética I. Faria E. Pedro I. Duarte C. Gouveia Introdução à Linguística Geral e Portuguesa 1996 Caminho Lisbon 113 167 West, 2000 West, P., 2000. Long-distance coarticulatory effects of British English /l/ and /r/: an EMA, EPG and acoustic study. In: Speech Production Seminar, Seeon, Germany, pp. 105–108. Yang, 1999 Yang, B., 1999. Measurement and synthesis of the vocal tract of Korean monophthongs by MRI. In: XIVth Internat. Congress of Phonetic Sciences (ICPhS), pp. 2005–2008. "
    },
    {
        "doc_title": "Serial volumetric registration of pulmonary CT studies",
        "doc_scopus_id": "44349121638",
        "doc_doi": "10.1117/12.769771",
        "doc_eid": "2-s2.0-44349121638",
        "doc_date": "2008-06-02",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Electronic, Optical and Magnetic Materials",
                "area_abbreviation": "MATE",
                "area_code": "2504"
            },
            {
                "area_name": "Atomic and Molecular Physics, and Optics",
                "area_abbreviation": "PHYS",
                "area_code": "3107"
            },
            {
                "area_name": "Biomaterials",
                "area_abbreviation": "MATE",
                "area_code": "2502"
            },
            {
                "area_name": "Radiology, Nuclear Medicine and Imaging",
                "area_abbreviation": "MEDI",
                "area_code": "2741"
            }
        ],
        "doc_keywords": [
            "Lung imaging",
            "Oncological pathology",
            "Pathologic changes",
            "Spatial resolution"
        ],
        "doc_abstract": "Detailed morphological analysis of pulmonary structures and tissue, provided by modern CT scanners, is of utmost importance as in the case of oncological applications both for diagnosis, treatment, and follow-up. In this case, a patient may go through several tomographic studies throughout a period of time originating volumetric sets of image data that must be appropriately registered in order to track suspicious radiological findings. The structures or regions of interest may change their position or shape in CT exams acquired at different moments, due to postural, physiologic or pathologic changes, so, the exams should be registered before any follow-up information can be extracted. Postural mismatching throughout time is practically impossible to avoid being particularly evident when imaging is performed at the limiting spatial resolution. In this paper, we propose a method for intra-patient registration of pulmonary CT studies, to assist in the management of the oncological pathology. Our method takes advantage of prior segmentation work. In the first step, the pulmonary segmentation is performed where trachea and main bronchi are identified. Then, the registration method proceeds with a longitudinal alignment based on morphological features of the lungs, such as the position of the carina, the pulmonary areas, the centers of mass and the pulmonary trans-axial principal axis. The final step corresponds to the trans-axial registration of the corresponding pulmonary masked regions. This is accomplished by a pairwise sectional registration process driven by an iterative search of the affine transformation parameters leading to optimal similarity metrics. Results with several cases of intra-patient, intra-modality registration, up to 7 time points, show that this method provides accurate registration which is needed for quantitative tracking of lesions and the development of image fusion strategies that may effectively assist the follow-up process.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Brokerage mechanism proposal for teleradiology studies distribution",
        "doc_scopus_id": "42949109165",
        "doc_doi": "10.1117/12.770753",
        "doc_eid": "2-s2.0-42949109165",
        "doc_date": "2008-05-07",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Electronic, Optical and Magnetic Materials",
                "area_abbreviation": "MATE",
                "area_code": "2504"
            },
            {
                "area_name": "Atomic and Molecular Physics, and Optics",
                "area_abbreviation": "PHYS",
                "area_code": "3107"
            },
            {
                "area_name": "Biomaterials",
                "area_abbreviation": "MATE",
                "area_code": "2502"
            },
            {
                "area_name": "Radiology, Nuclear Medicine and Imaging",
                "area_abbreviation": "MEDI",
                "area_code": "2741"
            }
        ],
        "doc_keywords": [
            "Teleradiology",
            "Workflow optimization"
        ],
        "doc_abstract": "The asymmetric distribution of PACS equipment and service providers across countries leads typically to the need to hire third party service professionals outside the institutions where the exams were made. In this paper we present a brokerage mechanism that puts customers and remote providers together in a seamless way. The proposed solution, asserted with a case study for the Portuguese national health system, addresses the problems that now impair the optimal provision of those services, enabling a more agile relationship between buyers and sellers, optimizing administrative work and complying with clinical and legal requirements under discussion in the European Union for the free movement of patients and professional health workers. In this document, the detailed process and technical description of the broker functioning is made, and the main benefits for the participants are also evaluated from a technical and economical point of view. Finally, in the discussion chapter, an assessment of the creation of a spot market for imaging studies is made and the integration with other similar markets is discussed.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "NUFFT-based Direct Fourier methods and regional tomography",
        "doc_scopus_id": "84898855586",
        "doc_doi": null,
        "doc_eid": "2-s2.0-84898855586",
        "doc_date": "2008-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Computer Networks and Communications",
                "area_abbreviation": "COMP",
                "area_code": "1705"
            },
            {
                "area_name": "Computer Science Applications",
                "area_abbreviation": "COMP",
                "area_code": "1706"
            }
        ],
        "doc_keywords": [
            "Direct Fourier methods",
            "Filtered back-projection",
            "Filtered back-projection methods",
            "Fourier transformations",
            "Low computational complexity",
            "Non-uniform fast Fourier transforms",
            "Regional reconstruction",
            "X-ray computed tomography"
        ],
        "doc_abstract": "Direct Fourier methods, a class of reconstruction methods suitable for 2D reconstruction in x-ray Computed Tomography, have been known for the low computational complexity (O(N2logN) compared to the O(N3) of the commonly used Filtered Backprojection method), but also for the lack of flexibility, difficult extension to projection geometries other than the parallel and poor image quality. The bad performance of these methods was essentially due to the need for interpolation in Fourier domain prior to inverse Fourier transformation on a certain step of the algorithm. With the introduction of efficient computational methods for the calculation of Fourier transform in the case of nonequally spaced samples (Non-Uniform Fast Fourier Transform - NUFFT), a number of Direct Fourier algorithms have been proposed with no need for interpolation in Fourier domain. It has been shown that these new algorithms allow to improve image quality while keeping the computational complexity to O(N2logN). The quality of the resulting images is equivalent to the quality of the images obtained by Filtered Backprojection. In this paper we'll show that the introduction of NUFFT also allows to perform regional reconstruction, a feature that was considered exclusive of Filtered Bacjprojection method. A NUFFT-based Direct Fourier regional reconstruction algorithm will be described and the results will be compared with those obtained by Filtered Backprojection.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Web platform to support the share and remote access to medical images",
        "doc_scopus_id": "67650261376",
        "doc_doi": null,
        "doc_eid": "2-s2.0-67650261376",
        "doc_date": "2007-12-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Information Systems",
                "area_abbreviation": "COMP",
                "area_code": "1710"
            }
        ],
        "doc_keywords": [
            "DICOM",
            "Image network",
            "Medical images",
            "PACS",
            "WADO"
        ],
        "doc_abstract": "The production of digital medical images has been growing in every healthcare institution, representing nowadays one the most valuable tools supporting the medical decision process and treatment procedures. One of the most important advantages of these digital systems is to simplifr the widespread sharing and remote access of medical data between healthcare institutions. However, due to security and performance issues, the usage of these software packages has been restricted to Intranets. In general, the storage and transmission of digital medical image is based on the international DICOM standard and PACS systems. This paper analyses the traditional PACS communication limitations that contribute to their reduced usage in the Internet. It is also proposed an architecture, based on Webservices and encapsulation of DICOM objects in HTTP, to enable trans-institutional medical data transfers.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "An MRI study of European Portuguese nasals",
        "doc_scopus_id": "56149084721",
        "doc_doi": null,
        "doc_eid": "2-s2.0-56149084721",
        "doc_date": "2007-12-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Computer Science Applications",
                "area_abbreviation": "COMP",
                "area_code": "1706"
            },
            {
                "area_name": "Software",
                "area_abbreviation": "COMP",
                "area_code": "1712"
            },
            {
                "area_name": "Modeling and Simulation",
                "area_abbreviation": "MATH",
                "area_code": "2611"
            },
            {
                "area_name": "Linguistics and Language",
                "area_abbreviation": "SOCI",
                "area_code": "3310"
            },
            {
                "area_name": "Communication",
                "area_abbreviation": "SOCI",
                "area_code": "3315"
            }
        ],
        "doc_keywords": [
            "3d analyses",
            "Dynamic informations",
            "European portuguese",
            "Europeans",
            "MRI",
            "Nasal vowels",
            "Nasals",
            "Research teams"
        ],
        "doc_abstract": "In this work we present a recently acquired MRI database for European Portuguese. As a first example of possible studies, we present results on 2D and 3D analyses of European Portuguese nasals, particularly nasal vowels. This database will enable the extraction of 2D and/or 3D articulatory parameters as well as some dynamic information to include in articulatory synthesizers. It can also be useful to compare the production of European Portuguese with the production of other languages and have further insight on some of the European Portuguese characteristics, as the nasalization and coarticulation. The MRI database and related studies were made possible by the interdisciplinary nature of the research team, comprised of a radiologist, image processing specialists and a speech scientist.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Breast cancer diagnosis based on a suitable combination of deformable models and artificial neural networks techniques",
        "doc_scopus_id": "38549181889",
        "doc_doi": null,
        "doc_eid": "2-s2.0-38549181889",
        "doc_date": "2007-12-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Architectural distortions",
            "Breast cancer",
            "Deformable models"
        ],
        "doc_abstract": "According to the World Health Organization (WHO) breast cancer is the most common cancer suffered by women in the world, which during the last two decades has increased the women mortality in developing countries. Mammography is the best method used for screening; it is a test producing no inconvenience and with small diagnostic doubts of breast cancer since the preclinical phase. For this reason, unfailing Computer-Aided Diagnosis systems for automated detection/classification of abnormalities are very useful and helpful to medical personnel. In this work is proposed a novel method that combines deformable models and Artificial Neural Networks among others techniques to diagnose diverse mammography abnormalities (calcifications, well-defined / circumscribed masses, spiculated masses, ill-defined masses, architectural distortions and asymmetries) as benign or malignant. The proposed algorithm was validated on the Mammographic Image Analysis Society (MiniMIAS) database in a dataset formed by 100 mammography images, which were selected randomly. © Springer-Verlag Berlin Heidelberg 2007.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Current perspectives on PACS and a cardiology case study",
        "doc_scopus_id": "34250214449",
        "doc_doi": "10.1007/978-3-540-72375-2_5",
        "doc_eid": "2-s2.0-34250214449",
        "doc_date": "2007-06-18",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            }
        ],
        "doc_keywords": [],
        "doc_abstract": "Since the first experiments on digital medical imaging, Pictures Archiving and Communication Systems (PACS) have been gaining acceptance along healthcare practitioners. PACS based infrastructures are currently being driven by powerful medical applications that rely completely on the seamless access to images' databases and related metadata. New and demanding applications such as study co-registration and content based retrieval are already driving PACS into new prominent roles. In this chapter we will revise the major key factors that have promoted this technology. We will then present our own solution for a Web-based PACS and the results achieved by its use on a Cardiology Department. We will finally consider future applications that are pushing developmental research in this field. © 2007 Springer-Verlag Berlin Heidelberg.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "A demanding Web-based PACS supported by Web Services technology",
        "doc_scopus_id": "33745410012",
        "doc_doi": "10.1117/12.653935",
        "doc_eid": "2-s2.0-33745410012",
        "doc_date": "2006-06-30",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Electronic, Optical and Magnetic Materials",
                "area_abbreviation": "MATE",
                "area_code": "2504"
            },
            {
                "area_name": "Atomic and Molecular Physics, and Optics",
                "area_abbreviation": "PHYS",
                "area_code": "3107"
            },
            {
                "area_name": "Biomaterials",
                "area_abbreviation": "MATE",
                "area_code": "2502"
            },
            {
                "area_name": "Radiology, Nuclear Medicine and Imaging",
                "area_abbreviation": "MEDI",
                "area_code": "2741"
            }
        ],
        "doc_keywords": [
            "DICOM",
            "Encoding syntax",
            "PACS",
            "Web Services technology"
        ],
        "doc_abstract": "During the last years, the ubiquity of web interfaces have pushed practically all PACS suppliers to develop client applications in which clinical practitioners can receive and analyze medical images, using conventional personal computers and Web browsers. However, due to security and performance issues, the utilization of these software packages has been restricted to Intranets. Paradigmatically, one of the most important advantages of digital image systems is to simplify the widespread sharing and remote access of medical data between healthcare institutions. This paper analyses the traditional PACS drawbacks that contribute to their reduced usage in the Internet and describes a PACS based on Web Services technology that supports a customized DICOM encoding syntax and a specific compression scheme providing all historical patient data in a unique Web interface.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "A volumetric pulmonary CT segmentation method with applications in emphysema assessment",
        "doc_scopus_id": "33745401842",
        "doc_doi": "10.1117/12.652622",
        "doc_eid": "2-s2.0-33745401842",
        "doc_date": "2006-06-30",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Electronic, Optical and Magnetic Materials",
                "area_abbreviation": "MATE",
                "area_code": "2504"
            },
            {
                "area_name": "Biomaterials",
                "area_abbreviation": "MATE",
                "area_code": "2502"
            },
            {
                "area_name": "Atomic and Molecular Physics, and Optics",
                "area_abbreviation": "PHYS",
                "area_code": "3107"
            },
            {
                "area_name": "Radiology, Nuclear Medicine and Imaging",
                "area_abbreviation": "MEDI",
                "area_code": "2741"
            }
        ],
        "doc_keywords": [
            "3D lung surfaces",
            "Emphysema Assessment",
            "Medical Image Analysis",
            "Volumetric Pulmonary Segmentation"
        ],
        "doc_abstract": "A segmentation method is a mandatory pre-processing step in many automated or semi-automated analysis tasks such as region identification and densitometric analysis, or even for 3D visualization purposes. In this work we present a fully automated volumetric pulmonary segmentation algorithm based on intensity discrimination and morphologic procedures. Our method first identifies the trachea as well as primary bronchi and then the pulmonary region is identified by applying a threshold and morphologic operations. When both lungs are in contact, additional procedures are performed to obtain two separated lung volumes. To evaluate the performance of the method, we compared contours extracted from 3D lung surfaces with reference contours, using several figures of merit. Results show that the worst case generally occurs at the middle sections of high resolution CT exams, due the presence of aerial and vascular structures. Nevertheless, the average error is inferior to the average error associated with radiologist inter-observer variability, which suggests that our method produces lung contours similar to those drawn by radiologists. The information created by our segmentation algorithm is used by an identification and representation method in pulmonary emphysema that also classifies emphysema according to its severity degree. Two clinically proved thresholds are applied which identify regions with severe emphysema, and with highly severe emphysema. Based on this thresholding strategy, an application for volumetric emphysema assessment was developed offering new display paradigms concerning the visualization of classification results. This framework is easily extendable to accommodate other classifiers namely those related with texture based segmentation as it is often the case with interstitial diseases.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Development of a new index to evaluate zooplanktons' gonads: An approach based on a suitable combination of deformable models",
        "doc_scopus_id": "33745336559",
        "doc_doi": "10.1007/11578079_52",
        "doc_eid": "2-s2.0-33745336559",
        "doc_date": "2005-12-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Biological samples",
            "Gonadic masses",
            "Histochemical evaluation",
            "Nucleus contours"
        ],
        "doc_abstract": "Acartia tonsa was used as model to establish an index for oocyte maturity determination in zooplankters based in citometry and histochemical evaluation of gonadic masses. Biometry was performed using an ocular micrometer and nucleus/cytoplasm ratios were obtained characterizing each of the three identified stages: Immature, Vitellogenic and Mature. This paper presents a novel approach since it joins (and, indeed, reinforces) the index framework with the evaluation of the same biological samples by a suitable combination of deformable models. Nucleus contour is identified through Active Shape Models techniques, and cytoplasm contour's detected through parametric Snakes, with prior image preprocessing based on statistical and mathematical morphology techniques. Morphometric parameters such as nucleus and cytoplasm area and ratio between them are then easily computed. As a result the dataset validated the applied methodology with a realistic background and a new, more accurate and ecologically realistic index for oocyte staging emerged. © Springer-Verlag Berlin Heidelberg 2005.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "E-services in mission-critical organizations: Identification enforcement",
        "doc_scopus_id": "8444230475",
        "doc_doi": null,
        "doc_eid": "2-s2.0-8444230475",
        "doc_date": "2004-11-23",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Engineering (all)",
                "area_abbreviation": "ENGI",
                "area_code": "2200"
            }
        ],
        "doc_keywords": [
            "Authentication and identification",
            "Digital credentials",
            "E-sevices security",
            "Intranet scenarios"
        ],
        "doc_abstract": "The increasing dependency of enterprise on IT has rise up major concerns on security technology and procedures. Access control mechanisms, which are the core of most security policies, are mostly based on PIN and, some times, in Public Key Cryptography (PKC). Despite these techniques can be already broadly disseminated, the storage and retrieval of security secrets is yet a sensitive and open issue for organization and users. One possible solution can be provided by the utilization of smart cards to store digital certificates and private keys. However, there are special organizations where even this solution does not solve the security problems. When users deal with sensible data and it is mandatory to prevent the delegation of access privileges to third persons new solutions must be provided. In this case the access to the secrets can be enforced by a three-factor scheme: the possession of the token, the knowledge of a PIN code and the fingerprint validation. This paper presents a Professional Information Card system that dynamically combines biometrics with PKC technology to assure a stronger authentication that can be used indistinctly in Internet and Intranet scenarios. The system was designed to fulfill current mission-critical enterprises access control requirements, and was deployed, as a proof of concept, in a Healthcare Information System of a major Portuguese Hospital.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Efficient NUFFT-based Direct Fourier algorithm for fan beam CT reconstruction",
        "doc_scopus_id": "5644255955",
        "doc_doi": "10.1117/12.534189",
        "doc_eid": "2-s2.0-5644255955",
        "doc_date": "2004-10-27",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Electronic, Optical and Magnetic Materials",
                "area_abbreviation": "MATE",
                "area_code": "2504"
            },
            {
                "area_name": "Condensed Matter Physics",
                "area_abbreviation": "PHYS",
                "area_code": "3104"
            },
            {
                "area_name": "Computer Science Applications",
                "area_abbreviation": "COMP",
                "area_code": "1706"
            },
            {
                "area_name": "Applied Mathematics",
                "area_abbreviation": "MATH",
                "area_code": "2604"
            },
            {
                "area_name": "Electrical and Electronic Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2208"
            }
        ],
        "doc_keywords": [
            "Direct Fourier methods",
            "Fan-beam projections",
            "Linogram",
            "NUFFT",
            "Rebinning",
            "Sinogram",
            "Tomographic reconstruction algorithms"
        ],
        "doc_abstract": "Related to the demand for fast and efficient tomographic reconstruction methods, the interest for Direct Fourier (DF) methods, which have a reduced computational complexity, has been growing. In this paper we present a new NUFFT-based DF reconstruction method which can be directly applied to fan-beam CT data sets avoiding the interpolation in Radon space as well as the interpolation in Fourier space. The performance of the new algorithm, in ideal and noisy conditions, is compared to those of other well known reconstruction methods, revealing an excellent behavior, specially in noisy conditions.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Quantitative evaluation of a pulmonary contour segmentation algorithm in x-ray computed tomography images",
        "doc_scopus_id": "3442887729",
        "doc_doi": "10.1016/j.acra.2004.05.004",
        "doc_eid": "2-s2.0-3442887729",
        "doc_date": "2004-08-01",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Radiology, Nuclear Medicine and Imaging",
                "area_abbreviation": "MEDI",
                "area_code": "2741"
            }
        ],
        "doc_keywords": [],
        "doc_abstract": "Rationale and objectives Pulmonary contour extraction from thoracic x-ray computed tomography images is a mandatory preprocessing step in many automated or semiautomated analysis tasks. This study was conducted to quantitatively assess the performance of a method for pulmonary contour extraction and region identification. Materials and methods The automatically extracted contours were statistically compared with manually drawn pulmonary contours detected by six radiologists on a set of 30 images. Exploratory data analysis, nonparametric statistical tests, and multivariate analysis were used, on the data obtained using several figures of merit, to perform a study of the interobserver variability among the six radiologists and the contour extraction method. The intraobserver variability of two human observers was also studied. Results In addition to a strong consistency among all of the quality indexes used, a wider interobserver variability was found among the radiologists than the variability of the contour extraction method when compared with each radiologist. The extraction method exhibits a similar behavior (as a pulmonary contour detector), to the six radiologists, for the used image set. Conclusion As an overall result of the application of this evaluation methodology, the consistency and accuracy of the contour extraction method was confirmed to be adequate for most of the quantitative requirements of radiologists. This evaluation methodology could be applied to other scenarios. © AUR, 2004.",
        "available": true,
        "clean_text": "serial JL 272938 291210 291703 31 Academic Radiology ACADEMICRADIOLOGY 2004-07-28 2004-07-28 2010-11-13T22:12:05 S1076-6332(04)00281-8 S1076633204002818 10.1016/j.acra.2004.05.004 S300 S300.2 FULL-TEXT 2015-05-15T05:02:15.579713-04:00 0 0 20040801 20040831 2004 2004-07-28T00:00:00Z articleinfo crossmark dco dateupdated tomb dateloaded datesearch indexeddate issuelist volumelist yearnav articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright dateloadedtxt docsubtype doctype doi eid ewtransactionid hubeid issfirst issn issnnorm itemstage itemtransactionid itemweight openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sortorder srctitle srctitlenorm srctype subheadings volfirst volissue figure table body acknowledge affil articletitle auth authfirstini authfull authkeywords authlast doctopic primabst pubtype ref alllist content subj ssids 1076-6332 10766332 11 11 8 8 Volume 11, Issue 8 10 868 878 868 878 200408 August 2004 2004-08-01 2004-08-31 2004 converted-article fla Copyright © 2004 AUR. Published by Elsevier Inc. All rights reserved. QUANTITATIVEEVALUATIONAPULMONARYCONTOURSEGMENTATIONALGORITHMINXRAYCOMPUTEDTOMOGRAPHYIMAGES1 SOUSASANTOS B Materials and methods Quality assessment strategies Quantitative evaluation of the performance Interobserver variability Intraobserver variability Test dataset Hand-outlined contours References contour obtained from the hand-drawn contours Comparing contours Figures of merit Statistical methods Results Study of the interobserver and intraobserver variability involving our algorithm and two expert radiologists Study of the interobserver variability through direct comparison among the algorithm and six expert radiologists Study of the interobserver variability using a reference contour Conclusions Acknowledgements References ROBB 2003 756 760 W BRINK 1994 887 893 J LI 2003 255 265 B BROWN 1997 828 839 M SONKA 1996 314 326 M DURYEA 1995 183 191 J PARKER 1980 291 295 R PROCEEDINGSPHYSICALASPECTSMEDICALIMAGING MEASUREMENTBASICCTDATA HU 2001 490 498 S HASEGAWA 1998 241 250 A SILVA 2000 583 598 J PROCEEDINGSVIBEROAMERICANSYMPOSIUMPATTERNRECOGNITIONSIARP2000 LUNGSEGMENTATIONMETHODSINXRAYCTIMAGES SILVA 2001 216 224 A SPIEMEDICALIMAGING2001 FASTPULMONARYCONTOUREXTRACTIONINXRAYCTIMAGES CHALANA 1997 642 652 V BOWYER 1999 567 606 K HANDBOOKMEDICALIMAGINGVOL2MEDICALIMAGEPROCESSINGANALYSISCAPX VALIDATIONMEDICALIMAGEANALYSISTECHNIQUES BLAKE 1998 A ACTIVECONTOURS GUNN 1997 63 68 S KASS 1988 321 331 M LIANG 1999 933 940 J INTERNATIONALCONFERENCECOMPUTERVISIONVOLUME2SEPTEMBER2025 UNITEDSNAKES YEZZI 1997 199 209 A SIVARAMAKRISHNA 2001 250 256 R FERREIRA 2003 347 358 C SPIEMEDICALIMAGING2003 COMPARISONASEGMENTATIONALGORITHMSIXEXPERTIMAGIOLOGISTSINDETECTINGPULMONARYCONTOURSXRAYCTIMAGES WAGNER 2003 213 224 R SPIEMEDICALIMAGING2003 CONTEMPORARYISSUESFOREXPERIMENTALDESIGNINASSESSMENTMEDICALIMAGINGCOMPUTERASSISTSYSTEMS ALTMAN 1999 D PRACTICALSTATISTICSFORMEDICALRESEARCH ABDOU 1979 753 763 I SACHS 1984 L APPLIEDSTATISTICSAHANDBOOKTECHNIQUES HOAGLIN 1983 D UNDERSTANDINGROBUSTEXPLORATORYDATAANALYSIS 1999 STATSOFTSTATISTICARELEASE55FORWINDOWSSTATSOFTINC GIBBONS 1997 J NONPARAMETRICMETHODSFORQUANTITATIVEANALYSIS HAIR 1995 J MULTIVARIATEDATAANALYSISREADINGS BUVAT 1999 1466 1477 I SPIEMEDICALIMAGING1999 NEEDDEVELOPGUIDELINESFOREVALUATIONMEDICALIMAGEPROCESSINGPROCEDURES SOUSASANTOSX2004X868 SOUSASANTOSX2004X868X878 SOUSASANTOSX2004X868XB SOUSASANTOSX2004X868X878XB item S1076-6332(04)00281-8 S1076633204002818 10.1016/j.acra.2004.05.004 272938 2010-12-23T00:07:40.847864-05:00 2004-08-01 2004-08-31 true 292261 MAIN 11 55545 849 656 IMAGE-WEB-PDF 1 si5 1177 40 193 si4 722 39 153 si3 793 17 188 si2 837 48 140 si1 1095 48 201 gr1 2340 93 87 gr1 68862 534 499 gr2 882 34 125 gr2 6262 137 499 gr3 1968 93 121 gr3 17616 385 499 gr4 3273 93 122 gr4 19776 288 376 gr5 1504 72 125 gr5 7590 218 376 gr6 1705 72 125 gr6 8884 218 376 gr7 1345 73 125 gr7 6598 220 376 gr8 1574 78 125 gr8 14367 310 498 XACRA 586 S1076-6332(04)00281-8 10.1016/j.acra.2004.05.004 AUR Original investigations Figure 1 Images (a, c) and corresponding contours detected by six radiologists (b, d). Figure 2 Definition of the auxiliary contour to obtain pairs of corresponding points on two contours A and B. P and Q are matching points on the contours under comparison. Figure 3 Box-plots for the comparison of the contours using (a) FPratt, (b) mean distance, and (c) angle θ, involving our algorithm and two radiologists. Figure 4 Box-plots comparing contours detected by the algorithm (a) and all the radiologists (dr) using FPratt. Figure 5 Box-plots corresponding to the comparison (to the reference) of the contours detected by each detector (dr1 to dr6 and the algorithm AlG) using the maximum distance figure of merit. Figure 6 Box-plots corresponding to the comparison (to the reference) of the contours detected by each radiologist, in the first time (dr1_T1 to dr6_T1), two radiologists in the second time (dr1_T2 and dr2_T2) and the algorithm (A) using FPratt. Figure 7 Dendogram plot (clustering analysis) showing all the radiologists in the first time (dr1_T1 to dr6_T1), two radiologists in the second time (dr1_T2 and dr2_T2), and the algorithm (A) using FPratt. Figure 8 Correspondence analysis plot showing all the radiologists in the first time (dr1_T1 to dr6_T1), two radiologists in the second time (dr1_T2 and dr2_T2), and the algorithm (alg) using FPratt. Table 1 Friedman ANOVA for the Comparison of the Contours using FPratt- H = 157.67, (P < .000001) and the Null Hypothesis is Rejected Variable Sum of Ranks DR2T1 144 DR1DR2T2 186 DR2T2 203 DR1T12 272 DR1DR2T1 284 DR1T2 293 DR1T1 377 DR2T12 401 Original investigations Quantitative evaluation of a pulmonary contour segmentation algorithm in x-ray computed tomography images1 Beatriz Sousa Santos PhD a b * Carlos Ferreira PhD c d José Silvestre Silva MSc a e Augusto Silva PhD a b Luı́sa Teixeira MD f a Departamento de Electrónica e Telecomunicações, Portugal b Instituto de Engenharia Electrónica e Telemática de Aveiro, (B.S.S., A.S.), Portugal c Departamento de Economia, Gestão e Engenharia Industrial, Universidade de Aveiro, Portugal d Centro de Investigação Operacional, Universidade de Lisboa, Portugal e Departamento de Fı́sica, Faculdade de Ciências e Tecnologia, Universidade de Coimbra, Portugal f Serviço de Imagiologia, Hospitais da Universidade de Coimbra, Portugal * Address correspondence to B.S.S. DET Departamento de Electronica e Telecomunicaçoes, Universidade de Aveiro, 3810 Aveiro, Portugal Rationale and objectives Pulmonary contour extraction from thoracic x-ray computed tomography images is a mandatory preprocessing step in many automated or semiautomated analysis tasks. This study was conducted to quantitatively assess the performance of a method for pulmonary contour extraction and region identification. Materials and methods The automatically extracted contours were statistically compared with manually drawn pulmonary contours detected by six radiologists on a set of 30 images. Exploratory data analysis, nonparametric statistical tests, and multivariate analysis were used, on the data obtained using several figures of merit, to perform a study of the interobserver variability among the six radiologists and the contour extraction method. The intraobserver variability of two human observers was also studied. Results In addition to a strong consistency among all of the quality indexes used, a wider interobserver variability was found among the radiologists than the variability of the contour extraction method when compared with each radiologist. The extraction method exhibits a similar behavior (as a pulmonary contour detector), to the six radiologists, for the used image set. Conclusion As an overall result of the application of this evaluation methodology, the consistency and accuracy of the contour extraction method was confirmed to be adequate for most of the quantitative requirements of radiologists. This evaluation methodology could be applied to other scenarios. Keywords Quantitative evaluation computed tomography (CT) pulmonary segmentation interobserver and intraobserver variability We have reached a point at which computed tomography (CT) images can be reconstructed faster than they can be read. This fact encourages software developers to design programs that will aid radiologists in the reading of CT images and in diagnosing conditions on the basis of CT findings (1). Segmentation often occurs as a preprocessing step of more global image analysis tasks, as is the case of computer-aided analysis of pulmonary x-ray tomograms (2), where many analytic procedures start by correctly identifying the pulmonary regions (3–6). Most algorithms for the segmentation of pulmonary regions are based on intensity discrimination within the Hounsfield scale (7–9); however this task may become very complex because of the presence of spurious structures within the same scale range or the visual merging of the pulmonary regions themselves. In previous works (10,11) we presented algorithms designed to cope with these difficulties, which generate contours with a variable degree of similarity to those provided by radiologists. A quantitative evaluation of the performance of these algorithms is crucial before their clinical use can be considered. Yet, the performance evaluation of segmentation algorithms in medical imaging is recognized as a difficult problem; actually, if one can find in the literature a significant number of contributions concerning the overall segmentation problem by itself, the same is not true when looking for quality and effectiveness assessments performed in some systematic way (12) and having a practical value (13). This evaluation encounters the first great obstacle: the fact that the ground truth is unknown (13) (ie, it is not possible to identify the real contour corresponding to a given image). This problem is often circumvented using the contour resulting from manually tracing the object boundary by a knowledgeable human as a surrogate of that truth. However, not only will contours drawn by two radiologists be different (interobserver variability), but there will also not be agreement between contours drawn by the same radiologist at different occasions (intraobserver variability). These two types of variability have to be taken into account in the performance evaluation of segmentation algorithms; we will have to compare this performance with the performance of several radiologists in some statistically supported manner. In an earlier work (11) we verified that a greater similarity existed between the contours produced by our algorithm and the contours drawn by two expert radiologists, than between the contours drawn by the same two radiologists. This meant that the interobserver variability between our algorithm and any of the two radiologists was less than the interobserver variability between the two radiologists. To investigate if this was specific for those two radiologists, or if it was more general, we have performed a study including six radiologists from different hospitals. To further investigate this issue, we have considered the study of the intraobserver variability relevant; in this respect our algorithm has a clear advantage because its intraobserver variability is zero. Still, the comparison of the interobserver variability between our algorithm and each radiologist to hers/his intraobserver variability could provide interesting additional information on the performance of the algorithm. While other authors have proposed pulmonary segmentation algorithms and have evaluated them (4,8), they have not compared their performance as contour detectors with as many radiologists, nor have they used such a statistically based method as we have used in this study. Materials and methods Quality assessment strategies It is common to treat the physician ground truth as unquestionable, and assume it as a relatively error-free gold standard; however, there is some level of variability in the specification of the ground truth and it is important to have an estimate of this level. This type of variability is an important concern in determining the appropriate criteria for matching a detected contour to a ground truth contour (13). Quantitative evaluation of the performance of segmentation algorithms in medical imaging has been recognized as an important problem. However, many of the evaluation studies that have been carried out did not use a large enough dataset, real images, convenient performance metrics, appropriate statistical methods, or a suitable ground truth. Thus, they cannot be considered correct or complete. Several methodologies have been proposed to perform this evaluation appropriately. The Handbook of Medical Imaging (13) presents a thorough overview of the field. Chalana and Kim (12) also present a concrete approach to segmentation performance assessment through contour comparison. Quantitative evaluation of the performance As mentioned previously, the ideal way of evaluating the performance of our segmentation algorithm would be to compare the contours detected on a valid test dataset with the “real contours” corresponding to each image. However, as we have seen, there are no such real contours. Several expert radiologists will detect different contours on the same image (see Fig 1b); also, each expert radiologist will detect on the same image, at different times, slightly different contours, unlike our algorithm, which always detects the same contours on the same image (its variability is 0 and it does not depend on any seed points introduced by a human observer, as other pulmonary segmentation algorithms (14–18)). This intraobserver variability can be used as a “variability quantum”; it gives an idea of the level of variability that has to be expected and thus can be acceptable to exist between any two contour detectors (algorithm or human). Therefore, comparing the variability between our algorithm and each radiologist with the intraobserver variability of any expert could work as an “acceptability measure” of that variability. As a consequence of the intraobserver and interobserver variability, the manually drawn contours can be considered as a collection of ground truths, all of them equally acceptable. To circumvent this problem we have performed two studies (using different methods) to compare the behavior of our algorithm, as a contour detector, with the behavior of a reasonable number of expert radiologists. These studies involve the assessment of the interobserver variability among a number of “contour detectors”: several humans and one automated (our algorithm). The rationale for this study was that, if the interobserver variability between the algorithm and any of the radiologists is similar in magnitude to the interobserver variability between any two radiologists, then the difference between the algorithm and the radiologists, as contour detectors, could be considered not significant. This rational is similar to the one behind the study by Sivaramakrishna et al (19) to validate a segmentation algorithm of mammographic images, which also seems comparable to our case. Interobserver variability In our first study concerning interobserver variability we directly compared the contours produced by all detectors (algorithm vs all radiologists and every radiologist vs all the others and algorithm). In a subsequent study we compared each detector with a reference contour (surrogate ground truth) obtained from the hand-drawn contours, as described by Ferreira et al (20). To perform these studies we asked six experienced radiologists, from three different hospitals, to draw contours of the pulmonary regions on the chosen images. This number of radiologists seemed reasonable for such a study, taking into consideration that they have been trained and work at three different hospitals. Moreover, it would be difficult to obtain the collaboration of more radiologists. Intraobserver variability To assess intraobserver variability, we asked two radiologists to hand-draw the contours on the same set of images twice, without telling them that they had already drawn contours on those images. We chose the youngest radiologist and the head of the CT department who was responsible for thoracic radiology at the University Hospital, because these radiologists have a significant difference in years of experience. This choice was made in the hope of obtaining two significantly different values of intraobserver variability (which would probably not be the case if the two radiologists had approximately the same experience). The time elapsed between the delineation of the two contours on the same image by the same radiologist was at least 1 month (which agrees with the proposal of Wagner et al (21)]) to minimize the effect of the recollection of having drawn the previous contours. Test dataset The proper choice of the used dataset is very important; a poor selection of either the number of images or the method to select these images can jeopardize the validity of the evaluation procedure. We used 30 512 × 512 images (N = 60 contours) selected using a pseudorandom generator from a set of 253 images that had not been used to develop the algorithm. These images were all the images that could be used to support diagnosis corresponding to exams of eight patients collected at the Radiology Department of the University Hospital in Coimbra, independently of their pathologies. While the used dataset contained images corresponding to different pulmonary levels, which increased variability, using images from a greater number of patients would probably increase case variability. We used the power of a hypothesis test to calculate the sample size, N, of the test dataset, specifying the smallest difference that would be worthwhile to detect. This means, according to Altman (22), trying to make “clinical” importance and statistical significance agree. As a first approach, we hoped to be able to detect a difference of 1 standard deviation. We set the power (1-β) at 90% and chose a 1% significance level (α); using the nomogram for calculating sample size (22), this gives a total sample of N = 60. Hand-outlined contours Our radiologists manually outlined all the contours on transparent sheets superimposed on quality printings of the test images working independently from each other and (as much as possible) in the same way and on the same conditions. The obtained contours were digitized and processed to identify the contours of left and right lungs. This identification is performed computing the image Radon transforms for 0° and 90°, estimating the center of each lung from the maximum values of these two transforms. Applying a morphologic filling starting from the center of one lung and a second filling starting from any point external to the lungs, we obtained an image containing the filled area of the other lung. The contour of the lung was then easily obtained. Erosion was applied to obtain a thinner version of each of the contours (20). We have chosen this method as a compromise between feasibility to the radiologists and acceptable accuracy. References contour obtained from the hand-drawn contours In the last study of interobserver variability, we compared all contours to reference contours obtained from the six contours detected by the radiologists on each image, as described by Ferreira et al (20). For most images having diagnostic value, the contours detected by all the radiologists are only slightly different and thus using a kind of “average” contour seemed an acceptable surrogate to “ground truth” (Fig 1b); however, in particular regions of a few images of the data set, affected by partial volume effect or motion artifacts, the six radiologists detected contours that seem to correspond to the use of different segmentation criteria (Fig 1d); in this case an “average” contour does not make sense as “ground truth” and a different approach should be used. This needs further investigation; however, the impact on the results of this study is not expected to be significant because of the small number of images and reduced zones where this fact was observed in the used data set. Comparing contours The comparison between any two contours was accomplished in two different ways: one based on the local distances between contours and the other exploring a similarity measure between the image masks (binary images containing the pulmonary areas defined by the contours). The computation of distances between contours implies defining pairs of matching points on both contours. To find these pairs of points we used an auxiliary contour as shown in Figure 2. Differences between the contours were quantified using the Euclidean distances measured between corresponding points (11). Figures of merit The values of the computed distances between the contours allow a localized and accurate quantification of their differences, easily assessable through simple visualization techniques. However, we consider it fundamental to use global quality figures of merit, which facilitate a comprehensive comparison. Thus, several figures of merit, based on the computed distances, were used as performance measures: the Pratt figure of merit F Pratt (23): (1) F Pratt = 1 N ∑ i=1 N 1 1+α×di 2 the Mean Distance: (2) dmean= 1 N ∑ i=1 N di the Maximum Distance: (3) d max =max(di)1≤i≤N and the number of distances greater than 5 pixels (approximately 1% error for a resolution of 512 × 512): (4) n>1%= ∑i=1 N mi N (where mi = 0 if di ≤ 5 and mi = 1 if di > 5). The Pratt figure of merit gives a general impression of the distances between contours; it is a relative measure and varies in the interval [0,1] where “1” means a complete match of the contours. In our case, α, which is a normalization parameter related to the size of the contours, was chosen to be 1/9 so that if all the distances di are equal to 3 pixels, F Pratt will have a value of 0.5. The value of 3 pixels was chosen to produce a scale that allows enough discrimination among the contours drawn by the radiologists. The mean distance also gives an integrated view of the distances between contours, while the maximum distance gives a worst case view. Finally, the number of distances greater than 1% (5 pixels in our case) provides information on the number of relevant errors and thus complements the information obtained from the previous indexes. Another figure of merit was computed based on the similarity between the two binary images, A and B, including the areas defined by the pulmonary contours. This simple measure of similarity may be defined by: (5) θ=cos −1 A·B ‖A‖·‖B‖ where “.” and “‖‖” denote the usual inner product and norm of vectors. In a Hilbert space context, θ is the angle between two binary image vectors A and B. The correct identification of the measurement scale (24) is an important issue concerning the information provided by these figures of merit and the statistical methods that can be used. In this respect, the Pratt and θ figures of merit are measured on an ordinal scale whereas the mean error and the number of distances greater than 5 pixels are measured on a ratio scale. Statistical methods As a first step in the analysis of the data obtained from the comparison among contours using all figures of merit, we performed an exploratory data analysis (25); this analysis provided an overview of the structure of the data (showing the amplitudes, asymmetries, location, possible outliers, etc) and also some clues to the type of statistical tests to be used to test our hypothesis. The software used was Statistica (Statsoft, Tulsa, OK) (26). Because the sample set did not correspond to independent experiments, nor did the data have a normal distribution, a nonparametric test was used (27). We also used multivariate data analysis (28) to assess if our algorithm is generally comparable to the six human observers as a contour detector on the used image data set. Results Study of the interobserver and intraobserver variability involving our algorithm and two expert radiologists The two radiologists were called dr1 and dr2, and the two contour drawing moments were called t1 and t2. Figure 3 shows the box-plots and corresponding median and quartile values for the comparison between the contours detected by our algorithm and the two radiologists in the two moments, using different figures of merit. The box-plots can be interpreted in the following way: drit1-comparison between the contours detected by dri at moment t1 to the contours detected by our algorithm, on the selected set of images; drit12-comparison between the contours detected by dri at moments t1 and t2, on the same images. According to this notation: dr1t12 and dr2t12 represent the intraobserver variability of experts dr1 and dr2; dr1t1, dr1t2, dr2t1 and dr2t2 represent the interobserver variability between our algorithm and each radiologist in each moment; dr1dr2t1 and dr1dr2t2 represent the interobserver variability between both radiologists at moments t1 and t2, respectively. All these can be compared in Figure 3 through several figures of merit: FPratt, mean distance, and angle θ. Observing the box-plots corresponding to FPratt we note that: 1. At moment t1, dr1 is more similar to our algorithm than to dr2, because the median value of dr1t1 (median, 0.81) is higher (ie, better) than the median value of dr1dr2t1 (median, 0.75); this was confirmed using a nonparametric test for the equality of the median, the Wilcoxon test (28), which rejected the null hypothesis (P < .00004). Also the range of the values is smaller for dr1t1 than for dr1dr2t1. Both results suggest that the interobserver variability between the two radiologists is higher than the variability between dr1 and our algorithm; 2. At moment t2, both dr1 and dr2 are more similar to our algorithm than to each other; for instance, the median value of dr1t2 (median, 0.78) is higher than the median value of dr1dr2t2 (median, 0.70), confirmed using the Wilcoxon test (P < .00009). 3. dr1 is more similar to our algorithm than to himself because the median value of dr1t1 (median, 0.81) is higher (better) than the median value of dr1t12 (median, 0.76), according to the Wilcoxon test (P < .00007). On the other hand, the median value of dr1t2 (median, 0.78) was not considered significantly different of the median value of dr1t12, according to the Wilcoxon test (P < .4). The above results suggest that the interobserver variability between dr1 and our algorithm is ≤ the intraobserver variability of dr1. These findings are not contradicted by the observation of the information obtained using the other figures of merit and were confirmed using a nonparametric method, the Friedman’s two-way analysis of variance (27). The calculated H = 157.67 (with N = 60 and k = 8); under the null hypothesis (equality of medians), H has a χ2 distribution with (k-1) degrees of freedom. In our case, for a 1% significance level (α), χ2 (7);0.01 = 18.48; thus H = 157.67⪢χ2 (7);0.01 = 18.48 (P < .000001) and the null hypothesis is rejected. Table 1 presents the sum of ranks in ascending order. This means that the medians are in fact significantly different, which reinforces the three observations presented above. Moreover, these observations can be confirmed through Table 1, where we can see, for instance, that the sum of ranks corresponding to dr1t1 and dr1t2 are both higher than the sum of ranks corresponding to dr1t12 (377, 299, and 272, respectively). Taking the observation of Table 1 further, we notice that all (except dr2t1) variabilities between our algorithm and each radiologist are less than (at least) the interobserver variability between the two radiologists at moment t2 (dr1dr2t2). These and other findings that can be extracted from these results seem to indicate that, as a detector of pulmonary contours on the used set of images, our algorithm behaves as a third human observer. Study of the interobserver variability through direct comparison among the algorithm and six expert radiologists Let us generalize the previous comparison to six radiologists. dr1 … dr6 stand for the six radiologists and A for the algorithm. Figure 4 shows the box-plots and corresponding median and quartile values for the comparison between the contours detected by our algorithm and the six radiologists in all possible combinations using FPratt (considering that, for instance, dri_drj is equal to drj_dri, we only show one). Thus, in Figure 4, the meaning is: a_dri-comparison between the contours detected by our algorithm and the contours detected by dri, on the selected set of images; it represents the interobserver variability between our algorithm and this radiologist; dri_drj-comparison between the contours detected by dri and the contours detected by drj, on the selected set of images; it represents the interobserver variability between these two radiologists. Observing Figure 4 we note that the median values corresponding to situations of the type a_dri are generally higher and more similar among them than the ones corresponding to dri_drj. Performing a correspondence analysis (28) and observing the plane defined by the first two axis (which represents approximately 46% of the total inertia), we notice that our algorithm is clearly included in the main groups formed by the comparisons among all the radiologists and the algorithm. Comparisons between dr5, dr6 and dr2 seem to be isolated. This could be because dr2 had just finished his training as a radiologist and dr5 and dr6 both work in the same hospital (different from dr2). Study of the interobserver variability using a reference contour We primarily show results obtained using the Pratt figure of merit because we have concluded in previous studies, and confirmed through this one, that the figures of merit (except for the maximum distance) produce consistent results, conveying the same type of information. As a first approach, we studied the interobserver variability among all radiologists and the algorithm in a worst-case scenario. This was performed using the maximum distance figure of merit and exploratory data analysis. Figure 5 shows the box-plots of the data resulting from the comparison of the contours obtained by each detector (humans and algorithm) to the reference contours using the maximum distance. On these plots we observe a concentration of the smaller values, some outliers for all detectors (corresponding to images that should be analyzed) and median values for all detectors between 5.4 and 9.9 pixels; these values can be considered low for images of 512 × 512 pixels. Thus, even in this case all the detectors (including our algorithm) seem to have a good performance for the used image data set. As a second approach, we studied the variability between the reference and all radiologists as well as the algorithm using the Pratt figure of merit and exploratory data analysis. In this study, we included the contours drawn by all the radiologists (dr1 to dr6) in first time, the contours drawn by dr1 and dr2 the second time (as dr1_T2 and dr2_T2), as well as the contours obtained using our algorithm (a). Observing Figure 6, which shows the box corresponding to these data, we notice that the median value obtained for our algorithm is quite similar to the value for radiologist dr4_t1, higher than the values for radiologists dr1_T2, dr3_t1, dr5_t1, dr6_T1 and lower than the values for radiologists dr1_T1, dr2_t1, dr2_T2. This indicates that our algorithm produced, for the used image set, contours more similar to the reference than a significant part of the radiologists. The above result suggested that we should further explore the relation among the performance of our algorithm as a detector to the performance of all the radiologists. Thus, we used clustering analysis (28), which closely associated our algorithm with dr1_t1 as shown by the dendogram plot of Figure 7; this means that, in this context, our algorithm is more similar to radiologist dr1 than he is to himself in different moments, namely dr1_t1 and dr1_t2. This conclusion was already obtained in the previous study through direct comparison among radiologists and algorithm. A confirmation of this result was obtained through the use of another method of multivariate data analysis. Figure 8 shows the projection on the plane defined by the first two axes (approximately 66% of the total inertia) of a correspondence analysis. Observing this figure, we notice that our algorithm is clearly included in a group of four radiologists (dr1_t1, dr1_t2, dr3_ t1, dr4_t1), radiologists dr5 and dr6 form another group and dr2 is isolated between the two groups. Note that the same conclusion could be drawn from the dendogram of Figure 7. This could be related, as observed in the previous study, to the facts that radiologists dr5 and dr6 work in the same department, (different from the others) and perhaps use different segmentation criteria, radiologist dr2 has just finished his training as a radiologist and all the others have a much larger experience. To obtain a global average view of the distance between detected contours and the reference, we used the mean-distance figure of merit and angle θ, and we obtained a confirmation of the results previously found through the Pratt figure of merit (20). Conclusions In this article we propose a methodology to the quantitative evaluation of the performance of a pulmonary contour segmentation algorithm involving the study of interobserver and intraobserver variability. Making accurate, unbiased estimates or comparisons of performance is, in general, a very difficult task. However, some guidelines are known to facilitate it (13,22,29). For our case, we considered the following guidelines useful: • Report results on common test datasets; • Use test datasets different from those used to train the segmentation method; • Use an adequate methodology to choose the test datasets and clearly state it (eg, the inclusion and exclusion criteria and the determination of the sample size); • Choose carefully and define clearly the observers and methods used to obtain the ground-truth; • Let the observers operate in the same conditions; • Clearly specify the performance metric (figures of merit) used; • Correctly identify the measurement scales, which determine the kind of statistical methods that could be used; • Choose hypothesis tests compatible with the quality indexes used and clearly justify it (as the chosen α and β and if the test is one- or two-tailed); • Use nonparametric tests if the data is categorical, the statistical distribution of the data is unknown (or known and not suitable for parametric methods) or the sample size is small; • Use paired test if possible (if all the methods can be applied to the same image). We present results concerning the interobserver variability among six radiologists and the algorithm, using two different approaches: Through the direct comparison of the contours detected by this algorithm to the contours hand-drawn by six radiologists; Through a comparison to a reference contour (obtained from the hand-drawn contours) used as a surrogate ground truth. This last approach is easier to generalize to a greater number of radiologists; however, it is necessary to further investigate what is the most correct way of computing the reference contour when radiologists use different segmentation criteria. All the comparisons were made using several figures of merit. While the Pratt figure of merit, the mean distance, and the angle θ produced consistent results conveying the same type of information, an integrated view of the distances between contours, maximum distance is useful for worst-case scenarios. We also assessed the intraobserver variability of two radiologists to have a measure of the level of interobserver variability that is expected and has to be accepted. We believe this methodology is general enough to be applicable to many other problems of segmentation on medical images, in spite of the fact that it was developed for this specific application. Concerning the performance of our segmentation algorithm, the results presented allow us to conclude that it is possibly as good a lung contour detector, in most thoracic CT images with diagnostic value, as any of the six radiologists. This assertion is mainly based on the fact that it exhibits a greater “agreement” to any of the radiologists than the radiologists among them, in the used image set. This is true, with a few exceptions, for images with complex vascular patterns crossing the interface between the mediastinic and pulmonary fields. Acknowledgements The authors express their gratitude to the following radiologists for drawing contours: Dr Pedro Agostinho from University Hospital of Coimbra, Dr Rui Pinho e Melo and Dr Jorge Pinho e Melo from CENTAC-Center of Computed Tomography, Aveiro; Dr Anabela Fidalgo and Dr Fernando Figueiredo from the Imagiology Department at the Hospital Infante D. Pedro, Aveiro. The authors are also grateful to an anonymous reviewer for his pertinent comments and suggestions. References 1 W.L. Robb Perspective on the first 10 years of the CT scanner industry Acad Radiol 10 2003 756 760 2 J. Brink J.P. Heiken G. Wang K.W. McEnery F.J. Schlueter M.W. Vannier Helical CT principles and technical considerations Radiographics 14 1994 887 893 3 B. Li G. Christensen E. Hoffmann G. McLeannan J. Reinhardt Establishing a normative atlas of the human lung intersubject warping and registration of volumetric CT images Acad Radiol 10 2003 255 265 4 M.S. Brown M.F. McNitt-Gray N.J. Mankovich Method for segmentation chest CT image data using an anatomical model preliminary results IEEE Trans Med Imaging 16 1997 828 839 5 M. Sonka W. Park E.A. Hoffman Rule-based detection of intrathoracic airways trees IEEE Trans Med Imaging 15 1996 314 326 6 J. Duryea J.M. Boone A fully automated algorithm for the segmentation of lung fields on digital chest radiographic images Med Phys 22 1995 183 191 7 R.P. Parker Measurement of basic CT data B.M. Moores R.P. Parker B.R. Pullan Proceedings of physical aspects of medical imaging 1980 Wiley & Sons Manchester, UK 291 295 8 S. Hu E.A. Hoffman J.M. Reinhardt Automatic lung segmentation for accurate quantization of volume x-ray CT images IEEE Trans Med Imaging 20 2001 490 498 9 A. Hasegawa S.-.C.B Lo J.-.S Lin M.T. Freedman S.K. Mun A shift-invariant neural network for the lung field segmentation in chest radiography J VLSI Signal Process 18 1998 241 250 10 J.S. Silva A. Silva B.S. Santos Lung segmentation methods in x-ray CT images Proceedings of V Ibero-American Symposium On Pattern Recognition-SIARP’2000 2000 APRP—Portuguese Association for Pattern Recognition Lisbon, Portugal 583 598 11 A. Silva J.S. Silva B.S. Santos C. Ferreira Fast pulmonary contour extraction in x-ray CT images a methodology and quality assessment C.-.T Chen A.V. Clough SPIE-Medical Imaging 2001 Physiology and Function from Multidimensional Images 4321 2001 SPIE Bellingham, WA 216 224 12 V. Chalana Y. Kim A methodology for evaluation of boundary detection algorithms on medical images IEEE Trans Pattern Anal Machine Intell 16 1997 642 652 13 K.W. Bowyer Validation of medical image analysis techniques J. Fitzpatrick M. Sonka Handbook of medical imaging. Vol 2. Medical image processing and analysis (cap. X) 1999 SPIE-The International Society for Optical Engineering Bellingham, WA 567 606 14 A. Blake M. Isard Active contours 1998 Springer Verlag London 15 S.R. Gunn M.S. Nixon A robust snake implementation; a dual active contour IEEE Trans Pattern Anal Machine Intell 19 1997 63 68 16 M. Kass A. Witkin D. Terzopoulos Snakes active contour models Int J Comput Vision 1 1988 321 331 17 J. Liang T. McInerney D. Terzopoulos United snakes International Conference of Computer Vision—Volume 2, September 20–25 1999 Kerkyra Greece 933 940 18 A. Yezzi S. Kichenassamy A. Kumar P. Olver A. Tannenbaum A geometric snake model for segmentation of medical imagery IEEE Trans Med Imaging 16 1997 199 209 19 R. Sivaramakrishna N. Obuchowski W. Chilcote K. Powell Automatic segmentation of mammographic density Acad Radiol 8 2001 250 256 20 C. Ferreira B.S. Santos J.S. Silva A. Silva Comparison of a segmentation algorithm to six expert imagiologists in detecting pulmonary contours on x-ray CT images SPIE Medical Imaging 2003 Image Perception, Observer Performance and Technology Assessment 2003 SPIE Bellingham, WA 347 358 21 R. Wagner S. Beiden G. Campbell C. Metz W. Sacks Contemporary issues for experimental design in assessment of medical imaging and computer-assist systems SPIE Medical Imaging 2003 Image Perception, Observer Performance and Technology Assessment 5034 2003 SPIE Bellingham, WA 213 224 22 D.G. Altman Practical statistics for medical research 1999 CRC Press London, UK 23 I.E. Abdou W.K. Pratt Quantitative design and evaluation of enhancement/thresholding edge detectors Proceedings IEEE 67 1979 753 763 24 L. Sachs Applied statistics-a handbook of techniques 1984 Springer-Verlag New York, NY 25 D. Hoaglin F. Mosteller J. Tukey Understanding robust and exploratory data analysis 1983 Wiley & Sons 26 Statsoft. Statistica-release 5.5 for Windows. Statsoft Inc 1999 27 J.D. Gibbons Nonparametric methods for quantitative analysis 1997 American Sciences Press Syracuse, NY 28 J.F. Hair R.E. Anderson R.L. Tatham W.C. Black Multivariate data analysis with readings 1995 Prentice-Hall Upper Saddle River, NJ 29 I. Buvat The need to develop guidelines for the evaluation of medical image processing procedures K.M. Hanson SPIE-Medical Imaging 1999 Image Processing 1999 SPIE Bellingham, WA 1466 1477 "
    },
    {
        "doc_title": "A Level-Set Based Volumetric CT Segmentation Technique: A Case Study with Pulmonary Air Bubbles",
        "doc_scopus_id": "35048899295",
        "doc_doi": "10.1007/978-3-540-30126-4_9",
        "doc_eid": "2-s2.0-35048899295",
        "doc_date": "2004-01-01",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Air bubbles",
            "High-resolution computed tomography",
            "Level Set",
            "Level set functions",
            "Level Set method",
            "Surface topology",
            "Volumetric CT",
            "Volumetric data"
        ],
        "doc_abstract": "The identification of pulmonary air bubbles plays a significant role for medical diagnosis of pulmonary pathologies. A method to segment these abnormal pulmonary regions on volumetric data, using a model deforming towards the objects of interest, is presented. We propose a variant to the well known level-set method that keeps the level-set function moving along desired directions, with an improved stopping function that proved to be successful, even for large time steps. A region seeking approach is used instead of the traditional edge seeking. Our method is stable, robust, and automatically handles changes in surface topology during the deformation. Experimental results, for 2D and 3D high resolution computed tomography images, demonstrate its performance. © Springer-Verlag 2004.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "A quantitative algorithm for parameter estimation in magnetic induction tomography",
        "doc_scopus_id": "3242689920",
        "doc_doi": "10.1088/0957-0233/15/7/025",
        "doc_eid": "2-s2.0-3242689920",
        "doc_date": "2004-01-01",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Instrumentation",
                "area_abbreviation": "PHYS",
                "area_code": "3105"
            },
            {
                "area_name": "Engineering (miscellaneous)",
                "area_abbreviation": "ENGI",
                "area_code": "2201"
            },
            {
                "area_name": "Applied Mathematics",
                "area_abbreviation": "MATH",
                "area_code": "2604"
            }
        ],
        "doc_keywords": [
            "Magnetic induction tomography",
            "Spatial distribution"
        ],
        "doc_abstract": "Magnetic induction tomography aims at producing images of the spatial distribution of electric conductivity and/or magnetic permeability in a given region of space. The associated inverse problem is ill posed and strongly nonlinear, making it very hard to deal with. However, if 'a priori' knowledge is incorporated into the solution, the problem may be simplified and an inversion procedure that produces quantitative results for some situations may be obtained. This paper describes an approach that follows this rationale. The spatial distribution in the region of interest is restricted to a single object of cylindrical shape and the physical property to be imaged to the magnetic permeability. Solving the problem will mean in this sense estimating only four parameters: two spatial coordinates for the position of the cylinder's centre, its radius and its magnetic permeability. The geometry of data collection is simple enough for the direct problem to be solved analytically and allows one to concentrate on the main characteristics of the inversion. It is shown that the problem is invertible, although in the limit, when the radius tends to zero, this is no longer true. A Newton-Raphsontype algorithm was developed for inversion purposes. It converges in a small number of iterations and produces exact values of the parameters for a predefined range of magnetic permeability and cylinder radius, if no noise is present. The inversion procedure is studied and its performance evaluated in several situations, related to the amount of S/N in the measurement vector, the degree of overdetermination in the system of equations and the choice of the sampling points. © 2004 IOP Publishing Ltd.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "MIT image reconstruction based on edge-preserving regularization",
        "doc_scopus_id": "1342268919",
        "doc_doi": "10.1088/0967-3334/25/1/026",
        "doc_eid": "2-s2.0-1342268919",
        "doc_date": "2004-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Biophysics",
                "area_abbreviation": "BIOC",
                "area_code": "1304"
            },
            {
                "area_name": "Physiology",
                "area_abbreviation": "BIOC",
                "area_code": "1314"
            },
            {
                "area_name": "Biomedical Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2204"
            },
            {
                "area_name": "Physiology (medical)",
                "area_abbreviation": "MEDI",
                "area_code": "2737"
            }
        ],
        "doc_keywords": [
            "Cylindrical objects",
            "Edge-preserving regularization",
            "EIT",
            "Electrical tomography",
            "Half quadratic regularization",
            "Ill-posedness",
            "Images reconstruction",
            "Magnetic induction tomography",
            "Regularisation",
            "Tikhonov regularization"
        ],
        "doc_abstract": "Tikhonov regularization has been widely used in electrical tomography to deal with the ill-posedness of the inverse problem. However, due to the fact that discontinuities are strongly penalized, this approach tends to produce blurred images. Recently, a lot of interest has been devoted to methods with edge-preserving properties, such as those related to total variation, wavelets and half-quadratic regularization. In the present work, the performance of an edge-preserving regularization method, called ARTUR, is evaluated in the context of magnetic induction tomography (MIT). ARTUR is a deterministic method based on half-quadratic regularization, where complementary a priori information may be introduced in the reconstruction algorithm by the use of a nonnegativity constraint. The method is first tested using an MIT analytical model that generates projection data given the position, the radius and the magnetic permeability of a single nonconductive cylindrical object. It is shown that even in the presence of strong Gaussian additive noise, it is still able to recover the main features of the object. Secondly, reconstructions based on real data for different configurations of conductive nonmagnetic cylindrical objects are presented and some of their parameters estimated.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Detection and 3D representation of pulmonary air bubbles in HRCT volumes",
        "doc_scopus_id": "0041326302",
        "doc_doi": "10.1117/12.480283",
        "doc_eid": "2-s2.0-0041326302",
        "doc_date": "2003-09-19",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Electronic, Optical and Magnetic Materials",
                "area_abbreviation": "MATE",
                "area_code": "2504"
            },
            {
                "area_name": "Condensed Matter Physics",
                "area_abbreviation": "PHYS",
                "area_code": "3104"
            },
            {
                "area_name": "Computer Science Applications",
                "area_abbreviation": "COMP",
                "area_code": "1706"
            },
            {
                "area_name": "Applied Mathematics",
                "area_abbreviation": "MATH",
                "area_code": "2604"
            },
            {
                "area_name": "Electrical and Electronic Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2208"
            }
        ],
        "doc_keywords": [
            "Bubble emphysema",
            "High resolution computer tomography",
            "Lungs",
            "Pulmonary air bubbles",
            "Pulmonary volume delimitation"
        ],
        "doc_abstract": "Bubble emphysema is a disease characterized by the presence of air bubbles with the lungs. With the purpose of identifying pulmonary air bubbles, two alternative methods are developed, using High Resolution Computer Tomography (HRCT) exams. The first detection method follows a slice by slice approach and uses selection criteria based on the Hounsfield levels, dimensions, shape and localization of the bubbles. The second detection method, after the pulmonary volume delimitation, follows a fully 3D approach. The 3D approach morphologic operators are used to remove spurious structures and to circumscribe the bubbles.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Electronic patient record virtually unique based on a crypto Smart Card",
        "doc_scopus_id": "35248872485",
        "doc_doi": "10.1007/3-540-45068-8_102",
        "doc_eid": "2-s2.0-35248872485",
        "doc_date": "2003-01-01",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Electronic patient record",
            "Multi-services",
            "Patient data",
            "Patient mobility",
            "Web technologies"
        ],
        "doc_abstract": "This paper presents a Multi-Service Patient Data Card (MS-PDC) based on a crypto smart card and Web technology that integrates a new set of functionalities that allow handling well patient mobility. © Springer-Verlag Berlin Heidelberg 2003.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Critical information systems authentication based on PKC and biometrics",
        "doc_scopus_id": "35248824578",
        "doc_doi": "10.1007/3-540-45068-8_101",
        "doc_eid": "2-s2.0-35248824578",
        "doc_date": "2003-01-01",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Access control models",
            "Authentication mechanisms",
            "Health care professionals"
        ],
        "doc_abstract": "This paper presents an access control model that dynamically combines biometrics with PKC technology to assure a stronger authentication mechanism to healthcare professional that can be used indistinctly in Internet and Intranets access scenario. © Springer-Verlag Berlin Heidelberg 2003.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Multi-slice spiral CT simulator for dynamic cardio-pulmonary studies",
        "doc_scopus_id": "0036032207",
        "doc_doi": "10.1117/12.463596",
        "doc_eid": "2-s2.0-0036032207",
        "doc_date": "2002-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Electronic, Optical and Magnetic Materials",
                "area_abbreviation": "MATE",
                "area_code": "2504"
            },
            {
                "area_name": "Condensed Matter Physics",
                "area_abbreviation": "PHYS",
                "area_code": "3104"
            },
            {
                "area_name": "Computer Science Applications",
                "area_abbreviation": "COMP",
                "area_code": "1706"
            },
            {
                "area_name": "Applied Mathematics",
                "area_abbreviation": "MATH",
                "area_code": "2604"
            },
            {
                "area_name": "Electrical and Electronic Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2208"
            }
        ],
        "doc_keywords": [],
        "doc_abstract": "We've developed a Multi-slice Spiral CT Simulator modeling the acquisition process of a real tomograph over a 4-dimensional phantom (4D MCAT) of the human thorax. The simulator allows us to visually characterize artifacts due to insufficient temporal sampling and \"a priori\" evaluate the quality of the images obtained in cardio-pulmonary studies (both with single-/multi-slice and ECG gated acquisition processes). The simulating environment allows both for conventional and spiral scanning modes and includes a model of noise in the acquisition process. In case of spiral scanning, reconstruction facilities include longitudinal interpolation methods (360LI and 180LI both for single and multi-slice). Then, the reconstruction of the section is performed through FBP. The reconstructed images/volumes are affected by distortion due to insufficient temporal sampling of the moving object. The developed simulating environment allows us to investigate the nature of the distortion characterizing it qualitatively and quantitatively (using, for example, Herman's measures). Much of our work is focused on the determination of adequate temporal sampling and sinogram regularization techniques. At the moment, the simulator model is limited to the case of multi-slice tomograph, being planned as a next step of development the extension to cone beam or area detectors.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Fast pulmonary contour extraction in X-ray CT images: A methodology and quality assessment",
        "doc_scopus_id": "0034866059",
        "doc_doi": "10.1117/12.428139",
        "doc_eid": "2-s2.0-0034866059",
        "doc_date": "2001-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Electronic, Optical and Magnetic Materials",
                "area_abbreviation": "MATE",
                "area_code": "2504"
            },
            {
                "area_name": "Condensed Matter Physics",
                "area_abbreviation": "PHYS",
                "area_code": "3104"
            },
            {
                "area_name": "Computer Science Applications",
                "area_abbreviation": "COMP",
                "area_code": "1706"
            },
            {
                "area_name": "Applied Mathematics",
                "area_abbreviation": "MATH",
                "area_code": "2604"
            },
            {
                "area_name": "Electrical and Electronic Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2208"
            }
        ],
        "doc_keywords": [],
        "doc_abstract": "Segmentation of thoracic X-Ray Computed Tomography images is a mandatory pre-processing step in many automated or semi-automated analysis tasks such us region identification, densitometric analysis, or even for 3D visualization purposes when a stack of slices has to be prepared for surface or volume rendering. In this work, we present a fully automated and fast method for pulmonary contour extraction and region identification. Our method combines adaptive intensity discrimination, geometrical feature estimation and morphological processing resulting into a fast and flexible algorithm. A complementary but not less important objective of this work consisted on a quality assessment study of the developed contour detection technique. The automatically extracted contours were statistically compared to manually drawn pulmonary outlines provided by two radiologists. Exploratory data analysis and non-parametric statistical tests were performed on the results obtained using several figures of merit. Results indicate that, besides a strong consistence among all the quality indexes, there is a wider inter-observer variability concerning both radiologists than the variability of our algorithm when compared to each one of the radiologists. As an overall conclusion we claim that the consistence and accuracy of our detection method is more than acceptable for most of the quantitative requirements mentioned by the radiologists.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "A cardiology oriented PACS",
        "doc_scopus_id": "58749107317",
        "doc_doi": "10.1117/12.319775",
        "doc_eid": "2-s2.0-58749107317",
        "doc_date": "1998-12-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Electronic, Optical and Magnetic Materials",
                "area_abbreviation": "MATE",
                "area_code": "2504"
            },
            {
                "area_name": "Condensed Matter Physics",
                "area_abbreviation": "PHYS",
                "area_code": "3104"
            },
            {
                "area_name": "Computer Science Applications",
                "area_abbreviation": "COMP",
                "area_code": "1706"
            },
            {
                "area_name": "Applied Mathematics",
                "area_abbreviation": "MATH",
                "area_code": "2604"
            },
            {
                "area_name": "Electrical and Electronic Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2208"
            }
        ],
        "doc_keywords": [
            "Asynchronous transfer mode (ATM)",
            "ATM",
            "Cardiac imaging",
            "DICOM",
            "PACS",
            "Short term",
            "Switched LANs",
            "Video sequencing"
        ],
        "doc_abstract": "This paper describes an integrated system designed to provide efficient means for DICOM compliant cardiac imaging archival, transmission and visualization based on a communications backbone matching recent enabling telematic technologies like Asynchronous Transfer Mode (ATM) and switched Local Area Networks (LANs). Within a distributed client-server framework, the system was conceived on a modality based bottom-up approach, aiming ultrafast access to short term archives and seamless retrieval of cardiac video sequences throughout review stations located at the outpatient referral rooms, intensive and intermediate care units and operating theaters. ©2003 Copyright SPIE - The International Society for Optical Engineering.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Integrated package for interactive analysis and interpretation of nuclear medicine images",
        "doc_scopus_id": "0026971135",
        "doc_doi": null,
        "doc_eid": "2-s2.0-0026971135",
        "doc_date": "1992-12-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Electronic, Optical and Magnetic Materials",
                "area_abbreviation": "MATE",
                "area_code": "2504"
            },
            {
                "area_name": "Condensed Matter Physics",
                "area_abbreviation": "PHYS",
                "area_code": "3104"
            },
            {
                "area_name": "Computer Science Applications",
                "area_abbreviation": "COMP",
                "area_code": "1706"
            },
            {
                "area_name": "Applied Mathematics",
                "area_abbreviation": "MATH",
                "area_code": "2604"
            },
            {
                "area_name": "Electrical and Electronic Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2208"
            }
        ],
        "doc_keywords": [
            "Colors tool",
            "Graphics tool",
            "UNIX workstations",
            "X Window graphics interface"
        ],
        "doc_abstract": "This paper describes a software package based on a set of integrated tools intended to be used in nuclear medicine imaging environments. These tools, following a functionally consistent and open architecture, aim to provide an efficient and user-friendly way for handling the analysis and interpretation of nuclear medicine images in a broad range of applications. The Image, Graphics, and Colors tools are the basic building blocks. Besides basic image handling facilities, the Image tool was designed to accomplish both conventional and special purposed processing tasks. Among these, the interactive definition of organ shaped regions of interest, functional imaging (e.g., mean transit time images in ventilatory lung studies) and activity quantitation should be pointed out as the most intensively used facilities. The Graphics tool is used mainly to display and analyze the activity/time curves resulting from parametric related studies. As intensity color coding has gained wide acceptance in nuclear medicine it was thought convenient to implement a Colors tool intended to provide interactive intensity manipulation. The X Window graphics interface system is the basis for the implementation of this set of independent but intercommunicating tools which are intended to run on all UNIX workstations provided with, at least, an 8 bit depth frame buffer.",
        "available": false,
        "clean_text": ""
    }
]