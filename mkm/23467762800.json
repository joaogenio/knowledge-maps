[
    {
        "doc_title": "Initial Study Using Electrocardiogram for Authentication and Identification",
        "doc_scopus_id": "85126020860",
        "doc_doi": "10.3390/s22062202",
        "doc_eid": "2-s2.0-85126020860",
        "doc_date": "2022-03-01",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Analytical Chemistry",
                "area_abbreviation": "CHEM",
                "area_code": "1602"
            },
            {
                "area_name": "Information Systems",
                "area_abbreviation": "COMP",
                "area_code": "1710"
            },
            {
                "area_name": "Atomic and Molecular Physics, and Optics",
                "area_abbreviation": "PHYS",
                "area_code": "3107"
            },
            {
                "area_name": "Biochemistry",
                "area_abbreviation": "BIOC",
                "area_code": "1303"
            },
            {
                "area_name": "Instrumentation",
                "area_abbreviation": "PHYS",
                "area_code": "3105"
            },
            {
                "area_name": "Electrical and Electronic Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2208"
            }
        ],
        "doc_keywords": [
            "Biometric systems",
            "Biometric traits",
            "Cardiac cycles",
            "Classification algorithm",
            "Comparative analyzes",
            "Convolutional neural network",
            "Distance based algorithm",
            "Features extraction",
            "Physiological signatures",
            "Public database",
            "Algorithms",
            "Biometry",
            "Databases, Factual",
            "Electrocardiography",
            "Humans",
            "Neural Networks, Computer"
        ],
        "doc_abstract": "© 2022 by the authors. Licensee MDPI, Basel, Switzerland.Recently, several studies have demonstrated the potential of electrocardiogram (ECG) to be used as a physiological signature for biometric systems (BS). We investigated the potential of ECG as a biometric trait for the identification and authentication of individuals. We used data from a public database, CYBHi, containing two off-the-person records from 63 subjects, separated by 3 months. For the BS, two templates were generated: (1) cardiac cycles (CC) and (2) scalograms. The identification with CC was performed with LDA, kNN, DT, and SVM, whereas a convolutional neural network (CNN) and a distance-based algorithm were used for scalograms. The authentication was performed with a distance-based algorithm, with a leave-one-out cross validation, for impostors evaluation. The identification system yielded accuracies of 79.37% and 69.84% for CC with LDA and scalograms with CNN, respectively. The authentication yielded an accuracy of 90.48% and an impostor score of 13.06% for CC, and it had an accuracy of 98.42% and an impostor score of 14.34% for scalograms. The obtained results support the claim that ECG can be successfully used for personal recognition. To the best of our knowledge, our study is the first to thoroughly compare templates and methodologies to optimize the performance of an ECG-based biometric system.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Characterization of Emotions Through Facial Electromyogram Signals",
        "doc_scopus_id": "85129865306",
        "doc_doi": "10.1007/978-3-031-04881-4_19",
        "doc_eid": "2-s2.0-85129865306",
        "doc_date": "2022-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Classification system",
            "Condition",
            "Detection signal",
            "Electromyo grams",
            "Electromyogram signals",
            "Emotion characterization",
            "Emotion classification",
            "Expression detections",
            "Micro-expressions",
            "Visual content"
        ],
        "doc_abstract": "© 2022, Springer Nature Switzerland AG.Emotions are a high interesting subject for the development of areas such as health and education. As a result, methods that allow their understanding, characterization, and classification have been under the attention in recent years. The main objective of this work is to investigate the feasibility of characterizing emotions from facial electromyogram (EMG) signals. For that, we rely on the EMG signals, from the frontal and zygomatic muscles, collected on 37 participants while emotional conditions were induced by visual content, namely fear, joy, or neutral. Using only the entropy of the EMG signals, from the frontal and zygomatic muscles, we can distinguish, respectively, neutral and joy conditions for 70% and 84% of the participants, fear and joy conditions for 81% and 92% of the participants and neutral, and fear conditions for 65% and 70% of the participants. These results show that opposite emotional conditions are easier to distinguish through the information of EMG signals. Moreover, we can also conclude that the information from the zygomatic muscle allowed to characterized more participants with respect to the 3 emotional conditions induced. The characterization of emotions through EMG signals opens the possibility for a classification system for emotion classification relying only on EMG information. This has the advantages of micro-expressions detection, signal constant collection, and no need to acquire face images. This work is a first step towards the automatic classification of emotions based solely on facial EMG.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Exploring Alterations in Electrocardiogram During the Postoperative Pain",
        "doc_scopus_id": "85129818769",
        "doc_doi": "10.1007/978-3-031-04881-4_14",
        "doc_eid": "2-s2.0-85129818769",
        "doc_date": "2022-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Clusterings",
            "Critical steps",
            "Electrocardiogram signal",
            "Features extraction",
            "Features selection",
            "Pain management",
            "Physiological indicators",
            "Physiological pain assessment",
            "Postoperative pain",
            "Surgical procedures"
        ],
        "doc_abstract": "© 2022, Springer Nature Switzerland AG.The assessment of postoperative pain after a surgical procedure is a critical step to guarantee a suitable analgesic control of pain, and currently, it is based on the self-reports of the patients. However, these assessment methods are subjective, discontinuous, and inadequate for evaluating the pain of patients unable or with limited ability to communicate verbally. Developing an objective and continuous tool for assessing and monitoring postoperative pain, which does not require patient reports could assist pain management during the patient stay in the post-surgery care unit and, ultimately, promote better recovery. In the last years, the evaluation of pain through physiological indicators has been investigated. In the present work, electrocardiogram (ECG) signals collected from 19 patients during the postoperative period were studied in order to find relationships between physiological alterations and pain and identify which ECG-feature or combination of ECG-features better describe postoperative pain. Considering a multivariate approach, analysing the performance of sets of two or more ECG-features using clustering algorithms proved to be promising, allowing the identification of different pain characteristics based on the extracted features from the ECG signals.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Classification of critical levels of co exposure of firefigthers through monitored heart rate",
        "doc_scopus_id": "85101281107",
        "doc_doi": "10.3390/s21051561",
        "doc_eid": "2-s2.0-85101281107",
        "doc_date": "2021-03-01",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Analytical Chemistry",
                "area_abbreviation": "CHEM",
                "area_code": "1602"
            },
            {
                "area_name": "Biochemistry",
                "area_abbreviation": "BIOC",
                "area_code": "1303"
            },
            {
                "area_name": "Atomic and Molecular Physics, and Optics",
                "area_abbreviation": "PHYS",
                "area_code": "3107"
            },
            {
                "area_name": "Instrumentation",
                "area_abbreviation": "PHYS",
                "area_code": "3105"
            },
            {
                "area_name": "Electrical and Electronic Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2208"
            }
        ],
        "doc_keywords": [
            "Cardiac disorders",
            "Classification trees",
            "Experimental fires",
            "Minimally invasive",
            "Occupational exposure",
            "Overall accuracies",
            "Physiological data",
            "Toxic air pollutants",
            "Carbon Monoxide",
            "Firefighters",
            "Fires",
            "Heart Rate",
            "Humans",
            "Inhalation Exposure",
            "Occupational Exposure",
            "Smoke"
        ],
        "doc_abstract": "© 2021 by the authors. Licensee MDPI, Basel, Switzerland.Smoke inhalation poses a serious health threat to firefighters (FFs), with potential effects including respiratory and cardiac disorders. In this work, environmental and physiological data were collected from FFs, during experimental fires performed in 2015 and 2019. Extending a previous work, which allowed us to conclude that changes in heart rate (HR) were associated with alterations in the inhalation of carbon monoxide (CO), we performed a HR analysis according to different levels of CO exposure during firefighting based on data collected from three FFs. Based on HR collected and on CO occupational exposure standards (OES), we propose a classifier to identify CO exposure levels through the HR measured values. An ensemble of 100 bagged classification trees was used and the classification of CO levels obtained an overall accuracy of 91.9%. The classification can be performed in real-time and can be embedded in a decision fire-fighting support system. This classification of FF’ exposure to critical CO levels, through minimally-invasive monitored HR, opens the possibility to identify hazardous situations, preventing and avoiding possible severe problems in FF’ health due to inhaled pollutants. The obtained results also show the importance of future studies on the relevance and influence of the exposure and inhalation of pollutants on the FF’ health, especially in what refers to hazardous levels of toxic air pollutants.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Classification of Anxiety Based on EDA and HR",
        "doc_scopus_id": "85102744502",
        "doc_doi": "10.1007/978-3-030-69963-5_8",
        "doc_eid": "2-s2.0-85102744502",
        "doc_date": "2021-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Computer Networks and Communications",
                "area_abbreviation": "COMP",
                "area_code": "1705"
            }
        ],
        "doc_keywords": [
            "Base-line conditions",
            "Classification tasks",
            "Classification trees",
            "Coping strategies",
            "Mobile applications",
            "Overall accuracies",
            "Physiological data",
            "Wearable devices"
        ],
        "doc_abstract": "© 2021, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.This work presents anxiety classification using physiological data, namely, EDA (eletrodermal activity) and HR (heart rate), collected with a sensing wrist-wearable device during a neutral baseline state condition. For this purpose, the WESAD public available dataset was used. The baseline condition was collected for around 20 min on 15 participants. Afterwards, to assess anxiety scores, the shortened 6-item STAI was filled by the participants. Using train and test sets with 70% and 30% of data, respectively, the proposed ensemble of 100 bagged classification trees obtained an overall accuracy of 95.7%. This, along with the high precision and recall obtained, reveal the good performance of the proposed classifier and support the ability of anxiety score classification using physiological data. Such a classification task can be integrated in a mobile application presenting coping strategies to deal and manage anxiety.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "rOral: Use of a Teledentistry System for Remote Images Assessment in Oral Health Education Workflows",
        "doc_scopus_id": "85075853819",
        "doc_doi": "10.1007/978-3-030-31635-8_103",
        "doc_eid": "2-s2.0-85075853819",
        "doc_date": "2020-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Bioengineering",
                "area_abbreviation": "CENG",
                "area_code": "1502"
            },
            {
                "area_name": "Biomedical Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2204"
            }
        ],
        "doc_keywords": [
            "Assessment activities",
            "Medical training",
            "Oral care",
            "Remote diagnosis",
            "Research teams",
            "Secure storage",
            "Teledentistry",
            "Web environment"
        ],
        "doc_abstract": "© 2020, Springer Nature Switzerland AG.Medical training in oral health includes interpreting images of the oral cavity. The use of extended datasets, real cases, and the ability to monitor the progress of students is beneficial. In this work, we investigate the feasibility of using a teledentistry solution to support medical training. The rOral integrated teledentistry solution, developed by the research team, allows the decoupling of image acquisition and image review: images of the oral cavity can be recorded using the camera of regular mobile devices, near the subject of care; the images are then uploaded to a secure storage and reviewed by experts, using a web environment. This workflow, primarily designed for remote oral health diagnosis (e.g.: population screening), can be used for dentistry education, allowing students to play the role of experts. A population of dentistry students was involved in the present study and used rOral to access anonymized cases to form a diagnosis. The results show that the existing solution, planned for remote diagnosis, is suitable for education and that smartphone-acquired images can be used in diagnosis assessment activities.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Detecting changes in the heart rate of firefighters to prevent smoke inhalation and health effects",
        "doc_scopus_id": "85065908297",
        "doc_doi": "10.1007/s12530-018-9241-0",
        "doc_eid": "2-s2.0-85065908297",
        "doc_date": "2019-06-01",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Control and Systems Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2207"
            },
            {
                "area_name": "Modeling and Simulation",
                "area_abbreviation": "MATH",
                "area_code": "2611"
            },
            {
                "area_name": "Computer Science Applications",
                "area_abbreviation": "COMP",
                "area_code": "1706"
            },
            {
                "area_name": "Control and Optimization",
                "area_abbreviation": "MATH",
                "area_code": "2606"
            }
        ],
        "doc_keywords": [
            "Change detection",
            "Decision supports",
            "Heart-rate monitoring",
            "Pollutants inhalation",
            "Well being"
        ],
        "doc_abstract": "© 2018, Springer-Verlag GmbH Germany, part of Springer Nature.Firefighters can suffer serious health problems and experience cardiac disorders derived from high pollutants inhalation. During experimental field burns, environmental and heart rate data from firefighters were collected and it was possible to observe that changes in heart rate were related with variations in pollutants inhalation. Therefore, detecting changes in heart rate may provide a good indicator to identify hazardous situations for firefighters. An automated method, based on the detection of changes in the heart rate, is proposed to prevent and to avoid serious undesirable side-effects in the health of firefighters due to pollutants inhalation. Within the experiments performed, a precision and a recall of 91.5 and 78.2%, respectively, were obtained. Furthermore, this approach can be part of a real-time decision support system for routine use in firefighting practice. Our results show the potential to provide effective support in real operational scenarios and that further research on the impact of environmental conditions in the well-being of firefighters is of utmost importance.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Fading histograms in detecting distribution and concept changes",
        "doc_scopus_id": "85030115407",
        "doc_doi": "10.1007/s41060-017-0043-4",
        "doc_eid": "2-s2.0-85030115407",
        "doc_date": "2017-05-01",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Information Systems",
                "area_abbreviation": "COMP",
                "area_code": "1710"
            },
            {
                "area_name": "Modeling and Simulation",
                "area_abbreviation": "MATH",
                "area_code": "2611"
            },
            {
                "area_name": "Computer Science Applications",
                "area_abbreviation": "COMP",
                "area_code": "1706"
            },
            {
                "area_name": "Computational Theory and Mathematics",
                "area_abbreviation": "COMP",
                "area_code": "1703"
            },
            {
                "area_name": "Applied Mathematics",
                "area_abbreviation": "MATH",
                "area_code": "2604"
            }
        ],
        "doc_keywords": [
            "Amount of information",
            "Data distribution",
            "Detection delays",
            "Dissimilarity measures",
            "Dynamic scenarios",
            "Memory restrictions",
            "Online monitoring",
            "Real applications"
        ],
        "doc_abstract": "© 2017, Springer International Publishing Switzerland.The remarkable number of real applications under dynamic scenarios is driving a novel ability to generate and gather information. Nowadays, a massive amount of information is generated at a high-speed rate, known as data streams. Moreover, data are collected under evolving environments. Due to memory restrictions, data must be promptly processed and discarded immediately. Therefore, dealing with evolving data streams raises two main questions: (i) how to remember discarded data? and (ii) how to forget outdated data? To maintain an updated representation of the time-evolving data, this paper proposes fading histograms. Regarding the dynamics of nature, changes in data are detected through a windowing scheme that compares data distributions computed by the fading histograms: the adaptive cumulative windows model (ACWM). The online monitoring of the distance between data distributions is evaluated using a dissimilarity measure based on the asymmetry of the Kullback–Leibler divergence. The experimental results support the ability of fading histograms in providing an updated representation of data. Such property works in favor of detecting distribution changes with smaller detection delay time when compared with standard histograms. With respect to the detection of concept changes, the ACWM is compared with 3 known algorithms taken from the literature, using artificial data and using public data sets, presenting better results. Furthermore, we the proposed method was extended for multidimensional and the experiments performed show the ability of the ACWM for detecting distribution changes in these settings.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Supporting the page-hinkley test with empirical mode decomposition for change detection",
        "doc_scopus_id": "85022078857",
        "doc_doi": "10.1007/978-3-319-60438-1_48",
        "doc_eid": "2-s2.0-85022078857",
        "doc_date": "2017-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Change detection",
            "Data stream",
            "Empirical Mode Decomposition",
            "Page-Hinkley",
            "Personalized approach",
            "Sliding Window"
        ],
        "doc_abstract": "© Springer International Publishing AG 2017.In the dynamic scenarios faced nowadays, when handling non stationary data streams it is of utmost importance to perform change detection tests. In this work, we propose the Intrinsic Page Hinkley Test (iPHT), which enhances the Page Hinkley Test (PHT) eliminating the user-defined parameter (the allowed magnitude of change of the data that are not considered real distribution change of the data stream) by using the second order intrinsic mode function (IMF) which is a data dependent value reflecting the intrinsic data variation. In such way, the PHT change detection method is expected to be more robust and require less tunes. Furthermore, we extend the proposed iPHT to a blockwise approach. Computing the IMF over sliding windows, which is shown to be more responsive to changes and suitable for online settings. The iPHT is evaluated using artificial and real data, outperforming the PHT.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Inhalation during fire experiments: An approach derived through ECG",
        "doc_scopus_id": "84991065620",
        "doc_doi": "10.1145/2968219.2968284",
        "doc_eid": "2-s2.0-84991065620",
        "doc_date": "2016-09-12",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Hardware and Architecture",
                "area_abbreviation": "COMP",
                "area_code": "1708"
            },
            {
                "area_name": "Software",
                "area_abbreviation": "COMP",
                "area_code": "1712"
            },
            {
                "area_name": "Information Systems",
                "area_abbreviation": "COMP",
                "area_code": "1710"
            },
            {
                "area_name": "Computer Networks and Communications",
                "area_abbreviation": "COMP",
                "area_code": "1705"
            },
            {
                "area_name": "Human-Computer Interaction",
                "area_abbreviation": "COMP",
                "area_code": "1709"
            }
        ],
        "doc_keywords": [
            "Continuous monitoring",
            "ECG derived respiration",
            "Environmental information",
            "Firefighters Smoke Exposure",
            "Health impact",
            "Operational scenario",
            "Physiological informations",
            "Smoke inhalation"
        ],
        "doc_abstract": "© 2016 ACM.During forest fire fights, firefighters are exposed to several pollutants at different concentrations, which can induce critical health problems. This study main goal is to estimate firefighters' pollutants inhalation when in operational scenarios by combining environmental and physiological information. Both exposures to CO (carbon monoxide) and physiological data, such as ECG (electrocardiogram), HR (Heart Rate) and body temperature, were monitored during firefighters' activities in experimental forest fire. From the QRS complex of ECG the ECG-derived respiration (EDR) was estimated and convoluted with pollutants concentration to estimate individual smoke inhalation. The analysis of smoke inhalations allowed to detect extensive exposures and to identify critical situations namely risk of faint due to smoke intoxication. Our results support the usefulness of continuous monitoring of both physiological and environmental information to prevent and detect hazardous situations while firefighters are in operational scenario like forest fires. The results encourage the development of a decision support system to be applied in real-Time during firefighting scenarios.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Comparing data distribution using fading histograms",
        "doc_scopus_id": "84923169171",
        "doc_doi": "10.3233/978-1-61499-419-0-1095",
        "doc_eid": "2-s2.0-84923169171",
        "doc_date": "2014-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            }
        ],
        "doc_keywords": [
            "Change detection",
            "Data distribution",
            "Detection delays",
            "Dynamic scenarios",
            "Evolving datum",
            "Kullback Leibler divergence",
            "Online monitoring",
            "Temporal applications"
        ],
        "doc_abstract": "© 2014 The Authors and IOS Press.The emergence of real temporal applications under non-stationary scenarios has drastically altered the ability to generate and gather information. Nowadays, under dynamic scenarios, potentially unbounded and massive amounts of information are generated at high-speed rate, known as data streams. Dealing with evolving data streams imposes the online monitoring of data in order to detect changes. The contribution of this paper is to present the advantage of using fading histograms to compare data distribution for change detection purposes. In an windowing scheme, data distributions provided by the fading histograms are compared using the Kullback-Leibler divergence. The experimental results support that the detection delay time is smaller when using fading histograms to represent data instead of standard histograms.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Constructing fading histograms from data streams",
        "doc_scopus_id": "84923124107",
        "doc_doi": "10.1007/s13748-014-0050-9",
        "doc_eid": "2-s2.0-84923124107",
        "doc_date": "2014-01-01",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            }
        ],
        "doc_keywords": [
            "Compact representation",
            "Data stream",
            "Dynamic environments",
            "Error constraints",
            "Fading histograms",
            "Finite data streams",
            "Massive data streams",
            "Online histograms"
        ],
        "doc_abstract": "The ability to collect data is changing drastically. Nowadays, data are gathered in the form of transient and finite data streams. Memory restrictions preclude keeping all received data in memory. When dealing with massive data streams, it is mandatory to create compact representations of data, also known as synopses structures or summaries. Reducing memory occupancy is of utmost importance when handling a huge amount of data. This paper addresses the problem of constructing histograms from data streams under error constraints. When constructing online histograms from data streams there are two main characteristics to embrace: the updating facility and the error of the histogram. Moreover, in dynamic environments, besides the need of compact summaries to capture the most important properties of data, it is also essential to forget old data. Therefore, this paper presents sliding histograms and fading histograms, an abrupt and a smooth strategies to forget outdated data. © 2014 Springer-Verlag Berlin Heidelberg.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "On evaluating stream learning algorithms",
        "doc_scopus_id": "84874677467",
        "doc_doi": "10.1007/s10994-012-5320-9",
        "doc_eid": "2-s2.0-84874677467",
        "doc_date": "2013-03-01",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Software",
                "area_abbreviation": "COMP",
                "area_code": "1712"
            },
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            }
        ],
        "doc_keywords": [
            "Bayes error",
            "Best practices",
            "Change detection",
            "Change detection algorithms",
            "Concept drifts",
            "Continuous process",
            "Data stream",
            "Decision models",
            "Error estimators",
            "Evaluation design",
            "Fading factors",
            "Forgetting mechanisms",
            "Hypothesis testing",
            "Memoryless",
            "Performance assessment",
            "Prequential analysis",
            "Resource aware",
            "Sliding Window",
            "Streaming applications"
        ],
        "doc_abstract": "Most streaming decision models evolve continuously over time, run in resource-aware environments, and detect and react to changes in the environment generating data. One important issue, not yet convincingly addressed, is the design of experimental work to evaluate and compare decision models that evolve over time. This paper proposes a general framework for assessing predictive stream learning algorithms. We defend the use of prequential error with forgetting mechanisms to provide reliable error estimators. We prove that, in stationary data and for consistent learning algorithms, the holdout estimator, the prequential error and the prequential error estimated over a sliding window or using fading factors, all converge to the Bayes error. The use of prequential error with forgetting mechanisms reveals to be advantageous in assessing performance and in comparing stream learning algorithms. It is also worthwhile to use the proposed methods for hypothesis testing and for change detection. In a set of experiments in drift scenarios, we evaluate the ability of a standard change detection algorithm to detect change using three prequential error estimators. These experiments point out that the use of forgetting mechanisms (sliding windows or fading factors) are required for fast and efficient change detection. In comparison to sliding windows, fading factors are faster and memoryless, both important requirements for streaming applications. Overall, this paper is a contribution to a discussion on best practice for performance assessment when learning is a continuous process, and the decision models are dynamic and evolve over time. © 2012 The Author(s).",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Real-time algorithm for changes detection in depth of anesthesia signals",
        "doc_scopus_id": "84874143472",
        "doc_doi": "10.1007/s12530-012-9063-4",
        "doc_eid": "2-s2.0-84874143472",
        "doc_date": "2013-03-01",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Control and Systems Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2207"
            },
            {
                "area_name": "Modeling and Simulation",
                "area_abbreviation": "MATH",
                "area_code": "2611"
            },
            {
                "area_name": "Computer Science Applications",
                "area_abbreviation": "COMP",
                "area_code": "1706"
            },
            {
                "area_name": "Control and Optimization",
                "area_abbreviation": "MATH",
                "area_code": "2606"
            }
        ],
        "doc_keywords": [
            "Change detection algorithms",
            "Depth of anesthesia",
            "Dynamic behaviors",
            "Forgetting factors",
            "Forgetting mechanisms",
            "General anesthesias",
            "Real time algorithms",
            "Real-time decision support systems"
        ],
        "doc_abstract": "This paper presents a real-time algorithm for changes detection in depth of anesthesia signals. A Page-Hinkley test (PHT) with a forgetting mechanism (PHT-FM) was developed. The samples are weighted according to their \"age\" so that more importance is given to recent samples. This enables the detection of the changes with less time delay than if no forgetting factor was used. The performance of the PHT-FM was evaluated in a two-fold approach. First, the algorithm was run offline in depth of anesthesia (DoA) signals previously collected during general anesthesia, allowing the adjustment of the forgetting mechanism. Second, the PHT-FM was embedded in a real-time software and its performance was validated online in the surgery room. This was performed by asking the clinician to classify in real-time the changes as true positives, false positives or false negatives. The results show that 69 % of the changes were classified as true positives, 26 % as false positives, and 5 % as false negatives. The true positives were also synchronized with changes in the hypnotic or analgesic rates made by the clinician. The contribution of this work has a high impact in the clinical practice since the PHT-FM alerts the clinician for changes in the anesthetic state of the patient, allowing a more prompt action. The results encourage the inclusion of the proposed PHT-FM in a real-time decision support system for routine use in the clinical practice. © 2012 Springer-Verlag.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Contributions to a decision support system based on depth of anesthesia signals",
        "doc_scopus_id": "84867324839",
        "doc_doi": "10.1109/CBMS.2012.6266382",
        "doc_eid": "2-s2.0-84867324839",
        "doc_date": "2012-10-16",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Radiology, Nuclear Medicine and Imaging",
                "area_abbreviation": "MEDI",
                "area_code": "2741"
            },
            {
                "area_name": "Computer Science Applications",
                "area_abbreviation": "COMP",
                "area_code": "1706"
            }
        ],
        "doc_keywords": [
            "Abdominal surgery",
            "Automatic Detection",
            "Clinical practices",
            "Depth of anesthesia",
            "Minimally invasive",
            "Sensor fault",
            "Therapeutic procedures"
        ],
        "doc_abstract": "In the clinical practice the concerns about the administration of hypnotics and analgesics for minimally invasive diagnostics and therapeutic procedures have enormously increased in the past years. The automatic detection of changes in the signals used to evaluate the depth of anesthesia is hence of foremost importance in order to decide how to adapt the doses of hypnotics and analgesics that should be administered to patients. The aim of this work is to online detect drifts in the referred depth of anesthesia signals of patients undergoing general anesthesia. The performance of the proposed method is illustrated using BIS records previously collected from patients subject to abdominal surgery. The results show that the drifts detected by the proposed method are in accordance with the actions of the clinicians in terms of times where a change in the hypnotic or analgesic rates had occurred. This detection was performed under the presence of noise and sensor faults. The presented algorithm was also online validated. The results encourage the inclusion of the proposed algorithm in a decision support system based on depth of anesthesia signals. © 2012 IEEE.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Online evaluation of a changes detection algorithm for depth of anesthesia signals ?",
        "doc_scopus_id": "84881059400",
        "doc_doi": "10.3182/20120829-3-HU-2029.00076",
        "doc_eid": "2-s2.0-84881059400",
        "doc_date": "2012-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Control and Systems Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2207"
            }
        ],
        "doc_keywords": [
            "Changes detections",
            "Data ow analysis",
            "Depth of anesthesia",
            "Detection of changes",
            "Dynamic behaviors",
            "General anesthesias",
            "Minimally invasive",
            "Therapeutic procedures"
        ],
        "doc_abstract": "The detection of changes in the signals used to evaluate the depth of anesthesia of patients undergoing surgery is of foremost importance. This detection allows to decide how to adapt the doses of hypnotics and analgesics to be administered to patients for minimally invasive diagnostics and therapeutic procedures. This paper presents an algorithm based on the Page-Hinkley test to automatically detect changes in the referred depth of anesthesia signals of patients undergoing general anesthesia. The performance of the proposed method is evaluated online using data from patients subject to surgery. The results show that most of the detected changes are in accordance with the actions of the clinicians in terms of times where a change in the hypnotic or analgesic rates had occurred. This detection was performed under the presence of noise and sensor faults. The results encourage the inclusion of the proposed algorithm in a decision support system based on depth of anesthesia signals. © 2012 IFAC.",
        "available": true,
        "clean_text": "serial JL 314898 291210 291718 291882 291883 31 IFAC Proceedings Volumes IFACPROCEEDINGSVOLUMES 2016-04-16 2016-04-21 2016-04-16 2016-04-21 2012-09-14 2016-04-21T07:44:06 S1474-6670(16)32122-X S147466701632122X 10.3182/20120829-3-HU-2029.00076 S350 S350.2 HEAD-AND-TAIL 2022-06-08T09:31:00.192018Z 0 0 20120101 20121231 2012 2016-04-16T12:15:59.460582Z rawtext articleinfo articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid hubeid indexeddate isbn isbns isbnnorm isbnsnorm issfirst issn issnnorm issuelist itemstage itemtransactionid itemweight openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sortorder srctitle srctitlenorm srctype ssids content subj tomb vol volfirst volissue volumelist yearnav affil articletitle auth authfirstini authfull authkeywords authlast primabst ref 1474-6670 14746670 978-3-902823-10-6 9783902823106 false 45 45 18 18 Volume 45, Issue 18 61 343 348 343 348 2012 2012 2012-01-01 2012-12-31 2012 8th IFAC Symposium on Biological and Medical Systems article fla Copyright © 2012 IFAC. Published by Elsevier Ltd. All rights reserved. ONLINEEVALUATIONACHANGESDETECTIONALGORITHMFORDEPTHANESTHESIASIGNALS SEBASTIAO R ABSALOM 2011 516 518 A BASSEVILLE 1987 M DETECTIONABRUPTCHANGESTHEORYAPPLICATIONS GAN 1997 808 815 T KAUL 2002 323 332 H LIU 2011 546 557 N MASHOUR 2009 273 277 G MINTO 2000 1603 1616 C ORTOLANI 2002 644 648 O PAGE 1954 100 115 E RAMPIL 1998 980 1002 I SELBST 2000 864 865 S STRUYS 2002 803 816 M VIERTIOOJA 2004 154 161 H SEBASTIAOX2012X343 SEBASTIAOX2012X343X348 SEBASTIAOX2012X343XR SEBASTIAOX2012X343X348XR item S1474-6670(16)32122-X S147466701632122X 10.3182/20120829-3-HU-2029.00076 314898 2016-04-21T10:24:33.026044-04:00 2012-01-01 2012-12-31 true 563722 MAIN 6 72751 849 656 IMAGE-WEB-PDF 1 8th IFAC Symposium on Biological and Medical Systems The International Federation of Automatic Control August 29-31, 2012. Budapest, Hungary Online evaluation of a changes detection algorithm for depth of anesthesia signals Raquel Sebasti~o , Margarida M. Silva ,, a Rui Rabi¸o Jo~o Gama , Teresa Mendon¸a , c a c LIAAD-INESC Porto, L.A., Universidade do Porto, Rua de Ceuta, 118, 6, 4050-190 Porto, Portugal Dep. de Matem´tica, Fac. Ci^ncias da Universidade do Porto, a e Rua do Campo Alegre, 4169-007 Porto, Portugal Div. Systems and Control, Dep. Information Technology, Uppsala University, Box 337, SE-751 05 Uppsala, Sweden Center for Research & Development in Mathematics and Applications, Departamento de Matem´tica, Campus Universit´rio de a a Santiago, 3810-193 Aveiro, Portugal Unidade Local de Sa´de de Matosinhos, Porto, Portugal u Fac. Economia da Universidade do Porto, Rua Dr. Roberto Frias, 4200-464 Porto, Portugal Abstract: The detection of changes in the signals used to evaluate the depth of anesthesia of patients undergoing surgery is of foremost importance. This detection allows to decide how to adapt the doses of hypnotics and analgesics to be administered to patients for minimally invasive diagnostics and therapeutic procedures. This paper presents an algorithm based on the Page-Hinkley test to automatically detect changes in the referred depth of anesthesia signals of patients undergoing general anesthesia. The performance of the proposed method is evaluated online using data from patients subject to surgery. The results show that most of the detected changes are in accordance with the actions of the clinicians in terms of times where a change in the hypnotic or analgesic rates had occurred. This detection was performed under the presence of noise and sensor faults. The results encourage the inclusion of the proposed algorithm in a decision support system based on depth of anesthesia signals. Keywords: Adaptive systems, Changes detection algorithms, Data flow analysis, Dynamic behavior 1. BACKGROUND, CHALLENGES AND AIM Aiming to induce general anesthesia to patients undergoing surgery a combination of different anesthetic drugs is commonly used. The clinicians manipulate the amount of drugs to be given to each patient in order to achieve an adequate overall anesthetic state taking into account the three main components of anesthesia: muscle relaxation, analgesia and hypnosis. Muscle relaxation is achieved by the administration of muscle relaxants and it is quantified by the neuromuscular blockade (NMB), measured from an evoked electromyography at the hand of the patient. Analgesia and hypnosis are strongly connected in what concerns the Depth of Anesthesia (DoA). For pain relief (analgesia), the dedicated administration of opioids is usually performed. Nevertheless, due to lack of reliable sensors to directly and quantitatively measure the level of The work of R. Sebasti~o and M. M. Silva is supported by a Funda¸~o para a Ci^ncia e a Tecnologia (FCT) under the PhD ca e Grants SFRH/BD/41569/2007 and SFRH/BD/60973/2009, respectively. This work has been developed in the context of the Projects GALENO - Modeling and Control for Personalized Drug Administration (PTDC/SAU-BEB/103667/2008) and KDUDS Knowledge Discovery from Ubiquitous Data Streams (PTDC/EIAEIA/098355/2008). analgesia, the patient's analgesic state is usually inferred by the clinician through the observation of some clinical signals such as the electroencephalogram (EEG), the heart rate, and the blood pressure. Hypnosis is the component related with unconsciousness, for which there are many available indices, e.g. Index of Consciousness (IoC), Jensen et al. (2008), Auditory Evoked Potentials (AEP), Struys et al. (2002), Spectral Entropy (SE), Vierti¨-Oja et al. o (2004), and Bispectral Index (BIS), Gan (1997), Kaul and Bharti (2002). The BIS is the most widely used index to infer the DoA of a patient, being related with the responsiveness level and the probability of intraoperative recall, Kaul and Bharti (2002), Ortolani et al. (2002). It is an index derived from the EEG, Gan (1997), through the combination of the time domain, frequency domain and high order spectral variables, Rampil (1998), Kaul and Bharti (2002). The BIS represents the DoA in a dimensionless continuous scale ranging from 0 (equivalent to the absence of brain activity) to 97.7 (representing a fully awake and alert state). Values between 40 to 60 indicate an adequate BIS level for general anesthesia, Rampil (1998), Luginbuhl and Schnider (2002). In the clinical practice the concerns about the administration of hypnotics and analgesics for minimally invasive 10.3182/20120829-3-HU-2029.00076 978-3-902823-10-6/12/$20.00 © 2012 IFAC 343 8th IFAC Symposium on Biological and Medical Systems August 29-31, 2012. Budapest, Hungary diagnostic and therapeutic procedures have enormously increased during the past years. The hypnotics and analgesics usually interact with each other, Minto et al. (2000), such that the use of both drugs often enhances the final effect. This interaction poses difficulties to assess the correct dosage of each drug needed during the surgery. These drawbacks, and the fact that the patient's response to anesthesia changes over the time-course of the surgery, make the ability to monitor and control the DoA one of the main challenges of modern anesthesia. At present, research groups working in the anesthesia field are focused on the development of advisory systems to be incorporated in automatic control platforms of DoA, Mashour et al. (2009), Absalom et al. (2011), Liu et al. (2011). The detection of changes in the DoA signals has paramount importance in the adaptation of the drug doses needed to achieve an optimum degree of comfort while avoiding undesirable side-effects, Selbst (2000). Changes in DoA signals may occur due to changes in the patient hypnosis or analgesia levels (intrinsic factors) or due to external factors, such as intubations, incisions or other painful stimuli. The development and analysis of change detection algorithms and control strategies for the NMB play an important role in this actual challenge, Silva et al. (2009). Owing to the characteristics of the DoA problem it is necessary to carefully re-designed the overall strategy. As a matter of fact there are different features mainly concerning the clinical sensors, the acting time and the signals that increase the difficulty to attain a robust and reliable advisory system for the automatic control of the DoA. The main contribution of this work is the development of an algorithm to detect changes in the BIS of patients undergoing surgery. The performance of the proposed method is evaluated online using BIS records of patients subjected to general anesthesia. The main advantage of this validation is to correctly identify the changes in the BIS which are correlated with the changes in the patient's DoA level and may be a warning to adjust the drugs, allowing individual adaptation of the administered dose of anesthetics. The automatic online detection of changes in the BIS signals acknowledges triggering a decision support system for the DoA. The remainder of this paper is organized as follows. The clinical data used in this study is presented in Section 2. Section 3 describes the methodology to detect changes in the data, while Section 4 shows the results. Concluding remarks and possibilities for further research are presented in Section 5. 2. CLINICAL DATA: BIS MEASUREMENTS The proposed changes detection algorithm is embedded in the software system GALENO: Computer Aided System for Modeling, Monitoring and Control in Anesthesia. The GALENO software records and stores the physiological data monitored during an anesthesia episode, the anesthetic protocols that are used, and the administered drug rates. Besides fault detection monitoring, this system also incorporates communication message decoding, graphic data presentation, signal filtering, model identification and control, Paz et al. (2011). To evaluate the performance of the changes detection algorithm presented in this paper, the clinicians validated the changes that were detected online on clinical data from 78 patients undergoing abdominal surgery. The patients were 56±14 years old, 71.8±16.4 kg and 70 female. The hypnotic propofol and the analgesic remifentanil were intravenously administrated. The DoA was manually controlled by the clinician who changed the drug doses according to clinical requirements using as reference the patient's vital signs and BIS. BIS, hemodynamic parameters and drug rates were recorded, with a frequency of 1/5 s-1 . The surgeries had an average duration of 123±66 minutes. 3. PHT-FM FOR CHANGES DETECTION IN DOA SIGNALS The Page-Hinkley test (PHT) was selected among other change detection algorithms because is easy to implement and the time required to evaluate the examples is reduced. The changes detection in the signals must be performed on the flow and the low computational complexity of the PHT makes it appropriated to use in this context. The PHT is a sequential adaptation of the detection of an abrupt change in the average of a Gaussian signal, Basseville and Nikiforov (1987), and is commonly used to online detect changes in signal processing, Gama et al. (2009), Mouss et al. (2004), Page (1954). This algorithm considers two cumulative variables UT and LT , defined as the cumulated difference between the observed values and their mean until the current moment: T UT = t=1 T (xt - xT - ) ¯ LT = t=1 t (xt - xT + ) ¯ where xT = 1/T ¯ t=1 xt , T is the index of the current sample and corresponds to the magnitude of changes that are allowed. Note that the index of samples is reseted every time a change is detected. The minimum and maximum value of these variables are also computed: mT = min(Ut , t = 1 . . . T ) and MT = max(Lt , t = 1 . . . T ), respectively. As a final step, the PHT consists of running two tests in parallel, each one to detect increases or decreases in the signal. This test monitors the difference between the cumulative variable (UT ) and its minimum (mT ) and the difference between the cumulative variable (LT ) and its maximum value (MT ), respectively. When one of these differences is greater than a given threshold () the test alarm a change in the distribution. Since the PHT is applied to dynamic data and in swift and evolving environments old data is usually less important than recent one, this method was enhanced with a forgetting mechanism (PHT-FM), resulting in the following tests: For increase cases: U0 = 0 344 8th IFAC Symposium on Biological and Medical Systems August 29-31, 2012. Budapest, Hungary T -1 UT -1 + (xT - xT - ) ¯ T mT = min (Ut , t = 1 . . . T ) UT = P HU = UT - mT For decrease cases: L0 = 0 T -1 LT = LT -1 + (xT - xT + ) ¯ T MT = max (Lt , t = 1 . . . T ) P HL = MT - LT where T is the current time, xT is the variable value at time T , and is a tuning parameter, highly dependent of the characteristics of the signal under study. The value of this parameter is chosen to avoid false detections due to noise, taking into account the magnitude of changes that should not trigger an alarm. In these equations, the forgetting mechanism is the weight of the variables UT -1 and LT -1 in the update process. -1 Since the ratio T T increases with time, the recent samples have more importance in the update process than the older ones. With this forgetting mechanism, the algorithm will be able to earlier detect both abrupt (sudden) and gradual (slow) drifts. At every instant the two P H statistics (P HU and P HL ) are monitored and a change is reported whenever one of them is above a given threshold . This threshold parameter is chosen considering a tradeoff between admissible false alarm rates and delay time detections. Therefore, increasing the algorithm will entail fewer false alarms but might miss some true changes. Figure 1 illustrates how the PHT works. The upper plot plots the trace of the initial phase of a BIS signal used in this study. As it can be observed, two drifts occur around minutes 14 and 17 due to a decrease in the BIS signal. The bottom plot represents the evolution of the statistic test P HL and the detection threshold (). As it can be observed, the PH statistic test follows both decreases in the signal. The parameter should guarantee that the algorithm, while being resilient to false alarms, can detect and react to changes as soon as they occur, decreasing the delay time of the detections. Controlling this detection threshold parameter, a tradeoff between the false positive alarms and the miss detections is established. 4. RESULTS AND DISCUSSION An extensive offline analysis has been previously conducted in order to adjust the PHT-FM input parameters. The and the parameters were set to 20 and 10, respectively, Sebasti~o et al. (2012). a 4.1 Online validation Figure 2 shows records of patients undergoing mastectomies. For each case, the top plot shows the BIS signal and the detected changes by the PHT-FM (indicated by a vertical line and arrows pointing upwards if a increase in the BIS signal was detected and pointing downwards if a decrease in the BIS was detected). According to the clinicians' validation, the changes are also marked as TP (True Positive), FP (False Positive) or FN (False Negative). The same representation was used in all cases in the aforementioned database. A TP represents a correctly detected drift, a FP, also known as type I error, indicates the error of detecting a drift when the signal is stable and a FN, also known as type II error, corresponds to the error of not detecting a change when in fact there exists one. The changes that were not validated are marked as nC (not classified). As shown in the two upper plots of Fig. 2, the change around minute 6, consequence the administration of the initial bolus of propofol, is detected by the algorithm, as expected, and evaluated as TP by the clinician. The PHTFM consistently detects the decreases of the BIS signal as a result of this propofol bolus, as it can also be observed later at minute 10. Although validated as TP, the changes detected around minute 50 were neither consequences nor followed by any clinical action. To counterpoint this, around minute 65, the clinician validated as FP a detected change. These situations intend to illustrate the difficulties that the problem under study poses to the development of change detection algorithms, namely the false positive detections due to noise present in the BIS signals. Around minute 70 a detection of an increase in the BIS is marked as TP and is followed by the administration of a propofol bolus by the clinician. As expected, after this bolus the BIS decreases which is detected by the PHT-FM. The second detection of this change is validated as TP by the clinician. This is one example where the online use of this algorithm may be advantageous: advised by the algorithm of this increase the clinician could act more promptly. The last changes detections, classified as TP, were result of the end of drugs administration. The middle plots in Fig. 2 show a different clinical case. After the administration of the initial bolus of propofol the PHT-FM detected two decreases and later (around minute 25) another one as the result of the accommodation of the BIS to this dose (all classified by the clinicians as TP). After a stable period with values within the range inside [40,60], the BIS signal increases, which was detected by the PHT-FM. This change, evaluated as TP, resulted in Fig. 1. The upper plot shows the initial phase of a BIS signal used in this study. The bottom plot represents the evolution of the PH statistic and the detection threshold . 345 8th IFAC Symposium on Biological and Medical Systems August 29-31, 2012. Budapest, Hungary Fig. 2. Example of the detected changes in a BIS signal of three clinical cases in the database. The upper plots of each case show the BIS signal, the detected changes (indicated by a vertical line and arrows) and the clinicians evaluation. The bottom plot of each case shows the propofol and remifentanil doses (ml/h). 346 8th IFAC Symposium on Biological and Medical Systems August 29-31, 2012. Budapest, Hungary an administration of a propofol bolus by the clinician. As a result of this administration, the BIS decreases and this change is evaluated as TP. From minute 40 to minute 60 the BIS signal remains stable around a mean value of 45. Around minute 60 the algorithm detects another increase, classified as TP leading to an administration of a propofol bolus. However, this dosage was not enough to reduce the BIS signal which remain with an increasing behavior that was identified by the PHT-FM around minute 65. As a consequence, in order to avoid that the BIS increases, the clinician administrated another propofol bolus. After these administrations, the BIS recovered to the clinical reference range which was also detected by the PHT-FM (around minute 75). Later, two false positive detections exist (the PHT-FM alarmed these changes without evident existence of any). It should be noted that the noisy level of these signals poses difficulties to this algorithm and often noise can be confused with smooth drigts, alarming a change when the signal remains stable and raising the rate of false positives. The latest algorithm's detections (validated as TP) are a consequence of the end of drugs administration due to the end of the surgery. The two bottom plots of Fig. 2 show a clinical case where the PHT-FM missed a change, identified as FN (around minute 60). The first three detected decreases, classified as TP by the clinician, are the result of the accommodation of the BIS to the initial dose of propofol. Around minute 25 the PHT-FM detects an increase in the BIS. The administration of a propofol bolus follows this increase in order to maintain the BIS in the predefined target window. A rise in the BIS around minute 40 is also detected by the algorithm and succeeded by decrease in the signal despite any clinical action. These two detections were result of an incision. Since the BIS was back to the clinical window of [40,60] in a short time, these changes were classified as FP. Around minute 70, a TP detection is followed by a decrease in the propofol rate. Approaching the end of the surgery, the drugs administration was ended, and the algorithm, as expected, detected two increases in the BIS signal (both validated as TP). 4.2 Evaluation metrics To evaluate the performance of the PHT-FM, quality metrics such as Precision and Recall were computed. The Precision gives a ratio between the correct detected changes (TP) and all the detected changes (TP+FP). The Recall is defined as a ratio between the correct detected changes and all the occurred changes (TP+FN). For all cases in the database, the obtained results were a Precision of 72% and a Recall of 93%. For both quality metrics, the closer to 100% the better the results are. Considering that the changee detection algorithm is implemented online, it is not possible to avoid the presence of noise and sensor faults. Therefore, it should be stressed out, that the clinicians' validations were only taken into account if the quality of the BIS signal was greater or equal to 50%. Likewise, some of the detected changes were not classified (those were not considered in the following measurements). Table 1 shows the evaluation metrics corresponding to the online clinicians' validation. The True Negatives (TN), representing the stable points where the algorithm did not detect a drift were not assessed. Table 1. Confusion matrix. Drift 660 48 708 Real No Drift 255 X 255 Total Total 915 48 963 Detected Drift No Drift Total The above figures and Table 1 show that the PHT-FM identifies increasing and decreasing behaviors of the BIS, detecting the most significant changes in the signal and missing few ones, even in the presence of noise. It should be noted that, in most of the cases, the detected changes by the PHT-FM are related with an action of the clinicians. Some false positives were noticed. However those are not a major concern since clinicians might be advised and then decide based upon their experience taking into account patients' vital signals. Those results sustain the feasibility of the proposed method as an auxiliary decision support system in surgeries to monitor the DoA. 5. CONCLUDING REMARKS The Page-Hinkley test with a forgetting mechanism (PHTFM) was implemented and tuned to detect drifts in BIS signals from patients under general anesthesia. The developed PHT-FM algorithm consistently reveals the increasing and decreasing behaviors of the BIS signals under study. The good performance of the algorithm when applied to the real records encourage an extended online clinical validation. The online evaluations obtained so far, support the incorporation of this changes detection algorithm in a robust and reliable online decision support system based on DoA monitoring for general anesthesia procedures. It should be noted that the environment of the application and the specific features of the BIS signal, namely the high level noise present in the measurements, point to further improvements of this detection algorithm. The development of a dedicate online filter to smooth the BIS signals is a task to be addressed in the near future in order to improve the obtained results. ACKNOWLEDGEMENTS The authors gratefully acknowledge Dr. Manuel Seabra and his colleagues from Unidade Local de Sa´de de u Matosinhos, Matosinhos, Portugal, for their participation in data collection and collaboration in the results analysis. REFERENCES A. R. Absalom, R. De Keyser and M. M. R. F. Struys. Closed Loop Anesthesia: Are We Getting Close to Finding the Holy Grail? Anesthesia & Analgesia, vol:112(3), pages 516­518, March 2011. M. Basseville and I. Nikiforov. Detection of abrupt changes: theory and applications. Prentice-Hall Inc, 1987. J. Gama, R. Sebasti~o and P. P. Rodrigues. Issues in a evaluation of stream learning algorithms. Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 329­338, ACM Press, New York, NY, 2009. 347 8th IFAC Symposium on Biological and Medical Systems August 29-31, 2012. Budapest, Hungary T. J. Gan, P. S. Glass, A. Windsor, F. Payne, C. Rosow, P. Sebel and P. Manberg. Bispectral index monitoring allows faster emergence and improved recovery from propofol, alfentanil and nitrous oxide anaesthesia. Anesthesiology, vol. 87(4), pages 808­15, October 1997. E. W. Jensen, M. Jospin, P. L. Gambus, M. Vallverdu and P. Caminal. Validation of the Index of Consciousness (IoC) during sedation/analgesia for ultrasonographic endoscopy. Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society, pages 5552­5555, August 2008. H. L. Kaul and N. Bharti. Monitoring depth of anaesthesia. Indian Journal of Anaesthesia, vol:46(4), pages 323­332, August 2002. N. Liu, T. Chazot, S. Hamada, A. Landais, N. Boichut, C. Dussaussoy, B. Trillat, L. Beydon, E. Samain, D. I. Sessler and M. Fischler. Closed-Loop Coadministration of Propofol and Remifentanil Guided by Bispectral Index: A Randomized Multicenter Study. Anesthesia & Analgesia, vol:112(3), pages 546­557, March 2011. M. Luginbuhl and T. W. Schnider. Detection of awareness with the bispectral index: two case reports. Anesthesiology, vol:96(1), pages 241­243, January 2002. G. Mashour, R. Esaki, J. Vandervest, A. Shanks and S. Kheterpal. A novel electronic algorithm for detecting potentially insufficient anesthesia: implications for the prevention of intraoperative awareness. Journal of Clinical Monitoring and Computing, vol:23(5), pages 273­277, October 2009. C. F. Minto, T. W. Schnider, T. G. Short, K. M. Gregg, A. Gentilini and S. L. Shafer. Response Surface Model for Anesthetic Drug Interactions. Anesthesiology, vol:92(6), pages 1603­1616, June 2000. H. Mouss, D. Mouss, N. Mouss and L. Sefouhi. Test of Page-Hinkley, an approach for fault detection in an agro-alimentary production system. Proceedings of the 5th Asian Control Conference, pages 815­818, IEEE Computer Society, 2004. O. Ortolani, A. Conti, A. Di Filippo, C. Adembri, E. Moraldi, A. Evangelisti, M. Maggini and S. J. Roberts. EEG signal processing in anaesthesia. Use of a neural network technique for monitoring depth of anaesthesia. British Journal of Anaesthesia, vol:88(5), pages 644­ 648, May 2002. E. S. Page. Continuous inspection schemes. Biometrika, vol:41(1-2), pages 100­115, June 1954. L. A. Paz, J. Almeida, M. M. Silva, T. Mendon¸a, S. c Esteves and B. Andrade. Integrated design system for monitoring digital processing and control in anesthesia. American Society of Anesthesiologists Annual Meeting 2011, Chicago, Illinois, October 2011. I. J. Rampil. A primer for EEG signal processing in anesthesia. Anesthesiology, vol:89(4), pages 980­1002, October 1998. R. Sebasti~o, M. M. Silva, J. Gama and T. Mendon¸a. a c Contributions to a Decision Support System Based on Depth of Anesthesia Signals. Proceedings of the 25th IEEE International Symposium on Computer-Based Medical Systems (accepted for publication). S. M. Selbst. Adverse sedation events in pediatrics: a critical incident analysis of contributing factors. Pediatrics, vol:10(4), pages 864­865, April 2000. M. M. Silva, C. Sousa, R. Sebasti~o, J. Gama, T. Mena don¸a, P. Rocha and S. Esteves. Total mass TCI driven c by parametric estimation. Proceedings of the IEEE Mediterranean Conference on Control and Automation, pages 1149­1154, June 2009. M. M. R. F. Struys, E. W. Jensen, W. Smith, N. Ty Smith, I. Rampil, F. J. E. Dumortier, C. Mestach and E. P. Mortier. Performance of the ARX-derived auditory evoked potential index as an indicator of anesthetic depth: a comparison with bispectral index and hemodynamic measures during propofol administration. Anesthesiology, vol:96(4), pages 803­816, April 2002. H. Vierti¨-Oja, V. Maja, M. S¨rkel¨, P. Talja, N. Tenkao a a nen, H. Tolvanen-Laakso, M. Paloheimo, A. Vakkuri, A. Yli-Hankala and P. Meril¨inen. Description of the a entropy algorithm as applied in the Datex-Ohmeda S/5 Entropy Module. Acta Anaesthesiol Scand, vol:48(2), pages 154­161, February 2004. 348 Biological and Medical Systems August 29-31, 2012. Budapest, Hungary T. J. Gan, P. S. Glass, A. Windsor, F. Payne, C. Rosow, P. Sebel and P. Manberg. Bispectral index monitoring allows faster emergence and improved recovery from propofol, alfentanil and nitrous oxide anaesthesia. Anesthesiology, vol. 87(4), pages 808­15, October 1997. E. W. Jensen, M. Jospin, P. L. Gambus, M. Vallverdu and P. Caminal. Validation of the Index of Consciousness (IoC) during sedation/analgesia for ultrasonographic endoscopy. Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society, pages 5552­5555, August 2008. H. L. Kaul and N. Bharti. Monitoring depth of anaesthesia. Indian Journal of Anaesthesia, vol:46(4), pages 323­332, August 2002. N. Liu, T. Chazot, S. Hamada, A. Landais, N. Boichut, C. Dussaussoy, B. Trillat, L. Beydon, E. Samain, D. I. Sessler and M. Fischler. Closed-Loop Coadministration of Propofol and Remifentanil Guided by Bispectral Index: A Randomized Multicenter Study. Anesthesia & Analgesia, vol:112(3), pages 546­557, March 2011. M. Luginbuhl and T. W. Schnider. Detection of awareness with the bispectral index: two case reports. Anesthesiology, vol:96(1), pages 241­243, January 2002. G. Mashour, R. Esaki, J. Vandervest, A. Shanks and S. Kheterpal. A novel electronic algorithm for detecting potentially insufficient anesthesia: implications for the prevention of intraoperative awareness. Journal of Clinical Monitoring and Computing, vol:23(5), pages 273­277, October 2009. C. F. Minto, T. W. Schnider, T. G. Short, K. M. Gregg, A. Gentilini and S. L. Shafer. Response Surface Model for Anesthetic Drug Interactions. Anesthesiology, vol:92(6), pages 1603­1616, June 2000. H. Mouss, D. Mouss, N. Mouss and L. Sefouhi. Test of Page-Hinkley, an approach for fault detection in an agro-alimentary production system. Proceedings of the 5th Asian Control Conference, pages 815­818, IEEE IPV 32122 S1474-6670(16)32122-X 10.3182/20120829-3-HU-2029.00076 IFAC The work of R. Sebastião and M. M. Silva is supported by Fundação para a Ciěncia e a Tecnologia (FCT) under the PhD Grants SFRH/BD/41569/2007 and SFRH/BD/60973/2009, respectively. This work has been developed in the context of the Projects GALENO - Modeling and Control for Personalized Drug Administration (PTDC/SAU-BEB/103667/2008) and KDUDS - Knowledge Discovery from Ubiquitous Data Streams (PTDC/EIA-EIA/098355/2008). Online evaluation of a changes detection algorithm for depth of anesthesia signals Raquel Sebastião * ** Margarida M. Silva ** *** **** Rui Rabiço † João Gama * ‡ Teresa Mendonça ** *** * LIAAD-INESC Porto, L.A., Universidade do Porto, Rua de Ceuta, 118, 6, 4050-190 Porto, Portugal LIAAD-INESC Porto L.A. Universidade do Porto Rua de Ceuta, 118, 6 Porto 4050-190 Portugal ** Dep. de Matemática, Fac. Ciěncias da Universidade do Porto, Rua do Campo Alegre, 4169-007 Porto, Portugal Dep. de Matemática Fac. Ciěncias da Universidade do Porto Rua do Campo Alegre Porto 4169-007 Portugal *** Div. Systems and Control, Dep. Information Technology, Uppsala University, Box 337, SE-751 05 Uppsala, Sweden Div. Systems and Control Dep. Information Technology Uppsala University Box 337 Uppsala SE-751 05 Sweden **** Center for Research & Development in Mathematics and Applications, Departamento de Matemática, Campus Universitário de Santiago, 3810-193 Aveiro, Portugal Center for Research & Development in Mathematics and Applications Departamento de Matemática Campus Universitário de Santiago Aveiro 3810-193 Portugal † Unidade Local de Saúde de Matosinhos, Porto, Portugal Unidade Local de Saúde de Matosinhos Porto Portugal ‡ Fac. Economia da Universidade do Porto, Rua Dr. Roberto Frias, 4200-464 Porto, Portugal Fac. Economia da Universidade do Porto Rua Dr. Roberto Frias Porto 4200-464 Portugal The detection of changes in the signals used to evaluate the depth of anesthesia of patients undergoing surgery is of foremost importance. This detection allows to decide how to adapt the doses of hypnotics and analgesics to be administered to patients for minimally invasive diagnostics and therapeutic procedures. This paper presents an algorithm based on the Page-Hinkley test to automatically detect changes in the referred depth of anesthesia signals of patients undergoing general anesthesia. The performance of the proposed method is evaluated online using data from patients subject to surgery. The results show that most of the detected changes are in accordance with the actions of the clinicians in terms of times where a change in the hypnotic or analgesic rates had occurred. This detection was performed under the presence of noise and sensor faults. The results encourage the inclusion of the proposed algorithm in a decision support system based on depth of anesthesia signals. Keywords Adaptive systems Changes detection algorithms Data flow analysis Dynamic behavior References Absalom et al., 2011 A.R. Absalom R. De Keyser M.M.R.F. Struys Closed Loop Anesthesia: Are We Getting Close to Finding the Holy Grail? Anesthesia & Analgesia 112 3 2011 516 518 vol:, March Basseville and Nikiforov, 1987 M. Basseville I. Nikiforov Detection of abrupt changes: theory and applications 1987 Prentice-Hall Inc Gama et al., 2009 J. Gama, R. Sebastião and P. P. Rodrigues. Issues in evaluation of stream learning algorithms. Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 329-338, ACM Press, New York, NY, 2009. Gan et al., October 1997 T.J. Gan P.S. Glass A. Windsor F. Payne C. Rosow P. Sebel P. Manberg Bispectral index monitoring allows faster emergence and improved recovery from propofol, alfentanil and nitrous oxide anaesthesia Anesthesiology 87 4 October 1997 808 815 vol Jensen et al., 2008 E. W. Jensen, M. Jospin, P. L. Gambus, M. Vallverdu and P. Caminal. Validation of the Index of Consciousness (IoC) during sedation/analgesia for ultrasonographic endoscopy. Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society, pages 5552-5555, August 2008. Kaul and Bharti, August 2002 H.L. Kaul N. Bharti Monitoring depth of anaesthesia Indian Journal of Anaesthesia 46 4 August 2002 323 332 vol: Liu et al., March 2011 N. Liu T. Chazot S. Hamada A. Landais N. Boichut C. Dussaussoy B. Trillat L. Beydon E. Samain D.I. Sessler M. Fischler Closed-Loop Coadministration of Propofol and Remifentanil Guided by Bispectral Index: A Randomized Multicenter Study Anesthesia & Analgesia 112 3 March 2011 546 557 vol: Luginbuhl, 2002 M. Luginbuhl and T. W. Schnider. Detection of awareness with the bispectral index: two case reports. Anesthesiology, vol:96(1), pages 241-243, January 2002. Mashour et al., October 2009 G. Mashour R. Esaki J. Vandervest A. Shanks S. Kheterpal A novel electronic algorithm for detecting potentially insufficient anesthesia: implications for the prevention of intraoperative awareness Journal of Clinical Monitoring and Computing 23 5 October 2009 273 277 vol: Minto et al., June 2000 C.F. Minto T.W. Schnider T.G. Short K.M. Gregg A. Gentilini S.L. Shafer Response Surface Model for Anesthetic Drug Interactions Anesthesiology 92 6 June 2000 1603 1616 vol: Mouss et al., 2004 H. Mouss, D. Mouss, N. Mouss and L. Sefouhi. Test of Page-Hinkley, an approach for fault detection in an agro-alimentary production system. Proceedings of the 5th Asian Control Conference, pages 815-818, IEEE Computer Society, 2004. Ortolani et al., May 2002 O. Ortolani A. Conti A. Di Filippo C. Adembri E. Moraldi A. Evangelisti M. Maggini S.J. Roberts EEG signal processing in anaesthesia. Use of a neural network technique for monitoring depth of anaesthesia British Journal of Anaesthesia 88 5 May 2002 644 648 vol: Page, June 1954 E.S. Page Continuous inspection schemes Biometrika 41 1-2 June 1954 100 115 vol: Paz et al., 2011 L. A. Paz, J. Almeida, M. M. Silva, T. Mendonça, S. Esteves and B. Andrade. Integrated design system for monitoring digital processing and control in anesthesia. American Society of Anesthesiologists Annual Meeting 2011, Chicago, Illinois, October 2011. Rampil, October 1998 I.J. Rampil A primer for EEG signal processing in anesthesia Anesthesiology 89 4 October 1998 980 1002 vol: Sebastião et al. R. Sebastião, M. M. Silva, J. Gama and T. Mendonça. Contributions to a Decision Support System Based on Depth of Anesthesia Signals. Proceedings of the 25th IEEE International Symposium on Computer-Based Medical Systems (accepted for publication). Selbst, April 2000 S.M. Selbst Adverse sedation events in pediatrics: a critical incident analysis of contributing factors Pediatrics 10 4 April 2000 864 865 Vol: Silva et al., 2009 M. M. Silva, C. Sousa, R. Sebastião, J. Gama, T. Mendonça, P. Rocha and S. Esteves. Total mass TCI driven by parametric estimation. Proceedings of the IEEE Mediterranean Conference on Control and Automation, pages 1149-1154, June 2009. Struys et al., April 2002 M.M.R.F. Struys E.W. Jensen W. Smith N. Ty Smith I. Rampil F.J.E. Dumortier C. Mestach E.P. Mortier Performance of the ARX-derived auditory evoked potential index as an indicator of anesthetic depth: a comparison with bispectral index and hemodynamic measures during propofol administration Anesthesiology 96 4 April 2002 803 816 Vol: Viertiö-Oja et al., February 2004 H. Viertiö-Oja V. Maja M. Särkelä P. Talja N. Tenkanen H. Tolvanen-Laakso M. Paloheimo A. Vakkuri A. Yli-Hankala P. Meriläinen Description of the entropy algorithm as applied in the Datex-Ohmeda S/5 Entropy Module Acta Anaesthesiol Scand 48 2 February 2004 154 161 Vol: "
    },
    {
        "doc_title": "Contributions to an advisory system for changes detection in depth of anesthesia signals",
        "doc_scopus_id": "84891930961",
        "doc_doi": null,
        "doc_eid": "2-s2.0-84891930961",
        "doc_date": "2011-12-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Anesthesia",
            "Bispectral index",
            "Change detection",
            "Clinical environments",
            "General anesthesias",
            "Online learning algorithms",
            "Surgical procedures",
            "Therapeutic procedures"
        ],
        "doc_abstract": "In the clinical practice the concerns about the administration of hypnotics and analgesics for minimally invasive diagnostics and therapeutic procedures have enormously increased in recent years. The automatic detection of changes in the signals used to evaluate the depth of anesthesia is hence of foremost importance in order to decide how to adapt administered doses to patients undergoing surgical procedures. The aim of this work is to online detect changes in depth of anesthesia signals of patients undergoing general anesthesia. The performance of the proposed method is evaluated using bispectral index records. The results show that the changes detected by the proposed method are in accordance with the actions of the clinicians. This fact and the good results that were obtained support the online validation of the proposed advisory system for changes detection in depth of anesthesia signal in a real clinical environment.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Improving cardiotocography monitoring: A memory-less stream learning approach Position Paper",
        "doc_scopus_id": "84891919356",
        "doc_doi": null,
        "doc_eid": "2-s2.0-84891919356",
        "doc_date": "2011-12-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Cardiotocography",
            "Fading statistics",
            "Fetal heart rate",
            "Learning approach",
            "Monitoring system",
            "Permanent damage",
            "Quantitative parameters",
            "Uterine contractions"
        ],
        "doc_abstract": "Cardiotocography is widely used, all over the world, for fetal heart rate and uterine contractions monitoring before (antepartum) and during (intrapartum) labor, regarding the detection of fetuses in danger of death or permanent damage. However, analysis of cardiotocogram tracings remains a large and unsolved issue. State-of-the-art monitoring systems provide quantitative parameters that are difficult to assess by the human eye. These systems also trigger alerts for changes in the behavior of the signals. However, they usually take up to 10 min to detect these different behaviors. Previous work using machine learning for concept drift detection has successfully achieved faster results in the detection of such events. Our aim is to extend the monitoring system with memory-less fading statistics, which have been successfully applied in drift detection and statistical tests, to improve detection of alarming events.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "New results on minimum error entropy decision trees",
        "doc_scopus_id": "81855161442",
        "doc_doi": "10.1007/978-3-642-25085-9_42",
        "doc_eid": "2-s2.0-81855161442",
        "doc_date": "2011-11-28",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Alternative algorithms",
            "entropy-of-error",
            "Error entropy",
            "Error performance",
            "New results",
            "node split criteria",
            "Real-world datasets"
        ],
        "doc_abstract": "We present new results on the performance of Minimum Error Entropy (MEE) decision trees, which use a novel node split criterion. The results were obtained in a comparive study with popular alternative algorithms, on 42 real world datasets. Carefull validation and statistical methods were used. The evidence gathered from this body of results show that the error performance of MEE trees compares well with alternative algorithms. An important aspect to emphasize is that MEE trees generalize better on average without sacrifing error performance. © 2011 Springer-Verlag.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Monitoring incremental histogram distribution for change detection in data streams",
        "doc_scopus_id": "77957913416",
        "doc_doi": "10.1007/978-3-642-12519-5_2",
        "doc_eid": "2-s2.0-77957913416",
        "doc_date": "2010-10-20",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Adaptive Cumulative Windows",
            "Change detection",
            "Data stream",
            "Learning histograms",
            "Machine-learning"
        ],
        "doc_abstract": "Histograms are a common technique for density estimation and they have been widely used as a tool in exploratory data analysis. Learning histograms from static and stationary data is a well known topic. Nevertheless, very few works discuss this problem when we have a continuous flow of data generated from dynamic environments. The scope of this paper is to detect changes from high-speed time-changing data streams. To address this problem, we construct histograms able to process examples once at the rate they arrive. The main goal of this work is continuously maintain a histogram consistent with the current status of the nature. We study strategies to detect changes in the distribution generating examples, and adapt the histogram to the most recent data by forgetting outdated data. We use the Partition Incremental Discretization algorithm that was designed to learn histograms from high-speed data streams. We present a method to detect whenever a change in the distribution generating examples occurs. The base idea consists of monitoring distributions from two different time windows: the reference window, reflecting the distribution observed in the past; and the current window which receives the most recent data. The current window is cumulative and can have a fixed or an adaptive step depending on the distance between distributions. We compared both distributions using Kullback-Leibler divergence, defining a threshold for change detection decision based on the asymmetry of this measure. We evaluated our algorithm with controlled artificial data sets and compare the proposed approach with nonparametric tests. We also present results with real word data sets from industrial and medical domains. Those results suggest that an adaptive window's step exhibit high probability in change detection and faster detection rates, with few false positives alarms. © 2010 Springer-Verlag Berlin Heidelberg.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Drift severity metric",
        "doc_scopus_id": "77956031241",
        "doc_doi": "10.3233/978-1-60750-606-5-1119",
        "doc_eid": "2-s2.0-77956031241",
        "doc_date": "2010-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            }
        ],
        "doc_keywords": [
            "Concept drifts",
            "Data stream",
            "Drift rates"
        ],
        "doc_abstract": "Concept drift in data is usually considered only as abrupt or gradual thus referring to the speed of change. Such simple distinguishing by speed is sufficient for most of the problems, but there might be situations for which a finer representation would be of use. This paper studies further the phenomenon of concept drift and introduces a simple measure which is relevant to the speed and amount of change between different concepts. © 2010 The authors and IOS Press. All rights reserved.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Change detection in climate data over the Iberian Peninsula",
        "doc_scopus_id": "77951175741",
        "doc_doi": "10.1109/ICDMW.2009.27",
        "doc_eid": "2-s2.0-77951175741",
        "doc_date": "2009-12-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Computational Theory and Mathematics",
                "area_abbreviation": "COMP",
                "area_code": "1703"
            },
            {
                "area_name": "Computer Vision and Pattern Recognition",
                "area_abbreviation": "COMP",
                "area_code": "1707"
            },
            {
                "area_name": "Software",
                "area_abbreviation": "COMP",
                "area_code": "1712"
            }
        ],
        "doc_keywords": [
            "Change detection",
            "Change detection algorithms",
            "Climate data",
            "Cluster structure",
            "Data sets",
            "Geographical correlation",
            "Geographical information",
            "Graphical representations",
            "Iberian Peninsula",
            "McNemar",
            "Non-parametric statistical tests",
            "Physical locations",
            "Temporal Data",
            "Temporal drifts",
            "Time change",
            "Time drift",
            "Visualization tools"
        ],
        "doc_abstract": "This paper addresses the space-time change detection problem in climate data over the Iberian Peninsula using a 50 years dataset. The data were analyzed concerning the temporal and geographical information, using the following methodology: information about space-time drifts in climate data was obtained by applying a change detection algorithm on all the temporal data available for each physical location considered in this study; the performance and the robustness of this algorithm were then assessed by the McNemar nonparametric statistical test on cluster structures; geographical correlations were inferred using visualization tools and graphical representations of data. Most of the space-temporal drifts detected by the algorithm were confirmed by the results of the McNemar test and are in accordance with visual and graphical representations, supporting the advantage of using inter-disciplinary methods. This analysis also shows that there are locations which do not reveal any change along all the observed years. © 2009 IEEE.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Evaluating algorithms that learn from data streams",
        "doc_scopus_id": "72949119714",
        "doc_doi": "10.1145/1529282.1529616",
        "doc_eid": "2-s2.0-72949119714",
        "doc_date": "2009-12-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Software",
                "area_abbreviation": "COMP",
                "area_code": "1712"
            }
        ],
        "doc_keywords": [
            "Data stream",
            "Decision models",
            "Evaluating algorithms",
            "Evaluation Method",
            "Non-stationary environment",
            "Research areas",
            "Resource aware",
            "Sequential error",
            "Sliding Window"
        ],
        "doc_abstract": "Learning from data streams is a research area of increasing importance. Nowadays, several stream learning algorithms have been developed. Most of them learn decision models that continuously evolve over time, run in resource-aware environments, and detect and react to changes in the environment generating data. One important issue, not yet conveniently addressed, is the design of experimental work to evaluate and compare decision models that evolve over time. In this paper we propose a general framework for assessing the quality of streaming learning algorithms. We defend the use of Predictive Sequential error estimates over a sliding window to assess performance of learning algorithms that learn from open-ended data streams in non-stationary environments. This paper studies properties of convergence and methods to comparatively assess algorithms performance. Copyright 2009 ACM.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Regression trees from data streams with drift detection",
        "doc_scopus_id": "71049127519",
        "doc_doi": "10.1007/978-3-642-04747-3_12",
        "doc_eid": "2-s2.0-71049127519",
        "doc_date": "2009-11-16",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Change detection",
            "Concept drift",
            "Data stream",
            "Regression trees",
            "Stream data mining"
        ],
        "doc_abstract": "The problem of extracting meaningful patterns from time changing data streams is of increasing importance for the machine learning and data mining communities. We present an algorithm which is able to learn regression trees from fast and unbounded data streams in the presence of concept drifts. To our best knowledge there is no other algorithm for incremental learning regression trees equipped with change detection abilities. The FIRT-DD algorithm has mechanisms for drift detection and model adaptation, which enable to maintain accurate and updated regression models at any time. The drift detection mechanism is based on sequential statistical tests that track the evolution of the local error, at each node of the tree, and inform the learning process for the detected changes. As a response to a local drift, the algorithm is able to adapt the model only locally, avoiding the necessity of a global model adaptation. The adaptation strategy consists of building a new tree whenever a change is suspected in the region and replacing the old ones when the new trees become more accurate. This enables smooth and granular adaptation of the global model. The results from the empirical evaluation performed over several different types of drift show that the algorithm has good capability of consistent detection and proper adaptation to concept drifts. © 2009 Springer Berlin Heidelberg.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Issues in evaluation of stream learning algorithms",
        "doc_scopus_id": "70350664414",
        "doc_doi": "10.1145/1557019.1557060",
        "doc_eid": "2-s2.0-70350664414",
        "doc_date": "2009-11-09",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Software",
                "area_abbreviation": "COMP",
                "area_code": "1712"
            },
            {
                "area_name": "Information Systems",
                "area_abbreviation": "COMP",
                "area_code": "1710"
            }
        ],
        "doc_keywords": [
            "Change detection",
            "Concept drift",
            "Data stream",
            "Data streams",
            "Decision models",
            "Error estimates",
            "Error estimators",
            "Evaluation design",
            "Fading factors",
            "Hypothesis testing",
            "Illustrative examples",
            "McNemar",
            "Non-stationary environment",
            "Page-Hinkley",
            "Performance assessment",
            "Research areas",
            "Resource aware",
            "Sequential methods",
            "Sliding Window",
            "Streaming applications"
        ],
        "doc_abstract": "Learning from data streams is a research area of increasing importance. Nowadays, several stream learning algorithms have been developed. Most of them learn decision models that continuously evolve over time, run in resource-aware environments, detect and react to changes in the environment generating data. One important issue, not yet conveniently addressed, is the design of experimental work to evaluate and compare decision models that evolve over time. There are no golden standards for assessing performance in non-stationary environments. This paper proposes a general framework for assessing predictive stream learning algorithms. We defend the use of Predictive Sequential methods for error estimate { the prequential error. The prequential error allows us to monitor the evolution of the performance of models that evolve over time. Nevertheless, it is known to be a pessimistic estimator in comparison to holdout estimates. To obtain more reliable estimators we need some forgetting mechanism. Two viable alternatives are: sliding windows and fading factors. We observe that the prequential error converges to an holdout estimator when estimated over a sliding window or using fading factors. We present illustrative examples of the use of prequential error estimators, using fading factors, for the tasks of: i) assessing performance of a learning algorithm; ii) comparing learning algorithms; iii) hypothesis testing using McNemar test; and iv) change detection using Page-Hinkley test. In these tasks, the prequential error estimated using fading factors provide reliable estimators. In comparison to sliding windows, fading factors are faster and memory-less, a requirement for streaming applications. This paper is a contribution to a discussion in the good-practices on performance assessment when learning dynamic models that evolve over time. Copyright 2009 ACM.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Decision trees using the minimum Entropy-of-error principle",
        "doc_scopus_id": "70349306674",
        "doc_doi": "10.1007/978-3-642-03767-2_97",
        "doc_eid": "2-s2.0-70349306674",
        "doc_date": "2009-09-28",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Binary decision trees",
            "Class distributions",
            "Generalization properties",
            "Minimum entropy",
            "Neural network training",
            "New concept",
            "Node split criteria",
            "Univariate"
        ],
        "doc_abstract": "Binary decision trees based on univariate splits have traditionally employed so-called impurity functions as a means of searching for the best node splits. Such functions use estimates of the class distributions. In the present paper we introduce a new concept to binary tree design: instead of working with the class distributions of the data we work directly with the distribution of the errors originated by the node splits. Concretely, we search for the best splits using a minimum entropy-of-error (MEE) strategy. This strategy has recently been applied in other areas (e.g. regression, clustering, blind source separation, neural network training) with success. We show that MEE trees are capable of producing good results with often simpler trees, have interesting generalization properties and in the many experiments we have performed they could be used without pruning. © 2009 Springer Berlin Heidelberg.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Total mass TCI driven by parametric estimation",
        "doc_scopus_id": "85011390069",
        "doc_doi": "10.1109/MED.2009.5164701",
        "doc_eid": "2-s2.0-85011390069",
        "doc_date": "2009-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Control and Systems Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2207"
            }
        ],
        "doc_keywords": [
            "Bayesian identification",
            "Compartmental systems",
            "Fixed intervals",
            "Neuromuscular blockade",
            "Parameter uncertainty",
            "Parametric estimation",
            "Recovery detection",
            "Transient phase"
        ],
        "doc_abstract": "© 2019 Elsevier B.V.. All rights reserved.This paper presents the total mass target controlled infusion algorithm. The system comprises an on line tuned algorithm for recovery detection (OLARD) after an initial bolus administration and a Bayesian identification method for parametric estimation based on sparse measurements of the accessible signal. To design the drug dosage profile, two algorithms are here proposed. During the transient phase, an input variance control (IVC) algorithm is used. It is based on the concept of TCI and aims to steer the drug effect to a predefined target value within an a priori fixed interval of time. After the steady state phase is reached the drug dose regimen is controlled by a total mass control (TMC) algorithm. The mass control law for compartmental systems is robust even in the presence of parameter uncertainties. The whole system feasibility has been evaluated for the case of neuromuscular blockade (NMB) level and was tested both in simulation and in real cases.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Learning from data streams: Synopsis and change detection",
        "doc_scopus_id": "84875949106",
        "doc_doi": "10.3233/978-1-58603-893-9-163",
        "doc_eid": "2-s2.0-84875949106",
        "doc_date": "2008-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            }
        ],
        "doc_keywords": [
            "Change detection",
            "Current problems",
            "Data distribution",
            "Data stream",
            "High speed flows",
            "Learning histograms",
            "Memory algorithms",
            "Modern applications"
        ],
        "doc_abstract": "The aim of this PhD program is the study of algorithms for learning histograms, with the capacity of representing continuous high-speed flows of data and dealing with the current problem of change detection on data streams. In many modern applications, information is no longer gathered as finite stored data sets, but assuming the form of infinite data streams. As a large volume of information is produced at a high-speed rate it is no longer possible to use memory algorithms which require the full historic data stored in the main memory, so new ones are needed to process data online at the rate it is available. Moreover, the process generating data is not strictly stationary and evolves over time; so algorithms should, while extracting some sort of knowledge from this incessantly growing data, be able to adapt themselves to changes, maintaining a representation consistent with the most recent status of nature. In this work, we presented a feasible approach, using incremental histograms and monitoring data distributions, to detect concept drift in data stream context. © 2008 The authors and IOS Press. All rights reserved.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Visual phenotype in Williams-Beuren syndrome challenges magnocellular theories explaining human neurodevelopmental visual cortical disorders",
        "doc_scopus_id": "36849026198",
        "doc_doi": "10.1172/JCI32556",
        "doc_eid": "2-s2.0-36849026198",
        "doc_date": "2007-12-01",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Medicine (all)",
                "area_abbreviation": "MEDI",
                "area_code": "2700"
            }
        ],
        "doc_keywords": [],
        "doc_abstract": "Williams-Beuren syndrome (WBS), a neurodevelopmental genetic disorder whose manifestations include visuospatial impairment, provides a unique model to link genetically determined loss of neural cell populations at different levels of the nervous system with neural circuits and visual behavior. Given that several of the genes deleted in WBS are also involved in eye development and the differentiation of retinal layers, we examined the retinal phenotype in WBS patients and its functional relation to global motion perception. We discovered a low-level visual phenotype characterized by decreased retinal thickness, abnormal optic disk concavity, and impaired visual responses in WBS patients compared with age-matched controls by using electrophysiology, confocal and coherence in vivo imaging with cellular resolution, and psychophysics. These mechanisms of impairment are related to the magnocellular pathway, which is involved in the detection of temporal changes in the visual scene. Low-level magnocellular performance did not predict high-level deficits in the integration of motion and 3D information at higher levels, thereby demonstrating independent mechanisms of dysfunction in WBS that will require remediation strategies different from those used in other visuospatial disorders. These findings challenge neurodevelopmental theories that explain cortical deficits based on low-level magnocellular impairment, such as regarding dyslexia.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Change detection in learning histograms from data streams",
        "doc_scopus_id": "38349032865",
        "doc_doi": "10.1007/978-3-540-77002-2_10",
        "doc_eid": "2-s2.0-38349032865",
        "doc_date": "2007-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Change detection",
            "Histograms"
        ],
        "doc_abstract": "In this paper we study the problem of constructing histograms from high-speed time-changing data streams. Learning in this context requires the ability to process examples once at the rate they arrive, maintaining a histogram consistent with the most recent data, and forgetting out-date data whenever a change in the distribution is detected. To construct histogram from high-speed data streams we use the two layer structure used in the Partition Incremental Discretization (PiD) algorithm. Our contribution is a new method to detect whenever a change in the distribution generating examples occurs. The base idea consists of monitoring distributions from two different time windows: the reference time window, that reflects the distribution observed in the past; and the current time window reflecting the distribution observed in the most recent data. We compare both distributions and signal a change whenever they are greater than a threshold value, using three different methods: the Entropy Absolute Difference, the Kullback-Leibler divergence and the Cosine Distance. The experimental results suggest that Kullback-Leibler divergence exhibit high probability in change detection, faster detection rates, with few false positives alarms. © Springer-Verlag Berlin Heidelberg 2007.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Face recognition from spatially-morphed video sequences",
        "doc_scopus_id": "33749658613",
        "doc_doi": "10.1007/11867661_33",
        "doc_eid": "2-s2.0-33749658613",
        "doc_date": "2006-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Human face visual information",
            "Image acquisition",
            "Video sequences"
        ],
        "doc_abstract": "The aim of the present work is the recognition of human face visual information, in order to automatically control the access to restricted areas, granting access to authorized \"clients\" and barring the entrance to \"impostors\". The vision system assembled performed the image acquisition, processing and recognition by first creating a database with a single view of each \"client\" and then by using multiple test images of each individual candidate to access. To get the test images, a video sequence was captured during the individual's approach path to the camera. Because subjects presented themselves in a random pose before the camera, the synthesis of frontal views was incorporated, by using a view-morphing method. The modelling and the recognition were handled through the use of ICA methods. The identification of valid \"clients\" was fully successful. In order to check the rejection of \"impostors\", a leave-one-out test was performed which gave promising results. © Springer-Verlag Berlin Heidelberg 2006.",
        "available": false,
        "clean_text": ""
    }
]