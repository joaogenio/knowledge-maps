{"item": {"ait:process-info": {"ait:status": {"@state": "update", "@type": "core", "@stage": "S300"}, "ait:date-delivered": {"@day": "13", "@timestamp": "2021-11-13T07:08:34.000034-05:00", "@year": "2021", "@month": "11"}, "ait:date-sort": {"@day": "01", "@year": "2014", "@month": "01"}}, "bibrecord": {"head": {"author-group": [{"affiliation": {"country": "Portugal", "@afid": "60024825", "@country": "prt", "organization": {"$": "Department of Electronics, Telecomunications, and Informatics, University of Aveiro"}, "affiliation-id": {"@afid": "60024825", "@dptid": "104251958"}, "@dptid": "104251958"}, "author": [{"ce:given-name": "Jo\u00e3o", "preferred-name": {"ce:given-name": "Jo\u00e3o", "ce:initials": "J.", "ce:surname": "Cunha", "ce:indexed-name": "Cunha J."}, "@seq": "1", "ce:initials": "J.", "@_fa": "true", "@type": "auth", "ce:surname": "Cunha", "@auid": "57188533953", "ce:indexed-name": "Cunha J."}, {"ce:given-name": "Rui", "preferred-name": {"ce:given-name": "Rui", "ce:initials": "R.", "ce:surname": "Serra", "ce:indexed-name": "Serra R."}, "@seq": "2", "ce:initials": "R.", "@_fa": "true", "@type": "auth", "ce:surname": "Serra", "@auid": "55973150400", "ce:indexed-name": "Serra R."}, {"ce:given-name": "Nuno", "preferred-name": {"ce:given-name": "Nuno", "ce:initials": "N.", "ce:surname": "Lau", "ce:indexed-name": "Lau N."}, "@seq": "3", "ce:initials": "N.", "@_fa": "true", "@type": "auth", "ce:surname": "Lau", "@auid": "13907323500", "ce:indexed-name": "Lau N."}, {"ce:given-name": "Lu\u00eds Seabra", "preferred-name": {"ce:given-name": "Lu\u00eds Seabra", "ce:initials": "L.S.", "ce:surname": "Lopes", "ce:indexed-name": "Lopes L.S."}, "@seq": "4", "ce:initials": "L.S.", "@date-locked": "2018-03-05T12:19:10.460", "@_fa": "true", "@type": "auth", "ce:surname": "Lopes", "@auid": "7102509123", "ce:indexed-name": "Lopes L.S."}, {"ce:given-name": "Ant\u00f3nio J.R.", "preferred-name": {"ce:given-name": "Ant\u00f3nio J.R.", "ce:initials": "A.J.R.", "ce:surname": "Neves", "ce:indexed-name": "Neves A.J.R."}, "@seq": "5", "ce:initials": "A.J.R.", "@_fa": "true", "@type": "auth", "ce:surname": "Neves", "@auid": "43461712600", "ce:indexed-name": "Neves A.J.R."}]}, {"affiliation": {"country": "Portugal", "@afid": "60079336", "@country": "prt", "organization": {"$": "Institute of Electronics and Telematics Engineering of Aveiro, University of Aveiro"}, "affiliation-id": [{"@afid": "60079336"}, {"@afid": "60024825"}]}, "author": [{"ce:given-name": "Jo\u00e3o", "preferred-name": {"ce:given-name": "Jo\u00e3o", "ce:initials": "J.", "ce:surname": "Cunha", "ce:indexed-name": "Cunha J."}, "@seq": "1", "ce:initials": "J.", "@_fa": "true", "@type": "auth", "ce:surname": "Cunha", "@auid": "57188533953", "ce:indexed-name": "Cunha J."}, {"ce:given-name": "Nuno", "preferred-name": {"ce:given-name": "Nuno", "ce:initials": "N.", "ce:surname": "Lau", "ce:indexed-name": "Lau N."}, "@seq": "3", "ce:initials": "N.", "@_fa": "true", "@type": "auth", "ce:surname": "Lau", "@auid": "13907323500", "ce:indexed-name": "Lau N."}, {"ce:given-name": "Lu\u00eds Seabra", "preferred-name": {"ce:given-name": "Lu\u00eds Seabra", "ce:initials": "L.S.", "ce:surname": "Lopes", "ce:indexed-name": "Lopes L.S."}, "@seq": "4", "ce:initials": "L.S.", "@date-locked": "2018-03-05T12:19:10.460", "@_fa": "true", "@type": "auth", "ce:surname": "Lopes", "@auid": "7102509123", "ce:indexed-name": "Lopes L.S."}, {"ce:given-name": "Ant\u00f3nio J.R.", "preferred-name": {"ce:given-name": "Ant\u00f3nio J.R.", "ce:initials": "A.J.R.", "ce:surname": "Neves", "ce:indexed-name": "Neves A.J.R."}, "@seq": "5", "ce:initials": "A.J.R.", "@_fa": "true", "@type": "auth", "ce:surname": "Neves", "@auid": "43461712600", "ce:indexed-name": "Neves A.J.R."}]}], "citation-title": "Learning robotic soccer controllers with the Q-Batch update-rule", "abstracts": "Robotic soccer provides a rich environment for the development of Reinforcement Learning controllers. The competitive environment imposes strong requirements on performance of the developed controllers. RL offers a valuable alternative for the development of efficient controllers while avoiding the hassle of parameter tuning a hand coded policy. This paper presents the application of a recently proposed Batch RL update-rule to learn robotic soccer controllers in the context of the RoboCup Middle Size League. The Q-Batch update-rule exploits the episodic structure of the data collection phase of Batch RL to efficiently evaluate and improve the learned policy. Three different learning tasks, with increasing difficulty, were developed and applied on a simulated environment and later on the physical robot. The performance of the learned controllers is mostly compared to hand-tuned controllers while some comparisons with other RL methods were performed. Results show that the proposed approach is able to learn the tasks in a reduced amount of time, even outperforming existing hand-coded solutions. \u00a9 2014 IEEE.", "citation-info": {"citation-type": {"@code": "cp"}, "citation-language": {"@language": "English", "@xml:lang": "eng"}, "abstract-language": {"@language": "English", "@xml:lang": "eng"}}, "source": {"sourcetitle-abbrev": "IEEE Int. Conf. Auton. Robot Syst. Compet., ICARSC", "@country": "usa", "issuetitle": "2014 IEEE International Conference on Autonomous Robot Systems and Competitions, ICARSC 2014", "volisspag": {"pagerange": {"@first": "134", "@last": "139"}}, "@type": "p", "publicationyear": {"@first": "2014"}, "additional-srcinfo": {"conferenceinfo": {"confpublication": {"procpagerange": "var.pagings"}, "confevent": {"confname": "2014 IEEE International Conference on Autonomous Robot Systems and Competitions, ICARSC 2014", "confsponsors": {"confsponsor": [{"$": "IEEE Portugal Section"}, {"$": "IEEE Portugal Section RA Chapter"}, {"$": "Sociedade Portuguesa de Robotica (SPR)"}], "@complete": "y"}, "confcatnumber": "CFP1482X-ART", "conflocation": {"city-group": "Espinho", "@country": "prt"}, "confcode": "106646", "confdate": {"enddate": {"@day": "15", "@year": "2014", "@month": "05"}, "startdate": {"@day": "14", "@year": "2014", "@month": "05"}}}}}, "publisher": {"publishername": "IEEE Computer Society", "ce:e-address": {"$": "help@computer.org", "@type": "email"}}, "sourcetitle": "2014 IEEE International Conference on Autonomous Robot Systems and Competitions, ICARSC 2014", "article-number": "6849775", "@srcid": "21100326085", "publicationdate": {"year": "2014", "date-text": {"@xfab-added": "true", "$": "2014"}}}, "enhancement": {"classificationgroup": {"classifications": [{"@type": "ASJC", "classification": [{"$": "1702"}, {"$": "2207"}]}, {"@type": "CPXCLASS", "classification": [{"classification-code": "461.3", "classification-description": "Biomechanics"}, {"classification-code": "723.4", "classification-description": "Artificial Intelligence"}, {"classification-code": "731.5", "classification-description": "Robotics"}, {"classification-code": "732.1", "classification-description": "Control Equipment"}]}, {"@type": "FLXCLASS", "classification": {"classification-code": "902", "classification-description": "FLUIDEX; Related Topics"}}, {"@type": "SUBJABBR", "classification": [{"$": "COMP"}, {"$": "ENGI"}]}]}}}, "item-info": {"copyright": {"$": "Copyright 2014 Elsevier B.V., All rights reserved.", "@type": "Elsevier"}, "dbcollection": [{"$": "CPX"}, {"$": "SCOPUS"}, {"$": "Scopusbase"}], "history": {"date-created": {"@day": "05", "@year": "2014", "@month": "08"}}, "itemidlist": {"itemid": [{"$": "373639580", "@idtype": "PUI"}, {"$": "364495361", "@idtype": "CAR-ID"}, {"$": "20143218020608", "@idtype": "CPX"}, {"$": "84905017754", "@idtype": "SCP"}, {"$": "84905017754", "@idtype": "SGR"}], "ce:doi": "10.1109/ICARSC.2014.6849775"}}, "tail": {"bibliography": {"@refcount": "12", "reference": [{"ref-fulltext": "R. S. Sutton and A. G. Barto, Reinforcement learning: An introduction. Cambridge (MA): MIT Press, 1998.", "@id": "1", "ref-info": {"ref-publicationyear": {"@first": "1998"}, "refd-itemidlist": {"itemid": {"$": "0004102479", "@idtype": "SGR"}}, "ref-text": "Cambridge (MA MIT Press", "ref-authors": {"author": [{"@seq": "1", "ce:initials": "R.S.", "@_fa": "true", "ce:surname": "Sutton", "ce:indexed-name": "Sutton R.S."}, {"@seq": "2", "ce:initials": "A.G.", "@_fa": "true", "ce:surname": "Barto", "ce:indexed-name": "Barto A.G."}]}, "ref-sourcetitle": "Reinforcement Learning: An Introduction"}}, {"ref-fulltext": "M. A. Wiering and M. van Otterlo, Eds., Reinforcement Learning: State of the Art, ser. Adaptation, Learning, and Optimization. Springer, 2012, vol. 12.", "@id": "2", "ref-info": {"ref-publicationyear": {"@first": "2012"}, "refd-itemidlist": {"itemid": {"$": "84873574800", "@idtype": "SGR"}}, "ref-volisspag": {"pagerange": {"@first": "12"}}, "ref-text": "ser. Adaptation, Learning, and Optimization. Springer", "ref-authors": {"author": [{"@seq": "1", "ce:initials": "M.A.", "@_fa": "true", "ce:surname": "Wiering", "ce:indexed-name": "Wiering M.A."}, {"@seq": "2", "ce:initials": "M.", "@_fa": "true", "ce:surname": "Van Otterlo", "ce:indexed-name": "Van Otterlo M."}]}, "ref-sourcetitle": "Reinforcement Learning: State of the Art"}}, {"ref-fulltext": "C. Szepesv\u0301ari, Algorithms for Reinforcement Learning, ser. Synthesis Lectures on Artificial Intelligence and Machine Learning, R. J. Brachman and T. G. Dietterich, Eds. Morgan & Claypool, 2010.", "@id": "3", "ref-info": {"ref-publicationyear": {"@first": "2010"}, "refd-itemidlist": {"itemid": {"$": "77955790905", "@idtype": "SGR"}}, "ref-text": "ser. Synthesis Lectures on Artificial Intelligence and Machine Learning, R. J. Brachman and T. G. Dietterich, Eds. Morgan & Claypool", "ref-authors": {"author": [{"@seq": "1", "ce:initials": "C.", "@_fa": "true", "ce:surname": "Szepesv\u0301ari", "ce:indexed-name": "Szepesvari C."}]}, "ref-sourcetitle": "Algorithms for Reinforcement Learning"}}, {"ref-fulltext": "S. Lange, T. Gabel, and M. Riedmiller, \"Batch Reinforcement Learning,\" in Reinforcement Learning: State of the Art, M. Wiering and M. van Otterlo, Eds. Springer, 2012, ch. 2, pp. 45-74.", "@id": "4", "ref-info": {"ref-publicationyear": {"@first": "2012"}, "ref-title": {"ref-titletext": "Batch reinforcement learning"}, "refd-itemidlist": {"itemid": {"$": "85036626464", "@idtype": "SGR"}}, "ref-volisspag": {"pagerange": {"@first": "45", "@last": "74"}}, "ref-text": "M. Wiering and M. van Otterlo, Eds. Springer ch. 2", "ref-authors": {"author": [{"@seq": "1", "ce:initials": "S.", "@_fa": "true", "ce:surname": "Lange", "ce:indexed-name": "Lange S."}, {"@seq": "2", "ce:initials": "T.", "@_fa": "true", "ce:surname": "Gabel", "ce:indexed-name": "Gabel T."}, {"@seq": "3", "ce:initials": "M.", "@_fa": "true", "ce:surname": "Riedmiller", "ce:indexed-name": "Riedmiller M."}]}, "ref-sourcetitle": "Reinforcement Learning: State of the Art"}}, {"ref-fulltext": "M. Riedmiller and H. Braun, \"A direct adaptive method for faster backropagation learning: the RPROP algorithm,\" in Proceedings of the IEEE International Conference on Neural Networks, H. Ruspini, Ed., San Francisco, CA, 1993, pp. 586-591.", "@id": "5", "ref-info": {"ref-publicationyear": {"@first": "1993"}, "ref-title": {"ref-titletext": "A direct adaptive method for faster backropagation learning: The RPROP algorithm"}, "refd-itemidlist": {"itemid": {"$": "84943274699", "@idtype": "SGR"}}, "ref-volisspag": {"pagerange": {"@first": "586", "@last": "591"}}, "ref-authors": {"author": [{"@seq": "1", "ce:initials": "M.", "@_fa": "true", "ce:surname": "Riedmiller", "ce:indexed-name": "Riedmiller M."}, {"@seq": "2", "ce:initials": "H.", "@_fa": "true", "ce:surname": "Braun", "ce:indexed-name": "Braun H."}]}, "ref-sourcetitle": "Proceedings of the IEEE International Conference on Neural Networks, H. Ruspini, Ed., San Francisco, CA"}}, {"ref-fulltext": "M. Riedmiller, \"Neural fitted Q iteration-first experiences with a data efficient neural reinforcement learning method,\" in Proc. of the European Conference on Machine Learning, ser. Lecture Notes in Computer Science, J. Gama, R. Camacho, P. Brazdil, A. Jorge, and L. Torgo, Eds., vol. 3720. Porto, Portugal: Springer, 2005, pp. 317-328.", "@id": "6", "ref-info": {"ref-publicationyear": {"@first": "2005"}, "ref-title": {"ref-titletext": "Neural fitted Q iteration-first experiences with a data efficient neural reinforcement learning method"}, "refd-itemidlist": {"itemid": {"$": "33646398129", "@idtype": "SGR"}}, "ref-volisspag": {"pagerange": {"@first": "317", "@last": "328"}}, "ref-text": "J. Gama, R. Camacho, P. Brazdil, A. Jorge, and L. Torgo, Eds. 3720. Porto, Portugal: Springer", "ref-authors": {"author": [{"@seq": "1", "ce:initials": "M.", "@_fa": "true", "ce:surname": "Riedmiller", "ce:indexed-name": "Riedmiller M."}]}, "ref-sourcetitle": "Proc. of the European Conference on Machine Learning, Ser. Lecture Notes in Computer Science"}}, {"ref-fulltext": "J. Cunha, N. Lau, and A. J. R. Neves, \"Q-Batch: initial results with a novel update rule for Batch Reinforcement Learning,\" in Advances in Artificial Intelligence-Local Proceedings, XVI Portuguese Conference on Artificial Intelligence, Azores, Portugal, September 2013, pp. 240-251.", "@id": "7", "ref-info": {"ref-title": {"ref-titletext": "Q-Batch: Initial results with a novel update rule for Batch Reinforcement Learning"}, "refd-itemidlist": {"itemid": {"$": "84945455020", "@idtype": "SGR"}}, "ref-volisspag": {"pagerange": {"@first": "240", "@last": "251"}}, "ref-authors": {"author": [{"@seq": "1", "ce:initials": "J.", "@_fa": "true", "ce:surname": "Cunha", "ce:indexed-name": "Cunha J."}, {"@seq": "2", "ce:initials": "N.", "@_fa": "true", "ce:surname": "Lau", "ce:indexed-name": "Lau N."}, {"@seq": "3", "ce:initials": "A.J.R.", "@_fa": "true", "ce:surname": "Neves", "ce:indexed-name": "Neves A.J.R."}]}, "ref-sourcetitle": "Advances in Artificial Intelligence-Local Proceedings, XVI Portuguese Conference on Artificial Intelligence, Azores, Portugal, September 2013"}}, {"ref-fulltext": "M. Lauer, S. Langue, and M. Riedmiller, \"Motion estimation of moving objects for autonomous mobile robots,\" in Kunstliche Intelligenz, vol. 20, no. 1, 2006, pp. 11-17.", "@id": "8", "ref-info": {"ref-publicationyear": {"@first": "2006"}, "ref-title": {"ref-titletext": "Motion estimation of moving objects for autonomous mobile robots"}, "refd-itemidlist": {"itemid": {"$": "33745207959", "@idtype": "SGR"}}, "ref-volisspag": {"voliss": {"@volume": "20", "@issue": "1"}, "pagerange": {"@first": "11", "@last": "17"}}, "ref-authors": {"author": [{"@seq": "1", "ce:initials": "M.", "@_fa": "true", "ce:surname": "Lauer", "ce:indexed-name": "Lauer M."}, {"@seq": "2", "ce:initials": "S.", "@_fa": "true", "ce:surname": "Langue", "ce:indexed-name": "Langue S."}, {"@seq": "3", "ce:initials": "M.", "@_fa": "true", "ce:surname": "Riedmiller", "ce:indexed-name": "Riedmiller M."}]}, "ref-sourcetitle": "Kunstliche Intelligenz"}}, {"ref-fulltext": "J. Cunha, N. Lau, J. M. O. S. Rodrigues, B. Cunha, and J. L. Azevedo, \"Predictive Control for Behavior Generation of Omni-Directional Robots,\" in Progress in Artificial Intelligence, 14th Portuguese Conference on Artificial Intelligence, ser. Lecture Notes in Artificial Intelligence, vol. 5816. Aveiro, Portugal: Springer-Verlag Berlin/Heidelberg, October 12-15 2009, pp. 275-286.", "@id": "9", "ref-info": {"ref-publicationyear": {"@first": "2009"}, "ref-title": {"ref-titletext": "Predictive control for behavior generation of omni-directional robots"}, "refd-itemidlist": {"itemid": {"$": "71049152967", "@idtype": "SGR"}}, "ref-volisspag": {"voliss": {"@volume": "5816"}, "pagerange": {"@first": "275", "@last": "286"}}, "ref-text": "Aveiro, Portugal: Springer-Verlag Berlin/Heidelberg, October 12-15", "ref-authors": {"author": [{"@seq": "1", "ce:initials": "J.", "@_fa": "true", "ce:surname": "Cunha", "ce:indexed-name": "Cunha J."}, {"@seq": "2", "ce:initials": "N.", "@_fa": "true", "ce:surname": "Lau", "ce:indexed-name": "Lau N."}, {"@seq": "3", "ce:initials": "J.M.O.S.", "@_fa": "true", "ce:surname": "Rodrigues", "ce:indexed-name": "Rodrigues J.M.O.S."}, {"@seq": "4", "ce:initials": "B.", "@_fa": "true", "ce:surname": "Cunha", "ce:indexed-name": "Cunha B."}, {"@seq": "5", "ce:initials": "J.L.", "@_fa": "true", "ce:surname": "Azevedo", "ce:indexed-name": "Azevedo J.L."}]}, "ref-sourcetitle": "Progress in Artificial Intelligence, 14th Portuguese Conference on Artificial Intelligence, Ser. Lecture Notes in Artificial Intelligence"}}, {"ref-fulltext": "R. Hafner and M. Riedmiller, \"Reinforcement learning in feedback control,\" Machine Learning, vol. 84, pp. 137-169, 2011.", "@id": "10", "ref-info": {"ref-title": {"ref-titletext": "Reinforcement learning in feedback control"}, "refd-itemidlist": {"itemid": {"$": "79958779459", "@idtype": "SGR"}}, "ref-volisspag": {"voliss": {"@volume": "84", "@issue": "2011"}, "pagerange": {"@first": "137", "@last": "169"}}, "ref-authors": {"author": [{"@seq": "1", "ce:initials": "R.", "@_fa": "true", "ce:surname": "Hafner", "ce:indexed-name": "Hafner R."}, {"@seq": "2", "ce:initials": "M.", "@_fa": "true", "ce:surname": "Riedmiller", "ce:indexed-name": "Riedmiller M."}]}, "ref-sourcetitle": "Machine Learning"}}, {"ref-fulltext": "M. Riedmiller, T. Gabel, R. Hafner, and S. Lange, \"Reinforcement learning for robot soccer,\" Autonomous Robots, vol. 27, no. 1, pp. 55-73, May 2009.", "@id": "11", "ref-info": {"ref-publicationyear": {"@first": "2009"}, "ref-title": {"ref-titletext": "Reinforcement learning for robot soccer"}, "refd-itemidlist": {"itemid": {"$": "67650996818", "@idtype": "SGR"}}, "ref-volisspag": {"voliss": {"@volume": "27", "@issue": "1"}, "pagerange": {"@first": "55", "@last": "73"}}, "ref-text": "May", "ref-authors": {"author": [{"@seq": "1", "ce:initials": "M.", "@_fa": "true", "ce:surname": "Riedmiller", "ce:indexed-name": "Riedmiller M."}, {"@seq": "2", "ce:initials": "T.", "@_fa": "true", "ce:surname": "Gabel", "ce:indexed-name": "Gabel T."}, {"@seq": "3", "ce:initials": "R.", "@_fa": "true", "ce:surname": "Hafner", "ce:indexed-name": "Hafner R."}, {"@seq": "4", "ce:initials": "S.", "@_fa": "true", "ce:surname": "Lange", "ce:indexed-name": "Lange S."}]}, "ref-sourcetitle": "Autonomous Robots"}}, {"ref-fulltext": "G. Corrente, J. Cunha, R. Sequeira, and N. Lau, \"Cooperative Robotics: Passes in Robotic Soccer,\" in Proceedings of 13th International Conference on Autonomous Robot Systems and Competitions, Lisbon, Portugal, April 2013, pp. 82-87.", "@id": "12", "ref-info": {"ref-publicationyear": {"@first": "2013"}, "ref-title": {"ref-titletext": "Cooperative robotics: Passes in robotic soccer"}, "refd-itemidlist": {"itemid": {"$": "84890888048", "@idtype": "SGR"}}, "ref-volisspag": {"pagerange": {"@first": "82", "@last": "87"}}, "ref-text": "Lisbon, Portugal, April", "ref-authors": {"author": [{"@seq": "1", "ce:initials": "G.", "@_fa": "true", "ce:surname": "Corrente", "ce:indexed-name": "Corrente G."}, {"@seq": "2", "ce:initials": "J.", "@_fa": "true", "ce:surname": "Cunha", "ce:indexed-name": "Cunha J."}, {"@seq": "3", "ce:initials": "R.", "@_fa": "true", "ce:surname": "Sequeira", "ce:indexed-name": "Sequeira R."}, {"@seq": "4", "ce:initials": "N.", "@_fa": "true", "ce:surname": "Lau", "ce:indexed-name": "Lau N."}]}, "ref-sourcetitle": "Proceedings of 13th International Conference on Autonomous Robot Systems and Competitions"}}]}}}}, "affiliation": [{"affiliation-city": "Aveiro", "@id": "60079336", "affilname": "Instituto de Engenharia Electr\u00f3nica e Telem\u00e1tica de Aveiro", "@href": "https://api.elsevier.com/content/affiliation/affiliation_id/60079336", "affiliation-country": "Portugal"}, {"affiliation-city": "Aveiro", "@id": "60024825", "affilname": "Universidade de Aveiro", "@href": "https://api.elsevier.com/content/affiliation/affiliation_id/60024825", "affiliation-country": "Portugal"}], "coredata": {"srctype": "p", "eid": "2-s2.0-84905017754", "dc:description": "Robotic soccer provides a rich environment for the development of Reinforcement Learning controllers. The competitive environment imposes strong requirements on performance of the developed controllers. RL offers a valuable alternative for the development of efficient controllers while avoiding the hassle of parameter tuning a hand coded policy. This paper presents the application of a recently proposed Batch RL update-rule to learn robotic soccer controllers in the context of the RoboCup Middle Size League. The Q-Batch update-rule exploits the episodic structure of the data collection phase of Batch RL to efficiently evaluate and improve the learned policy. Three different learning tasks, with increasing difficulty, were developed and applied on a simulated environment and later on the physical robot. The performance of the learned controllers is mostly compared to hand-tuned controllers while some comparisons with other RL methods were performed. Results show that the proposed approach is able to learn the tasks in a reduced amount of time, even outperforming existing hand-coded solutions. \u00a9 2014 IEEE.", "prism:coverDate": "2014-01-01", "prism:aggregationType": "Conference Proceeding", "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/84905017754", "subtypeDescription": "Conference Paper", "dc:creator": {"author": [{"ce:given-name": "Jo\u00e3o", "preferred-name": {"ce:given-name": "Jo\u00e3o", "ce:initials": "J.", "ce:surname": "Cunha", "ce:indexed-name": "Cunha J."}, "@seq": "1", "ce:initials": "J.", "@_fa": "true", "affiliation": [{"@id": "60024825", "@href": "https://api.elsevier.com/content/affiliation/affiliation_id/60024825"}, {"@id": "60079336", "@href": "https://api.elsevier.com/content/affiliation/affiliation_id/60079336"}], "ce:surname": "Cunha", "@auid": "57188533953", "author-url": "https://api.elsevier.com/content/author/author_id/57188533953", "ce:indexed-name": "Cunha J."}]}, "link": [{"@_fa": "true", "@rel": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84905017754"}, {"@_fa": "true", "@rel": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84905017754&origin=inward"}, {"@_fa": "true", "@rel": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84905017754&origin=inward"}], "prism:publicationName": "2014 IEEE International Conference on Autonomous Robot Systems and Competitions, ICARSC 2014", "source-id": "21100326085", "citedby-count": "3", "subtype": "cp", "prism:pageRange": "134-139", "dc:title": "Learning robotic soccer controllers with the Q-Batch update-rule", "prism:endingPage": "139", "openaccess": "0", "openaccessFlag": "false", "prism:doi": "10.1109/ICARSC.2014.6849775", "prism:startingPage": "134", "article-number": "6849775", "dc:identifier": "SCOPUS_ID:84905017754", "dc:publisher": "IEEE Computer Societyhelp@computer.org"}, "idxterms": {"mainterm": [{"$": "Competitive environment", "@weight": "b", "@candidate": "n"}, {"$": "Data collection", "@weight": "b", "@candidate": "n"}, {"$": "Learning tasks", "@weight": "b", "@candidate": "n"}, {"$": "Parameter-tuning", "@weight": "b", "@candidate": "n"}, {"$": "Physical robots", "@weight": "b", "@candidate": "n"}, {"$": "RoboCup", "@weight": "b", "@candidate": "n"}, {"$": "Robotic soccer", "@weight": "b", "@candidate": "n"}, {"$": "Simulated environment", "@weight": "b", "@candidate": "n"}]}, "language": {"@xml:lang": "eng"}, "authkeywords": null, "subject-areas": {"subject-area": [{"@_fa": "true", "$": "Artificial Intelligence", "@code": "1702", "@abbrev": "COMP"}, {"@_fa": "true", "$": "Control and Systems Engineering", "@code": "2207", "@abbrev": "ENGI"}]}, "authors": {"author": [{"ce:given-name": "Jo\u00e3o", "preferred-name": {"ce:given-name": "Jo\u00e3o", "ce:initials": "J.", "ce:surname": "Cunha", "ce:indexed-name": "Cunha J."}, "@seq": "1", "ce:initials": "J.", "@_fa": "true", "affiliation": [{"@id": "60024825", "@href": "https://api.elsevier.com/content/affiliation/affiliation_id/60024825"}, {"@id": "60079336", "@href": "https://api.elsevier.com/content/affiliation/affiliation_id/60079336"}], "ce:surname": "Cunha", "@auid": "57188533953", "author-url": "https://api.elsevier.com/content/author/author_id/57188533953", "ce:indexed-name": "Cunha J."}, {"ce:given-name": "Rui", "preferred-name": {"ce:given-name": "Rui", "ce:initials": "R.", "ce:surname": "Serra", "ce:indexed-name": "Serra R."}, "@seq": "2", "ce:initials": "R.", "@_fa": "true", "affiliation": {"@id": "60024825", "@href": "https://api.elsevier.com/content/affiliation/affiliation_id/60024825"}, "ce:surname": "Serra", "@auid": "55973150400", "author-url": "https://api.elsevier.com/content/author/author_id/55973150400", "ce:indexed-name": "Serra R."}, {"ce:given-name": "Nuno", "preferred-name": {"ce:given-name": "Nuno", "ce:initials": "N.", "ce:surname": "Lau", "ce:indexed-name": "Lau N."}, "@seq": "3", "ce:initials": "N.", "@_fa": "true", "affiliation": [{"@id": "60024825", "@href": "https://api.elsevier.com/content/affiliation/affiliation_id/60024825"}, {"@id": "60079336", "@href": "https://api.elsevier.com/content/affiliation/affiliation_id/60079336"}], "ce:surname": "Lau", "@auid": "13907323500", "author-url": "https://api.elsevier.com/content/author/author_id/13907323500", "ce:indexed-name": "Lau N."}, {"ce:given-name": "Lu\u00eds Seabra", "preferred-name": {"ce:given-name": "Lu\u00eds Seabra", "ce:initials": "L.S.", "ce:surname": "Lopes", "ce:indexed-name": "Lopes L.S."}, "@seq": "4", "ce:initials": "L.S.", "@_fa": "true", "affiliation": [{"@id": "60024825", "@href": "https://api.elsevier.com/content/affiliation/affiliation_id/60024825"}, {"@id": "60079336", "@href": "https://api.elsevier.com/content/affiliation/affiliation_id/60079336"}], "ce:surname": "Lopes", "@auid": "7102509123", "author-url": "https://api.elsevier.com/content/author/author_id/7102509123", "ce:indexed-name": "Lopes L.S."}, {"ce:given-name": "Ant\u00f3nio J.R.", "preferred-name": {"ce:given-name": "Ant\u00f3nio J.R.", "ce:initials": "A.J.R.", "ce:surname": "Neves", "ce:indexed-name": "Neves A.J.R."}, "@seq": "5", "ce:initials": "A.J.R.", "@_fa": "true", "affiliation": [{"@id": "60024825", "@href": "https://api.elsevier.com/content/affiliation/affiliation_id/60024825"}, {"@id": "60079336", "@href": "https://api.elsevier.com/content/affiliation/affiliation_id/60079336"}], "ce:surname": "Neves", "@auid": "43461712600", "author-url": "https://api.elsevier.com/content/author/author_id/43461712600", "ce:indexed-name": "Neves A.J.R."}]}}