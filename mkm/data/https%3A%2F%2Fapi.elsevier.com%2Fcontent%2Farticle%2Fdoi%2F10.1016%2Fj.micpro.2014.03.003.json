{"scopus-eid": "2-s2.0-84903318125", "originalText": "serial JL 271554 291210 291716 291718 291791 291869 291883 31 Microprocessors and Microsystems MICROPROCESSORSMICROSYSTEMS 2014-03-14 2014-03-14 2014-06-23T09:20:13 1-s2.0-S0141933114000301 S0141-9331(14)00030-1 S0141933114000301 10.1016/j.micpro.2014.03.003 S300 S300.1 FULL-TEXT 1-s2.0-S0141933114X00050 2015-05-14T04:11:00.055321-04:00 0 0 20140701 20140731 2014 2014-03-14T00:00:00Z articleinfo articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid hubeid indexeddate issfirst issn issnnorm issuelist itemstage itemtransactionid itemweight openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sortorder srctitle srctitlenorm srctype subheadings tomb volfirst volissue volumelist webpdf webpdfpagecount yearnav figure table body mmlmath acknowledge affil articletitle auth authfirstini authfull authkeywords authlast orcid primabst ref vitae alllist content subj ssids 0141-9331 01419331 true 38 38 5 5 Volume 38, Issue 5 12 470 484 470 484 201407 July 2014 2014-07-01 2014-07-31 2014 article fla Copyright \u00a9 2014 Elsevier B.V. All rights reserved. HIGHPERFORMANCEIMPLEMENTATIONREGULAREASILYSCALABLESORTINGNETWORKSFPGA SKLYAROV V 1 Introduction 2 Related work 3 The proposed method and motivations 4 Theoretical comparisons of the proposed and the best known networks 5 Variations of the proposed network 6 Practical applications 7 Experiments and comparisons 7.1 Experimental setup 7.2 Experimental comparison of the proposed and the best known networks 8 Conclusion Acknowledgments References KNUTH 2011 D ARTCOMPUTERPROGRAMMINGSORTINGSEARCHING MUELLER 2012 1 23 R GAPANNINI 2012 903 917 G GROZEA 2010 105 117 C FACINGMULTICORECHALLENGE FPGAVSMULTICORECPUSVSGPUS LACEY 1991 315 316 S COPE 2010 433 448 B SKLIAROVA 2004 1449 1461 I ALIAS 2012 606 619 C PIESTRAK 2007 611 612 S SKLYAROV 2004 197 211 V SKLYAROVX2014X470 SKLYAROVX2014X470X484 SKLYAROVX2014X470XV SKLYAROVX2014X470X484XV item S0141-9331(14)00030-1 S0141933114000301 1-s2.0-S0141933114000301 10.1016/j.micpro.2014.03.003 271554 2014-06-23T05:12:23.089259-04:00 2014-07-01 2014-07-31 1-s2.0-S0141933114000301-main.pdf https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0141933114000301/MAIN/application/pdf/8c20456bd087b1694126f5209e13bfd5/main.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0141933114000301/MAIN/application/pdf/8c20456bd087b1694126f5209e13bfd5/main.pdf main.pdf pdf true 4026889 MAIN 15 1-s2.0-S0141933114000301-main_1.png https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0141933114000301/PREVIEW/image/png/fb87e7b3b7455c72eb88c32a55eaa974/main_1.png https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0141933114000301/PREVIEW/image/png/fb87e7b3b7455c72eb88c32a55eaa974/main_1.png main_1.png png 57736 849 656 IMAGE-WEB-PDF 1 1-s2.0-S0141933114000301-si7.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0141933114000301/STRIPIN/image/gif/8d29d8e40910bd27b10efd882fbc666c/si7.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0141933114000301/STRIPIN/image/gif/8d29d8e40910bd27b10efd882fbc666c/si7.gif si7 si7.gif gif 348 22 33 ALTIMG 1-s2.0-S0141933114000301-si6.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0141933114000301/STRIPIN/image/gif/1437ed795ae69e97df3d1865eb18c389/si6.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0141933114000301/STRIPIN/image/gif/1437ed795ae69e97df3d1865eb18c389/si6.gif si6 si6.gif gif 425 17 48 ALTIMG 1-s2.0-S0141933114000301-si5.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0141933114000301/STRIPIN/image/gif/8d29d8e40910bd27b10efd882fbc666c/si7.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0141933114000301/STRIPIN/image/gif/8d29d8e40910bd27b10efd882fbc666c/si7.gif si5 si5.gif gif 348 22 33 ALTIMG 1-s2.0-S0141933114000301-si4.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0141933114000301/STRIPIN/image/gif/3b38d44ff8db4135c303a5853c8d92eb/si4.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0141933114000301/STRIPIN/image/gif/3b38d44ff8db4135c303a5853c8d92eb/si4.gif si4 si4.gif gif 232 18 13 ALTIMG 1-s2.0-S0141933114000301-si3.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0141933114000301/STRIPIN/image/gif/abe7cbc55fab8c847f1a2d7ba1b2a7b3/si2.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0141933114000301/STRIPIN/image/gif/abe7cbc55fab8c847f1a2d7ba1b2a7b3/si2.gif si3 si3.gif gif 230 21 13 ALTIMG 1-s2.0-S0141933114000301-si2.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0141933114000301/STRIPIN/image/gif/abe7cbc55fab8c847f1a2d7ba1b2a7b3/si2.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0141933114000301/STRIPIN/image/gif/abe7cbc55fab8c847f1a2d7ba1b2a7b3/si2.gif si2 si2.gif gif 230 21 13 ALTIMG 1-s2.0-S0141933114000301-si1.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0141933114000301/STRIPIN/image/gif/bceae4b31cc6e1dcc30d9c9d3cf9eb01/si1.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0141933114000301/STRIPIN/image/gif/bceae4b31cc6e1dcc30d9c9d3cf9eb01/si1.gif si1 si1.gif gif 625 17 119 ALTIMG 1-s2.0-S0141933114000301-gr1.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0141933114000301/gr1/DOWNSAMPLED/image/jpeg/08a9965e285caa320c809a2479a18505/gr1.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0141933114000301/gr1/DOWNSAMPLED/image/jpeg/08a9965e285caa320c809a2479a18505/gr1.jpg gr1 gr1.jpg jpg 24856 330 314 IMAGE-DOWNSAMPLED 1-s2.0-S0141933114000301-fx2.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0141933114000301/fx2/DOWNSAMPLED/image/jpeg/f3f10d08386bbc98887cd7fc300fe3dd/fx2.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0141933114000301/fx2/DOWNSAMPLED/image/jpeg/f3f10d08386bbc98887cd7fc300fe3dd/fx2.jpg fx2 fx2.jpg jpg 11568 155 111 IMAGE-DOWNSAMPLED 1-s2.0-S0141933114000301-fx1.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0141933114000301/fx1/DOWNSAMPLED/image/jpeg/baf0870a2a9c6fe80c37e1f64e01b408/fx1.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0141933114000301/fx1/DOWNSAMPLED/image/jpeg/baf0870a2a9c6fe80c37e1f64e01b408/fx1.jpg fx1 fx1.jpg jpg 10010 155 111 IMAGE-DOWNSAMPLED 1-s2.0-S0141933114000301-gr9.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0141933114000301/gr9/DOWNSAMPLED/image/jpeg/a0e5ba9fc4bd0a426b733799e6b43f74/gr9.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0141933114000301/gr9/DOWNSAMPLED/image/jpeg/a0e5ba9fc4bd0a426b733799e6b43f74/gr9.jpg gr9 gr9.jpg jpg 25035 179 467 IMAGE-DOWNSAMPLED 1-s2.0-S0141933114000301-gr8.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0141933114000301/gr8/DOWNSAMPLED/image/jpeg/5dc34391ea0f9fa51e9ee48acacaa6ff/gr8.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0141933114000301/gr8/DOWNSAMPLED/image/jpeg/5dc34391ea0f9fa51e9ee48acacaa6ff/gr8.jpg gr8 gr8.jpg jpg 94579 433 600 IMAGE-DOWNSAMPLED 1-s2.0-S0141933114000301-gr7.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0141933114000301/gr7/DOWNSAMPLED/image/jpeg/e893bae4709aea5dec0302cf755235c9/gr7.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0141933114000301/gr7/DOWNSAMPLED/image/jpeg/e893bae4709aea5dec0302cf755235c9/gr7.jpg gr7 gr7.jpg jpg 37502 232 499 IMAGE-DOWNSAMPLED 1-s2.0-S0141933114000301-gr6.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0141933114000301/gr6/DOWNSAMPLED/image/jpeg/f378c4042c503149841221863db7830d/gr6.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0141933114000301/gr6/DOWNSAMPLED/image/jpeg/f378c4042c503149841221863db7830d/gr6.jpg gr6 gr6.jpg jpg 17264 222 224 IMAGE-DOWNSAMPLED 1-s2.0-S0141933114000301-gr5.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0141933114000301/gr5/DOWNSAMPLED/image/jpeg/e63b86ee99403530762004f9a4608cfc/gr5.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0141933114000301/gr5/DOWNSAMPLED/image/jpeg/e63b86ee99403530762004f9a4608cfc/gr5.jpg gr5 gr5.jpg jpg 78369 356 606 IMAGE-DOWNSAMPLED 1-s2.0-S0141933114000301-gr4.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0141933114000301/gr4/DOWNSAMPLED/image/jpeg/937b754dd026ef3b13db8a818fb24c4b/gr4.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0141933114000301/gr4/DOWNSAMPLED/image/jpeg/937b754dd026ef3b13db8a818fb24c4b/gr4.jpg gr4 gr4.jpg jpg 52246 414 336 IMAGE-DOWNSAMPLED 1-s2.0-S0141933114000301-gr3.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0141933114000301/gr3/DOWNSAMPLED/image/jpeg/ff93acfdb471d01640f3a0aa9e344eb9/gr3.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0141933114000301/gr3/DOWNSAMPLED/image/jpeg/ff93acfdb471d01640f3a0aa9e344eb9/gr3.jpg gr3 gr3.jpg jpg 59880 423 379 IMAGE-DOWNSAMPLED 1-s2.0-S0141933114000301-gr2.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0141933114000301/gr2/DOWNSAMPLED/image/jpeg/ac25ad69b5306d6cfb0e4d4630e9d990/gr2.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0141933114000301/gr2/DOWNSAMPLED/image/jpeg/ac25ad69b5306d6cfb0e4d4630e9d990/gr2.jpg gr2 gr2.jpg jpg 25739 167 378 IMAGE-DOWNSAMPLED 1-s2.0-S0141933114000301-gr17.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0141933114000301/gr17/DOWNSAMPLED/image/jpeg/e8537d839bb0f9d070c4a1f09436fd18/gr17.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0141933114000301/gr17/DOWNSAMPLED/image/jpeg/e8537d839bb0f9d070c4a1f09436fd18/gr17.jpg gr17 gr17.jpg jpg 49961 363 528 IMAGE-DOWNSAMPLED 1-s2.0-S0141933114000301-gr16.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0141933114000301/gr16/DOWNSAMPLED/image/jpeg/213db3b2059be54448fdeedd698b6102/gr16.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0141933114000301/gr16/DOWNSAMPLED/image/jpeg/213db3b2059be54448fdeedd698b6102/gr16.jpg gr16 gr16.jpg jpg 38441 351 461 IMAGE-DOWNSAMPLED 1-s2.0-S0141933114000301-gr15.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0141933114000301/gr15/DOWNSAMPLED/image/jpeg/07dfe69abe38322ed623fd796f9c4065/gr15.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0141933114000301/gr15/DOWNSAMPLED/image/jpeg/07dfe69abe38322ed623fd796f9c4065/gr15.jpg gr15 gr15.jpg jpg 40210 356 448 IMAGE-DOWNSAMPLED 1-s2.0-S0141933114000301-gr14.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0141933114000301/gr14/DOWNSAMPLED/image/jpeg/10c2fd2b698c543b72d5b5cf09e84e26/gr14.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0141933114000301/gr14/DOWNSAMPLED/image/jpeg/10c2fd2b698c543b72d5b5cf09e84e26/gr14.jpg gr14 gr14.jpg jpg 69801 309 601 IMAGE-DOWNSAMPLED 1-s2.0-S0141933114000301-gr13.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0141933114000301/gr13/DOWNSAMPLED/image/jpeg/bab85adc02412ebb3d8c173949acd1cf/gr13.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0141933114000301/gr13/DOWNSAMPLED/image/jpeg/bab85adc02412ebb3d8c173949acd1cf/gr13.jpg gr13 gr13.jpg jpg 45927 243 511 IMAGE-DOWNSAMPLED 1-s2.0-S0141933114000301-gr12.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0141933114000301/gr12/DOWNSAMPLED/image/jpeg/7694115f7bbe2aeacdbc0c1638bf5fb0/gr12.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0141933114000301/gr12/DOWNSAMPLED/image/jpeg/7694115f7bbe2aeacdbc0c1638bf5fb0/gr12.jpg gr12 gr12.jpg jpg 33781 282 499 IMAGE-DOWNSAMPLED 1-s2.0-S0141933114000301-gr11.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0141933114000301/gr11/DOWNSAMPLED/image/jpeg/b97dda9e420fcb846dcf55cce5d9a76f/gr11.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0141933114000301/gr11/DOWNSAMPLED/image/jpeg/b97dda9e420fcb846dcf55cce5d9a76f/gr11.jpg gr11 gr11.jpg jpg 73339 350 514 IMAGE-DOWNSAMPLED 1-s2.0-S0141933114000301-gr10.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0141933114000301/gr10/DOWNSAMPLED/image/jpeg/759bf289c14af033184fe190d0e412e2/gr10.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0141933114000301/gr10/DOWNSAMPLED/image/jpeg/759bf289c14af033184fe190d0e412e2/gr10.jpg gr10 gr10.jpg jpg 83900 314 542 IMAGE-DOWNSAMPLED 1-s2.0-S0141933114000301-gr1.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0141933114000301/gr1/THUMBNAIL/image/gif/d0988f1f39498b64c8c149172719da54/gr1.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0141933114000301/gr1/THUMBNAIL/image/gif/d0988f1f39498b64c8c149172719da54/gr1.sml gr1 gr1.sml sml 4449 164 156 IMAGE-THUMBNAIL 1-s2.0-S0141933114000301-fx2.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0141933114000301/fx2/THUMBNAIL/image/gif/acdb9b7c655bda79bbb773e41e7eecad/fx2.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0141933114000301/fx2/THUMBNAIL/image/gif/acdb9b7c655bda79bbb773e41e7eecad/fx2.sml fx2 fx2.sml sml 9964 164 117 IMAGE-THUMBNAIL 1-s2.0-S0141933114000301-fx1.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0141933114000301/fx1/THUMBNAIL/image/gif/bc2c0b336fc30ec56c4e364b0e93540a/fx1.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0141933114000301/fx1/THUMBNAIL/image/gif/bc2c0b336fc30ec56c4e364b0e93540a/fx1.sml fx1 fx1.sml sml 9534 164 117 IMAGE-THUMBNAIL 1-s2.0-S0141933114000301-gr9.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0141933114000301/gr9/THUMBNAIL/image/gif/9742cfd3163284d7d7fdf1d3f0e7dc60/gr9.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0141933114000301/gr9/THUMBNAIL/image/gif/9742cfd3163284d7d7fdf1d3f0e7dc60/gr9.sml gr9 gr9.sml sml 4057 84 219 IMAGE-THUMBNAIL 1-s2.0-S0141933114000301-gr8.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0141933114000301/gr8/THUMBNAIL/image/gif/adb08656d3df8b166b6c1b2ce2a5c9ac/gr8.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0141933114000301/gr8/THUMBNAIL/image/gif/adb08656d3df8b166b6c1b2ce2a5c9ac/gr8.sml gr8 gr8.sml sml 10922 158 219 IMAGE-THUMBNAIL 1-s2.0-S0141933114000301-gr7.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0141933114000301/gr7/THUMBNAIL/image/gif/ca92d68bc4f0b21bd168d1a0dcbd71cc/gr7.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0141933114000301/gr7/THUMBNAIL/image/gif/ca92d68bc4f0b21bd168d1a0dcbd71cc/gr7.sml gr7 gr7.sml sml 6704 102 219 IMAGE-THUMBNAIL 1-s2.0-S0141933114000301-gr6.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0141933114000301/gr6/THUMBNAIL/image/gif/7d26acaeff1ad8a8f097f6728b2b2fbb/gr6.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0141933114000301/gr6/THUMBNAIL/image/gif/7d26acaeff1ad8a8f097f6728b2b2fbb/gr6.sml gr6 gr6.sml sml 6200 164 165 IMAGE-THUMBNAIL 1-s2.0-S0141933114000301-gr5.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0141933114000301/gr5/THUMBNAIL/image/gif/a19b2af50a5e2c479cb95f25045c358a/gr5.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0141933114000301/gr5/THUMBNAIL/image/gif/a19b2af50a5e2c479cb95f25045c358a/gr5.sml gr5 gr5.sml sml 9734 129 219 IMAGE-THUMBNAIL 1-s2.0-S0141933114000301-gr4.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0141933114000301/gr4/THUMBNAIL/image/gif/e846a76008dcc859f9fe60fcb8ff14f4/gr4.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0141933114000301/gr4/THUMBNAIL/image/gif/e846a76008dcc859f9fe60fcb8ff14f4/gr4.sml gr4 gr4.sml sml 7138 164 133 IMAGE-THUMBNAIL 1-s2.0-S0141933114000301-gr3.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0141933114000301/gr3/THUMBNAIL/image/gif/5a9b3fdb9c92b8b3e8a07039dfd30956/gr3.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0141933114000301/gr3/THUMBNAIL/image/gif/5a9b3fdb9c92b8b3e8a07039dfd30956/gr3.sml gr3 gr3.sml sml 7349 164 147 IMAGE-THUMBNAIL 1-s2.0-S0141933114000301-gr2.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0141933114000301/gr2/THUMBNAIL/image/gif/6b355d2cd71c40e01774e077b7aa05cf/gr2.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0141933114000301/gr2/THUMBNAIL/image/gif/6b355d2cd71c40e01774e077b7aa05cf/gr2.sml gr2 gr2.sml sml 7286 97 219 IMAGE-THUMBNAIL 1-s2.0-S0141933114000301-gr17.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0141933114000301/gr17/THUMBNAIL/image/gif/1049352929e2f8af4b14eee959979f79/gr17.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0141933114000301/gr17/THUMBNAIL/image/gif/1049352929e2f8af4b14eee959979f79/gr17.sml gr17 gr17.sml sml 7025 151 219 IMAGE-THUMBNAIL 1-s2.0-S0141933114000301-gr16.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0141933114000301/gr16/THUMBNAIL/image/gif/b8cdcd399c529ce7d9203669920c9f43/gr16.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0141933114000301/gr16/THUMBNAIL/image/gif/b8cdcd399c529ce7d9203669920c9f43/gr16.sml gr16 gr16.sml sml 6584 164 215 IMAGE-THUMBNAIL 1-s2.0-S0141933114000301-gr15.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0141933114000301/gr15/THUMBNAIL/image/gif/badf904fdcff5d431f4846505ff3b0ec/gr15.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0141933114000301/gr15/THUMBNAIL/image/gif/badf904fdcff5d431f4846505ff3b0ec/gr15.sml gr15 gr15.sml sml 6872 164 206 IMAGE-THUMBNAIL 1-s2.0-S0141933114000301-gr14.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0141933114000301/gr14/THUMBNAIL/image/gif/b43fc80efd81b71dfe99e9cb5f122082/gr14.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0141933114000301/gr14/THUMBNAIL/image/gif/b43fc80efd81b71dfe99e9cb5f122082/gr14.sml gr14 gr14.sml sml 8627 113 219 IMAGE-THUMBNAIL 1-s2.0-S0141933114000301-gr13.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0141933114000301/gr13/THUMBNAIL/image/gif/1d011285e3219454b8961b239b6c6b1b/gr13.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0141933114000301/gr13/THUMBNAIL/image/gif/1d011285e3219454b8961b239b6c6b1b/gr13.sml gr13 gr13.sml sml 7685 104 219 IMAGE-THUMBNAIL 1-s2.0-S0141933114000301-gr12.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0141933114000301/gr12/THUMBNAIL/image/gif/b496f9641d4e8a628ae085072ca9cc1a/gr12.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0141933114000301/gr12/THUMBNAIL/image/gif/b496f9641d4e8a628ae085072ca9cc1a/gr12.sml gr12 gr12.sml sml 5244 124 219 IMAGE-THUMBNAIL 1-s2.0-S0141933114000301-gr11.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0141933114000301/gr11/THUMBNAIL/image/gif/fb83e076593300099d32baf7c892e4ca/gr11.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0141933114000301/gr11/THUMBNAIL/image/gif/fb83e076593300099d32baf7c892e4ca/gr11.sml gr11 gr11.sml sml 10866 149 219 IMAGE-THUMBNAIL 1-s2.0-S0141933114000301-gr10.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0141933114000301/gr10/THUMBNAIL/image/gif/30f6ef6da7d0e643bb023b02b76c1532/gr10.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0141933114000301/gr10/THUMBNAIL/image/gif/30f6ef6da7d0e643bb023b02b76c1532/gr10.sml gr10 gr10.sml sml 10844 127 219 IMAGE-THUMBNAIL MICPRO 2119 S0141-9331(14)00030-1 10.1016/j.micpro.2014.03.003 Elsevier B.V. Fig. 1 Number of comparators for different values N of data items. Fig. 2 Basic concepts of the proposed method. Fig. 3 Even\u2013odd merge network (a); bitonic merge network (b); a comparator/swapper (c). Fig. 4 The even\u2013odd transition sorting network (a) and the network with reusable comparators (b). Fig. 5 Pipelined implementations: for even\u2013odd merge sorter in Fig. 3a (a); for bitonic sorter in Fig. 3b (b), for the proposed circuit in Fig. 4b (c); the sequence of vectors recorded in the register R and in the PLR for the worst and for the best cases (d); a fragment of a state transition diagram to control the proposed circuit (e). Fig. 6 Variations of the proposed circuit which now has 4 reusable lines. Fig. 7 Pipeline for the circuit shown in Fig. 6a. Fig. 8 Pipelined implementation (a) and an example (b). Fig. 9 Merging of sorted sets in a host system. Fig. 10 The structure of the even\u2013odd merge network (a) and the number of comparators for different values of N (b). Fig. 11 Using the proposed circuit for radix sort (a); comparison is done for segments composed of n <M bits but swapping has to be applied to whole words (b); an example of sorting (c). Fig. 12 Using the proposed circuits in address-based sorting: an example (a); processing of segments (b). Fig. 13 Experimental setup for the Atlys board (a) and ZedBoard (b). Fig. 14 A general structure of circuits implemented in FPGA and organization of experiments. Fig. 15 Resource (a) and throughput (b) evaluation for different non-pipelined circuits (i.e. combinational even\u2013odd mergers and the proposed circuit in Fig. 4b) implemented and tested in the Atlys board. Fig. 16 Resource (a) and throughput (b) evaluation for different non-pipelined circuits (i.e. combinational even\u2013odd mergers and the proposed circuit in Fig. 4b) implemented and tested in the ZedBoard. Fig. 17 Resource (a) and performance (b) evaluation for different pipelined circuits implemented and tested in the Atlys board. Table 1 Characteristics of different sorting networks. Ns F max (MHz) T min (ns) Throughput (the number of sorted items per second) Even\u2013odd merge (Fig. 3a) 474 (6%) a 21.02 47.6 168160000 Bitonic merge (Fig. 3b) 584 (8%) a 20.42 49.0 163360000 The proposed circuit (Fig. 4b) 279 (4%) a 108.38 9.2 216760000 (the worst case) a Resources used also include circuits for interactions with the host computer that fill embedded FPGA memory with the initial data and transmit back the sorted sets. Table 2 Resource consumption of different circuits. N Ns (xc6slx45) Ns (xc7z020) Ns (xc6slx45) Ns (xc7z020) Ns (xc6slx45) Ns (xc7z020) Even\u2013odd merge Bitonic merge Proposed 16 1323 (19%) 1071 (8%) 1680 (25%) 1360 (10%) 315 (5%) 255 (2%) 32 4011 (59%) 3247 (24%) 5040 (74%) 4080 (31%) 651 (10%) 527 (4%) 64 >100% 9231 (69%) >100% 11,424 (86%) 1321 (19%) 1071 (8%) 128 >100% >100% >100% >100% 2667 (39%) 2159 (20%) 256 >100% >100% >100% >100% 5355 (78%) 4335 (33%) 512 >100% >100% >100% >100% >100% 8687 (65%) Table 3 Throughput estimates for different circuits. N Even\u2013odd merge/bitonic merge Proposed I s k / I s p 16 1600000000/D comp 1000000000/D comp 1.6 32 2133333333/D comp 1000000000/D comp 2.1 64 3047619048/D comp 1000000000/D comp 3.0 Table 4 Number of iterations in columns (1), (2) and steps in column (3) in different sorters. N (1) Circuit in Fig. 4b without pre-sort (and without enable signal) (2) Circuit in Fig. 4b with pre-sort (and with enable signal) (3) Even\u2013odd/bitonic merge networks 32 16 [2\u00d7 D comp] 8 [2\u00d7 D comp] 15 [D comp] 64 32 [2\u00d7 D comp] 15 [2\u00d7 D comp] 21 [D comp] 128 64 [2\u00d7 D comp] 31 [2\u00d7 D comp] 28 [D comp] 256 128 [2\u00d7 D comp] 60 [2\u00d7 D comp] 36 [D comp] 512 256 [2\u00d7 D comp] 120 [2\u00d7 D comp] 45 [D comp] 1024 512 [2\u00d7 D comp] 251 [2\u00d7 D comp] 55 [D comp] High-performance implementation of regular and easily scalable sorting networks on an FPGA Valery Sklyarov \u204e Iouliia Skliarova Department of Electronics, Telecommunications and Informatics, IEETA, University of Aveiro, 3810-193 Aveiro, Portugal Department of Electronics Telecommunications and Informatics IEETA, University of Aveiro 3810-193 Aveiro Portugal \u204e Corresponding author. The paper is dedicated to fast FPGA-based hardware accelerators that implement sorting networks. The primary emphasis is on the uniformity of core components, feasible combinations of parallel, pipelined and sequential operations, and the regularity of the circuits and interconnections. The paper shows theoretically, and based on numerous experiments, that many existing solutions that are commonly considered to be very efficient have worthy competitors that are better for many practical problems. We compared the even\u2013odd merge and bitonic merge sorting networks (which are among the fastest known) with the even\u2013odd transition network, which is often characterized as significantly slower and more resource consuming. We found that the latter is the most regular network that can be implemented very efficiently in FPGA, so we are proposing new, easily scalable hardware solutions and processing techniques based on this. Finally, the paper provides four main contributions and suggests: (1) a regular hardware implementation of resource and time effective architectures based on the even\u2013odd transition network; (2) a pipelined implementation of even\u2013odd transition networks; (3) a pre-processing technique that enables sorting to be further accelerated; (4) combinations of this technique with a merge sort, an address-based sort, a quicksort, and a radix sort. Keywords FPGA Parallel processing Sorting networks Pipeline 1 Introduction Sorting is a procedure that is needed in numerous computing systems [1]. For many practical applications, sorting throughput is very important. To better satisfy performance requirements, fast accelerators based on FPGAs (e.g. [2\u201310]), GPUs (e.g. [6,11\u201315]) and multi-core CPUs (e.g. [16,17]), have been investigated in depth with increased intensity during the last few years. The latter can be explained by the recent significant advances in high-density and high performance microelectronic devices that have resulted in serious competitors to general-purpose and application-specific processing systems for solving computationally intensive problems. The results are especially promising if multiple operations can execute simultaneously. Two of the most frequently investigated parallel sorters are based on sorting [2] and linear [3] networks. A sorting network is a set of vertical lines composed of comparators that can swap data to change their positions in the input multi-item vector. The data propagate through the lines from left to right to produce the sorted multi-item vector on the outputs of the rightmost vertical line. Three types of such networks have been studied: pure combinational (e.g. [2,8]), pipelined (e.g. [2,8]), and combined (partially combinational and partially sequential) [e.g. 4]. The linear networks, which are often referred to as linear sorters [3], take a sorted list and insert new incoming items in the proper positions. The method is the same as the insertion sort [1] that compares a new item with all items in parallel, then inserts the new item at the appropriate position and shifts the existing elements in the entire multi-item vector. Additional capabilities of parallelization are demonstrated in the interleaved linear sorter system proposed in [3]. The main problem with this is that it is applicable only for small data sets (see, for example, the designs discussed in [3], which accommodate only tens of items). The majority of sorting networks implemented in hardware use Batcher even\u2013odd and bitonic mergers [18]. Such networks are described in [2,4,8,11,12]. Other types are rarer (see for example the comb sort [19] in [7], the bubble and insertion sort in [2,8] and the even\u2013odd transition sort in [11]). Research efforts are concentrated mainly on networks with a minimal depth or number of comparators (e.g. [2,12]) and on co-design, rationally splitting the problem between software and hardware (e.g. [2,8]). To our knowledge, the regularity of the circuits and interconnections is almost never taken into account. The only instance appeared recently in [4], where a generator for networks with reusable components was proposed. The results in [4] were discussed just in terms of circuit sizes, and performance was not analyzed (an estimation of throughput for the method [4] is in Section 2 of this paper). Further, no particular circuit was demonstrated. We target our results towards FPGAs because they are regarded more and more as a universal platform incorporating many complex components that were used autonomously not so long ago. For example, the All Programmable System-on-Chip (APSoC) Xilinx Zynq includes a dual ARM\u00ae Cortex\u2122-A9 MPCore\u2122 and an Artix/Kintex FPGA on the same microchip. The first prototyping systems (e.g. ZedBoard [20,21], ZyBo [21]) with this microchip are already available for a very reasonable price. The majority of modern FPGAs contain embedded DSP slices (e.g. the DSP48E1 slice for Xilinx FPGAs [22]) and embedded dual-port memories, which are very appropriate for sorting. We believe that in future, GPU cores might also be placed inside an FPGA, but even without such cores, streaming SIMD (single instruction multiple data) applications can be created with existing programmable logic. Comparisons of FPGA-based implementations with alternative systems [16,23,24] clearly demonstrate the potential of reconfigurable hardware, which encourages further research in this area. FPGAs still operate on a lower clock frequency than non-configurable ASICs and ASSPs and broad parallelism is evidently required to compete with potential alternatives. Thus, sorting and linear networks can be seen as very adequate models. Unfortunately, they have many limitations. Suppose N data items, each of size M bits need to be sorted. The results of [2,8] show that sorting networks cannot be built for N >64 (M =32), even in the relatively advanced FPGA FX130T from the Xilinx Virtex-5 family, because the hardware resources are insufficient. When N is increased, the complexity of the networks (the number of comparators C(N)) grows rapidly [1,2,8,18] (see Fig. 1 ). Also, to our knowledge, propagation delays through long combinational paths in FPGA networks have not been analyzed in depth and were not taken into account at all in many publications. Such delays are caused, not only by comparators, but also by multiplexers that have to be inserted even in partially regular circuits [4], and by interconnections. Components that execute comparisons with extended functionality are more flexible, but they cause new problems. For example, comparators for bitonic networks frequently perform reverse operations because the comparisons may be required for opposite orderings (first maximum, second minimum or vice versa). This requires either blocks that are driven by a special signal, or slightly different interconnections. Although at a first glance the problem looks trivial, it can be serious for networks with thousands of comparators. Let us look at Fig. 1. If a comparator requires one extra FPGA slice, it can lead to a huge number of additional slices in the resulting circuits. It is important to note that although sorting networks enhance the results, such improvements are not very practical for processing large data sets. This is because the increase in performance requires huge additional hardware resources that are often not realizable in practice. For this reason such networks are frequently combined with other methods, such as merging sorted subsets [7,9]. This paper provides four main contributions and suggests: (1) Regular and easily scalable hardware implementation of resource and time effective architectures based on even\u2013odd transition networks. With these, the number of comparators can be reduced dramatically, offering sufficient throughput. (2) A pipelined implementation of even\u2013odd transition networks with a reduced number of stages (sequentially executed steps). This requires fewer resources than existing alternative data sorters, while providing high throughput. The performance is sufficient, considering that the maximum attainable overall performance is constrained by surrounding circuits that use the results of sorting. (3) A pre-processing technique that enables sorting to be further accelerated. The main idea is to apply the concepts of methods such as quicksort in particular to achieve simple pre-positioning of the input data items. (4) Combining this technique with merge sort, address-based sort, quicksort, and radix sort. This allows hardware/software co-design that couples processing systems (PS) and programmable logic (PL) to be done more easily and effectively. Special attention has been paid to experiments and comparisons, the majority of which were done for relatively low cost FPGAs, with the main objective being to demonstrate wide applicability. Points (1 and 2) above have been evaluated and compared theoretically and experimentally with the best known alternatives. Points (3 and 4) above have not been fully tested in hardware, but the proposals have been verified in software. The transfer of data sets between PL (hardware that implements sorters) and PS (software that does pre- and post-processing) is also discussed. The remainder of the paper is organized in 7 sections. Section 2 presents an analysis of related work. Section 3 summarizes the main ideas of the paper and shows that they are practical. Section 4 compares the proposed networks with the best known alternatives theoretically. Section 5 discusses variations of the proposed circuits. Section 6 is dedicated to potential practical applications. Section 7 reports the results of experiments in FPGAs with comparison charts and simulation in software. The conclusion is in Section 8. 2 Related work Performance is critical for the majority of computational systems in which sorting plays an important role. One of the fastest known parallel sorting methods is based on the even\u2013odd merge and bitonic merge networks [1,2,4,8,11,12,18]. The depth D(N) of a network that sorts N data items is the minimal number of data dependent steps S 0,\u2026, Sk ,\u2026, SD ( N )\u22121 that have to be executed sequentially. This characteristic is important for both pure combinational and sequential implementations. In the first case, circuits operated at any step k use the results of circuits from the previous step k \u22121; i.e. there exists a data dependency between step k and step k \u22121. If we assume that propagation delays of all steps are equal, then the total delay is proportional to D(N). For sequential implementations, D(N) determines the number of sequentially executed steps (clock cycles). In both cases, D(N) together with clock frequency for sequential implementations determines the latency of the network, which influences the throughput (i.e. the number of sorted data items per time unit). If N is a power p of 2 (i.e. N =2 p ), then D(N =2 p )= p \u00d7(p +1)/2 [1,2] for both networks indicated above. Thus, these networks are very fast. Indeed, sorting 33million items (N =225) can be done with just 325 steps (D(N =225)=325). However, there is another problem. The hardware resources needed are enormous. Let us analyze the even\u2013odd merge network (that is less resource consuming than the bitonic merge network). The number of comparators for this network is C(N =2 p )=(p 2 \u2212 p +4)\u00d72 p \u22122 \u22121 [1,2]. Thus, sorting 33million items requires 5066719231 comparators. We found experimentally that one comparator/swapper for 32-bit data items (M =32) consumes at least 17 slices for Xilinx FPGAs. To our knowledge the largest existing FPGA XC7V2000T contains 305400 slices. Hence, to implement a network-based sorter for 33million items combinationally we would need more than a quarter of million of the most advanced FPGAs, and this is without taking into account routing overhead. Sequential implementations permit hardware resources to be reduced but cause a new problem: the number of memory transactions becomes very large [12]. So, the 325 steps indicated above are either not realizable in practice, or each step becomes very time consuming. The main idea of this paper is to find a good compromise between pure combinational parallel operations and sequential stages that execute the parallel operations. The emphasis is on circuits that are as regular as possible and thus easily scalable, avoiding redirecting data streams through multiplexing operations. This is because any multiplexer involves additional propagation delays and complicates interconnections. Of course the latter can cause further propagation delays. The results of [4] show the implementation of a sorting network for N =2048 on 3000 FPGA slices (Virtex-6 XC6VLX760). However, according to known theoretical results (e.g. [1,2,18]) this can be done if there are many sequentially executed steps, which are not explicitly shown in [4]. Indeed, 58,367 comparators are required for an even\u2013odd merge sort and 67,584 comparators for a bitonic merge sort [1,2,18]. Any comparator/swapper occupies 21 slices for the FPGA in [4]. Thus, 3000 slices can be employed just for 142 comparators. Any vertical line of comparators for the bitonic merge considered in [4] contains 1024 comparators and there are 66 vertical lines [1,2,18]. So, we need at least: \u2308 1024 / 142 \u2309 = 8 sequential steps to multiplex any vertical line; 66 steps to multiplex lines; and in total 66\u00d78=528 steps. Our experience with circuits implemented in FPGA shows that multiplexing involves excessive propagation delay. Pipelining permits the clock frequency for circuits to be increased because delays between registers in a pipeline are reduced. A number of such solutions are described in [2,8]. However, once again, the complexity of the circuits becomes the main limitation. We have already mentioned in the introduction that for N >64 (M =32), sorting networks [2,8] cannot be built even in the relatively advanced FPGA FX130T from the Xilinx Virtex-5 family because of the lack of hardware resources. Thus, FPGAs can only be used for sorting very small sets of data. Large data sets are ultimately sorted in [2,8] in software in host computers/processors and the FPGA just provides assistance by sorting small subsets. Clearly the smaller the number of items in the subsets, the greater is the communications overhead. Communication (preferably in burst mode) is involved between the host system/processor and the sorters in reconfigurable logic. The analysis presented above enables us to conclude the following: (1) The known even\u2013odd merge and bitonic merge circuits are the fastest and they enable the best throughput to be achieved. However, they are very resource consuming and can only be used effectively in existing FPGAs for sorting very small data sets. (2) Pipelined solutions permit faster circuits than in point 1 to be designed. However, assuming that pipelining can be based on flip-flops in the slices used so additional slices are not required, resource consumption is at least the same as in point 1. So, in practice, only very small data sets can be sorted. (3) To use even\u2013odd merge and bitonic merge circuits for large data sets, the following two methods are the most commonly applied: (a) large data sets are sorted in host computers/processors based on sorted subsets of large sets produced by an FPGA (see, for example, [2,8]); (b) the sorting networks for large sets are segmented in such a way that any segment can be processed easily and the results from the processing are handled sequentially to form the sorted set (see, for example, [4,12]). Both methods involve intensive communications, either between an FPGA and a host computing system/external memory (the size of memory embedded in FPGA is limited), or between a processing system (such as [12]) and memory. (4) The existing even\u2013odd merge and bitonic merge circuits are not very regular (compared to the even\u2013odd transition network for example) and, thus the routing overhead may be significant in FPGAs. 3 The proposed method and motivations The basic ideas of the method discussed in this paper are illustrated in Fig. 2 . The key points are numbered by the digits 1, 2, 3 and 4 enclosed in circles. They are: (1) Sequential reuse of the same sub-sorter (Fig. 2 shows a sub-sorter for N =6) instead of a sorter composed of connected sub-sorters (such as that in the even\u2013odd transition network in [11]). This permits the number of comparators/swappers to be reduced. (2) Connection of K sub-sorters in a pipeline. (3) Use of an optional pre-sorter, which enables the number of iterations in the sorter to be reduced. We will show later that using just the first stage of a method such as quicksort in [15] enables the number of iterations to be halved. (4) Using optional merging of sorted subsets for larger data sets. Note that the paper mainly focuses on points (1 and 2) above and is primarily dedicated to the sorter underlined in Fig. 2. Points (3 and 4) above are optional. They are discussed, but in less detail. To show the importance of these ideas we provide an initial comparison of the circuit indicated in point (1) that makes use of reusable sub-sorters with the two most frequently discussed and popular sorting networks (even\u2013odd merge and bitonic merge) shown in Fig. 3 for N =8 (the network is scalable for any N) and M =32. The functionality of the comparator/swapper can be described by the following simple VHDL code: MaxValue<=A when A>=B else B; MinValue<=B when A>=B else A; Both circuits in Fig. 3 were synthesized in Xilinx ISE 14.6 and implemented and tested in the Atlys prototyping board of Digilent [21] containing the xc6slx45 FPGA from the Xilinx Spartan-6 family. Source data were taken from a host PC through USB and sorted data were sent back to the PC. Table 1 presents the results (Ns is the number of FPGA slices, F max is the maximum attainable clock frequency, T min is the minimum clock period). F max and T min determine how fast sorted items can be read after any change in input data. We compared the results with the proposed alternative circuit that reuses the same comparators/swappers iteratively through a feedback register R (details are in Fig. 4 ). The circuit is very regular, easily scalable, and does not require any additional components when input data are written to and sorted output data are read from the register R sequentially, applying a shift operation. To transfer data to register R in parallel would require N multiplexers at the register inputs to receive data from outside before processing and from the comparators during processing. In all the experiments, parallel recording of data to register R was applied. The role of the additional comparator in Fig. 4b will be explained later. The maximum number of clock cycles \u03c4 max in the even\u2013odd transition network (see Fig. 4b) for sorting N =8 data items is equal to \u03c4 max = N/2=4 [11]. However this can be less than N/2 and thus less than 4 in Fig. 4b. For example, data in Fig. 3a are sorted at step 3, but because the network is hardwired, the results are transmitted through all the lines of comparators, which causes an unnecessary propagation delay. The same problem occurs in Fig. 4a. Let us introduce an enable signal which is zero at any second vertical line of the circuit in Fig. 4b when there is no exchange of data. As soon as enable=0, all data have been sorted. Suppose we need to sort data that are occasionally received in the sorted order, let us say: 8, 7, 6, 5, 4, 3, 2, 1. The sequential circuit (Fig. 4b) concludes that data have already been sorted in time 2\u00d7 t, where t is the delay of any vertical line in Fig. 4b. The combinational circuits in Figs. 3 and 4a still need time D(N)\u00d7 t. So, the simple iterative circuit in Fig. 4b permits the number of steps to be reduced, which cannot be done for the circuits in Figs. 3 and 4a. Moreover, the networks in Fig. 3 cannot be implemented with an enable signal similar to Fig. 4b. Indeed, since a set of merges of previously sorted subsets has to be executed, sorting is not guaranteed until the last merge phase, i.e. until the last stage that is composed of the remaining steps (e.g. after step 3 in Fig. 3a). In case of pipelining [25], the resources required are almost the same because FPGA slice flip-flops can be used without the need for additional components. The positions of pipeline registers (PLR) are shown in Fig. 5 a\u2013c for the even\u2013odd merge sorter (Fig. 5a), the bitonic merge sorter (Fig. 5b), and the proposed circuit (Fig. 5c). Fig. 5d depicts the sequence of vectors recorded in the register R and in the PLR for the worst and best cases (for the given example). The latter involves the enable signal (see Fig. 4b) that is tested in the simple fragment of a finite state machine (FSM) shown in Fig. 5e where the following steps are executed: (1) data from the first set are copied to the register R (state a 1); (2) data from the first set are transferred to the PLR through the first line of comparators/swappers and data from the second set are copied to the R (state a 2); (3) subsequent steps in the state a 3 depend on the enable signal. If there is a swap of inputs in the second line of comparators/swappers (i.e. the enable is equal to 1) then data are rotated (from R to PLR through the first line and from PLR to R through the second line). If there is no swap of signals in the second line of comparators/swappers (i.e. the enable is equal to 0) then sorted data are read from the outputs shown in Fig. 5c and data from a new set are copied to the register R. Note that interface signals (such as verifying availability of input data) are not shown in Fig. 5. Clock frequency for the even\u2013odd merge and the bitonic merge sorters can be increased in pipelined versions by a factor of about 6 (see Fig. 5a and b) and for the proposed circuit by about 2 (see Fig. 5c). Once again, the proposed circuit is the least resource consuming. The throughputs of the pipelined circuits will be evaluated and compared in Section 7.2. From the experiments we found that the maximum attainable clock frequency for the circuit in Fig. 5c is higher than for the circuits in Fig. 5a and b because of the difference in routing overheads. The circuit in Fig. 5c is more regular and the routing overhead for this circuit is smaller than for the circuits in Fig. 5a and b. Additional details and comments are in Section 7.2. The results of a preliminary comparison of the circuits in Figs. 3 and 4b (N =8) permit the following conclusions to be drawn: \u2022 For pure combinational implementations, the circuit in Fig. 4b is the fastest, even without the enable signal (i.e. in the worst case). \u2022 For pipelined implementations, the circuits need to be evaluated further, and compared taking account of the difference in routing overheads. This is done in Section 7.2. \u2022 If the enable signal is used, then sorting in Figs. 4b and 5c can be further accelerated. \u2022 The resources required for the proposed circuits are the smallest (see Table 1). Note that a visual comparison of the circuits in Figs. 3 and 4b shows that the propagation delays should differ by a factor of about 3 because the depth of the circuits in Fig. 3 is 6 and the depth of the circuit in Fig. 4b is 2. However, the actual difference is more than 5 times (see Table 1). This is because the interconnections in Fig. 3 are more complicated than those in Fig. 4b therefore the routing overhead is different. So, regularity and simplicity of interconnections are important. 4 Theoretical comparisons of the proposed and the best known networks The simple experimental comparison given in Table 1 shows that for N =8 and M =32 the proposed solutions are faster and less resource consuming. Let us now evaluate theoretically the two basic characteristics for the circuits for N >8: throughput (i.e. the number of sorted data items per second) and complexity (i.e. the number of FPGA slices required). Table 2 shows the number of slices Ns for two microchips, the APSoC Zynq xc7z020 [26] (FPGA section) and the Xilinx Spartan-6 xc6slx45 FPGA [27]. These are required for the comparators/swappers of the networks without taking account of the additional resources needed for interaction with the circuits, or the routing overheads. The values of Ns are calculated as Ns (comp)\u00d7 C(N), where Ns (comp) is the number of slices needed for one comparator/swapper with M =32 (i.e. for 32-bit data items), and C(N) is the number of comparators/swappers for the network. The values Ns (comp) have been found experimentally (for the xc6slx45 FPGA Ns (comp)=21 and for the APSoC Zynq xc7z020 Ns (comp)=17). The number of comparators/swappers for the proposed network in Fig. 4b is N \u22121. The number of comparators/swappers C(N =2 p ) for even\u2013odd merge networks is C(N =2 p )=(p 2 \u2212 p +4)\u00d72 p \u22122 \u22121 and for bitonic merge networks is C(N =2 p )=(p 2 + p)\u00d72 p \u22122 [1,2]. The percentage of FPGA slices used is also shown in Table 2 alongside the Ns values. For example, the even\u2013odd merge network for N =16 occupies 1323 slices, or 19% of the 6822 slices available in the xc6slx45 FPGA [27]. Table 2 shows clearly that the proposed technique permits larger data sets to be sorted in a given FPGA microchip. The resource estimation in Table 2 is not exact because the many supplementary circuits that are normally needed and the routing overheads have not been taken into account. The exact comparison will be done experimentally in Section 7.2. Much like [8], we only analyzed the isolated performance that can be achieved for sorting networks with small numbers of items. Table 3 indicates throughputs I s k (items per second) for different circuits. The values of I s k for the known even\u2013odd merge and bitonic merge networks are calculated as (the formulae below are given for non-pipelined circuits): [(1s=109 ns)/(D comp \u00d7 D(N))]\u00d7 N, where D comp is the delay of a comparator/swapper in nanoseconds and D(N =2 p )= p \u00d7(p +1)/2 [1,2]. For example, the even\u2013odd merge network sorts N =16 data items in D comp \u00d710ns (because D(N =2 p )= p\u00d7(p +1)/2=10). Thus, 108/D comp sets (each set contains 16 items) can be sorted per second and throughput is 16\u00d7108/D comp 32-bit items per second. The values of I s p for the proposed circuit (see Fig. 4b) in the worst case (i.e. the enable signal is not used) are calculated as: [(1s=109 ns)/(2\u00d7 D comp \u00d7 N/2)]\u00d7 N =109 ns/D comp. Indeed, there are two data independent vertical lines in Fig. 4b and a factor 2 is taken; in the worst case N/2 sequentially executed steps need to be done [11] and a factor N/2 is also used. We found that it is difficult to measure D comp values for individual comparators experimentally. If we analyze the ISE timing reports for an individual comparator and a set of sequentially connected comparators, the delays are not strictly proportional to the number of comparators in the chain. Also, the throughput estimates in Table 3 are not exact because the routing overhead has not been taken into account (and cannot be taken into account in our evaluation because it depends on particular synthesis tools). Thus, we will postpone the exact comparison until Section 7.2, where it will be done experimentally. Table 3 provides estimates of throughputs up to N =64 because for the microchips considered (xc7z020 and xc6slx45), the larger even\u2013odd merge and bitonic merge networks cannot be implemented (see Table 2). At first glance the existing solutions seem to be faster than the proposed circuits. Indeed, the values of I s k / I s p range from 1.6 to 3.0 and if N is increased, these values are also increased. Additionally, pipelining permits even better results to be obtained for these networks. However, in practice, even if the existing solutions are faster, we cannot take advantage of such high speeds and circuits implemented in FPGAs are never as fast as we expect. The reasons for this conclusion are: (1) Even trivial experimental comparisons (see Table 1) show that the routing overhead is higher for the known networks than for the proposed solution. (2) The throughputs in Table 3 cannot be achieved in practical circuits because of communication overheads. Indeed, initial data need to be supplied to the sorter, the results have to be taken from the sorter, and the speed of communications is a bottleneck. The latter is more critical for existing networks because they can only be used for data sets with a very small number of items and thus more frequent data exchange is involved (since the number of transmitted data is actually very small it is difficult to apply full burst mode capabilities). Let us look once again at Table 2. Even for the modern, relatively advanced microchip xc7z020, the available resources allow only up to 64 items (M =32) to be sorted by the known networks in programmable logic. Thus, real-world sorting problems require a higher level processing system such as the ARM Cortex-A9 in the APSoC xc7z020 in order to sort larger data sets using pre-sorted subsets. Communication between the processing system and the programmable logic in the APSoC is done inside the microchip but the speed is limited so no advantage can be gained from the potential higher throughput values shown in Table 3. (3) Extensive communications between the processing system and the programmable logic in hybrid sorters that are implemented partially in software and partially in hardware do not allow the desired performance to be achieved because the processing system is frequently interrupted for necessary data exchange. Clearly, existing networks require more intensive communication than the proposed circuits because the latter allow data sets with a larger number of items to be sorted in the same FPGA (see Table 2). (4) Using the enable signal permits the performance of the proposed circuits to be increased (see Fig. 4b) although hardware resources will also be increased slightly. 5 Variations of the proposed network Let us analyze the network depicted in Fig. 4b assuming that there is one additional comparator which handles items with indices 0 and N \u22121 when they are written to the register R before sorting starts. This costs nothing but may reduce the number of steps. We will assume that items are sorted in descending order in such a way that after processing, the upper item is the largest and the bottom item is the smallest. We also assume that the comparators are built as shown in Fig. 3c. Since large values (keys) will move one or two positions upwards in every clock cycle while small values move downwards, we need N/2 iterations (clock cycles) in the worst case [11]. The additional comparator (see Fig. 4b) guarantees that the top value is not the smallest and the bottom value is not the largest. Hence, we can reduce processing by one or more iterations. Any iteration has the delay 2\u00d7 D comp and signals from the register pass through two vertical lines in Fig. 4b. From the previous section we can see that the proposed circuit requires significantly smaller resources than the best known sorting networks and we will show later that it also provides sufficient throughput for practical applications. Variations of the proposed even\u2013odd transition network with sequentially reusable segments permit a better compromise to be found between the resources required and performance. In Fig. 6 the reusable segments are composed of a larger number of vertical lines than in Fig. 4b. When the number of vertical lines is increased, the resources required also increase but a pipeline similar to Fig. 5c can be created enabling performance to be improved. There are two major reasons for increasing the number of vertical lines: (1) to sort several data subsets for subsequent merging; (2) to achieve a higher overall throughput if this is required. Fig. 7 depicts a pipelined implementation of the circuit in Fig. 6. There are four pipeline registers PLR1,\u2026, PLR4 that are controlled by an FSM. It is assumed that the initial data are read from input memory and the sorted data are saved in the output memory, which is also controlled by the FSM. Thus, the output memory accumulates several sorted subsets which will be further merged. Fig. 8 demonstrates an example of the functionality of the circuit in Fig. 7 with more details. Input vectors composed of N items of size M are read from the input memory and saved in the register PLR1 of size N \u00d7 M. Several vectors are received sequentially and shifted through vertical lines of comparators (see Fig. 8a). Shifts are controlled by the FSM which indicates when the results can be read from the rightmost PLR (PLR4) through the last vertical line of comparators. Thus, depending on signals from the FSM, outputs of the block composed of PLR4 and the odd line 3 are copied, either to the output data memory, or to PLR1. Now N + L \u22121 steps are needed to sort L N-item sets, where L is the number of vertical lines/registers in Fig. 8a. Fig. 8b demonstrates an example where 4 (L =4) subsets with 8-items each (N =8) are sorted in 11 clock cycles. So, throughput is 2.75 clock cycles per subset. The signal \u201csubset is sorted\u201d, similar to the enable signal considered above, can be taken from the rightmost odd line (odd line 3 in Fig. 8a). As soon as there is no swap in the line, the signal \u201csubset is sorted\u201d indicates that the sorted data items can be read from the rightmost block (composed of the register PLR4 and the odd line 3 in Fig. 8a). Hence, less than N + L \u22121 steps might be required to sort all the subsets. As soon as a subset is sorted and read, the next (new) subset can be loaded into the register PLR1. Thus, and this is very important, sorting can be executed continuously with new subsets added periodically. Such processing is controlled by the same FSM. Let us look at the example in Fig. 8b. One subset (150, 144, 119, 96, 55, 39, 21, 17) is sorted at step 3 (the step numbers are enclosed in circles in Fig. 8b). The sorted subset can be read from the register PLR4 through the odd line 3 at step 4 and a new subset can be loaded to the register PLR1 (see step 5 in Fig. 8b). Another subset is sorted at step 5 and can be read at step 6. 6 Practical applications The following practical applications can benefit from the proposed solutions: \u2022 FPGA-based autonomous circuits for sorting small data sets which consume significantly fewer resources than the best known sorting networks (e.g. even\u2013odd merge and bitonic merge). \u2022 FPGA-based accelerators that sort subsets of data items received from host (higher-level) processors/computers while the remaining task is solved by software in the host system. Although data sorters implemented in general-purpose software exhibit high performance, they are slower than highly parallel hardware circuits. For example, programs written in the C/C++ language [28] sort large sets (100\u2013200million data items) on a PC in about 10s, which is about 50\u2013100ns per item. Sorting in embedded processors is usually slower than in PCs. From Sections 3 and 4 we can see that data processing in FPGAs might be significantly faster. Thus, the problem can be split into two parts, one executed in FPGA and the other in general-purpose/application-specific software. This is reasonable because FPGAs can sort small subsets of data considerably faster, but for large sets of data the same throughput either cannot be achieved, or requires substantial resources and is thus very expensive. \u2022 Applications that use the proposed circuits as components of sorting systems such as [7,9,10,29]. Let us discuss points (3 and 4) from Section 3, which suggest an optional pre-sorter that enables the number of iterations in an FPGA-based sorter to be reduced, and a merger that permits larger sorted sets to be built from subsets sorted in an FPGA. We found that pre-sorting and merging can be implemented easily in software on a host system that uses an FPGA as an accelerator. This is because the indicated operations are not very well parallelized in hardware and require additional resources that are typically very limited. Let us discuss these operations in more detail. In Fig. 4b the register contains N M-bit data items. Clearly, if the enable signal is used and the lower part contains larger values while the upper part holds smaller values, then sorting in descending sequence takes longer. The quicksort algorithm divides large sets of data items into two subsets containing smaller and larger elements. A similar separation can then be applied to the subsets recursively. We found that this technique can be helpful for the proposed sorter. Data with larger values are dispatched to the upper part of register R and items with smaller values to the lower part of register R. Let us call such processing pre-sorting (see Fig. 2). We carried out several experiments with C/C++ programs that implement this technique as simply as possible: the range of possible input values is divided into two halves and the middle value is considered to be a pivot. All data larger than the pivot are copied to the upper part of register R and all data smaller than the pivot are copied to the lower part. If either part is full, then all subsequent data are recorded in the other part. Input data were generated randomly by the C function, rand. Table 4 indicates the average number (from 100 runs) of sequential iterations needed for the circuits (1), (2) and steps for the circuit (3), where: (1) is the circuit in Fig. 4b without pre-sort; (2) is the circuit in Fig. 4b with pre-sort; (3) is the even\u2013odd merge and bitonic merge networks. Note that the combinational delay within an iteration in the proposed circuit is twice as long as in a step in the known networks. This is because signals pass through two vertical lines of comparators/swappers in the proposed network (see Fig. 4b) whereas in the known network they pass through just one line (see Fig. 3a and b). This is explicitly indicated in Table 4 by the values 2\u00d7 D comp and D comp in square brackets. We can see that although the distribution of input data between the upper and lower parts of register R is indeed trivial, the number of subsequent iterations is reduced by a factor of approximately 2 (compare columns (1 and 2) in Table 4). A more efficient pre-sort can be done similarly to the first few steps of the quicksort algorithm. This operation is not time consuming and it can be done in parallel for new subsets of data in a host system with sorting in FPGA. To get the final sorted sequence that is built from subsets of sorted sequences such as those shown in Fig. 8b, we need to merge the subsets. Note that merging is not the main target of the paper and the technique similar to [2,8] (see Fig. 9 ) is applied. The initial set of data that is to be sorted is divided into Z subsets of N items. Each subset is sorted in an FPGA using the proposed circuits. Merging is executed as shown in Fig. 9, in a host system that interacts with the FPGA. Two types of host systems were considered: (1) a desktop PC interacting with the board through a USB port (experiments were done with the Atlys prototyping board and Digilent software [21]), and (2) the processing system (PS) in the APSoC Zynq [26] interacting with the programmable logic (PL). In both cases, merging is done by software written in C. From column (3) of Table 4 we can see that the larger the value N, the fewer the steps that are required for the even\u2013odd merge and bitonic merge sorting networks compared to the even\u2013odd transition network shown in Fig. 4a. Merging is executed incrementally in the networks, as shown in Fig. 10 a for the even\u2013odd merge. Initially, each 2-item subset is sorted. Then pairs of the resulting 2-item sorted subsets are merged to compose 4-item sorted subsets. Pairs of the 4-item sorted subsets are merged again and so on, until the complete sorted set of data is produced. The number of comparators/swappers required in any block is shown in the rectangles. The table in Fig. 10b gives the number of comparators/swappers at each last stage where sorted subsets are merged, and the number of comparators at all stages for N varying from 8 to 2048. From the previous discussion we can see that the proposed circuits are significantly less resource consuming than even\u2013odd merge and bitonic merge networks when implemented in FPGA, but their complexity is still limited by the available FPGA resources. However, we can use the proposed circuits for sorting small subsets (let us say N \u2a7d512) and then apply even\u2013odd and bitonic mergers implemented in other microchips (such as a GPU). This approach might be constructive for multi-stage (sequential) merging that is used in GPU-based sorters [12]. This technique reduces the number of memory transactions and comparison operations significantly. For instance, if subsets of N =256 items are pre-sorted, the number of comparators/swappers is decreased (see the numbers in bold font in Fig. 10b) by a factor of 15 (3839 are needed for even\u2013odd merge vs. 255 needed for the circuit in Fig. 4b). The following advantages of such reduction can be pointed out: (1) Larger pre-sorted subsets (see Fig. 9) may be built in the same hardware (see the PL section in Fig. 9) while the remaining mergers are implemented in software (see the PS section in Fig. 9). This way permits the number of data transitions between software and memory in the PS section (see mergers in Fig. 9) to be reduced. Besides, burst mode may easier be applied to data exchange between the PS/memory and the PL. (2) The depth of the tree from mergers shown in Fig. 9 is reduced and, thus, the most time-consuming part of the sorter (implemented in the PS) becomes faster. (3) Fig. 10 permits the reduction of the depth of the tree of mergers to be evaluated. For example, if we compare the use of pre-sorters with N =16 and N =256 then the number of the tree horizontal levels is decreased by a factor of 4. The proposed technique can also be applied to non-comparison based methods that proved to be very efficient. Let us discuss two of them, the radix sort and the address-based sort. The radix sort implementation that relies on segmented scan primitives demonstrates very good results [29]. The address-based sort [10] is very fast, especially when N is close to 2 M , although the value of M is limited (to 32 or so). The main idea of the radix sort is to process individual digits, normally beginning from the least significant digit. Let us consider the example shown in Fig. 3: 144, 119, 150, 96, 39, 55, 17, 21, and apply a descending sort to the least significant digit. The result is: 119, 39, 17, 96, 55, 144, 21, 150. Now execute the same procedure for the second digit: 96, 55, 150, 144, 39, 21, 119, 17. Lastly the most significant digit is sorted, giving the final result: 150, 144, 119, 96, 55, 39, 21, 17. The original values in binary representation are: 10010000, 1110111, 10010110, 1100000, 100111, 110111, 10001, 10101. We can execute analogous steps for all 8 bits (the sorted bits at each iteration are shown in bold font): (1) 01110111, 00100111, 00110111, 00010001, 00010101, 10010000, 10010110, 01100000; (2) 01110111, 00100111, 00110111, 10010110, 00010001, 00010101, 10010000, 01100000; (3) 01110111, 00100111, 00110111, 10010110, 00010101, 00010001, 10010000, 01100000; (4) there is no change; (5) 01110111, 00110111, 10010110, 00010101, 00010001, 10010000, 00100111, 01100000; (6) 01110111, 00110111, 00100111, 01100000, 10010110, 00010101, 00010001, 10010000; (7) 01110111, 01100000, 00110111, 00100111, 10010110, 00010101, 00010001, 10010000; (8) 10010110, 10010000, 01110111, 01100000, 00110111, 00100111, 00010101, 00010001. The results at iteration 8 in decimal are: 150, 144, 119, 96, 55, 39, 21, 17. A similar technique can be applied to groups of bits. For example, the same result can be obtained if we apply 4 steps to groups of 2bits. Thus, the sorter proposed in this paper can be used as shown in Fig. 11 . It sorts items in each group G 0,\u2026, GQ \u22121 iteratively. Note that each group is an n-bit slice within M-bit items (n < M), so fewer bits have to be compared. However, swapping (if needed) still has to be applied to the whole M-bit words (see Fig. 11b). Fig. 11c demonstrates an example. Experiments that we conducted showed that the results depend on the number of bits in the sub-vectors that need to be compared. FPGA resources may be decreased but not significantly. The sort time increases by a factor of \u2308 M / Q \u2309 , and an FSM that selects different groups sequentially (see Fig. 11a) has to be used, which requires additional resources. For the chosen FPGAs, this method does not give advantages. However, it may turn out to be advantageous for potential future alternative FPGA architectures. The address-based sort [10] can be applied to non-repeated integers. The idea is to allocate memory with 2 M zero filled one-bit words. Each new item, I, is recorded by writing the value 1 at address I. As soon as all data items have been processed, they are sorted, so the next task is to extract the addresses from the memory. This can be done by ordering the one-bit memory words and recording their addresses (see an example in Fig. 12 a). Comparators become very simple [30]. Data have to be swapped if and only if the first one-bit value is 0 and the second one-bit value is 1 (i.e. A=0 and B=1 in Fig. 3c). Processing is executed sequentially (or, possibly, in parallel) over segments S 0,\u2026, SR \u22121 (see Fig. 12b). If segments are sorted from left to right (from S 0 to SR \u22121), then as soon as the first segment S 0 is sorted, the addresses can be output in ascending order (because all the segments S 0,\u2026, SR \u22121 are also properly ordered after recording the data items in the memory). Let us assume that each segment has N items. Since data in each segment are positioned sequentially, the most significant bits in their addresses are the same for all items. Thus at any swap we need to exchange only the least significant bits and the number of such bits is less than M. Since the address-based sort is not a target of this paper, many details are not explained, but it can be evidently seen that the proposed circuits can be applied. 7 Experiments and comparisons This section presents a thorough evaluation and comparison of the proposed circuits that have been synthesized and implemented in the Xilinx ISE 14.6 from specification in VHDL, and tested in two prototyping boards: the Atlys with the Xilinx Spartan-6 xc6slx45 FPGA [27] and ZedBoard with the Xilinx Zynq xc7z020 APSoC microchip [26]. 7.1 Experimental setup Fig. 13 shows the organization of the experiments. Initially, the proposed and the competitive known circuits were tested in the xc6slx45 FPGA and in the PL section of the APSoC Zynq xc7z020. In the both cases the FPGA (PL section) was configured autonomously, i.e. the host systems running the software were not involved. Initial data are supplied internally from embedded ROM/RAM. At the next step two types of software/hardware interactions were considered: (1) Interaction with a desktop PC through a USB port using Digilent software and drivers [21] (see Fig. 13a). (2) On-chip interactions between the PS and the PL [20] (see Fig. 13b) through AXI (Advanced eXtensible Interface). The FPGA is responsible for sorting using the known and the proposed circuits (see Figs. 3, 4b, 5a, c and 7). The host system (either a desktop PC or the PS of the APSoC xc7z020) supplies initial data and provides support for further analysis and processing of the FPGA results. Fig. 14 shows the general structure of circuits implemented in FPGA (in the PL of the xc7z020). Initial (unsorted) data are stored in embedded FPGA block RAM, which is filled using two methods: (1) from text files that are read in VHDL and copied to embedded memories during synthesis or initialization by constants in VHDL code (see number 1i on the left-hand side of Fig. 14 enclosed in a circle); (2) from a host system, i.e. from a desktop PC or PS of the xc7z020 (see number 2i on the left-hand side of Fig. 14 enclosed in a circle). Data items from the input memory are preliminarily loaded to a register R in. Since the width of available block-RAMs in FPGAs is limited, items can be transferred to the register R in from more than one memory word. For example, the available 116 blocks of 18Kb each in the FPGA xc6slx45 of the Atlys board cannot be used to read 128 items (M =32) in parallel (since the maximum width of one block is 36 [27]). However, initial data items can be read sequentially in more than one clock cycle, such as 4 cycles for 32 items (M =32). Similar sequential transfers to the output memory from the register R out are used for the sorted data. These operations are exactly the same for the proposed and the competitive circuits so the data transmission time is not taken into account. We compare throughputs only for competitive circuits that are placed between the registers R in and R out in Fig. 14. Some sequential operations that are required outside of the circuits are controlled by a hierarchical FSM [31]. We implemented several modules that can easily be invoked, modified and replaced in the HFSM that was designed with the aid of the methods [31]. For all experiments, the resources of the HFSM are not taken into account because they are not used within the sorters in Fig. 14. For pure combinational circuits, the maximum combinational path delays are taken from the ISE reports. For sequential circuits, the sort time is measured as N cc \u00d7 T mp, where N cc is the number of clock cycles reported by the FSM controller from receiving source data (reading the R in) to recording the results of sorting in the R out, T mp is the minimum clock period from the ISE reports (for the maximum attainable clock frequency F max). Clearly, potential additional delays caused by the FSM controller are taken into account in such measurements. Note that the HFSM [31] is used just outside of the analyzed circuits and only conventional FSM was used to control iterations and pipelines. We implemented and tested the following competitive designs: \u2022 The proposed circuit (see Fig. 4b) vs. the pure combinational even\u2013odd merge network. Since the even\u2013odd merge network (see Fig. 3a) has the same throughput as the bitonic merge network (see Fig. 3b) and slightly smaller hardware resources than the bitonic merge network, only the even\u2013odd merge network has been implemented and compared. \u2022 The proposed pipelined circuits (see Figs. 5c and 7) vs. the pipelined even\u2013odd merge network. The sorted results are tested either directly in R out or are transferred to embedded (output) block-RAM and examined further. Two verification methods were used: (1) autonomous testing (just in FPGA) in an additional supplementary circuit that verifies that the next item is less or equal to its predecessor (see number 1o on the right-hand side of Fig. 14 enclosed in a circle); (2) in a higher-level (host) system, i.e. in a desktop PC or the PS of the xc7z020 (see number 2o on the right-hand side of Fig. 14 enclosed in a circle). 7.2 Experimental comparison of the proposed and the best known networks Section 4 estimates two basic characteristics for the proposed and the competitive circuits: throughput (i.e. the number of sorted data items per second) and complexity (i.e. the number of FPGA slices required). However, supplementary circuits and routing overhead have not been taken into account. Thus, the results of Section 4 also need to be checked experimentally, which is done in this section. Fig. 15 presents the results of synthesis, implementation and testing (in FPGA of the Atlys board) of circuits that are a pure combinational even\u2013odd merge network and the proposed network (see Fig. 4b). Fig. 16 gives similar results for the PL section in APSoC of ZedBoard. Figs. 15a and 16a depict the percentage of FPGA resources occupied. A comparison with Table 2 shows that although the resources are increased comparing to theoretical evaluations, the tendency is the same and the number of slices for the proposed designs is significantly less than for the even\u2013odd merge network. Figs. 15b and 16b show throughputs. We did not use the enable signal shown in Fig. 4b. If this signal is involved, then the throughput can be increased. Hardware resources are also enlarged but insignificantly and the proposed solutions require essentially a smaller number of FPGA slices than the competitive networks. Since the even\u2013odd merge network is not as regular as the proposed circuit, delays in wires become significant, increasing routing overheads. We have already mentioned in Section 4 that in practice it is very difficult or even impossible to take advantage of the speed measured in hundred millions of data items per second because other limitations restrict the achievable performance. On the other hand, the resources used become a bottleneck preventing additional circuits from being implemented in programmable logic. Besides, the significant reduction in resources required for the proposed designs permits larger data sets to be sorted in parallel and the number of horizontal levels in merging circuits (see Fig. 9) is decreased, thus allowing additional acceleration. For example, if we compare merging from 8-item sorted sets and 256-item sorted sets, then the number of horizontal levels in Fig. 9 is reduced by a factor of 5. Fig. 17 a shows the percentage of FPGA resources occupied and Fig. 17b shows throughputs for pipelined implementations of the even\u2013odd merge (see the structure shown in Fig. 5a) and the proposed network. The latter is evaluated for the structure shown in Fig. 5c (indicated as L =2 pipeline) and in Figs. 7 and 8 (indicated as L =4 pipeline). The experiments were done with the Atlys board and the following conclusions can be drawn: 1. The best throughput is achieved in the pipelined even\u2013odd merge network and N =32 (M =32). However this circuit occupies more than 65% of the FPGA resources. Throughput for the proposed circuit is not as good but the resources used are a factor of 3.3 (for L =4 pipeline) and 5.5 (for L =2 pipeline) less. Note once again, that much like [8] we only analyzed the isolated performance for sorting networks that can be achieved just for small number N of data items, without taking into account the communication overheads involved in data input/output. 2. To sort larger sets of data, an FPGA is frequently used as an accelerator [2,8] while a host system/processor merges sorted subsets for larger sets. Thus, data need to be transferred to and from the FPGA. According to [27] FPGA dedicated memory controller blocks support access rates for external DDR memory of up to 800Mb/s (or for M =32-bit items\u223c25 mega items per second) for the Spartan-6 FPGA, and up to 1333Mb/s (or for M =32-bit items\u223c41mega items per second) for the Zynq APSoC [26]. Thus, the potential performance of the sorting networks (up to 3158 mega items per second for the even\u2013odd merge network) cannot be supported in practical applications. Data exchange in APSoC (such as Zynq) permits faster data transfer between on-chip programmable logic (PL) and processing system (PS) interacting through high-performance AXI ports. However, data need to be saved, and on-chip resources (embedded block-RAM) do not permit large data sets to be processed. Thus, once again, access to external memory (shared between the PS and the PL) is involved, causing similar problems and restricting performance. Using gigabit transceivers [26,27] also does not allow to benefit from the potential performance of the sorting networks. Only data rates up to 3200Mb/s (or for M =32-bit items\u223c100 mega items per second) for [27] and 12,500Mb/s (or for M =32-bit items\u223c390 mega items per second) for [26] are supported. 3. Autonomous sorters entirely implemented in FPGA can be practical for some applications and an on-chip merger can be built. There are at least three new limitations in such circuits. Firstly, FPGA resources as a rule, do not permit a large sorter (including also a merger) to be implemented on a single chip. Secondly, merging has to be executed sequentially over individual pre-sorted subsets and the maximum clock frequency for FPGAs is limited [26,27], so no benefit from the potential performance of the sorting networks can be obtained. Thirdly, after a sorter is implemented, the remaining FPGA resources are scarce and they are significantly more limited for the known even\u2013odd merge network than for the proposed circuits. 4. Our methods allow a sensible compromise between resources and performance to be found more easily. For example, the pipelined circuit (L =2) can be implemented in the xc6slx45 FPGA for up to N =256 (see Fig. 17a) and, thus, 8-times more items than in the even\u2013odd merge circuit can be processed. The pipelined circuit (L =4) can be implemented in the xc6slx45 FPGA for up to N =128 (see Fig. 17a). If we compare the throughputs of the pipelined even\u2013odd merge and the proposed (L =4) circuits we can see that although the proposed circuits are slower, in any case, we cannot take advantage of the higher throughput in practical applications (see point 2 above). 5. There is one result that is hard to explain. The resources for pipelined even\u2013odd merge networks are a bit smaller than for combinational even\u2013odd merge networks. The difference is negligible but it exists. We found that similar results were obtained in [8, see Section 6.4.2], where it was also not quite clear, and it was assumed that this is a feature of the Xilinx synthesis tools. 6. The analysis above has shown that the resources needed become a bottleneck for practical applications that cannot benefit from very high performance of sorters operating over data with limited number of items because systems that use the sorters cannot support the required speed for input/output data. The proposed solutions clearly demonstrate very good compromise between resource consumption and performance and can be seen as more practical and widely applicable for both autonomous small size very fast sorters and FPGA-based accelerators for higher-level systems (such as implemented in the PS). In all the experiments above, the enable signal that decreases the number of sequential steps in the proposed circuit was not used, i.e. the worst (the slowest) case for the proposed circuits has been analyzed. Clearly this signal can be used to obtain additional performance improvements. Some experiments with the ZedBoard demonstrate the same chart tendencies as in Fig. 17. We were able to implement the even\u2013odd merge network for up to N =64 (a similar result was reported in [8] for the Virtex-5 FPGA) and the proposed network for up to N =512. The majority of contemporary FPGAs possess embedded DSP slices (ex. DSP48E1 slice for Xilinx FPGAs [22]) and they can be used to implement comparators of the network through the execution of a subtraction operation. Let us consider Fig. 3c where operands A and B have to be compared. An operation A\u2013B executed in a DSP gives a result that is negative if B is greater than A, zero if A=B, or positive if A is greater than B. We found that swapping A and B in Fig. 3c requires more slices than the comparator described above. For the APSoC Zynq xc7z020 (ZedBoard) and M =32, a comparator occupies just 5 of 17 slices needed for the circuit in Fig. 3c. Nevertheless, making use of embedded DSPs that are available in addition to logical slices in any event permits larger sorters to be implemented in the same FPGA. For example, the PL section in the APSoC xc7z020 embeds 220 DSP48E1 slices processing 48-bit operands (M =48) and the most advanced FPGAs contain thousands of such slices. Our experiments have demonstrated that the FPGA resources needed for comparators and swappers can be reduced by approximately 20%, although the maximum attainable frequency is also slightly reduced. The enable signal (see Fig. 4b) requires ORing N/2-1 signals and it can also be produced in a DSP slice. Indeed, the DSP48E1 [22] permits bitwise logical operations to be executed over 48-bit operands. Thus, two 48-bit operands can be ORed in one slice and the result can be tested for 0, which is the equivalent of verifying 96bits from the comparators. This operation is fast, simple, and does not use logical slices. 8 Conclusion The fastest known sorting networks (namely, the even\u2013odd merge and the bitonic merge) consume very large hardware resources and can only be implemented in FPGAs for processing small number of items even in advanced devices. Furthermore, they require convoluted interconnection involving numerous multiplexing operations that lead to excessive propagation delays. We found that very regular even\u2013odd transition networks with two sequentially reusable vertical lines of comparators are more practical because they operate with a higher clock frequency, provide sufficient throughput, and enable a significantly larger number of items to be sorted on the same microchip. Further, a pipeline can be constructed and the number of vertical lines increased, allowing a compromise between the performance and resources to be found. The emphasis is on the ability to implement the circuits in commercially available FPGAs and on a compromise between affordable hardware resources and attainable throughputs, taking into account not only the network performance, but also the constraints imposed by surrounding systems. Finally, the results of extensive experiments (evaluating both pure combinational and pipelined implementations of the known and the proposed networks) and comparisons are presented, which clearly demonstrate the significant advantages of the proposed technique, which can be used both autonomously and in combination with such popular methods as merge sort, address-based sort, quicksort, and radix sort. Acknowledgments The authors would like to thank Ivor Horton for his very useful comments and suggestions. This research was supported by FEDER through the Operational Program Competitiveness Factors \u2013 COMPETE and by National Funds through FCT \u2013 Foundation for Science and Technology in the context of Projects FCOMP-01-0124-FEDER-022682 (FCT reference PEst-C/EEI/UI0127/2011) and Incentivo/EEI/UI0127/2013. References [1] D.E. Knuth The Art of Computer Programming. Sorting and Searching vol. III 2011 Addison-Wesley [2] R. Mueller J. Teubner G. Alonso Sorting networks on FPGAs Int. J. Very Large Data Bases 21 1 2012 1 23 [3] J. Ortiz, D. Andrews, A configurable high-throughput linear sorter system, in: Proceedings of IEEE International Symposium on Parallel & Distributed Processing, April, 2010, pp. 1\u20138. [4] M. Zuluada, P. Milder, M. Puschel, Computer generation of streaming sorting networks, in: Proceedings of the 49th Design Automation Conference, San Francisco, June, 2012, pp. 1245\u20131253. [5] D.J. Greaves, S. Singh, Kiwi: Synthesis of FPGA circuits from parallel programs, in: Proceedings of the 16th IEEE International Symposium on Field-Programmable Custom Computing Machines \u2013 FCCM\u201908, USA, 2008, pp. 3\u201312. [6] S. Chey, J. Liz, J.W. Sheaffery, K. Skadrony, J. Lach, Accelerating compute-intensive applications with GPUs and FPGAs, in: Proceedings of the Symposium on Application Specific Processors \u2013 SASP\u201908, USA, 2008, pp. 101\u2013107. [7] R.D. Chamberlain, N. Ganesan, Sorting on architecturally diverse computer systems, in: Proceedings of the 3rd International Workshop on High-Performance Reconfigurable Computing Technology and Applications \u2013 HPRCTA\u201909, USA, 2009, pp. 39\u201346. [8] R. Mueller, Data Stream Processing on Embedded Devices, Ph.D. Thesis, ETH, Zurich, 2010. [9] D. Koch, J. Torresen, FPGASort: a high performance sorting architecture exploiting run-time reconfiguration on FPGAs for large problem sorting, in: Proceedings of the 19th ACM/SIGDA International Symposium on Field Programmable Gate Arrays \u2013 FPGA\u201911, USA, 2011, pp. 45\u201354. [10] V. Sklyarov, I. Skliarova, D. Mihhailov, A. Sudnitson, Implementation in FPGA of address-based data sorting, in: Proceedings of the 21st International Conference on Field-Programmable Logic and Applications \u2013 FPL\u201911, Greece, 2011, pp. 405\u2013410. [11] GPU Gems, Improved GPU Sorting. <http://http.developer.nvidia.com/GPUGems2/gpugems2_chapter46.html>. [12] G. Gapannini F. Silvestri R. Baraglia Sorting on GPU for large scale datasets: a thorough comparison Inf. Process. Manage. 48 5 2012 903 917 [13] X. Ye, D. Fan, W. Lin, N. Yuan, P. Ienne, High performance comparison-based sorting algorithm on many-core GPUs, in: Proceedings of the IEEE International Symposium on Parallel & Distributed Processing \u2013 IPDPS\u201910, USA, 2010, pp. 1\u201310. [14] N. Satish, M. Harris, M. Garland, Designing efficient sorting algorithms for manycore GPUs, in: Proceedings of the IEEE International Symposium on Parallel & Distributed Processing \u2013 IPDPS\u201909, Italy, 2009, pp. 1\u201310. [15] D. Cederman, P. Tsigas, A practical quicksort algorithm for graphics processors, in: Proceedings of the 16th Annual European Symposium on Algorithms \u2013 ESA\u201908, Germany, 2008, pp. 246\u2013258. [16] C. Grozea Z. Bankovic P. Laskov FPGA vs. multi-core CPUs vs. GPUs R. Keller D. Kramer J.P. Weiss Facing the Multicore-challenge 2010 Springer-Verlag Berlin, Heidelberg 105 117 [17] M. Edahiro, Parallelizing fundamental algorithms such as sorting on multi-core processors for EDA acceleration, in: Proceedings of the 18th Asia and South Pacific Design Automation Conference \u2013 ASP-DAC\u201909, Japan, 2009, pp. 230\u2013233. [18] K.E. Batcher, Sorting networks and their applications, in: Proceedings of AFIPS Spring Joint Computer Conference, USA, 1968, pp. 307\u2013314. [19] S. Lacey R. Box A fast easy sort: a novel enhancement makes a bubble sort into one of the fastest sorting routines Byte 16 4 1991 315 316 318, 320 [20] ZedBoard (Zynq\u2122 Evaluation and Development), Hardware User\u2019s Guide. <http://www.zedboard.org/sites/default/files/documentations/ZedBoard_HW_UG_v1_9.pdf>. [21] Digilent Boards, Drivers, and VHDL Modules. <http://www.digilentinc.com/>. [22] 7 Series DSP48E1 Slice User Guide UG479 (v1.5), April 3, 2013. <http://www.xilinx.com/support/documentation/user_guides/ug479_7Series_DSP48E1.pdf>. [23] B. Cope P.Y.K. Cheung W. Luk L. Howes Performance comparison of graphics processors to reconfigurable logic: a case study IEEE Trans. Comput. 59 4 2010 433 448 [24] I. Skliarova A.B. Ferrari Reconfigurable hardware SAT solvers: a survey of systems IEEE Trans. Comput. 53 11 2004 1449 1461 [25] C. Alias B. Pasca A. Plesco FPGA-specific synthesis of loop-nests with pipelined computational cores Microprocess. Microsyst. 36 8 2012 606 619 [26] Zynq-7000 All Programmable SoC Overview. <http://www.xilinx.com/support/documentation/data_sheets/ds190-Zynq-7000-Overview.pdf>. [27] Xilinx, Spartan-6 Family Overview. <http://www.xilinx.com/support/documentation/data_sheets/ds160.pdf>. [28] Sorting Algorithms. <https://ece.uwaterloo.ca/~dwharder/aads/Algorithms/Sorting/>. [29] S. Sengupta, M. Harris, Y. Zhang, J.D. Owens, Scan Primitives for GPU Computing, GH\u201907, Eurographics Association, Switzerland, 2007. [30] S.J. Piestrak Efficient hamming weight comparators of binary vectors Electronic Lett. 43 11 2007 611 612 [31] V. Sklyarov FPGA-based implementation of recursive algorithms Microprocess. Microsyst. 28 5\u20136 2004 197 211 (Special Issue on FPGAs: Applications and Designs) Valery Sklyarov received the Engineering degree from the Technical University \u2013 UPI, Uljanovsk, Russia, in 1972, the Ph.D. degree in computer science from the Technical University \u2013 BSUIR, Minsk, Belarus, in 1978, the Doctor of Science degree in computer science from the Technical University \u2013 LETI, St. Petersburg, Russia, in 1986 and the Aggregation (Agrega\u00e7\u00e3o) in electronic engineering from University of Aveiro, Portugal in 2001. From 1972 to 1978 he was with the Research Institute, Minsk. From 1978 to 1994 he was with the Belorussian State University of Informatics and Radioelectronics, Belarus as an Associate Professor, and from 1987 onwards, as a Professor and the Head of the Computer Science Department. Since 1994 he has been with the Department of Electronics and Telecommunications, University of Aveiro, Portugal, where he is currently a Professor of computer engineering. He has authored and co-authored 20 books and over 300 papers on subjects which include reconfigurable computing, data processing, digital design, computer architecture, and programming. The research interests include design and optimization of reconfigurable digital systems. Iouliia Skliarova received the M.Sc. degree, in Computer Engineering, from the Belorussian State University of Informatics and Radioelectronics, Minsk, Republic of Belarus, in 1998, and the Ph.D. degree, in Electrical Engineering, from the University of Aveiro, Portugal, in 2004. She is currently an Assistant Professor in the Department of Electronics, Telecommunications and Informatics, University of Aveiro and the head of laboratory of Embedded Systems, Computing and Control in the Institute of Electronics Engineering and Telematics of Aveiro. She has authored and co-authored three books and over 100 papers on subjects which include reconfigurable systems, data processing, digital design, and combinatorial optimization. Her research interests include reconfigurable digital systems, application-specific architectures, and computer-aided design.", "scopus-id": "84903318125", "coredata": {"eid": "1-s2.0-S0141933114000301", "dc:description": "The paper is dedicated to fast FPGA-based hardware accelerators that implement sorting networks. The primary emphasis is on the uniformity of core components, feasible combinations of parallel, pipelined and sequential operations, and the regularity of the circuits and interconnections. The paper shows theoretically, and based on numerous experiments, that many existing solutions that are commonly considered to be very efficient have worthy competitors that are better for many practical problems. We compared the even\u2013odd merge and bitonic merge sorting networks (which are among the fastest known) with the even\u2013odd transition network, which is often characterized as significantly slower and more resource consuming. We found that the latter is the most regular network that can be implemented very efficiently in FPGA, so we are proposing new, easily scalable hardware solutions and processing techniques based on this. Finally, the paper provides four main contributions and suggests: (1) a regular hardware implementation of resource and time effective architectures based on the even\u2013odd transition network; (2) a pipelined implementation of even\u2013odd transition networks; (3) a pre-processing technique that enables sorting to be further accelerated; (4) combinations of this technique with a merge sort, an address-based sort, a quicksort, and a radix sort.", "openArchiveArticle": "false", "prism:coverDate": "2014-07-31", "openaccessUserLicense": null, "prism:aggregationType": "Journal", "prism:url": "https://api.elsevier.com/content/article/pii/S0141933114000301", "dc:creator": [{"@_fa": "true", "$": "Sklyarov, Valery"}, {"@_fa": "true", "$": "Skliarova, Iouliia"}], "link": [{"@_fa": "true", "@rel": "self", "@href": "https://api.elsevier.com/content/article/pii/S0141933114000301"}, {"@_fa": "true", "@rel": "scidir", "@href": "https://www.sciencedirect.com/science/article/pii/S0141933114000301"}], "dc:format": "application/json", "openaccessType": null, "pii": "S0141-9331(14)00030-1", "prism:volume": "38", "prism:publisher": "Elsevier B.V.", "dc:title": "High-performance implementation of regular and easily scalable sorting networks on an FPGA", "prism:copyright": "Copyright \u00a9 2014 Elsevier B.V. All rights reserved.", "openaccess": "0", "prism:issn": "01419331", "prism:issueIdentifier": "5", "dcterms:subject": [{"@_fa": "true", "$": "FPGA"}, {"@_fa": "true", "$": "Parallel processing"}, {"@_fa": "true", "$": "Sorting networks"}, {"@_fa": "true", "$": "Pipeline"}], "openaccessArticle": "false", "prism:publicationName": "Microprocessors and Microsystems", "prism:number": "5", "openaccessSponsorType": null, "prism:pageRange": "470-484", "prism:endingPage": "484", "pubType": "fla", "prism:coverDisplayDate": "July 2014", "prism:doi": "10.1016/j.micpro.2014.03.003", "prism:startingPage": "470", "dc:identifier": "doi:10.1016/j.micpro.2014.03.003", "openaccessSponsorName": null}, "objects": {"object": [{"@category": "thumbnail", "@height": "22", "@width": "33", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0141933114000301-si7.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "348", "@ref": "si7", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "48", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0141933114000301-si6.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "425", "@ref": "si6", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "22", "@width": "33", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0141933114000301-si5.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "348", "@ref": "si5", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "18", "@width": "13", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0141933114000301-si4.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "232", "@ref": "si4", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "21", "@width": "13", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0141933114000301-si3.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "230", "@ref": "si3", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "21", "@width": "13", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0141933114000301-si2.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "230", "@ref": "si2", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "119", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0141933114000301-si1.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "625", "@ref": "si1", "@mimetype": "image/gif"}, {"@category": "standard", "@height": "330", "@width": "314", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0141933114000301-gr1.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "24856", "@ref": "gr1", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "155", "@width": "111", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0141933114000301-fx2.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "11568", "@ref": "fx2", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "155", "@width": "111", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0141933114000301-fx1.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "10010", "@ref": "fx1", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "179", "@width": "467", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0141933114000301-gr9.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "25035", "@ref": "gr9", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "433", "@width": "600", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0141933114000301-gr8.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "94579", "@ref": "gr8", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "232", "@width": "499", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0141933114000301-gr7.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "37502", "@ref": "gr7", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "222", "@width": "224", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0141933114000301-gr6.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "17264", "@ref": "gr6", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "356", "@width": "606", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0141933114000301-gr5.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "78369", "@ref": "gr5", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "414", "@width": "336", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0141933114000301-gr4.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "52246", "@ref": "gr4", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "423", "@width": "379", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0141933114000301-gr3.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "59880", "@ref": "gr3", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "167", "@width": "378", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0141933114000301-gr2.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "25739", "@ref": "gr2", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "363", "@width": "528", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0141933114000301-gr17.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "49961", "@ref": "gr17", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "351", "@width": "461", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0141933114000301-gr16.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "38441", "@ref": "gr16", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "356", "@width": "448", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0141933114000301-gr15.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "40210", "@ref": "gr15", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "309", "@width": "601", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0141933114000301-gr14.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "69801", "@ref": "gr14", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "243", "@width": "511", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0141933114000301-gr13.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "45927", "@ref": "gr13", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "282", "@width": "499", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0141933114000301-gr12.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "33781", "@ref": "gr12", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "350", "@width": "514", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0141933114000301-gr11.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "73339", "@ref": "gr11", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "314", "@width": "542", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0141933114000301-gr10.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "83900", "@ref": "gr10", "@mimetype": "image/jpeg"}, {"@category": "thumbnail", "@height": "164", "@width": "156", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0141933114000301-gr1.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "4449", "@ref": "gr1", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "164", "@width": "117", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0141933114000301-fx2.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "9964", "@ref": "fx2", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "164", "@width": "117", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0141933114000301-fx1.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "9534", "@ref": "fx1", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "84", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0141933114000301-gr9.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "4057", "@ref": "gr9", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "158", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0141933114000301-gr8.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "10922", "@ref": "gr8", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "102", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0141933114000301-gr7.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "6704", "@ref": "gr7", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "164", "@width": "165", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0141933114000301-gr6.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "6200", "@ref": "gr6", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "129", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0141933114000301-gr5.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "9734", "@ref": "gr5", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "164", "@width": "133", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0141933114000301-gr4.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "7138", "@ref": "gr4", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "164", "@width": "147", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0141933114000301-gr3.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "7349", "@ref": "gr3", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "97", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0141933114000301-gr2.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "7286", "@ref": "gr2", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "151", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0141933114000301-gr17.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "7025", "@ref": "gr17", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "164", "@width": "215", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0141933114000301-gr16.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "6584", "@ref": "gr16", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "164", "@width": "206", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0141933114000301-gr15.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "6872", "@ref": "gr15", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "113", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0141933114000301-gr14.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "8627", "@ref": "gr14", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "104", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0141933114000301-gr13.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "7685", "@ref": "gr13", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "124", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0141933114000301-gr12.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "5244", "@ref": "gr12", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "149", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0141933114000301-gr11.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "10866", "@ref": "gr11", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "127", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0141933114000301-gr10.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "10844", "@ref": "gr10", "@mimetype": "image/gif"}]}, "link": {"@rel": "abstract", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84903318125"}}