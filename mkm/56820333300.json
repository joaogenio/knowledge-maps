[
    {
        "doc_title": "Data-Driven Analysis of European Portuguese Nasal Vowel Dynamics in Bilabial Contexts",
        "doc_scopus_id": "85130029911",
        "doc_doi": "10.3390/app12094601",
        "doc_eid": "2-s2.0-85130029911",
        "doc_date": "2022-05-01",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Materials Science (all)",
                "area_abbreviation": "MATE",
                "area_code": "2500"
            },
            {
                "area_name": "Instrumentation",
                "area_abbreviation": "PHYS",
                "area_code": "3105"
            },
            {
                "area_name": "Engineering (all)",
                "area_abbreviation": "ENGI",
                "area_code": "2200"
            },
            {
                "area_name": "Process Chemistry and Technology",
                "area_abbreviation": "CENG",
                "area_code": "1508"
            },
            {
                "area_name": "Computer Science Applications",
                "area_abbreviation": "COMP",
                "area_code": "1706"
            },
            {
                "area_name": "Fluid Flow and Transfer Processes",
                "area_abbreviation": "CENG",
                "area_code": "1507"
            }
        ],
        "doc_keywords": [],
        "doc_abstract": "© 2022 by the authors. Licensee MDPI, Basel, Switzerland.European Portuguese (EP) is characterized by a large number of nasals encompassing five phonemic nasal vowels. One notable characteristic of these sounds is their dynamic nature, involving both oral and nasal gestures, which makes their study and characterization challenging. The study of nasal vowels, in particular, has been addressed using a wide range of technologies: early descriptions were based on acoustics and nasalance, later expanded with articulatory data obtained from EMA and real-time magnetic resonance (RT-MRI). While providing important results, these studies were limited by the discrete nature of the EMA-pellets, providing only a small grasp of the vocal tract; by the small time resolution of the MRI data; and by the small number of speakers. To tackle these limitations, and to take advantage of recent advances in RT-MRI allowing 50 fps, novel articulatory data has been acquired for 11 EP speakers. The work presented here explores the capabilities of recently proposed data-driven approaches to model articulatory data extracted from RT-MRI to assess their suitability for investigating the dynamic characteristics of nasal vowels. To this end, we explore vocal tract configurations over time, along with the coordination of velum and lip aperture in oral and nasal bilabial contexts for nasal vowels and oral congeners. Overall, the results show that both generalized additive mixed models (GAMMs) and functional linear mixed models (FLMMs) provide an elegant approach to tackle the data from multiple speakers. More specifically, we found oro-pharyngeal differences in the tongue configurations for low and mid nasal vowels: vowel track aperture was larger in the pharyngeal and smaller in the palatal region for the three non-high nasal vowels, providing evidence of a raised and more advanced tongue position of the nasal vowels. Even though this work is aimed at exploring the applicability of the methods, the outcomes already highlight interesting data for the dynamic characterization of EP nasal vowels.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "An accessible smart home based on integrated multimodal interaction",
        "doc_scopus_id": "85112347183",
        "doc_doi": "10.3390/s21165464",
        "doc_eid": "2-s2.0-85112347183",
        "doc_date": "2021-08-02",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Analytical Chemistry",
                "area_abbreviation": "CHEM",
                "area_code": "1602"
            },
            {
                "area_name": "Information Systems",
                "area_abbreviation": "COMP",
                "area_code": "1710"
            },
            {
                "area_name": "Atomic and Molecular Physics, and Optics",
                "area_abbreviation": "PHYS",
                "area_code": "3107"
            },
            {
                "area_name": "Biochemistry",
                "area_abbreviation": "BIOC",
                "area_code": "1303"
            },
            {
                "area_name": "Instrumentation",
                "area_abbreviation": "PHYS",
                "area_code": "3105"
            },
            {
                "area_name": "Electrical and Electronic Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2208"
            }
        ],
        "doc_keywords": [
            "Adaptive interaction",
            "Environmentally friendly homes",
            "Green homes",
            "Information and communications technology",
            "Multi-modal",
            "Multi-Modal Interactions",
            "Multiple devices",
            "Suitable solutions",
            "Attitude",
            "Ecosystem",
            "Humans"
        ],
        "doc_abstract": "© 2021 by the authors. Licensee MDPI, Basel, Switzerland. aa.Our homes are becoming increasingly sensorized and smarter. However, they are also becoming increasingly complex, making accessing them and their advantages difficult. Assistants have the potential for improving the accessibility of smart homes, by providing everyone with an integrated, natural, and multimodal way of interacting with the home’s ecosystem. To demonstrate this potential and contribute to more environmentally friendly homes, in the scope of the project Smart Green Homes, a home assistant highly integrated with an ICT (Information and communications technology) home infrastructure was developed, deployed in a demonstrator, and evaluated by seventy users. The users’ global impression of our home assistant is in general positive, with 61% of the participants rating it as good or excellent overall and 51% being likely or very likely to recommend it to others. Moreover, most think that the assistant enhances interaction with the smart home’s multiple devices and is easy to use by everyone. These results show that a home assistant providing an integrated view of a smart home, through natural, multimodal, and adaptive interaction, is a suitable solution for enhancing the accessibility of smart homes and thus contributing to a better living ambient for all of their inhabitants.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Designing and Deploying an Interaction Modality for Articulatory-Based Audiovisual Speech Synthesis",
        "doc_scopus_id": "85116375726",
        "doc_doi": "10.1007/978-3-030-87802-3_4",
        "doc_eid": "2-s2.0-85116375726",
        "doc_date": "2021-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Articulatory",
            "Audio-visual speech",
            "Audiovisual speech synthesis",
            "Face contacts",
            "Face to face",
            "Interaction modality",
            "Multi-modal",
            "Multimodal Interaction",
            "Remote communication",
            "Speech interaction"
        ],
        "doc_abstract": "© 2021, Springer Nature Switzerland AG.Humans communicate with each other in a multimodal way. Even with several technologies mediating remote communication, face-to-face contact is still our main and most natural way to exchange information. Despite continuous advances in interaction modalities, such as speech interaction, much can be done to improve its naturalness and efficiency, particularly by considering the visual cues transmitted by facial expressions through audiovisual speech synthesis (AVS). To this effect, several approaches have been proposed, in the literature, mostly based in data-driven methods. These, while presenting very good results, rely on models that work as black boxes without a direct relation with the actual process of producing speech and, hence, do not contribute much to our understanding of the underpinnings of the synergies between the audio and visual outputs. In this context, the authors proposed a first proof of concept for an articulatory-based approach to AVS, supported on the articulatory phonology framework, and argued that this research needs to be challenged and informed by fast methods to translate it to interactive applications. In this article, we describe further evolutions of the pronunciation module of the AVS core system along with the proposal of a set of interaction modalities to enable its integration in applications to enable a faster translation into real scenarios. The proposed modalities are designed in line with the W3C recommendations for multimodal interaction architectures making it easy to integrate with any applications that consider it.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Assessing Velar Gestures Timing in European Portuguese Nasal Vowels with RT-MRI Data",
        "doc_scopus_id": "85116328665",
        "doc_doi": "10.1007/978-3-030-87802-3_3",
        "doc_eid": "2-s2.0-85116328665",
        "doc_date": "2021-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Articulatory data",
            "Articulatory synthesis",
            "Dynamic nature",
            "European portuguese",
            "Gestural timing",
            "Nasal vowels",
            "Real- time",
            "Real-time magnetic resonance",
            "Resonance imaging data",
            "Vowel production"
        ],
        "doc_abstract": "© 2021, Springer Nature Switzerland AG.European Portuguese (EP) nasal vowels are characterised by their dynamic nature entailing a gradual variation from an oral into a nasal configuration. The analysis of velar dynamics assumes a particular relevance for improving our understanding of nasal vowel production with an impact, e.g., on articulatory synthesis. Following on previous work, considering EMA and real-time magnetic resonance imaging (RT-MRI), at 14 fps, this study revisits the work regarding the characterisation of EP nasal vowels by analysing gesture timings considering articulatory data obtained from RT-MRI of the vocal tract at a higher frame rate (50 fps) and a larger number of speakers. The analysis, considering eleven EP speakers, characterises the duration of opening and closing velar gestures and explores synchronisation with the previous oral gesture (start-to-release lag) and the potential influence of vowel height in this regard.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "A Smart Home for All Supported by User and Context Adaptation",
        "doc_scopus_id": "85108058459",
        "doc_doi": "10.1145/3439231.3439259",
        "doc_eid": "2-s2.0-85108058459",
        "doc_date": "2020-12-02",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Software",
                "area_abbreviation": "COMP",
                "area_code": "1712"
            },
            {
                "area_name": "Human-Computer Interaction",
                "area_abbreviation": "COMP",
                "area_code": "1709"
            },
            {
                "area_name": "Computer Vision and Pattern Recognition",
                "area_abbreviation": "COMP",
                "area_code": "1707"
            },
            {
                "area_name": "Computer Networks and Communications",
                "area_abbreviation": "COMP",
                "area_code": "1705"
            }
        ],
        "doc_keywords": [
            "Low light",
            "Smart appliances",
            "Smart homes",
            "User and context adaptation"
        ],
        "doc_abstract": "© 2020 Owner/Author.Homes are becoming increasingly smarter, enabling us to control their smart appliances and devices, as well as obtain relevant information on the home. However, accessibility in smart homes for all is still a challenge, with information being presented in the same way to the different users and in distinct contexts. If the interaction is not adapted to the user, certain citizens (e.g., children, and older/impaired people) can be excluded from exploiting the full potential of smart homes. Furthermore, without adaptation to the context, interaction becomes more difficult in some situations (e.g., noisy or low-light environments). With the aim of enhancing smart home accessibility, we propose a solution for adapting the information presented during interaction with the home to the user's characteristics, capabilities and preferences, as well as to the context, namely the environment's noise and luminosity, and user distance.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Data-driven critical tract variable determination for European Portuguese",
        "doc_scopus_id": "85094103354",
        "doc_doi": "10.3390/info11100491",
        "doc_eid": "2-s2.0-85094103354",
        "doc_date": "2020-10-01",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Information Systems",
                "area_abbreviation": "COMP",
                "area_code": "1710"
            }
        ],
        "doc_keywords": [
            "Critical variables",
            "Data driven",
            "Dynamic aspects",
            "Imaging data",
            "Tract variables",
            "Unsupervised data",
            "Visual analysis",
            "Vocal-tracts"
        ],
        "doc_abstract": "© 2020 by the authors. Licensee MDPI, Basel, Switzerland.Technologies, such as real-time magnetic resonance (RT-MRI), can provide valuable information to evolve our understanding of the static and dynamic aspects of speech by contributing to the determination of which articulators are essential (critical) in producing specific sounds and how (gestures). While a visual analysis and comparison of imaging data or vocal tract profiles can already provide relevant findings, the sheer amount of available data demands and can strongly profit from unsupervised data-driven approaches. Recent work, in this regard, has asserted the possibility of determining critical articulators from RT-MRI data by considering a representation of vocal tract configurations based on landmarks placed on the tongue, lips, and velum, yielding meaningful results for European Portuguese (EP). Advancing this previous work to obtain a characterization of EP sounds grounded on Articulatory Phonology, important to explore critical gestures and advance, for example, articulatory speech synthesis, entails the consideration of a novel set of tract variables. To this end, this article explores critical variable determination considering a vocal tract representation aligned with Articulatory Phonology and the Task Dynamics framework. The overall results, obtained considering data for three EP speakers, show the applicability of this approach and are consistent with existing descriptions of EP sounds.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Enabling Multimodal Emotionally-Aware Ecosystems Through a W3C-Aligned Generic Interaction Modality",
        "doc_scopus_id": "85086143464",
        "doc_doi": "10.1007/978-3-030-49289-2_11",
        "doc_eid": "2-s2.0-85086143464",
        "doc_date": "2020-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Computer Networks and Communications",
                "area_abbreviation": "COMP",
                "area_code": "1705"
            }
        ],
        "doc_keywords": [
            "Affective Computing",
            "Daily lives",
            "Emotional state",
            "Fast tracks",
            "Interactive system",
            "Key resources",
            "Life experiences",
            "Multi-modal"
        ],
        "doc_abstract": "© ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering 2020.Emotions play a key role in our life experiences. In interactive systems, the user’s emotional state can be relevant to provide increased levels of adaptation to the user, but can also be paramount in scenarios where such information might enable us to help users manage and express their emotions (e.g., anxiety), with a positive impact on their daily life and on how they interact with others. However, although there is a clear potential for emotionally-aware applications, they still have a long road to travel to reach the desired potential and availability. This is mostly due to the still low translational nature of the research in affective computing, and to the lack of straightforward, off-the-shelf methods for easy integration of emotion in applications without the need for developers to master the different concepts and technologies involved. In light of these challenges, we advance our previous work and propose an extended conceptual vision for supporting emotionally-aware interactive ecosystems and a fast track to ensure the desired translational nature of the research in affective computing. This vision then leads to the proposal of an improved iteration of a generic affective modality, a key resource to the accomplishment of the proposed vision, enabling off-the-shelf support for emotionally-aware applications in multimodal interactive contexts.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Towards european portuguese conversational assistants for smart homes",
        "doc_scopus_id": "85071088633",
        "doc_doi": "10.4230/OASIcs.SLATE.2019.5",
        "doc_eid": "2-s2.0-85071088633",
        "doc_date": "2019-07-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Geography, Planning and Development",
                "area_abbreviation": "SOCI",
                "area_code": "3305"
            },
            {
                "area_name": "Modeling and Simulation",
                "area_abbreviation": "MATH",
                "area_code": "2611"
            }
        ],
        "doc_keywords": [
            "Conversational Assistants",
            "Device integration",
            "Green homes",
            "Home devices",
            "Low costs",
            "Smart devices",
            "Smart environment",
            "Smart homes"
        ],
        "doc_abstract": "© Maksym Ketsmur, António Teixeira, Nuno Almeida, and Samuel Silva.Nowadays, smart environments, such as Smart Homes, are becoming a reality, due to the access to a wide variety of smart devices at a low cost. These devices are connected to the home network and inhabitants can interact with them using smartphones, tablets and smart assistants, a feature with rising popularity. The diversity of devices, the user’s expectations regarding Smart Homes, and assistants’ requirements pose several challenges. In this context, a Smart Home Assistant capable of conversation and device integration can be a valuable help to the inhabitants, not only for smart device control, but also to obtain valuable information and have a broader picture of how the house and its devices behave. This paper presents the current stage of development of one such assistant, targeting European Portuguese, not only supporting the control of home devices, but also providing a potentially more natural way to access a variety of information regarding the home and its devices. The development has been made in the scope of Smart Green Homes (SGH) project.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Contribute for an ontology for smart homes and their conversational assistants",
        "doc_scopus_id": "85070062478",
        "doc_doi": "10.23919/CISTI.2019.8760934",
        "doc_eid": "2-s2.0-85070062478",
        "doc_date": "2019-06-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Computer Networks and Communications",
                "area_abbreviation": "COMP",
                "area_code": "1705"
            },
            {
                "area_name": "Information Systems",
                "area_abbreviation": "COMP",
                "area_code": "1710"
            }
        ],
        "doc_keywords": [
            "Conversational assistants",
            "Green homes",
            "Knowledge base",
            "Semantic information",
            "Smart homes",
            "User need"
        ],
        "doc_abstract": "© 2019 AISTI.Despite the improved capabilities of recent Assistants, control and access to the information regarding Smart Homes stills limited. More information is needed on what should be a Smart Home Assistant and how-to have the structured semantic information to support their answers and actions, i.e., how to structure the knowledge and make it simple to use by current approaches to Assistants, based commonly in intentions and entities. As contribute to increase Assistants capabilities in Smart Homes environments, based on analyses of the domain and user enquiries, we propose the basis for an ontology to support both, the interaction and the Smart Home knowledge base. The proposed ontology is being used to support the creation of an enhanced version of a Conversational Assistant for the Smart Green Homes project with novel functionalities, aligned with advanced user needs and expectations.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "The am4i architecture and framework formultimodal interaction and its application to smart environments",
        "doc_scopus_id": "85067542443",
        "doc_doi": "10.3390/s19112587",
        "doc_eid": "2-s2.0-85067542443",
        "doc_date": "2019-06-01",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Analytical Chemistry",
                "area_abbreviation": "CHEM",
                "area_code": "1602"
            },
            {
                "area_name": "Information Systems",
                "area_abbreviation": "COMP",
                "area_code": "1710"
            },
            {
                "area_name": "Atomic and Molecular Physics, and Optics",
                "area_abbreviation": "PHYS",
                "area_code": "3107"
            },
            {
                "area_name": "Biochemistry",
                "area_abbreviation": "BIOC",
                "area_code": "1303"
            },
            {
                "area_name": "Instrumentation",
                "area_abbreviation": "PHYS",
                "area_code": "3105"
            },
            {
                "area_name": "Electrical and Electronic Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2208"
            }
        ],
        "doc_keywords": [
            "Adaptation",
            "Devices",
            "Multi-devices",
            "Multi-Modal Interactions",
            "Smart environment"
        ],
        "doc_abstract": "© 2019 by the authors. Licensee MDPI, Basel, Switzerland.Technologies, such as smart sensors, actuators, and other kinds of devices, are often installed in our environments (e.g., our Homes) and available to integrate our daily lives. Despite their installation being motivated by the pursuit of automation and increased efficiency, making these environments usable, acceptable and enjoyable in a sustainable, energy efficient way is not only a matter of automation. Tackling these goals is a complex task demanding the combination of different perspectives including building and urban Architecture, Ubiquitous Computing and Human-Computer Interaction (HCI) to provide occupants with the means to shape these environments to their needs. Interaction is of paramount relevance in the creation of adequate relations of users with their environments, but it cannot be seen independently from the ubiquitous sensing and computing or the environment’s architecture. In this regard, there are several challenges to HCI, particularly in how to integrate this multidisciplinary effort. Although there are several solutions to address some of these challenges, the complexity and dynamic nature of the smart environments and the diversity of technologies involved still present many challenges,� particularly for its development. In general, the development is complex, and it is hard to create a dynamic environment providing versatile and adaptive forms of interaction. To participate in the multidisciplinary effort, the development of interaction must be supported by tools capable of facilitating co-design by multidisciplinary teams. In this article, we address the development of interaction for complex smart environments and propose the AM4I architecture and framework,� a novel modular approach to design and develop adaptive multiplatform multilingual multi-device multimodal interactive systems. The potential of the framework is demonstrated by proof-of-concept applications in two different smart environment contexts, non-residential buildings and smart homes.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Exploring critical articulator identification from 50Hz RT-MRI data of the vocal tract",
        "doc_scopus_id": "85074701958",
        "doc_doi": "10.21437/Interspeech.2019-2897",
        "doc_eid": "2-s2.0-85074701958",
        "doc_date": "2019-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Language and Linguistics",
                "area_abbreviation": "ARTS",
                "area_code": "1203"
            },
            {
                "area_name": "Human-Computer Interaction",
                "area_abbreviation": "COMP",
                "area_code": "1709"
            },
            {
                "area_name": "Signal Processing",
                "area_abbreviation": "COMP",
                "area_code": "1711"
            },
            {
                "area_name": "Software",
                "area_abbreviation": "COMP",
                "area_code": "1712"
            },
            {
                "area_name": "Modeling and Simulation",
                "area_abbreviation": "MATH",
                "area_code": "2611"
            }
        ],
        "doc_keywords": [],
        "doc_abstract": "Copyright © 2019 ISCAThe study of the static and dynamic aspects of speech production can profit from technologies such as electromagnetic midsagittal articulography (EMA) and real-time magnetic resonance (RTMRI). These can improve our knowledge on which articulators and gestures are involved in producing specific sounds and foster improved speech production models, paramount to advance, e.g., articulatory speech synthesis. Previous work, by the authors, has shown that critical articulator identification could be performed from RTMRI data of the vocal tract, with encouraging results, by extending the applicability of an unsupervised statistical identification method previously proposed for EMA data. Nevertheless, the slower time resolution of the considered RT-MRI corpus (14 Hz), when compared to EMA, potentially influencing the ability to select the most suitable representative configuration for each phone - paramount for strongly dynamic phones, e.g., nasal vowels -, and the lack of a richer set of contexts - relevant for observing coarticulation effects -, were identified as limitations. This article addresses these limitations by exploring critical articulator identification from a faster RTMRI corpus (50 Hz), for European Portuguese, providing a richer set of contexts, and testing how fusing the articulatory data of two speakers might influence critical articulator determination.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Multimodal interaction for accessible smart homes",
        "doc_scopus_id": "85061404918",
        "doc_doi": "10.1145/3218585.3218595",
        "doc_eid": "2-s2.0-85061404918",
        "doc_date": "2018-06-20",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Software",
                "area_abbreviation": "COMP",
                "area_code": "1712"
            },
            {
                "area_name": "Human-Computer Interaction",
                "area_abbreviation": "COMP",
                "area_code": "1709"
            },
            {
                "area_name": "Computer Vision and Pattern Recognition",
                "area_abbreviation": "COMP",
                "area_code": "1707"
            },
            {
                "area_name": "Computer Networks and Communications",
                "area_abbreviation": "COMP",
                "area_code": "1705"
            }
        ],
        "doc_keywords": [
            "Accessibility",
            "Context-Aware",
            "Design for all",
            "Multi-Modal Interactions",
            "Multi-platform",
            "Personas",
            "Smart homes",
            "Speech interface"
        ],
        "doc_abstract": "© 2018 Association for Computing Machinery.Nowadays, houses are being equipped with new smart products and smart sensors, from multiple manufacturers, each offering their own options for interaction with providing varying degrees of usability and user experience. This diverse nature of smart homes and buildings, in general, poses new challenges to interaction design and accessibility. To tackle them, human-building interaction needs to move from articulating different interactive artifacts towards an holistic view of the house as an interactive ecosystem. In a joint effort with Bosch Termotecnologia, S.A., and profiting from recent contributions including an architecture and framework supporting multimodal Interaction, the authors aim to explore novel ways of approaching interaction design with a smart house and proposing smart home applications for all. This paper presents the status of this ongoing work, in the scope of project Smart Green Homes, proposing how multimodal interaction can be supported in the scenario of a smart home and showing first results of tackling human-building interaction through a home assistant serving a family in their daily interactions with the house.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "EmotionalIy-aware multimodal interfaces: Preliminary work on a generic affective modality",
        "doc_scopus_id": "85061374910",
        "doc_doi": "10.1145/3218585.3218589",
        "doc_eid": "2-s2.0-85061374910",
        "doc_date": "2018-06-20",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Software",
                "area_abbreviation": "COMP",
                "area_code": "1712"
            },
            {
                "area_name": "Human-Computer Interaction",
                "area_abbreviation": "COMP",
                "area_code": "1709"
            },
            {
                "area_name": "Computer Vision and Pattern Recognition",
                "area_abbreviation": "COMP",
                "area_code": "1707"
            },
            {
                "area_name": "Computer Networks and Communications",
                "area_abbreviation": "COMP",
                "area_code": "1705"
            }
        ],
        "doc_keywords": [
            "Affective Computing",
            "Affective interaction",
            "Multi-Modal Interactions",
            "Multi-modal interfaces",
            "Multi-platform",
            "Multimodal interactive systems",
            "Natural interactions",
            "Straight-forward method"
        ],
        "doc_abstract": "© 2018 Association for Computing Machinery.In interactive systems, knowing the user's emotional state is not only important to understand and improve overall user experience, but also of the utmost relevance in scenarios where such information might foster our ability to help users manage and express their emotions (e.g., anxiety), with a strong impact on their daily life and on how they interact with others. Nevertheless, although there is a clear potential for emotionally-aware applications, several challenges preclude their wider availability, sometimes resulting from the low translational nature of the research in affective computing methods, and from a lack of straightforward methods for easy integration of emotion in applications. In light of these challenges, we propose a conceptual vision for the consideration of emotion in the scope of multimodal interactive systems, and how it can articulate with research in affective computing. Aligned with this vision, a first instantiation of an affective generic modality is presented, and a proof-of-concept application, enabling multimodal interaction with Spotify, illustrates how the modality can provide emotional context in interactive scenarios.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Conversational assistant for an accessible smart home: Proof-of-concept for Portuguese",
        "doc_scopus_id": "85061370847",
        "doc_doi": "10.1145/3218585.3218594",
        "doc_eid": "2-s2.0-85061370847",
        "doc_date": "2018-06-20",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Software",
                "area_abbreviation": "COMP",
                "area_code": "1712"
            },
            {
                "area_name": "Human-Computer Interaction",
                "area_abbreviation": "COMP",
                "area_code": "1709"
            },
            {
                "area_name": "Computer Vision and Pattern Recognition",
                "area_abbreviation": "COMP",
                "area_code": "1707"
            },
            {
                "area_name": "Computer Networks and Communications",
                "area_abbreviation": "COMP",
                "area_code": "1705"
            }
        ],
        "doc_keywords": [
            "Accessibility",
            "Conversational Assistants",
            "Design for all",
            "Smart homes",
            "Spoken interaction"
        ],
        "doc_abstract": "© 2018 Association for Computing Machinery.There is a continued increase in the integration of intelligent devices in our homes. Making these new complex ecosystems accessible poses great challenges, stemming from the very nature of the Home (several spaces separated by walls), the diversity of inhabitants (e.g., children, adults, older adults, persons with temporary or permanent impairments), the tasks they perform (e.g., cooking) or their native languages. In this context, an assistant capable of spoken and written conversation with the inhabitants can be a valuable help in making a household more accessible for several groups of persons, if not for all. This paper presents information regarding the development and first results of such an assistant targeting an Accessible Smart Home for a Portuguese speaking family with some accessibility needs.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Design and development of Medication Assistant: older adults centred design to go beyond simple medication reminders",
        "doc_scopus_id": "84978174530",
        "doc_doi": "10.1007/s10209-016-0487-7",
        "doc_eid": "2-s2.0-84978174530",
        "doc_date": "2017-08-01",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Software",
                "area_abbreviation": "COMP",
                "area_code": "1712"
            },
            {
                "area_name": "Information Systems",
                "area_abbreviation": "COMP",
                "area_code": "1710"
            },
            {
                "area_name": "Human-Computer Interaction",
                "area_abbreviation": "COMP",
                "area_code": "1709"
            },
            {
                "area_name": "Computer Networks and Communications",
                "area_abbreviation": "COMP",
                "area_code": "1705"
            }
        ],
        "doc_keywords": [
            "Design and Development",
            "Easy-to-use products",
            "Interaction design",
            "Iterative development",
            "Medication management",
            "Medication non-adherence",
            "Mobile applications",
            "Older adults"
        ],
        "doc_abstract": "© 2016, Springer-Verlag Berlin Heidelberg.Older adults have much to gain from bringing technology into their daily lives. The extent to which this is possible strongly depends on careful design and accessible, easy-to-use products, developed using an older adults centred methodology. This paper follows this design approach and puts it to the test in developing “Medication Assistant”, an application aimed to contribute to lower the high levels of non-adherence to medication in the ageing population. This application is developed following an iterative method centred on the older adults and interaction design. The method repeats short development cycles encompassing the definition of scenarios and goals, requirements engineering, design, prototyping and evaluation by the target users. The evaluation of the increasingly refined prototypes is of paramount importance in this methodology, gathering information about the strengths and weaknesses of the application. These, along with user suggestions, constitute an important starting point to support further improvements in the subsequent development cycle. The first three development cycles for “Medication Assistant” are presented, highlighting the main aspects of each stage, and how the evaluation performed, at the end of each cycle, provided feedback to further refine the application with new and improved features. At its current stage, “Medication Assistant” obtained very positive evaluation outcomes and already provides a set of useful features concerning medication management. These features go beyond the typical medication reminders and aim to provide a first contribution towards a more holistic approach to medication non-adherence.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "“Tell your day”: Developing multimodal interaction applications for children with ASD",
        "doc_scopus_id": "85025140611",
        "doc_doi": "10.1007/978-3-319-58706-6_43",
        "doc_eid": "2-s2.0-85025140611",
        "doc_date": "2017-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Autism spectrum disorders",
            "Children",
            "Design and Development",
            "Information exchanges",
            "Multi-Modal Interactions",
            "Multi-modality"
        ],
        "doc_abstract": "© Springer International Publishing AG 2017.The development of applications for children, and particularly for those diagnosed with autism spectrum disorders (ASD), is a challenging task. In this context, careful consideration of the characteristics of these users, along with those of different stakeholders, such as parents and teachers, is essential. Also, it is important to provide different ways of using applications through multimodal interaction, in order to adapt, as much as possible, to the users’ needs, capabilities and preferences. Providing multimodality does not mean that users will interact multimodally, but provides freedom of choice to the user. Additionally, enabling multiple forms of interaction might also help understanding what actually works better, for an audience that is not always able to express an opinion regarding what might work. In this article, we take on previous work regarding the definition of a Persona for a child diagnosed with ASD and, considering the goals above, propose and evaluate a first prototype of an application targeting the audience represented by this Persona. This application, aims to serve as a place for communication and information exchange among the child, her family, and teachers and supports multimodal interaction.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Applications of the multimodal interaction architecture in ambient assisted living",
        "doc_scopus_id": "85009674996",
        "doc_doi": "10.1007/978-3-319-42816-1_12",
        "doc_eid": "2-s2.0-85009674996",
        "doc_date": "2016-01-01",
        "doc_type": "Book Chapter",
        "doc_areas": [
            {
                "area_name": "Engineering (all)",
                "area_abbreviation": "ENGI",
                "area_code": "2200"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Ambient assisted living",
            "Ambient assisted living (AAL)",
            "Heterogeneous environments",
            "Multi-Modal Interactions",
            "Multimodal application",
            "Research outcome",
            "User groups",
            "User interaction"
        ],
        "doc_abstract": "© Springer International Publishing Switzerland 2017.Developing applications for ambient assisted living (AAL) scenarios requires dealing with diverse user groups, heterogeneous environments, and a large plethora of devices. These requirements pose several challenges on how to design and develop user interaction with the proposed applications and services. In this context, the versatility provided by multimodal interaction (MMI) is paramount and the adopted architecture should be instrumental in harnessing its full potential. This chapter offers an insight on how AAL challenges can be tackled by multimodal-based solutions. It presents the authors’ views and research outcomes in multimodal application development for AAL grounded on an architecture for MMI aligned with the W3C recommendations.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Multi-device applications using the multimodal architecture",
        "doc_scopus_id": "85009673838",
        "doc_doi": "10.1007/978-3-319-42816-1_17",
        "doc_eid": "2-s2.0-85009673838",
        "doc_date": "2016-01-01",
        "doc_type": "Book Chapter",
        "doc_areas": [
            {
                "area_name": "Engineering (all)",
                "area_abbreviation": "ENGI",
                "area_code": "2200"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Architecture-based",
            "Concrete applications",
            "Design and Development",
            "Multi-devices",
            "Multi-Modal Interactions",
            "Multimodal architectures",
            "Research outcome",
            "Screen sizes"
        ],
        "doc_abstract": "© Springer International Publishing Switzerland 2017.Nowadays, users have access to a multitude of devices at their homes, workplaces or that they can carry around. Each of these devices, given its features (e.g., interaction modalities, screen size), might be more suitable for particular users, tasks, and contexts. While having one application installed in several devices might be common, they mostly work isolated, not exploring the possibilities of several devices working together to provide a more versatile and richer interaction scenario. Adopting a multimodal interaction (MMI) architecture based on the W3C recommendations, beyond the advantages to the design and development of MMI, provides, we argue, an elegant approach to tackle multi-device interaction scenarios. In this regard, this chapter conveys our views and research outcomes addressing this subject, presenting concrete application examples.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Interactive, multi-device visualization supported by a multimodal interaction framework: Proof of concept",
        "doc_scopus_id": "84978914860",
        "doc_doi": "10.1007/978-3-319-39943-0_27",
        "doc_eid": "2-s2.0-84978914860",
        "doc_date": "2016-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Device characteristics",
            "First impressions",
            "Future improvements",
            "Interactive visualizations",
            "Multi-devices",
            "Multi-Modal Interactions",
            "Multiple representation",
            "User satisfaction"
        ],
        "doc_abstract": "© Springer International Publishing Switzerland 2016.Nowadays, users can interact with a system using a wide variety of modalities, such as touch and speech. Nevertheless, multimodal interaction has yet to be explored for interactive visualization scenarios. Furthermore, users have access to a wide variety of devices (e.g., smartphones, tablets) that could be harnessed to provide a more versatile visualization experience, whether by providing complementary views or by enabling multiple users to jointly explore the visualization using their devices. In our effort to gather multimodal interaction and multi-device support for visualization, this paper describes our first approach to an interactive multi-device system, based on the multimodal interaction architecture proposed by the W3C, enabling interactive visualization using different devices and representations. It allows users to run the application in different types of devices, e.g., tablets or smartphones, and the visualizations can be adapted to multiple screen sizes, by selecting different representations, with different levels of detail, depending on the device characteristics. Groups of users can rely on their personal devices to synchronously visualize and interact with the same data, maintaining the ability to use a custom representation according to their personal needs. A preliminary evaluation was performed, mostly to collect users’ first impressions and guide future developments. Although the results show a moderate user satisfaction, somehow expected at this early stage of development, user feedback allowed the identification of important routes for future improvement, particularly regarding a more versatile navigation along the data and the definition of composite visualizations (e.g., by gathering multiple representations on the same screen).",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Multilingual Speech Recognition for the Elderly: The AALFred Personal Life Assistant",
        "doc_scopus_id": "84962832783",
        "doc_doi": "10.1016/j.procs.2015.09.272",
        "doc_eid": "2-s2.0-84962832783",
        "doc_date": "2015-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "ageing",
            "Automatic speech recognition",
            "elderly",
            "Multi-modal",
            "multilingual"
        ],
        "doc_abstract": "© 2015 Published by Elsevier B.V.The PaeLife project is a European industry-academia collaboration in the framework of the Ambient Assisted Living Joint Programme (AAL JP), with a goal of developing a multimodal, multilingual virtual personal life assistant to help senior citizens remain active and socially integrated. Speech is one of the key interaction modalities of AALFred, the Windows application developed in the project; the application can be controlled using speech input in four European languages: French, Hungarian, Polish and Portuguese. This paper briefly presents the personal life assistant and then focuses on the speech-related achievements of the project. These include the collection, transcription and annotation of large corpora of elderly speech, the development of automatic speech recognisers optimised for elderly speakers, a speech modality component that can easily be reused in other applications, and an automatic grammar translation service that allows for fast expansion of the automatic speech recognition functionality to new languages.",
        "available": true,
        "clean_text": "serial JL 280203 291210 291871 31 90 Procedia Computer Science PROCEDIACOMPUTERSCIENCE 2015-11-06 2015-11-06 2015-11-06 2015-11-06 2016-01-06T20:55:21 S1877-0509(15)03118-X S187705091503118X 10.1016/j.procs.2015.09.272 S300 S300.2 HEAD-AND-TAIL 2016-01-06T16:14:49.492416-05:00 0 0 20150101 20151231 2015 2015-11-06T03:04:30.74972Z rawtext articleinfo articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids confeditor contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid hubeid indexeddate issn issnnorm itemstage itemtransactionid itemweight oauserlicense openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sortorder srctitle srctitlenorm srctype ssids alllist content oa subj suppl tomb vol volfirst volissue volumelist yearnav affil articletitle auth authfirstini authfull authkeywords authlast primabst ref 1877-0509 18770509 true 67 67 C Volume 67 32 283 292 283 292 2015 2015 2015-01-01 2015-12-31 2015 Proceedings of the 6th International Conference on Software Development and Technologies for Enhancing Accessibility and Fighting Info-exclusion Dr. Carlos Velasco Dr. Gerhard Weber Dr. João Barroso Dr. Yehya Mohamad Dr. Hugo Paredes article fla Copyright © 2015 Published by Elsevier B.V. MULTILINGUALSPEECHRECOGNITIONFORELDERLYAALFREDPERSONALLIFEASSISTANT HAMALAINEN A HAMALAINENX2015X283 HAMALAINENX2015X283X292 HAMALAINENX2015X283XA HAMALAINENX2015X283X292XA Full 2015-09-26T00:02:03Z ElsevierWaived OA-Window item S1877-0509(15)03118-X S187705091503118X 10.1016/j.procs.2015.09.272 280203 2016-01-06T16:14:49.492416-05:00 2015-01-01 2015-12-31 true 1280916 MAIN 10 50141 849 656 IMAGE-WEB-PDF 1 Procedia Computer Science 67 ( 2015 ) 283 â€“ 292 Available online at www.sciencedirect.com 1877-0509 Â© 2015 Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license Peer-review under responsibility of organizing committee of the 6th International Conference on Software Development and Technologies for Enhancing Accessibility and Fighting Info-exclusion (DSAI 2015) doi: 10.1016/j.procs.2015.09.272 ScienceDirect 6th International Conference on Software Development and Technologies for Enhancing Accessibility and Fighting Infoexclusion (DSAI 2015) Multilingual speech recognition for the elderly: The AALFred personal life assistant Annika HÃ¤mÃ¤lÃ¤inena,b, AntÃ³nio Teixeirac, Nuno Almeidac, Hugo Meinedoa, Tibor FegyÃ³d, Miguel Sales Diasa,b aMicrosoft Language Development Center, Lisbon, Portugal bISCTE â€“ University Institute of Lisbon (ISCTE-IUL), Lisbon, Portugal cDepartment of Electronics, Telecommunications & Informatics/IEETA, University of Aveiro, Aveiro, Portugal dDepartment of Telecommunications & Media Informatics, Budapest University of Technology & Economics, Budapest, Hungary Abstract The PaeLife project is a European industry-academia collaboration in the framework of the Ambient Assisted Living Joint Programme (AAL JP), with a goal of developing a multimodal, multilingual virtual personal life assistant to help senior citizens remain active and socially integrated. Speech is one of the key interaction modalities of AALFred, the Windows application developed in the project; the application can be controlled using speech input in four European languages: French, Hungarian, Polish and Portuguese. This paper briefly presents the personal life assistant and then focuses on the speech-related achievements of the project. These include the collection, transcription and annotation of large corpora of elderly speech, the development of automatic speech recognisers optimised for elderly speakers, a speech modality component that can easily be reused in other applications, and an automatic grammar translation service that allows for fast expansion of the automatic speech recognition functionality to new languages. Â© 2015 The Authors. Published by Elsevier B.V. Peer-review under responsibility of organizing committee of the 6th International Conference on Software Development and Technologies for Enhancing Accessibility and Fighting Info-exclusion (DSAI 2015). Keywords: ageing; automatic speech recognition; elderly; human-computer interaction; multilingual; multimodal; speech. 5 Published by Elsevier B.V. This i an open access article under the CC BY-NC-ND license rg/licenses/by-nc- d/4.0/). Peer-review under responsibility of organizing committee of the 6th International Conference on Software Development and Technologies for Enhancing Accessibility and Fighting Info-exclusion (DSAI 2015) 284 Annika HÃ¤mÃ¤lÃ¤inen et al. / Procedia Computer Science 67 ( 2015 ) 283 â€“ 292 1. Introduction Information and communication technology (ICT) has considerable potential when it comes to facilitating the lives of the elderly. However, due to the complexity of existing user interfaces and the limited set of available interaction modalities, combined with physical limitations such as poor eyesight, the elderly often have difficulties using ICT1. Therefore, it is very important to investigate the use of natural, easy-to-use interaction modalities in applications aimed at the elderly. Speech would be a particularly interesting interaction modality in the case of the elderly, as it offers a natural form of human-computer interaction (HCI) that requires neither visual attention nor the use of hands2. However, our voices change as we age3, and currently available automatic speech recognisers do not usually work well with elderly speech. This is because, to serve mainstream business requirements, they have been optimised for younger adultsâ€™ speech. The degradation in automatic speech recognition (ASR) performance on elderly speech has been illustrated, for instance, by Wilpon & Jacobsen4 and Vipperla et al.5. The same authors, however, also showed that performance improves considerably when automatic speech recognisers are specifically optimised for elderly speech. Such findings show that there is a real need for adapting ASR to elderly speech. There is growing international interest, both in academia and in industry, in developing speech-enabled applications for improving the daily lives of the elderly. Examples of already developed products, applications and services include, for instance, a telerehabilitation service with multimodal interaction6, Windows Phone applications tailored for the needs of the elderly7, a humanoid robot to help the elderly in their daily activities at home8, and a humanoid robot designed to be used for rehabilitation, fall detection and entertainment purposes at care institutions9. In this paper, we describe work done in the area of multilingual ASR in the AAL PaeLife project10. The goal of the project was to develop a multimodal virtual personal life assistant (PLA) that would help the elderly â€“ in particular those who have retired recently and have some experience in using technology â€“ to remain active, productive, independent, and socially integrated. The resulting application was named AALFred, and the ASR functionality was optimised for elderly speech in four European languages: French, Hungarian, Polish and Portuguese. Despite its potential, the integration of multilingual ASR in applications aimed at the elderly poses various challenges. First, as mentioned before, automatic speech recognisers need to be optimised for elderly speech â€“ a task that requires the availability of a sufficient amount of speech data collected from elderly speakers. In the context of the PaeLife project, we collected large corpora of French, Hungarian and Polish elderly speech â€“ which, in itself, is a time-consuming, demanding effort â€“ and then optimised the speech recognisers used in AALFred for elderly speech using these data. We also developed ASR for Portuguese elderly speech, using an elderly speech corpus collected in the context of the Living Usability Lab (LUL) project6. Second, the development of a multimodal application requires several components to seamlessly work together. To make this possible, we designed a speech modality component11 that works decoupled from the services available in AALFred and, therefore, makes it easier to integrate ASR in any future services, as well as in any future applications or products. Third, the speech modality needs to work in multiple languages. In the absence of speech interaction designers with relevant language skills, we proposed a way of automatically deriving the first versions of ASR grammars, which define the allowed speech input in speech-enabled applications, for new languages. This paper is further organised as follows. Section 2 describes AALFred and the services it offers. Section 3 describes our efforts to develop multilingual ASR for the four PaeLife languages, and illustrates the performance improvements we achieved when optimising ASR for elderly speech. In Section 4, we present the speech modality component and the way new languages can be integrated into it. Finally, in Section 5, we formulate our conclusions. 2. The AALFred Personal Life Assistant AALFred supports five human-computer interaction (HCI) modalities for easy, natural HCI: mouse, keyboard, speech, touch and gesture. Speech input is currently available and optimised for elderly speech in French, Hungarian, Polish and Portuguese. In those four languages, elderly users can use voice commands to access and operate services, and dictation to compose messages and to add descriptions of appointments (in the Messaging and Agenda services described below). 285 Annika HÃ¤mÃ¤lÃ¤inen et al. / Procedia Computer Science 67 ( 2015 ) 283 â€“ 292 Physically, AALFred comprises a stationary main unit, a desktop computer connected to a large screen (e.g. an LCD TV), as well as a portable device, a tablet. In the main unit, the large screen supports graphical output, the internal microphone and speakers support speech input (ASR) and output (speech synthesis), and a Kinect sensor supports gesture input. In the portable unit, on the other hand, the display supports graphical output, the internal microphone and speakers enable speech input and output, and the multi-touch support of the operating system makes touch input possible. The main and portable units can work either together or separately as stand-alone devices, and can be connected to the internet and to the cloud for providing the user with online services (see Fig. 1). AALFred offers the elderly a wide range of services in the areas of social communication, entertainment, information management and information search, accessible through different modalities: â€¢ Agenda â€“ managing appointments â€¢ Contacts â€“ managing contacts â€¢ Messaging â€“ receiving and sending messages (email, Twitter, Facebook, Skype) â€¢ Audio or videoconference â€“ establishing audiovisual communication (Skype) â€¢ Media â€“ viewing audiovisual information â€¢ Find My â€“ searching for local services (pharmacies, police, etc.) â€¢ News Reader â€“ having the latest news read out by a speech synthesiser â€¢ WeatherForAll â€“ checking the weather forecast Fig. 1. The architecture of AALFred. To give a simple illustration of the interaction modalities, let us consider the view of available services in AALFred in Fig. 2. To see the services hidden on the right side of the screen, the user can, for example, swipe right with their hand (gesture), drag the screen right with their finger (touch), or say, â€œMove rightâ€� (speech). To access a service, the user can touch the relevant icon, or use a voice command such as â€œShow my Agendaâ€� or â€œOpen my Agendaâ€�. In fact, several different voice commands are able to perform the same action. The user can also use various interaction modalities to operate a service. In the case of the Agenda service, (s)he might, for instance, want to add a new appointment. As illustrated in Fig.3, the user can touch the desired day or speak out the day of the week (e.g. â€œThursdayâ€� or â€œOpen Thursdayâ€�). When the desired day is displayed, (s)he can add a new appointment by tapping the +-button on the screen or say, for example, â€œAdd a new appointmentâ€�. (S)he can then add the details of the appointment using the keyboard (either an on-screen, inbuilt or external keyboard, depending on the device used) or speech input (dictation). The details of the appointment will be saved when the user, for instance, says, â€œSave.â€� $ %!\" % # ! % ) %* ! % $ â€¢ â€¢ â€¢ ! # â€¢ (% %! \" â€¢ \" ! % ! â€¢ % # #' $ !& #' $ 286 Annika HÃ¤mÃ¤lÃ¤inen et al. / Procedia Computer Science 67 ( 2015 ) 283 â€“ 292 Fig. 2 Interaction modalities available in AALFred include gesture, touch and speech. Fig. 3 Operating the Agenda service using different interaction modalities. 3. Providing State-of-the-Art Multilingual ASR for the Elderly In this section, we summarise how ASR works and describe how it was optimised for the elderly and for multiple input languages in the PaeLife project. ASR is technology that translates acoustic speech signals into the 287 Annika HÃ¤mÃ¤lÃ¤inen et al. / Procedia Computer Science 67 ( 2015 ) 283 â€“ 292 corresponding sequences of (written) words. To be able to do that, automatic speech recognisers typically use three types of language-specific knowledge bases: 1) a language model, which contains information about the possible words and sequences of words in the input language, together with their probabilities of occurrence (e.g. â€˜I use Bingâ€™ is a probable sequence of words while â€˜I chair Bingâ€™ is not), and/or grammars, which contain information about the allowed speech input in different situations (e.g. numbers from 1 to 31 are allowed in the case of grammars meant for recognising dates, while e.g. 32 is not), 2) a pronunciation lexicon, which represents each word in the ASR vocabulary (the finite set of words the system can recognise) in terms of individual speech sounds (phones) (e.g. â€˜Bingâ€™ word contains three phones: /b Éª Å‹/), and 3) acoustic models, which represent the stochastic time-based relationship between the input speech signal and the phones occurring in the speech. Together, the language model and/or the grammars, the lexicon and the acoustic models are used by the speech recogniser to find the most probable sequence of words for the input speech signal. State-of-the-art ASR systems employ statistical modelling techniques and are developed using large quantities of speech for training the acoustic models, and large quantities of text data for training the language model. Acoustic models are typically trained using speech collected from young to middle-aged adults. Because the acoustic properties of speech produced by elderly speakers differ from those produced by younger adults3, acoustic models expected to successfully recognise elderly speech have to be (re)trained using a sufficient amount of elderly speech. In the following subsections, we describe the work we did to collect, transcribe and annotate large corpora of elderly speech, to train acoustic models optimised for this kind of speech, and to test the performance of the models. 3.1. Collecting, Transcribing and Annotating Corpora of Elderly Speech To support the development of acoustic models optimised for the elderly, we collected a large corpus of elderly speech for each of the languages supported by AALFred. We selected speakers from 3rd age universities, care institutions, and social clubs and associations for seniors in different parts of France, Hungary, Poland and Portugal, to ensure a variety of regional accents in the data. All speakers were 60 years of age or older. The French and Polish corpora consist of read newspaper sentences, while the Portuguese corpus also contains a large amount of read command & control prompts. The Hungarian corpus comprises both read newspaper sentences (about 80% of the recordings) and spontaneous command & control utterances (about 20%). The main statistics of the corpora are detailed in Table 1. Table 1. Main statistics of the EASR corpora. #Speakers Total Audio (hh:mm:ss) Portuguese 986 185:10:25 French 328 76:09:07 Hungarian 1229 183:42:15 Polish 781 203:17:23 Once the data collection was finished, we used the prompts presented to the speakers as the starting point for orthographically transcribing the recordings with read speech. We verified and corrected those initial transcriptions to ensure that they matched what the speakers said in the recordings. In the case of the Hungarian spontaneous speech, we transcribed the recordings from scratch. In addition, using an annotation scheme, we marked the presence of noises and other audio events in the recordings. These audio events included filled pauses (e.g. ah, hmm), non-human (e.g. door banging) or human (e.g. coughing) noises, damaged words (e.g. false starts, mispronounced, unintelligible or truncated words), and speech from non-primary speakers (e.g. the recording supervisor). The corpora are collectively called the EASR Corpora of European Portuguese, Hungarian, French and Polish Elderly Speech, and are described in detail by HÃ¤mÃ¤lÃ¤inen et al.12. In the case of French, Hungarian and Polish, the data-related work was done in the PaeLife project, whereas the Portuguese data was collected, transcribed and annotated in the scope of the Living Usability Lab6 and Smartphones for Seniors7 projects. 288 Annika HÃ¤mÃ¤lÃ¤inen et al. / Procedia Computer Science 67 ( 2015 ) 283 â€“ 292 3.2. Development of Elderly-Specific Acoustic Models In AALFred, speech input is handled using two different ASR systems: Microsoft Public Speech Platform Runtime version 1113, which supports French, Polish and Portuguese, and VOXerver14, which is a SAPI/Microsoft Speech Server-compatible system that supports Hungarian. The goals of the ASR-related work were to create French, Hungarian, Polish and Portuguese acoustic models optimised for the elderly users of AALFred, and to obtain the best possible recognition performance using existing techniques and tools compatible with the requirements of the Microsoft Public Speech Platform. We divided all elderly speech corpora into three datasets (training set: 85% of the speakers; development test set used for optimisation purposes: 5% of the speakers; evaluation test set used for measuring the final performance of the acoustic models: 10% of the speakers). In the case of French, there was a total of 60.3 hours of audio in the training set, whereas the same figures were 107 hours, 165.8 hours and 147.5 hours for Hungarian, Polish and Portuguese, respectively. We adapted t $ $ \" \" $ # # \" \" \" ! ! $ $ The hesitation and noise models were retrained using the stretches of audio signal that correspond to the hesitation and noise tags inserted into the transcriptions during the transcription and annotation phase. In addition to the above, in the case of French, we tested a new acoustic modelling paradigm. This paradigm, based on Deep Belief Neural Networks (DNNs), is currently the state-of-the-art acoustic modelling approach, with ample evidence in the literature showing significant performance gains when compared with classic approaches, such as GMM-based acoustic models15. For our work, we used existing French DNN-based acoustic models as a starting point, and adapted them to elderly speech using the data in the French training set. Similar DNN-based acoustic models for Polish and Portuguese are currently under development. The Hungarian acoustic models are trained using a Gaussian Mixture Model (GMM) -based, gender-independent, position-dependent cross-word triphone approach. The training methodology included speaker normalisation and discriminative training. Similar to the other PaeLife languages, the Hungarian acoustic models also include silence, hesitation and noise models. In the case of Hungarian, however, we merged the noise and silence models into an extended silence model. Unlike the acoustic models for the other languages, we trained the Hungarian models from scratch (rather than using younger adult speech models as a starting point). As the transcription and annotation work was still ongoing when we trained the models, the training set included both read speech with manually verified transcriptions and annotations, spontaneous speech with manual transcriptions and annotations, as well as read speech without annotations. We used a lightly supervised selection method to eliminate mispronounced sentences from the unannotated read speech. In the future, we also intend to train DNN-based acoustic models for Hungarian. 3.3. Evaluation Results To illustrate the improvements in ASR performance that can be achieved by using acoustic models optimised for elderly speech, we trained comparable bigram language models (LMs) for all four PaeLife languages. The French, Hungarian and Polish corpora are the most comparable with each other in terms of contents; they mainly contain read out newspaper sentences (the Hungarian corpus also contains some spontaneous commands; cf. Section 3.1). In addition to newspaper sentences, the Portuguese corpus contains a considerable amount of command & control material; only about half of the recorded utterances are read out newspaper sentences. To keep the ASR results as comparable as possible across languages, we used the sentences in the Hungarian and Polish training sets â€“ excluding the sentences that also appear in the test sets â€“ to train the LMs but, in the case of Portuguese, we also excluded the command & control material from the training material. To compensate for this loss of training sentences in the case of Portuguese, we appended the training material with unused sentences from the original pool 289 Annika HÃ¤mÃ¤lÃ¤inen et al. / Procedia Computer Science 67 ( 2015 ) 283 â€“ 292 of newspaper texts available for collecting the EASR corpus. In the case of French, we had to use all the sentences in the training set for training the LM. Otherwise, the number of words in the test set that are not included in the ASR vocabulary, the so-called out-of-vocabulary (OOV) words, would have been very high; this would have masked the performance improvement arising from the elderly-specific acoustic models. In the case of Hungarian, the LM perplexity (an information theory -derived measure of how well a probability model (the LM) is able to predict a sample (the test set utterances); the lower a perplexity values is, the more accurately the LM is able to predict the word sequences in the test set utterances) and OOV rate are significantly higher than in the case of the other languages. This is due to the agglutinative nature of the language, resulting in thousands of possible word forms for a single stem. Table 2 summarises the key details of the LMs, as well as the results and improvements gained with the specialised acoustic models, as compared with standard acoustic models trained with young to middle-aged adultsâ€™ speech (baseline). Table 2. ASR results with acoustic models optimised for elderly speech. The 6th and 7th columns present the word error rates (WERs) obtained on the evaluation test sets using the baseline and the elderly-specific acoustic models. The last column indicates the relative reduction in the word error rates. Language ASR vocabulary words Word tokens (test set) LM perplexity (test set) OOV words (test set) WER (%) Baseline AMs WER (%) Elderly Speech AMs WER (%) relative reduction French 11287 36423 31.9 68 24.2 20.9 13.6 French - DNN 11287 36423 31.9 68 20.2 13.7 32.2 Hungarian 39151 40865 147.1 2372 27.0 19.4 28.1 Polish 19781 83135 54.3 283 16.0 13.6 15.0 Portuguese 8934 52970 60.0 219 18.3 16.4 10.4 As we can see in Table 2, the elderly-specific acoustic models provide considerable improvements in ASR performance over the baseline models. As expected, DNN-based models result in better ASR performance and a higher relative WER reduction than comparable GMM-based models. Once we are able to test ASR performance using LMs specifically developed for the dictation scenarios in AALFred (composing messages and agenda appointments), which â€“ from the language point of view â€“ are much harder ASR tasks than â€œpredictingâ€� newspaper sentences, the gains obtained from the acoustic model optimisation will be even higher. Conversely, the gains are expected to be lower in the case of commands, which are usually easy to recognise using relatively simple grammars. For now, we do not have suitable or enough data for the PaeLife languages to run experiments representing such scenarios. 4. Multilingual Speech-Enabled Interaction in AALFred In this section, we briefly describe the implementation of the speech modality in AALFred: a generic speech modality component that works decoupled from AALFred services, the interpretation of speech input using Spoken Language Understanding (SLU), and support for the fast integration of new languages by automatically deriving the first versions of semantic and ASR grammars. 4.1. Generic Speech Modality Component AALFred is based on a MultiModal Interaction (MMI) framework16, which follows the W3C recommendation of a multimodal architecture17. The major components of the architecture that are relevant for this paper include the modalities and the interaction manager (IM), which controls the HCI-related information. Communication between the modalities and the IM is based on events (life-cycle events17), and information is encoded for transmission using a mark-up language (Extensible MultiModal Annotation (EMMA)17). One important benefit of this architecture is its decoupled nature; the components are developed independently of the application and, as such, can easily be integrated in other applications. In the PaeLife project, we developed a generic speech modality component18 to support speech-based interaction with AALFred19. One major benefit of the speech modality component is that it is decoupled from the services available in AALFred and can, therefore, easily be integrated in new services (see Fig. 4). Furthermore, it can 290 Annika HÃ¤mÃ¤lÃ¤inen et al. / Procedia Computer Science 67 ( 2015 ) 283 â€“ 292 handle multiple languages and is very scalable when it comes to adding new languages (see Section 4.3). Similarly to the touch and gesture modality components, the speech modality component communicates with the IM. Whenever an event occurs in a modality component, the component in question uses an EMMA-encoded message wrapped inside an MMI life-cycle event to send the event information to the IM for processing and, if needed, the IM creates a new MMI life-cycle event with the same EMMA-encoded message to be forwarded to the application (AALFred). For instance, if a user has opened the Agenda service and uses a voice command (e.g. â€œOpen Thursdayâ€�) to request the application to display their schedule for Thursday, the speech modality component will send the corresponding event to the IM, with the semantic output resulting from the SLU processing of the ASR output (see Section 4.2). The IM processes the event and creates a new event to be sent to the application, which then displays the userâ€™s schedule for Thursday (see Fig. 3). Fig. 4 AALFred uses an architecture in which the speech modality is decoupled from the available services. [Main] ([ACTION]) ([HELP]) ; [ACTION] ([AGENDA]) ([APPOINTMENTS]) [...] ; [AGENDA] (agenda) (show my agenda) (go to my agenda) ([CHANGEDATE]) (*open [WEEKDAYS]) [...] ; [WEEKDAYS] ([MONDAY]) [...] ; [THURSDAY] ([Thursday]) ; [...] Fig. 5. Example of a semantic grammar used in AALFred. ASR output: open Thursday Semantic Result: [ACTION].[AGENDA].[WEEKDAYS].[THURSDAY] 291 Annika HÃ¤mÃ¤lÃ¤inen et al. / Procedia Computer Science 67 ( 2015 ) 283 â€“ 292 Fig. 6. Example of the semantic tags resulting from the semantic parsing of the ASR output â€œopen Thursdayâ€�. 4.2. Automatic Speech Recognition with Spoken Language Understanding To be able to use speech input to access and operate the AALFred services, we needed a way of robustly extracting the intended meaning of the speech input from the ASR output (i.e. the string of words that the automatic speech recogniser â€œthinksâ€� it â€œheardâ€�). This can be done using an SLU parser, which makes use of semantic grammars. Semantic grammars map possible ASR output to semantic tags that capture the intended meaning of speech input, and the SLU parser parses ASR output into a sequence of semantic tags defined in the grammars. The tags are then used by the application to produce the desired actions (e.g. opening the Agenda service). We chose to use the Phoenix20 parser and grammar specification format. This is because the Phoenix parser has been designed to be robust to errors in ASR output and disfluencies in speech. Let us consider SLU in AALFred. Whenever a user speaks and the ASR engine recognises the speech input, the speech modality component requests the service in question to extract the semantic tags for the ASR output, and sends the tags for the IM to process. Fig. 5 presents an example of a semantic grammar used in AALFred, and Fig. 6 is an example of the semantic tags for the ASR output â€œopen Thursdayâ€�. 4.3. Multilingual Support The speech modality needs semantic grammars for all supported languages. To produce these semantic grammars, we developed a service21 that enables the automatic translation of an English grammar into other languages, for instance, using Microsoft Translator API22. In other words, the developer only needs to create a semantic grammar for English, and this grammar can then automatically be translated into other languages. The semantic tags are the same for all languages, i.e., the tags in the English grammar are copied over to the automatically translated grammars. The ASR grammars, which are used by the automatic speech recognisers during recognition time (cf. Section 3), are generated by extracting all possible commands from the semantic grammars. Due to the limitations of machine translation, the grammar translation service also supports the manual revision and correction of the automatically translated grammars. Furthermore, AALFred is capable of dynamically updating grammars based on user input (e.g. when a user adds new contacts in the Contacts service). Of course, the semantic and ASR grammars could also be created manually. However, the grammar translation service that we developed allows for a fast integration of new languages into AALFred. 5. Conclusions In this paper, we described the work done in the area of multilingual automatic speech recognition in the scope of the PaeLife project10, which had the goal of developing a multimodal virtual personal life assistant to help the elderly remain active and socially integrated. The personal life assistant, AALFred, supports four European languages: French, Hungarian, Polish and Portuguese. We implemented the speech modality of AALFred as a generic component that is decoupled from the available AALFred services and can, therefore, be easily integrated in any future services. To be able to quickly increase the number of supported languages, we developed a grammar generation service that allows the automatic translation of English-language grammars into other languages, and supports the manual verification and correction of these automatically translated grammars. To provide the best possible user experience for the target audience, the automatic speech recognisers used in AALFred were optimised for elderly speech. For this purpose, we collected large corpora of elderly speech for all the supported languages. The results of our experiments show that the optimised speech recognisers can provide a considerable improvement in automatic speech recognition performance on elderly speech as compared with standard speech recognisers tuned for younger adult speech. Furthermore, the collected corpora are valuable resources for the international speech community. They will soon be available for research and development purposes through the Linguistic Data Consortium (LDC)23. 292 Annika HÃ¤mÃ¤lÃ¤inen et al. / Procedia Computer Science 67 ( 2015 ) 283 â€“ 292 Acknowledgements Authors acknowledge the funding from AAL JP and national agencies: MLDC was funded by the Portuguese Government through the Ministry of Science, Technology and Higher Education (MCES); University of Aveiro was funded by FEDER, COMPETE and FCT in the context of AAL/0015/2009 and IEETA Research Unit funding FCOMP-01-0124-FEDER-022682 (FCT-PEstC/EEI/UI0127/2011)). BME acknowledges the support of the FuturICT project (TÃ�MOP-4.2.2.C-11/1/KONV-2012-0013) and the PaeLife project (AAL-08-1-2001-0001). References 1. Teixeira, V., Pires, C., Pinto., F., Freitas, J., Dias, M.S., Mendes Rodrigues, E. Towards elderly social integration using a multimodal human-computer interface. In Proc. Living Usability Lab Workshop on AAL Latest Solutions, Trends and Applications, Vilamoura, Portugal; 2012. 2. Bernsen, N.O. Towards a tool for predicting speech functionality. Speech Communication 1997; 23(3):181-210. 3. Xue, S.A., Hao, G.J. Changes in the human vocal tract due to aging and the acoustic correlates of speech production: A pilot study. Journal of Speech, Language, and Hearing Research 2003; 46:689-701. 4. Wilpon, J.G., Jacobsen, C.N. A study of speech recognition for children and the elderly. In Proc. ICASSP, Atlanta, GA, USA; 1996. 5. Vipperla, R., Renals, S., Frankel, J. Longitudinal study of ASR performance on ageing voices. In Proc. Interspeech, Brisbane, Australia; 2008. 6. Living Usability Lab. [Online]. Available: [Accessed: 5-Feb-2015]. 7. Smartphones for Seniors. [Online]. Available: [Accessed: 5-Feb-2015] 8. Project ROMEO. [Online]. Available: [Accessed: 5-Feb-2015] 9. Zora. [Online]. Available: [Accessed: 5-Feb-2015] 10. PaeLife: Personal Assistant to Enhance the Social Life of Seniors. [Online]. Available: [Accessed: 5- Feb-2015] 11. Francisco, P., Almeida, N., Pereira, C., Silva, S. Services to support use and development of speech input for multilingual multimodal applications for mobile scenarios. In Proc. ICIW, Paris, France; 2014. 12. HÃ¤mÃ¤lÃ¤inen, A., Avelar, J., Rodrigues, S., Dias, M.S., KolesiÅ„ski, A., FegyÃ³, T., NÃ©meth, G., CsobÃ¡nka, P., Lan, K., Hewson, D. The EASR Corpora of European Portuguese, French, Hungarian and Polish Elderly Speech. In Proc. LREC, Reykjavik, Iceland; 2014. 13. Microsoft Speech Platform 11.0. [Online]. Available: [Accessed: 12-Feb-2015]. 14. TarjÃ¡n, B., SÃ¡rosi, G., FegyÃ³, T., Mihajlik, P. Improved recognition of Hungarian call center conversations. In Proc. SpeD, Cluj-Napoca, Romania; 2013. 15. Dahl, G.E., Yu, D., Deng, L., Acero, A. Context-dependent pre-trained deep neural networks for large-vocabulary speech recognition. IEEE Transactions on Audio, Speech, and Language Processing - Special Issue on Deep Learning for Speech and Language Processing 2012; 20(1):33-42. 16. Almeida, N., Teixeira, A. Enhanced interaction for the elderly supported by the W3C multimodal architecture. In Proc. InteracÃ§Ã£o, Vila Real, Portugal; 2013. 17. Bodell, M., Dahl, D., Kliche, I., Larson, J., Porter, B. Multimodal Architecture and Interfaces. arch/; 2012. 18. Almeida, N., Silva, S., Teixeira, A. Design and development of speech interaction: A methodology. In Proc. HCI International, Crete, Greece; 2014. 19. Teixeira, A., HÃ¤mÃ¤lÃ¤inen, A., Avelar, J., Almeida, N., NÃ©meth, G., FegyÃ³, T., ZainkÃ³, C., CsapÃ³, T., TÃ³th, B., Oliveira, A., Dias, M.S. Speech-centric multimodal interaction for easy-to-access online services: A personal life assistant for the elderly. In Proc. DSAI, Vigo, Spain; 2013. 20. Ward, W. Understanding spontaneous speech: The Phoenix system. In Proc. ICASSP, Toronto, Canada; 1991. 21. Teixeira, A., Francisco, P., Almeida, N., Pereira, C., Silva, S. Services to support use and development of speech input for multilingual multimodal applications for mobile scenarios. In Proc. ICIW, Paris, France; 2014. 22. Microsoft Translator API. [Online]. Available: [Accessed: 12-Feb- 2015]. 23. Linguistic Data Consortium. [Online]. Available: [Accessed: 12-Feb-2015]. CT in the context of AAL/0015/2009 and IEETA Research Unit funding FCOMP-01-0124-FEDER-022682 (FCT-PEstC/EEI/UI0127/2011)). BME acknowledges the support of the FuturICT project (TÃ�MOP-4.2.2.C-11/1/KONV-2012-0013) and the PaeLife project (AAL-08-1-2001-0001). References 1. Teixeira, V., Pires, C., Pinto., F., Freitas, J., Dias, M.S., Mendes Rodrigues, E. Towards elderly social integration using a multimodal human-computer interface. In Proc. Living Usability Lab Workshop on AAL Latest Solutions, Trends and Applications, Vilamoura, Portugal; 2012. 2. Bernsen, N.O. Towards a tool for predicting speech functionality. Speech Communication 1997; 23(3) PROCS 7136 S1877-0509(15)03118-X 10.1016/j.procs.2015.09.272 ☆ Peer-review under responsibility of organizing committee of the 6th International Conference on Software Development and Technologies for Enhancing Accessibility and Fighting Info-exclusion (DSAI 2015). Multilingual Speech Recognition for the Elderly: The AALFred Personal Life Assistant Annika Hämäläinen a b António Teixeira c Nuno Almeida c Hugo Meinedo a Tibor Fegyó d Miguel Sales Dias a b a Microsoft Language Development Center, Lisbon, Portugal Microsoft Language Development Center, Lisbon, Portugal b ISCTE – University Institute of Lisbon (ISCTE-IUL), Lisbon, Portugal ISCTE – University Institute of Lisbon (ISCTE-IUL), Lisbon, Portugal c Department of Electronics, Telecommunications & Informatics/IEETA, University of Aveiro, Aveiro, Portugal Department of Electronics, Telecommunications & Informatics/IEETA, University of Aveiro, Aveiro, Portugal d Department of Telecommunications & Media Informatics, Budapest University of Technology & Economics, Budapest, Hungary Department of Telecommunications & Media Informatics, Budapest University of Technology & Economics, Budapest, Hungary The PaeLife project is a European industry-academia collaboration in the framework of the Ambient Assisted Living Joint Programme (AAL JP), with a goal of developing a multimodal, multilingual virtual personal life assistant to help senior citizens remain active and socially integrated. Speech is one of the key interaction modalities of AALFred, the Windows application developed in the project; the application can be controlled using speech input in four European languages: French, Hungarian, Polish and Portuguese. This paper briefly presents the personal life assistant and then focuses on the speech-related achievements of the project. These include the collection, transcription and annotation of large corpora of elderly speech, the development of automatic speech recognisers optimised for elderly speakers, a speech modality component that can easily be reused in other applications, and an automatic grammar translation service that allows for fast expansion of the automatic speech recognition functionality to new languages. Keywords ageing automatic speech recognition elderly human-computer interaction multilingual multimodal speech. References [1] Teixeira, V., Pires, C., Pinto., F., Freitas, J., Dias, M.S., Mendes Rodrigues, E. Towards elderly social integration using a multimodal human-computer interface. In Proc. Living Usability Lab Workshop on AAL Latest Solutions, Trends and Applications, Vilamoura, Portugal; 2012. [2] Bernsen, N.O. Towards a tool for predicting speech functionality. Speech Communication 1997; 23(3):181-210. [3] Xue, S.A., Hao, G.J. Changes in the human vocal tract due to aging and the acoustic correlates of speech production: A pilot study. Journal of Speech, Language, and Hearing Research 2003; 46:689-701. [4] Wilpon, J.G., Jacobsen, C.N. A study of speech recognition for children and the elderly. In Proc. ICASSP, Atlanta, GA, USA; 1996. [5] Vipperla, R., Renals, S., Frankel, J. Longitudinal study of ASR performance on ageing voices. In Proc. Interspeech, Brisbane, Australia; 2008. [6] Living Usability Lab. [Online]. Available: [Accessed: 5-Feb-2015]. [7] Smartphones for Seniors. [Online]. Available: [Accessed: 5-Feb-2015]. [8] Project ROMEO. [Online]. Available: [Accessed: 5-Feb-2015]. [9] Zora. [Online]. Available: [Accessed: 5-Feb-2015] . [10] PaeLife: Personal Assistant to Enhance the Social Life of Seniors. [Online]. Available: [Accessed: 5-Feb-2015]. [11] Francisco, P., Almeida, N., Pereira, C., Silva, S. Services to support use and development of speech input for multilingual multimodal applications for mobile scenarios. In Proc. ICIW, Paris, France; 2014. [12] Hämäläinen, A., Avelar, J., Rodrigues, S., Dias, M.S., Kolesiński, A., Fegyó, T., Németh, G., Csobánka, P., Lan, K., Hewson, D. The EASR Corpora of European Portuguese, French, Hungarian and Polish Elderly Speech. In Proc. LREC, Reykjavik, Iceland; 2014. [13] Microsoft Speech Platform 11.0. [Online]. Available: [Accessed: 12-Feb-2015]. [14] Tarján, B., Sárosi, G., Fegyó, T., Mihajlik, P. Improved recognition of Hungarian call center conversations. In Proc. SpeD, Cluj-Napoca, Romania; 2013. [15] Dahl, G.E., Yu, D., Deng, L., Acero, A. Context-dependent pre-trained deep neural networks for large-vocabulary speech recognition. IEEE Transactions on Audio, Speech, and Language Processing - Special Issue on Deep Learning for Speech and Language Processing 2012; 20(1):33-42. [16] Almeida, N., Teixeira, A. Enhanced interaction for the elderly supported by the W3C multimodal architecture. In Proc. Interacção, Vila Real, Portugal; 2013. [17] Bodell, M., Dahl, D., Kliche, I., Larson, J., Porter, B. Multimodal Architecture and Interfaces. 2012. [18] Almeida, N., Silva, S., Teixeira, A. Design and development of speech interaction: A methodology. In Proc. HCI International, Crete, Greece; 2014. [19] Teixeira, A., Hämäläinen, A., Avelar, J., Almeida, N., Németh, G., Fegyó, T., Zainkó, C., Csapó, T., Tóth, B., Oliveira, A., Dias, M.S. Speech-centric multimodal interaction for easy-to-access online services: A personal life assistant for the elderly. In Proc. DSAI, Vigo, Spain; 2013. [20] Ward, W. Understanding spontaneous speech: The Phoenix system. In Proc. ICASSP, Toronto, Canada; 1991. [21] Teixeira, A., Francisco, P., Almeida, N., Pereira, C., Silva, S. Services to support use and development of speech input for multilingual multimodal applications for mobile scenarios. In Proc. ICIW, Paris, France; 2014. [22] Microsoft Translator API. [Online]. Available: [Accessed: 12-Feb-2015]. [23] Linguistic Data Consortium. [Online]. Available: [Accessed: 12-Feb-2015]. "
    },
    {
        "doc_title": "Trip 4 All: A Gamified App to Provide a New Way to Elderly People to Travel",
        "doc_scopus_id": "84962809876",
        "doc_doi": "10.1016/j.procs.2015.09.274",
        "doc_eid": "2-s2.0-84962809876",
        "doc_date": "2015-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Design approaches",
            "Easy-to-use products",
            "Elderly people",
            "Innovative technology",
            "Iterative development",
            "Mobile applications",
            "Social integrations",
            "Virtual assistants"
        ],
        "doc_abstract": "© 2015 The Authors.Older adults have much to gain from bringing technology into their daily lives. The extent to which this is possible strongly depends on careful design and accessible, easy to use products, developed using an elderly centered methodology. The senior tourism is a market in expansion and the old travelers need new and innovative technologies to help and support their trips. These technologies should contribute to a fun and safe experience, while promoting feelings of pleasure and self realization. In this paper we follow this design approach and put it to the test in developing the \"Trip 4 All\"(T4A), an application that works as a gamified virtual assistant to the elderly during a walking tourist visit. The gamified interaction with the visited environment intend to improve motivation to accomplish the visit and make the content absorption more fun and easier. The T4A works on georeferenced maps where the users' geoposition is a trigger to launch storytelling content and/or challenges based on the aspects of the visited site as such: geographical, art, religious, historic, cultural and human. The success in the challenges give the user prizes, new resources and abilities to try more complex challenges that brings more valuable prizes and so on. Furthermore, the proposed application intend to work as a companion that provides self confidence, support and social integration to elderly tourists.",
        "available": true,
        "clean_text": "serial JL 280203 291210 291871 31 90 Procedia Computer Science PROCEDIACOMPUTERSCIENCE 2015-11-06 2015-11-06 2015-11-06 2015-11-06 2016-01-06T20:55:21 S1877-0509(15)03120-8 S1877050915031208 10.1016/j.procs.2015.09.274 S300 S300.2 HEAD-AND-TAIL 2016-01-06T16:14:49.492416-05:00 0 0 20150101 20151231 2015 2015-11-06T03:04:30.753283Z rawtext articleinfo articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids confeditor contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid hubeid indexeddate issn issnnorm itemstage itemtransactionid itemweight oauserlicense openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sortorder srctitle srctitlenorm srctype ssids alllist content oa subj suppl tomb vol volfirst volissue volumelist yearnav affil articletitle auth authfirstini authfull authkeywords authlast primabst ref 1877-0509 18770509 true 67 67 C Volume 67 34 301 311 301 311 2015 2015 2015-01-01 2015-12-31 2015 Proceedings of the 6th International Conference on Software Development and Technologies for Enhancing Accessibility and Fighting Info-exclusion Dr. Carlos Velasco Dr. Gerhard Weber Dr. João Barroso Dr. Yehya Mohamad Dr. Hugo Paredes article fla Copyright © 2015 The Authors. Published by Elsevier B.V. TRIP4AGAMIFIEDAPPPROVIDEANEWWAYELDERLYPEOPLETRAVEL SIGNORETTI A CASTELLA 2005 27 J TEIXEIRA 2014 389 397 A BALLAGAS 2008 244 261 R FERREIRA 2012 4 S CASIMIRO 2012 400 409 J AHMAD 2010 185 196 W SIGNORETTIX2015X301 SIGNORETTIX2015X301X311 SIGNORETTIX2015X301XA SIGNORETTIX2015X301X311XA Full 2015-09-26T00:02:03Z ElsevierWaived OA-Window item S1877-0509(15)03120-8 S1877050915031208 10.1016/j.procs.2015.09.274 280203 2016-01-06T16:14:49.492416-05:00 2015-01-01 2015-12-31 true 2283284 MAIN 11 58257 849 656 IMAGE-WEB-PDF 1 Procedia Computer Science 67 ( 2015 ) 301 â€“ 311 Available online at www.sciencedirect.com 1877-0509 Â© 2015 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license Peer-review under responsibility of organizing committee of the 6th International Conference on Software Development and Technologies for Enhancing Accessibility and Fighting Info-exclusion (DSAI 2015) doi: 10.1016/j.procs.2015.09.274 ScienceDirect 6th International Conference on Software Development and Technologies for Enhancing Accessibility and Fighting Infoexclusion (DSAI 2015) Trip 4 All: A Gamiï¬�ed App to Provide a New Way to Elderly People to Travel Alberto Signorettia,âˆ—, Ana I. Martinsb,c, Nuno Almeidab,c, Diogo Vieirab,c, Ana Filipa Rosab,c, Carlos M. M. Costad, AntoÂ´nio Texeirab,c aDepartment of Informatics of Natal (DI/CAN), State University of Rio Grande do Norte, Av. Ayrton Senna s/n, Natal, 59056-400, Brasil bDepartment of Electronics Telecommunications and Informatics (DETI), University of Aveiro, C. Santiago, Aveiro, 3810-193, Portugal cInstitute of Electronics and Telematics Engineering of Aveiro (IEETA), University of Aveiro, C. Santiago, Aveiro, 3810-193, Portugal dDepartment of Economics, Management and Industrial Engineering (DEGEI), University of Aveiro, C. Santiago, Aveiro, 3810-193, Portugal Abstract Older adults have much to gain from bringing technology into their daily lives. The extent to which this is possible strongly depends on careful design and accessible, easy to use products, developed using an elderly centered methodology. The senior tourism is a market in expansion and the old travelers need new and innovative technologies to help and support their trips. These technologies should contribute to a fun and safe experience, while promoting feelings of pleasure and self realization. In this paper we follow this design approach and put it to the test in developing the â€œTrip 4 Allâ€�(T4A), an application that works as a gamiï¬�ed virtual assistant to the elderly during a walking tourist visit. The gamiï¬�ed interaction with the visited environment intend to improve motivation to accomplish the visit and make the content absorption more fun and easier. The T4A works on georeferenced maps where the usersâ€™ geoposition is a trigger to launch storytelling content and/or challenges based on the aspects of the visited site as such: geographical, art, religious, historic, cultural and human. The success in the challenges give the user prizes, new resources and abilities to try more complex challenges that brings more valuable prizes and so on. Furthermore, the proposed application intend to work as a companion that provides self conï¬�dence, support and social integration to elderly tourists. cÂ© 2015 The Authors. Published by Elsevier B.V. Peer-review under responsibility of organizing committee of the 6th International Conference on Software Development and Technologies for Enhancing Accessibility and Fighting Info-exclusion (DSAI 2015). Keywords: Active Aging, Elderly-centred design, Mobile application evaluation, Iterative development method; âˆ— Corresponding author. Tel.: +351234370520 ; Fax: +351234370545. E-mail address: alberto.signoretti@ua.pt or albertosignoretti@uern.br 2015 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license rg/licenses/by-nc-nd/4.0/). Peer-review under responsibility of organizing committee of the 6th International Conference on Software Development and Technologies for Enhancing Accessibility and Fighting Info-exclusion (DSAI 2015) 302 Alberto Signoretti et al. / Procedia Computer Science 67 ( 2015 ) 301 â€“ 311 1. Introduction 1.1. Concept of Senior Tourist The World Tourism Organization1 deï¬�nes tourists as people â€œtraveling to a country other than that in which s/he has his/her usual residence but outside his/her usual environment for a period not exceeding 12 months and whose main purpose of visit is other than the exercise of an activity remunerated from/with the country visited, and who stay at least one night in a collective or private accommodation in the country visitedâ€�1. The age at which a tourist is deï¬�ned as senior is no consensus among authors and organizations. AleÂ´n2 deï¬�nes senior tourist as tourist with more than 65 years, but other institution deï¬�ne a senior tourist as a tourist with more than 50, 55 or 60 years. This age is associated with the decrease of professional activity and family responsibilities as caring for children. 1.2. The Elderly Tourism and Traveling Market Currently more than 128 million citizens in the European Union are aged between 55 and 80 years, representing about 25% of the total population3. Worldwide, the proportion of people over 60 years is growing as a result of the decline in fertility rates and increased life expectancy, due to improvements in nutrition, in basic care and health care, and control of many infectious diseases4 The increase in the number and proportion of elderly is accompanied by a change in the age structure of the population. It is expected that in 2050, globally, the number of elderly will exceed the number of young people under 15 years5. All European countries are facing a similar demographic trend3. This demographic development is having a considerable impact on the increase of the tourism demand6. During the recent economic and ï¬�nancial crisis in Europe, the over 65 age group signiï¬�cantly contributed to counterbalance this negative impact: between 2006 and 2011 the number of tourists dropped in all age groups except for the over 65, posting a 10% increase over 20066. In 2011, the over 65 group made 29% more trips and 23% more overnight stays than ï¬�ve years earlier. Their tourism expenditure grew by 33% and accounted for 20% of all tourism spending of Europeans, compared with just 15% in 20066. At the same time, the senior touristic market quota is in expansion, and it is going to be even more accentuated in new generations, in contrast with the major part of the present older population, being much used to travel, which shall be reï¬‚ected in their future behaviors, even in more advanced ages7. In general, older people in retirement ages have more free time and are willing to spend it on tourism. Increasingly, as a result of the changes in health care and society, seniors are healthier and wealthier than in previous generations in many European countries. Besides that, the tendency is that this population show an increase in savings and assets with fewer ï¬�nancial commitments, especially in the early years of retirement. They also tend to be increasingly quality conscious and demanding, particularly committed with safety, responsible and sustainable services and infrastructures. Nevertheless, there are also seniors with less purchasing power and seniors with health problems. In fact, seniors are rather a heterogeneous group of individuals with diï¬€erent needs and motivations6. Seniors are more ï¬‚exible in travel patterns and take advantage of low seasons oï¬€ers that appeal senior travellers, such as less congested facilities and lower prices6. Nowadays seniors present a much more agile proï¬�le, much wider interests and a bigger desire to experience new things, until an advanced age. The European Commission considers that the contribution of senior citizens to the European tourism industry is indeed signiï¬�cant and should be reinforced to face the challenge of seasonality, stimulating economic growth and jobs in Europe3. This is still a new market area as just 3 out of 10 senior European citizens travel abroad. Therefore there is clearly a high potential for increasing the number of travels undertaken by this segment of the market6. The motivations more frequently referred on behalf of old people to enjoy holidays are: get away from routine, rest and relax, social motives /socialize (as well as to do new friendships as to be in family), as well as cultural motives (to enlarge horizons, visit new places, experience new things) and the carrying out physical activities, mainly outdoor8. 1.3. The Traveling Experience The creation of more services and tourist activities, including individual and group tourism, is a necessity at the des- tinations during the low and medium seasons6. The tourist demand of the elderly focuses on varied types of tourism. 303 Alberto Signoretti et al. / Procedia Computer Science 67 ( 2015 ) 301 â€“ 311 In terms of traditional tourism the most common are: cultural, urban, religious, rural, cruises and health/thermal tourism9. On the other hand, there is also a kind of tourism whose character, in the case of senior tourism, can be considered innovative: adventure tourism, eco-tourism, trips for tourists with special medical needs, educational trips and inter-generational travel. The strong potential of this tourism segment requires a diï¬€erentiated and appropriate approach by the tourism industry and other intervening factors in the development of this sector. This approach should be supported by a thor- ough knowledge of the characteristics, needs and expectations of older tourists. A diversiï¬�ed combination of activities that include, among others, activities that promote the knowledge of culture of the visited destination, activities that encourage a high interaction and social interaction and open door activities. As travelers get older, they tend to become less self-conï¬�dent, more apprehensive and concerned about safety and unexpected changes in travel arrangements. Elderly travelers prefer to travel with escorted and credible groups. Permanent accompanying of seniors by people with training in languages and that have a good knowledge of the spoken language in the visited destination and the own destination may also be appreciated by the senior population8. In this situation, a virtual companion that works as a virtual assistant for the travel seems to be a good strategy. 1.4. Why Gamiï¬�cation? Considering the report published by Gartener Group in 20124, by 2015 more than 50% of innovative organizations will use gamiï¬�ed process, and more than 70% of the biggest organizations of the world will use, at least, one applica- tion based in games in their business. This report, calculated the gamiï¬�cation market in some about US $2.8 billion dollars10,11. The authors of this paper did not ï¬�nd any report of Gartener Group conï¬�rming or refuting this prediction, but the game market is rising substantially in the past years and, with this growth, the term â€�gamiï¬�cationâ€� became a very important subject when the discussion is about peopleâ€™s motivation. The Y generation phenomenon (people born between years of 1980 and 2000) is not new and is a challenge for educators as for CEOs. This people was raised playing games and using the game thinking in a lot of life ï¬�elds, and represent something about 25% of economically active population. Nowadays they are leading some companies in the world and, for they, think about a game as a business process is not something unreal or unexpected11,12. Gamiï¬�cation refers to the process of using game thinking and game mechanic for traditional solving problem process or for engaging. In other words, it is the use of game elements in a non-game context. The use of these techniques has became common to achieve behavioral changes especially when it comes to encouraging people to adopt new technologies and/or methods to accomplish their tasks. This is forcing to change the traditional model of design focused on functionality for the design focused on human needs. Unlike the game design aimed at the sole purpose of entertaining, the gamiï¬�cation intend to use the mechanism of the games to transform or develop new behaviors11,12. Johan Huizinga13 established that the act of play is set in the most diverse social relations, such as politics, work, poetry and even the nature. Thus, the game is a cultural element which is much more than a physiological phenomenon or a psychological reï¬‚ection14. According to Maslowâ€™s hierarchy of needs theory15, gaming could be related to the top position since it is classiï¬�ed as a desirable activity, but not essential for survival. Ysmar11 points out: â€œit is understandable that we have created games, as they quench more easily, quickly, and eï¬ƒciently clear this constant search that plagues us for securing or meet goals when our relations and day by day work is composed by fuzzy rules, no feedback and rewards that are too small or normally absentâ€�. Bernard Suits, in his book The Grasshopper: Games, Life and Utopia16, says that â€œplaying a game is the voluntary attempt to overcome unnecessary obstaclesâ€� For the design of an application for the senior tourism it is perceived that the target audience is not deï¬�ned in the data presented above. This population certainly did not have access to various technological equipment which their grandchildren are familiar. These people however also had their childhood and also had times when games were very important things. Within this context and considering the fact that the technology is now an everyday factor in everyoneâ€™s life, the development of an application whose experience provided to elderly users is fun, engaging, intuitive, motivating and socializing, is a real challenge. But, from the point of view of an active aging process, is a challenge that will decrease the technical gap between them and their grandchildren. 304 Alberto Signoretti et al. / Procedia Computer Science 67 ( 2015 ) 301 â€“ 311 1.5. An Alternate Reality Game As mentioned before15, the games are connected to the search of the human being by the feeling of satisfaction and happiness. Therefore, the inclusion of gamiï¬�cation in daily activities can be a way to provide to individuals a set of good experiences, basic condition for what is known as happiness17,18. McGonigal19 describes three basic attributes of the rewards found in games that meet the requirement of meeting basic psychosocial needs of human beings: 1. (More) Satisfactory Work: the tasks oï¬€ered in games are oriented by clear goals, achievable and motivating on which it is always possible to see the direct impact of the eï¬€orts. This relates to the persistent and obstinate behavior shown by players. This type of behavior faces failures as necessary steps to achieve victory and not as a failure situation. 2. Social Connectivity: possibility of creating social ties among participants. This feature is common in online games where users form communities. 3. Adherence to socially relevant projects: associated with the communities, raise collaborative sense to join forces in favor of the major causes instead of personal interests both within the ï¬�ctional universe of games like in the real universe of players Since our users are elderly from whom is not expected knowledge or use of current technology, the choice of games that can work together real and virtual reality seems to be the best for obtaining the engagement of these new players. These kind of games are called Alternative Reality Games (ARGs) and they are considered an interesting way to conduct a gamiï¬�cation of some real activity or task. The purpose of the T4A is to encourage and motivate the elderly to create the behavior (or change an existing one) to visit tourist sites on foot. In other words, the ARG used as a process of gamiï¬�cation has the main objective to get the engagement and motivation of the elderly user. For this to happen it is necessary to understand the reasons why the games get a motivated and engaged behavior of its members, and for that, the BJ Foggâ€™s Behavior Model (FBM)was used20. It is a valuable tool for determining why people react in certain ways, or even why they fail to react in the manner expected. As Fogg notes: â€œif users are not performing a target behaviour, such as rating hotels on a travel web site (or completing an eLearning course), the FBM helps designers to see what psychological element is lackingâ€�. According to the FBM there are three key elements involved to inï¬‚uence the activation of a targeted behavior: motivation, ability and triggers. The activation demands that these three elements are provided simultaneously20. Users may be able to solve a problem, but if there is no motivation for them to do so, why should they? The user can be motivated but this is absolutely not suï¬ƒcient to do something he/she is not capable of (ability). But motivation and ability alone are not enough to determine behavior. There is the need of something that prompts the user to complete a certain action within a deï¬�ned time-frame (trigger). 1.5.1. The T4A Gamiï¬�cation The gamiï¬�cation process of the application T4A is based on a platform called RPGT4A. The RPGT4A is a platform for development of Role Playing Games (RPG)21 that can be used as a tool to support the process of engagement of people, preferably elderly, in virtually assisted touristic tours by foot. The platform consists of a set of hierarchically interlinked georeferenced maps. The application interacts with the player using the tourist real time location provided by the geolocation smartphone system. The maps are divided into several areas of interest that make the interaction occur. Each area of interest may be related to multimodal storytelling information based on text, sound, image or video, as well as related to challenges. The exploitation of the areas of interest of the maps will cause the application to give the player the possibility to have access to information and challenges based on a story that takes into account geographic, artistic, religious, historical, cultural and human aspects of the places that are been visited. The success in the proposed challenges is rewarded with points, improving the player score and unlocking new and more complex challenges to access more valuable prizes. Thus, the character that represents the player (avatar) is improved at each step with more resources to help address the new challenges presented. The challenges are considered as minigames coupled to the main application, allowing each challenge to be treated as an independent application. That is, respecting the communication protocol between the main application and the 305 Alberto Signoretti et al. / Procedia Computer Science 67 ( 2015 ) 301 â€“ 311 minigame, generic challenges may be attached to the platform without any changes in the core application. This ï¬‚exibility allows the same content to be approached by many diï¬€erent challenges whose creation can be left to third parties. This allows not only strengthening of the content but also the diversity that makes the activity becomes interesting to play. The main application will use a multiagent system based on agents with aï¬€ective perception focus implementing a virtual assistant22,23,24. Based on the userâ€™s proï¬�le and context (environment), this virtual assistant will oï¬€er the help needed by the user during the visit including personalized information on the site visited. The agents with aï¬€ective perception focus allows customization of agent behavior to make it compatible with each userâ€™s proï¬�le. Additionally, the assistant will be based on the multimodal architecture presented by Teixeira25. 1.6. Related Works Applications using the userâ€™s geoposition as a trigger are not new as the REXplorer project26 demonstrates. This is an interesting project of a pervasive game for tourists. Following the experience developed on 2007 and 2008 in the city of Regensburg, Germany, some guidelines that helped the design of the T4A were found, as such: about the sequencing problems of storytelling associated with the site seeing, the hot zones associated with the georeferenced map and the importance of the game not became more important than the touristic view. The T4A developed an platform to store all the information about the storytelling and the challenges using these guidelines. The result was a platform that allows use the application in any site and with diï¬€erent gamiï¬�cation processes. Furthermore, The T4A application was developed using the elderly centered design and work as a customized virtual assistant. Others expirences that worth to be cited are the Travel plot Porto27, the Tripzoon project28 although it is not directed to tourists, but it is about walking behavior, and the applications JiTT City Guides 1 developed by iClio 2 that works as managers for audio storytelling content. All these works use gamiï¬�cation to improve the userâ€™s experience but none of then were developed using an elderly centered design and, also, none of then intent to be a customized virtual assistant for the user. 2. Elderly Centered Development Method Over the First Prototype The development method was made according with a three phase spiral: obtaining the requirements (phase 1), prototype creation (phase 2) and evaluation (phase 3). This iterative methodology continues with additional cycles of requirements, prototypes and evaluations towards an increasingly reï¬�ned application as shown in Figure 1. Each phase of the development method was accompanied by a speciï¬�c evaluation process based on the method- ology described in29. This evaluation methodology consists in submitting each phase (requirements, prototype and evaluation) to a evaluation process based in the following steps: conceptual validation, prototype test and pilot test. In what follows, a general description of the overall aspects involved in each of the phases of the development method is described below. 2.1. Requirements This phase intended to verify if the idea of the T4A was sustainable in terms of functionalities to be included and interface trough the implementation of methodologies such as personas and brainstorming. â€¢ The persona was constructed based on the literature about elderly touristsâ€™, as described in Section 1.2. â€¢ The brainstorming was planned and oriented in accordance with Rawlinson30. The results of both this methodologies were used to decide the requirements of the very ï¬�rst prototype of T4A. For the next spiral cycle this process will be repeated based on the results of the evaluation process applied on the evaluation phase of the development method. 1 2 306 Alberto Signoretti et al. / Procedia Computer Science 67 ( 2015 ) 301 â€“ 311 Fig. 1. The methodology consists in an iterative process, in which multiple development cycles increasingly reï¬�ne requirements and prototypes. 2.2. Prototype The T4A prototype was developed as a way to mediate the interaction between the end users and the developers31. This will be accomplished using the diï¬€erent evolutions of the application prototype. Without discarding the possibil- ity of changes along the diï¬€erent iterations, to better accommodate the reï¬�ned requirements, the architecture initially adopted for the prototype should account, as best as possible, for the incremental nature of the work to be carried out, minimizing the development eï¬€ort and time. 2.3. Evaluation During the development of an application, designed taking into account the accessibility and usability features of end users, the application is evaluated several times (several iterations of phases 1 through 3). As described in29 the prototype test intended to collect information regarding the usability and user satisfaction. The prototype test is conducted in a controlled environment. When this prototype can no longer evolve, and the users are satisï¬�ed with the functionalities and usability, then this prototype is ready for a pilot test. This test intends to evaluate, in addition with usability and satisfaction, the meaning that a product or service has on usersâ€™ lives. For this reason, this last step of testing diï¬€ers from the prototype phase in the context where it happens. The product or service should be installed in usersâ€™ homes and integrated into their daily live routines. 3. Overall System Architecture The Figure 2 shows a basic illustration of the technological structure used in the development of the T4A applica- tion. Fig. 2. The technological structure of the solution T4A. Given the importance of the prototypes, in the described development methodology(Section 2), the chosen archi- tecture should be able to support the incremental reï¬�nement of the prototype, minimizing the development eï¬€orts. To support the development was adopted an architecture based on two main blocks: the smarphone and web services to complement its capabilities. 307 Alberto Signoretti et al. / Procedia Computer Science 67 ( 2015 ) 301 â€“ 311 To combine more ways of interaction, giving users others possibilities to interact with the application and leading to greater ease of use, the W3CMultimodal Interaction (MMI) Architecture32 was adopted. This is, a loosely coupled and extensible architecture supporting multiple modalities. Modalities can be added or modiï¬�ed without any changes in the application core and this ï¬‚exibility allows the developer of the application to code without having knowledge about the modalities, this way he only have to focus on the applications and other developer would focus only in the modalities. Previous experience33 showed that for instance speech can easily be integrated in our project using this architecture. 3.1. Modalities In the adopted architecture, three modalities were initially consider, the graphical user interface, speech and touch. One of the advantages of working with decoupled modalities is the chance to easily exchange them by improved versions or even by new modalities. This is important because it allows the developers to focus on the application core and use readily available modalities, instead of having to develop them from scratch, which might be a complex task. 3.2. Services Only part of the modalities are implemented in the smartphone and they use cloud based services, this ways completing the work of the modality. Considering the speech modality, for example, the ASR and TTS are provided by services communicating with the modality. The modality sends data (e.g., the audio of a spoken utterance to be recognized or a message with information to be read) and receives the required results. Another important service, which is already considered, is the natural language generator (NLG). It can be used to generate more natural sentences, with particular information. It uses a statistical machine translation system and includes a trained language model that can be adapted depending on the requirements34,35. The data for all users is gathered in the User Service manager, freeing the smartphone from providing persistent storage and allows synchronization between applications and devices. This set of generic services, considered from the start, can be expanded with the addition of specialized services to encompass the gathered requirements. 3.3. Georeferenced Gamifying Platform As previously explained, the T4A application was developed taking into consideration the usersâ€™ geoposition as a trigger. The data structure was designed to be attached to the map used by the main application, so it is possible to use the same structure at any place. The data structure has to be ï¬�lled considering that a Base Map is composed of at least one Sub-Map, each Sub-Map has to have at least one Area of Interest and, ï¬�nally, each Area of Interest has to have at least one Point of Interest (PoI). The use of digital games as an instructional framework has proved to be interesting by allow the playful insertion in the learning process36. The playful, brought by games, helps making the instructional content more interesting, interactive, meaningful and challenging37. The Georeferenced Gamifying Platform called RPGT4A has as main objective the easy and fast development of RPGs (Role Playing Games) that can be used as a support to people engagement process in virtually assisted walking tours. The use of RPG games can provide interactivity and encourage participation in the instructional process38. This type of game is an eï¬€ective tool to assist in the complex issues of questioning peopleâ€™s lives, such as urban violence, social inequality and racial conï¬‚icts, as well as learning curricula39. Figure 3 shows the Georeferenced Gamifying Platform RPGT4A connected hierarchies. As can be seen, the maps hierarchy is connected to the storytelling hierarchy, which in turn, is connected to the challenges hierarchy. The main application of T4A receives this conï¬�guration through a Json 3 ï¬�le. 3 308 Alberto Signoretti et al. / Procedia Computer Science 67 ( 2015 ) 301 â€“ 311 Fig. 3. Overall architecture of georeferenced gamifying platform used in the prototype. In the next section will be explained the implementation process used for the ï¬�rst prototype of T4A and the content of the georeferenced gamifying platform used. 4. Trip4All - T4A For this ï¬�rst prototype an application area nearby the development lab was chosen in order to avoid long shifts and improve the testing/correction process. The map of campus Santiago of the University of Aveiro was used as the base map for the prototype design. The T4A application will be based on the multimodal architecture presented by Teixeira25. Because of this, the prototype of T4A has been initially developed for Windows Phone 8.1 using the Visual Studio 2013 IDE. To future work the application intends to work in all architectures of mobile devices available on the market. Figure 4 shows the map structure used in the prototype development. The map structure was composed by two sub-maps identiï¬�ed by CSM1 and CSM2. The ï¬�rst sub-map was composed by two areas of interest identi- ï¬�ed by CSM1.CAI1 and CSM1.CAI2. For each of these areas of interest there is a point of interest identiï¬�ed by CSM1.CAI1.PoI1 and CSM1.CAI2.PoI1 respectively. The second sub-map is composed by one area of interest iden- tiï¬�ed by CSM2.CAI1 and this area has one point of interest identiï¬�ed by CSM2.CAI1.PoI1. To start the gamiï¬�ed experience the users needs to: 1) log in; 2) choose location of the visit and 3) start the visit walking through the site. To the extent that the visit is happening the visitorâ€™s geoposition works as a trigger to start the associated storytelling and challenges. Figure 5 shows an example of the concatenation of callbacks considering the visitor is walking through the base map, entering in a sub-map, then entering in a area of interest and, ï¬�nally, achieving a point of interest. For the ï¬�rst prototype a very simple storytelling was deï¬�ned explaining only the basics about the architecture of the buildings pointed by the points of interest. The points of interest were placed in front of the library building, in front of the the main door of the rectory building and in front of the main door of civil engineering department building. The main objective of the prototype is obtain a proof of concept so there are callbacks functions deï¬�ned only for the PoIs. That is, the ï¬�rst three steps shown in Figure 5 do not starts anything in the application, only the fourth step starts a pop up with a storytelling and a link pointing to a challenge when the user achieve the PoI area. The challenges were created using the web language package HTML5/CSS3/JS and they are initialized by the main application as web-views. This approach grants the use a huge quantity of games and features available in the internet and the possibility of easier development of new components for the T4A. Three kinds of challenges were developed for the prototype, a crossword game to be used in the PoI of the library building, a treasure hunt for the PoI of the rectory building and a quiz to be used in the PoI of the civil engineering department. Figure 6 shows some snapshots of the T4A prototype application. 309 Alberto Signoretti et al. / Procedia Computer Science 67 ( 2015 ) 301 â€“ 311 Fig. 4. Maps hierarchy used in the Prototype. Fig. 5. Concatenation of call backs used in the Prototype. 5. Conclusions and Future Work The main idea behind the Elderly Centered Design Method is the focus in the inclusion of the end-user in the development process since the beginning to achieve faster and more productive iterations. The participation of the user is crucial to generate better ideas in the brainstorming sessions to a more reï¬�ned development of personas and scenarios. In addition, their participation is important to a development of an accurate knowledge about the real needs and capabilities to enable a process of continuous development of the application by successive reï¬�nements and redesign. The application T4A is just starting the evaluating phase of the ï¬�rst cycle of the process requirements, prototyping and evaluating. Because of that, there is still no complete data set to point out the strengths and weaknesses of the current stage of development, but the initial feedback provides the feeling that the work is in the correct way. Considering this prototype as a proof of concept for the Georeferenced Gamifying Platform (discussed in section 3) the main goal was achieved. The design of the platform is functional and can be expanded to be used in any desired site. The hierarchical structure of maps, storytelling and challenges using Json conï¬�guration ï¬�les proved to be easy to use and to maintain. The use of HTML5/CSS3/JS to develop the challenges show that it is possible to incorporate to the main application a lot of new features with little programming eï¬€ort. 310 Alberto Signoretti et al. / Procedia Computer Science 67 ( 2015 ) 301 â€“ 311 Log In. Instructions. Selection of the Visit. â€œYou are here!â€�. The route of the visit. Storytelling content. Fig. 6. Snap shots of T4A application prototype. With the concept of the Georeferenced Gamifying Platform settled, the new step is the development of a road map for the historical midtown of the city of Aveiro, using as the gamiï¬�ed aspect of the application the history of the salt exploration and the cultural aspects of the moliceiros boats. This will be take place in a partnership with the Tourism Departament of University of Aveiro and City Hall of Aveiro. Acknowledgements This work has the ï¬�nancial support of CNPq (Brazilian Research Council), under process number PDE 201461/2014- 5, was partially funded by Project QREN N 13852 I&D â€œAAL4ALL Ambient Assisted Living for Allâ€�, UI 127/94 IEETA and has received partial funding from European Unions Seventh Framework Programme for research, tech- nological development and demonstration under grant agreement n 610986 (project IRIS, FP7-PEOPLE-2013-IAPP, References 1. United Nations, , World Tourism Organization, . Recommendations on Tourism Statistics. Tech. Rep.; United Nations publication; 2013. 2. AleÂ´n, E., DomÄ±Â´nguez, T., Losada, N.. New opportunities for the tourism market: Senior tourism and accessible tourism. . . . (a cura di) Visions for Global . . . 2012;URL: 3. European Commission, . Tourism for Seniors. 2014. URL: tourism-seniors/index_en.htm. 4. Goasduï¬€, L., Pettey, C.. Gartner says by 2015, more than 50 percent of organizations that manage innovation processes will gamify those processes. 2011. 5. United Nations, Department of Economic and Social Aï¬€airs, Population Division, . World Population Ageing 2013. ST/ESA/SER.A/348. 2013. 6. European Commission, . Europe, the best destination for seniors. Facilitating cooperation mechanisms to increase senior touristâ€™s travels within Europe and from third countries in the low and medium seasons - Experts draft report. Tech. Rep.; Brussels; 2014. 311 Alberto Signoretti et al. / Procedia Computer Science 67 ( 2015 ) 301 â€“ 311 7. Urhausen, J.. Eurostat Report: Tourism in Europe ? Does Age Matter? Tech. Rep.; Eurostat; 2009. 8. EuseÂ´bio, M., Carneiro, M., Kastenholz, E., Alvelos, H.. Potential Beneï¬�ts of the Development of an European Programme of Social Tourism for Seniors. Tech. Rep.; Department of Economy, Management and Industrial Engineering Aveiro University; 2012. URL: http: 9. Cavaco, C.. Turismo seÂ´nior: perï¬�s e praÂ´ticas 2009;URL: 10. Anderson, J.Q., Rainie, H.. Gamiï¬�cation: Experts Expectâ€™Game Layersâ€™ to Expand In the Future, With Positive and Negative Results. Pew Internet & American Life Project; 2012. 11. Ysmar Vianna Mauricio Vianna, B.M.S.T.. Gamiï¬�cation, Inc.: como reinventar empresas a partir de jogos; vol. 1. mjv Press; 1 ed.; 2013. Isbn 978-85-65424-08-0. 12. Ed Boswell Diane Youden, e.a.. The power of the net generation. Tech. Rep.; PricewaterhouseCoopers LLP; 2012. URL: 13. Huizinga, J.H.. Homo Ludens- Study of the Play Element in Culture (International Library of Society. Routledge; 1980. ISBN: 0-7100- 0578-4. 14. Caillois, R., Palha, J.. Os jogos e os homens: a maÂ´scara e a vertigem. Cotovia; 1990. ISBN 9789729013287. URL: google.pt/books?id=NVajOgAACAAJ. 15. Maslow, A.H.. A theory of human motivation. Start Publishing LLC; 2013. 16. Suits, B., Hurka, T.. The Grasshopper: Games, Life and Utopia. Broadview encore editions. Broadview Press; 2005. ISBN 9781551117720. URL: 17. Csikszentmihalyi, M., Csikzentmihaly, M.. Flow: The psychology of optimal experience; vol. 41. HarperPerennial New York; 1991. 18. Seligman, M.E., Csikszentmihalyi, M.. Positive psychology: An introduction.; vol. 55. American Psychological Association; 2000. 19. McGonigal, J.. Reality is broken: Why games make us better and how they can change the world. Penguin; 2011. 20. Fogg, B.. A behavior model for persuasive design. In: Proceedings of the 4th international Conference on Persuasive Technology. ACM; 2009, p. 40. 21. Castella, J.C., Trung, T.N., Boissau, S.. Participatory simulation of land-use changes in the northern mountains of vietnam: the combined use of an agent-based model, a role-playing game, and a geographic information system. Ecology and Society 2005;10(1):27. 22. Xavier-Junior, J.C., Signoretti, A., Canuto, A.M., Campos, A.M., GoncÂ¸alves, L.M., Fialho, S.V.. Introducing aï¬€ective agents in recommendation systems based on relational data clustering. In: Database and Expert Systems Applications. Springer; 2011, p. 303â€“310. 23. Signoretti, A., Feitosa, A., Campos, A.M., Canuto, A.M., Xavier, J., Fialho, S.V.. Using an aï¬€ective attention focus for improving the reasoning process and behavior of intelligent agents. In: Web Intelligence and Intelligent Agent Technology (WI-IAT), 2011 IEEE/WIC/ACM International Conference on; vol. 2. IEEE; 2011, p. 97â€“100. 24. Signoretti, A.. Agentes Inteligentes com Foco de AtencÂ¸aËœo Afetivo em SimulacÂ¸oËœes Baseadas em Agentes. Ph.D. thesis; UNIVERSIDADE FEDERAL DO RIO GRANDE DO NORTE; 2012. 25. Teixeira, A., HaÂ¨maÂ¨laÂ¨inen, A., Avelar, J., Almeida, N., NeÂ´meth, G., FegyoÂ´, T., et al. Speech-centric multimodal interaction for easy-to- access online servicesâ€“a personal life assistant for the elderly. Procedia Computer Science 2014;27:389â€“397. 26. Ballagas, R., Kuntze, A., Walz, S.P.. Gaming tourism: Lessons from evaluating rexplorer, a pervasive game for tourists. In: Pervasive computing. Springer; 2008, p. 244â€“261. 27. Ferreira, S., Alves, A., Quico, C.. Location based transmedia storytelling: The travelplot porto experience design. Journal of Tourism and Development [Revista Turismo & Desenvolvimento] 2012;17(18):4. 28. Broll, G., Cao, H., Ebben, P., Holleis, P., Jacobs, K., Koolwaaij, J., et al. Tripzoom: an app to improve your mobility behavior. In: Proceedings of the 11th International Conference on Mobile and Ubiquitous Multimedia. ACM; 2012, p. 57. 29. Martins, A.I., QueiroÂ´s, A., Cerqueira, M., Rocha, N., Teixeira, A.. The international classiï¬�cation of functioning, disability and health as a conceptual model for the evaluation of environmental factors. Procedia Computer Science 2012;14:293â€“300. URL: sciencedirect.com/science/article/pii/S1877050912007958. 30. Rawlinson, J.G.. Creative thinking and brainstorming. Gower Farnborough, Hants; 1981. 31. Compagna, D., Kohlbacher, F.. The limits of participatory technology development: The case of service robots in care facilities for older people. Technological Forecasting and Social Change 2014;(0):â€“. 32. Dahl, D.A.. The W3C multimodal architecture and interfaces standard. Journal on Multimodal User Interfaces 2013;7(3):171â€“182. doi:10. 1007/s12193-013-0120-5. 33. Almeida, N., Silva, S., Teixeira, J.S.A.. Design and development of speech interaction: A methodology. In: Human-Computer Interaction. Advanced Interaction Modalities and Techniques Lecture Notes in Computer Science Volume 8511. Springer; 2014, p. 370â€“381. 34. Casimiro, J., Teixeira, A., Pinto, J.S.. Natural language generation in the context of multimodal interaction in Portuguese. ElectroÂ´nica e TelecomunicacÂ¸oËœes 2012;5(4):400â€“409. 35. Casimiro, J., Pinto, J.S., Teixeira, A.. Natural language generation in the context of multimodal interaction in Portuguese. In: 8th Iberian Conference on Informaton Systems and Technologies (CISTI). 2013, . 36. Ahmad, W., Shaï¬�e, A.B., Latif, M.. Role-playing game-based learning in mathematics. The Electronic Journal of Mathematics and Technology 2010;4(2):185â€“196. 37. Medeiros, M.d.O., Schimiguel, J.. Uma abordagem para avaliacÂ¸ao de jogos educativos: enfase no ensino fundamental. In: Anais do SimpoÂ´sio Brasileiro de InformaÂ´tica na EducacÂ¸aËœo; vol. 23. 2012, . 38. KLIMICK, C.. Rpg & educacÂ¸aËœo: metodologia para o uso paradidaÂ´tico dos role playing games. Design MeÂ´todo Rio de Janeiro: Ed PUC-Rio; TeresoÂ´polis: Novas IdeÂ´ias 2006;. 39. MARCATTO, A.. Saindo do quadro: Uma metodologia educacional luÂ´dica e participativa baseada no role playing game. SaËœo Paulo: A Marcatto 1996;. mountains of vietnam: the combined use of an agent-based model, a role-playing game, and a geographic information system. Ecology and Society 2005;10(1):27. 22. Xavier-Junior, J.C., Signoretti, A., Canuto, A.M., Campos, A.M., GoncÂ¸alves, L.M., Fialho, S.V.. Introducing aï¬€ective agents in recommendation systems based on relational data clustering. In: Database and Expert Systems Applications. Springer; 2011, p. 303â€“310. 23. Signoretti, A., Feitosa, A., Campos, A.M., Canuto, A.M., Xavier, J., Fialho, S.V.. Using an aï¬€ective attention focus for improving the reasoning process and behavior of intelligent agents. In: Web Intelligence and Intelligent Agent Technology (WI-IAT), 2011 IEEE/WIC/ACM International Conference on; vol. 2. IEEE; 2011, p. 97â€“100. 24. Signoretti, A.. Agentes Inteligentes com Foco de AtencÂ¸aËœo Afetivo em SimulacÂ¸oËœes Baseadas em Agentes. Ph.D. thesis; UNIVERSIDADE FEDERAL DO RIO GRANDE DO NORTE; 2012. 25. Teixeira, A., HaÂ¨maÂ¨laÂ¨inen, A., Avelar, J., Almeida, N., NeÂ´meth, G., FegyoÂ´, T., et al. Speech-centric multimodal interaction for easy-to- access online servicesâ€“a personal life assistant for the elderly. Procedia Computer Science 2014;27:389â€“397. 26. Ballagas, R., Kuntze, A., Walz, S.P.. Gaming tourism: Lessons from evaluating rexplorer, a pervasive game for tourists. In: Pervasive computing. Springer; 2008, p. 244â€“261. 27. Ferreira, S., Alves, A., Quico, C.. Location based transmedia storytelling: The travelplot porto experience design. Journal of Tourism and Development [Revista Turismo & Desenvolvimento] 2012;17(18):4. 28. Broll, G., Cao, H., Ebben, P., Holleis, P., Jacobs, K., Koolwaaij, J., et al. Tripzoom: an app to improve your mobility behavior. In: Proceedings of the 11th International Conference on Mobile and Ubiquitous Multimedia. ACM; 2012, p. 57. 29. Martins, A.I., QueiroÂ´s, A., Cerqueira, M., Rocha, N., Teixeira, A.. The international classiï¬�cation of functioning, disability and health as a conceptual model for the evaluation of environmental factors. Procedia Computer Science 2012;14:293â€“300. URL: sciencedirect.com/science/article/pii/S1877050912007958. 30. Rawlinson, J.G.. Creative thinking and brainstorming. Gower Farnborough, Hants; 1981. 31. Compagna, D., Kohlbacher, F.. The limits PROCS 7138 S1877-0509(15)03120-8 10.1016/j.procs.2015.09.274 The Authors ☆ Peer-review under responsibility of organizing committee of the 6th International Conference on Software Development and Technologies for Enhancing Accessibility and Fighting Info-exclusion (DSAI 2015). Trip 4 All: A Gamified App to Provide a New Way to Elderly People to Travel Alberto Signoretti a ⁎ Ana I. Martins b c Nuno Almeida b c Diogo Vieira b c Ana Filipa Rosa b c Carlos M.M. Costa d António Texeira b c a Department of Informatics of Natal (DI/CAN), State University of Rio Grande do Norte, Av. Ayrton Senna s/n, Natal, 59056-400, Brasil Department of Informatics of Natal (DI/CAN), State University of Rio Grande do Norte, Av. Ayrton Senna s/n, Natal, 59056-400 Brasil b Department of Electronics Telecommunications and Informatics (DETI), University of Aveiro, C. Santiago, Aveiro, 3810-193, Portugal Department of Electronics Telecommunications and Informatics (DETI), University of Aveiro, C. Santiago, Aveiro, 3810-193 Portugal c Institute of Electronics and Telematics Engineering of Aveiro (IEETA), University of Aveiro, C. Santiago, Aveiro, 3810-193, Portugal Institute of Electronics and Telematics Engineering of Aveiro (IEETA), University of Aveiro, C. Santiago, Aveiro, 3810-193 Portugal d Department of Economics, Management and Industrial Engineering (DEGEI), University of Aveiro, C. Santiago, Aveiro, 3810-193, Portugal Department of Economics, Management and Industrial Engineering (DEGEI), University of Aveiro, C. Santiago, Aveiro, 3810-193 Portugal ⁎ Corresponding author. Tel.: +351234370520; fax: +351234370545. Older adults have much to gain from bringing technology into their daily lives. The extent to which this is possible strongly depends on careful design and accessible, easy to use products, developed using an elderly centered methodology. The senior tourism is a market in expansion and the old travelers need new and innovative technologies to help and support their trips. These technologies should contribute to a fun and safe experience, while promoting feelings of pleasure and self realization. In this paper we follow this design approach and put it to the test in developing the “Trip 4 All”(T4A), an application that works as a gamified virtual assistant to the elderly during a walking tourist visit. The gamified interaction with the visited environment intend to improve motivation to accomplish the visit and make the content absorption more fun and easier. The T4A works on georeferenced maps where the users’ geoposition is a trigger to launch storytelling content and/or challenges based on the aspects of the visited site as such: geographical, art, religious, historic, cultural and human. The success in the challenges give the user prizes, new resources and abilities to try more complex challenges that brings more valuable prizes and so on. Furthermore, the proposed application intend to work as a companion that provides self confidence, support and social integration to elderly tourists. Keywords Active Aging Elderly-centred design Mobile application evaluation Iterative development method References [1] United Nations,, World Tourism Organization, . Recommendations on Tourism Statistics. Tech. Rep.; United Nations publication; 2013. [2] Alén, E., Doḿınguez, T., Losada, N. New opportunities for the tourism market: Senior tourism and accessible tourism. . . . (a cura di) Visions for Global . . . 2012;URL: [3] European Commission, . Tourism for Seniors. 2014. URL: [4] Goasduff, L., Pettey, C. Gartner says by 2015, more than 50 percent of organizations that manage innovation processes will gamify those processes. 2011. [5] United Nations, Department of Economic and Social Affairs, Population Division, . World Population Ageing 2013. ST/ESA/SER.A/348. 2013. [6] European Commission, . Europe, the best destination for seniors. Facilitating cooperation mechanisms to increase senior tourist's travels within Europe and from third countries in the low and medium seasons - Experts draft report. Tech. Rep.; Brussels; 2014. [7] Urhausen, J. Eurostat Report: Tourism in Europe ? Does Age Matter? Tech. Rep.; Eurostat; 2009. [8] Eusébio, M., Carneiro, M., Kastenholz, E., Alvelos, H. Potential Benefits of the Development of an European Programme of Social Tourism for Seniors. Tech. Rep.; Department of Economy, Management and Industrial Engineering Aveiro University; 2012. URL: http: [9] Cavaco, C. Turismo sénior: perfis e práticas 2009;URL: [10] Anderson, J.Q., Rainie, H. Gamification: Experts Expect’Game Layers’ to Expand In the Future, With Positive and Negative Results. Pew Internet & American Life Project; 2012. [11] Ysmar Vianna Mauricio Vianna, B.M.S.T. Gamification, Inc.: como reinventar empresas a partir de jogos; vol. 1. mjv Press; 1 ed.; 2013. Isbn 978-85-65424-08-0. [12] Ed Boswell Diane Youden, e.a. The power of the net generation. Tech. Rep.; PricewaterhouseCoopers LLP; 2012. URL: [13] Huizinga, J.H. Homo Ludens- Study of the Play Element in Culture (International Library of Society. Routledge; 1980. ISBN: 0-7100-0578-4. [14] Caillois, R., Palha, J. Os jogos e os homens: a ma'scara e a vertigem. Cotovia; 1990. ISBN 9789729013287. URL: google.pt/books?id=NVajOgAACAAJ. [15] Maslow, A.H. A theory of human motivation. Start Publishing LLC; 2013. [16] Suits, B., Hurka, T. The Grasshopper: Games, Life and Utopia. Broadview encore editions. Broadview Press; 2005. ISBN 9781551117720. URL: [17] Csikszentmihalyi, M., Csikzentmihaly, M. Flow: The psychology of optimal experience; vol. 41. HarperPerennial New York; 1991. [18] Seligman, M.E., Csikszentmihalyi, M. Positive psychology: An introduction.; vol. 55. American Psychological Association; 2000. [19] McGonigal, J. Reality is broken: Why games make us better and how they can change the world. Penguin; 2011. [20] Fogg, B. A behavior model for persuasive design. In: Proceedings of the 4th international Conference on Persuasive Technology. ACM; 2009, p. 40. [21] J.C. Castella T.N. Trung S. Boissau Participatory simulation of land-use changes in the northern mountains of vietnam: the combined use of an agent-based model, a role-playing game, and a geographic information system Ecology and Society 10 1 2005 27 [22] Xavier-Junior, J.C., Signoretti, A., Canuto, A.M., Campos, A.M., Gonc¸alves, L.M., Fialho, S.V. Introducing affective agents in recommendation systems based on relational data clustering. In: Database and Expert Systems Applications. Springer; 2011, p. 303-310. [23] Signoretti, A., Feitosa, A., Campos, A.M., Canuto, A.M., Xavier, J., Fialho, S.V. Using an affective attention focus for improving the reasoning process and behavior of intelligent agents. In: Web Intelligence and Intelligent Agent Technology (WI-IAT), 2011 IEEE/WIC/ACM International Conference on; vol. 2. IEEE; 2011, p. 97-100. [24] Signoretti, A. Agentes Inteligentes com Foco de Atenc¸ão Afetivo em Simulac¸ões Baseadas em Agentes. Ph.D. thesis; UNIVERSIDADE FEDERAL DO RIO GRANDE DO NORTE; 2012. [25] A. Teixeira A. Hämäläinen J. Avelar N. Almeida Németh, G., Fegyó, T., et al. Speech-centric multimodal interaction for easy-to- access online services–a personal life assistant for the elderly Procedia Computer Science 27 2014 389 397 [26] R. Ballagas A. Kuntze S.P. Walz Gaming tourism: Lessons from evaluating rexplorer, a pervasive game for tourists In: Pervasive computing. Springer; 2008 244 261 [27] S. Ferreira A. Alves C. Quico Location based transmedia storytelling: The travelplot porto experience design Journal of Tourism and Development [Revista Turismo & Desenvolvimento] 17 18 2012 4 [28] Broll, G., Cao, H., Ebben, P., Holleis, P., Jacobs, K., Koolwaaij, J., et al. Tripzoom: an app to improve your mobility behavior. In: Proceedings of the 11th International Conference on Mobile and Ubiquitous Multimedia. ACM; 2012, p. 57. [29] Martins, A.I., Queirós, A., Cerqueira, M., Rocha, N., Teixeira, A. The international classification of functioning, disability and health as a conceptual model for the evaluation of environmental factors. Procedia Computer Science 2012;14:293-300. URL: sciencedirect.com/science/article/pii/S1877050912007958. [30] Rawlinson, J.G. Creative thinking and brainstorming. Gower Farnborough, Hants; 1981. [31] Compagna, D., Kohlbacher, F. The limits of participatory technology development: The case of service robots in care facilities for older people. Technological Forecasting and Social Change 2014;(0):–. [32] Dahl, D.A. The W3C multimodal architecture and interfaces standard. Journal on Multimodal User Interfaces 2013;7(3):171-182. doi:10. 1007/s12193-013-0120-5. [33] Almeida, N., Silva, S., Teixeira, J.S.A. Design and development of speech interaction: A methodology. In: Human-Computer Interaction. Advanced Interaction Modalities and Techniques Lecture Notes in Computer Science Volume 8511. Springer; 2014, p. 370-381. [34] J. Casimiro A. Teixeira J.S. Pinto Natural language generation in the context of multimodal interaction in Portuguese Electrónica e Telecomunicac¸ões 5 4 2012 400 409 [35] Casimiro, J., Pinto, J.S., Teixeira, A. Natural language generation in the context of multimodal interaction in Portuguese. In: 8th Iberian Conference on Informaton Systems and Technologies (CISTI). 2013,. [36] W. Ahmad A.B. Shafie M. Latif Role-playing game-based learning in mathematics The Electronic Journal of Mathematics and Technology 4 2 2010 185 196 [37] Medeiros, M.d.O., Schimiguel, J. Uma abordagem para avaliac¸ao de jogos educativos: enfase no ensino fundamental. In: Anais do Simpósio Brasileiro de Informática na Educac¸ão; vol. 23. 2012,. [38] KLIMICK, C. Rpg & educac¸ão: metodologia para o uso paradidático dos role playing games. Design Método Rio de Janeiro: Ed PUC-Rio; Teresópolis: Novas Idéias 2006; [39] MARCATTO, A. Saindo do quadro: Uma metodologia educacional lúdica e participativa baseada no role playing game. São Paulo: A Marcatto 1996;. "
    },
    {
        "doc_title": "Evaluation of complex distributed multimodal applications: Evaluating a TeleRehabilitation system when it really matters",
        "doc_scopus_id": "84949789710",
        "doc_doi": "10.1007/978-3-319-20913-5_14",
        "doc_eid": "2-s2.0-84949789710",
        "doc_date": "2015-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Ambient assisted living (AAL)",
            "Dynamic environments",
            "Evaluation",
            "Evaluation methodologies",
            "Hardware and software",
            "Multi-modality",
            "Multimodal application",
            "Telerehabilitation"
        ],
        "doc_abstract": "© Springer International Publishing Switzerland 2015.The evaluation of applications or systems within dynamic environments is complex. The existence of multiple hardware and software items which share the same space can provoke concurrency issues and result in erratic interactions. A sudden change within the environment can result is dramatic changes both to the user and application itself which can pass unnoticed in traditional evaluation methodologies. To verify if a component is compatible with a given environment is of paramount importance for areas like pervasive computing, ambient intelligence or ambient assisted living (AAL). In this paper, a semi-automatic platform for evaluation is presented and integrated with a TeleRehabilitation system in an AAL scenario to enhance evaluation. Preliminary results show the advantages of the platform in comparison with typical observation solutions mainly in terms of achieved data and overall ease of use.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Design and development of multimodal applications: A vision on key issues and methods",
        "doc_scopus_id": "84947276451",
        "doc_doi": "10.1007/978-3-319-20678-3_11",
        "doc_eid": "2-s2.0-84947276451",
        "doc_date": "2015-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Application scenario",
            "Constant improvement",
            "Design and Development",
            "Evaluation",
            "Evaluation methodologies",
            "Multi-Modal Interactions",
            "Multimodal application",
            "Multimodal user interface"
        ],
        "doc_abstract": "© Springer International Publishing Switzerland 2015.Multimodal user interfaces provide users with different ways of interacting with applications. This has advantages both in providing interaction solutions with additional robustness in environments where a single modality might result in ambiguous input or output (e.g., speech in noisy environments), and for users with some kind of limitation (e.g., hearing difficulties resulting from ageing) by yielding alternative andmore natural ways of interacting. The design and development of applications supporting multimodal interaction involves numerous challenges, particularly if the goals include the development of multimodal applications for a wide variety of scenarios, designing complex interaction and, at the same time, proposing and evolving interaction modalities. These require the choice of an architecture, development and evaluation methodologies and the adoption of principles that foster constant improvements at the interaction modalities level without disrupting existing applications. Based on previous and ongoing work, by our team, we present our approach to the design, development and evaluation of multimodal applications covering several devices and application scenarios.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Giving Voices to Multimodal Applications",
        "doc_scopus_id": "84944244352",
        "doc_doi": "10.1007/978-3-319-20916-6_26",
        "doc_eid": "2-s2.0-84944244352",
        "doc_date": "2015-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Age effects",
            "Intrinsic property",
            "Multi-Modal Interactions",
            "Multimodal application",
            "Speech interaction",
            "Speech output",
            "Synthetic voices",
            "User satisfaction"
        ],
        "doc_abstract": "© Springer International Publishing Switzerland 2015.The use of speech interaction is important and useful in a wide range of applications. It is a natural way of interaction and it is easy to use by people in general. The development of speech enabled applications is a big challenge that increases if several languages are required, a common scenario, for example, in Europe. Tackling this challenge requires the proposal of methods and tools that foster easier deployment of speech features, harnessing developers with versatile means to include speech interaction in their applications. Besides, only a reduced variety of voices are available (sometimes only one per language) which raises problems regarding the fulfillment of user preferences and hinders a deeper exploration regarding voices’ adequacy to specific applications and users. In this article, we present some of our contributions to these different issues: (a) our generic modality that encapsulates the technical details of using speech synthesis; (b) the process followed to create four new voices, including two young adult and two elderly voices; and (c) some initial results exploring user preferences regarding the created voices. The preliminary studies carried out targeted groups including both young and older-adults and addressed: (a) evaluation of the intrinsic properties of each voice; (b) observation of users while using speech enabled interfaces and elicitation of qualitative impressions regarding the chosen voice and the impact of speech interaction on user satisfaction; and (c) ranking of voices according to preference. The collected results, albeit preliminary, yield some evidence of the positive impact speech interaction has on users, at different levels. Additionally, results show interesting differences among the voice preferences expressed by both age groups and genders.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Design and development of speech interaction: A methodology",
        "doc_scopus_id": "84903128327",
        "doc_doi": "10.1007/978-3-319-07230-2_36",
        "doc_eid": "2-s2.0-84903128327",
        "doc_date": "2014-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Computer interaction",
            "decoupled modalities",
            "Design and Development",
            "Multimodal architectures",
            "Multimodal frameworks",
            "Speech interaction",
            "Speech modality",
            "Speech recognizer"
        ],
        "doc_abstract": "Using speech in computer interaction is advantageous in many situation and more natural for the user. However, development of speech enabled applications presents, in general, a big challenge when designing the application, regarding the implementation of speech modalities and what the speech recognizer will understand. In this paper we present the context of our work, describe the major challenges involved in using speech modalities, summarize our approach to speech interaction design and share experiences regarding our applications, their architecture and gathered insights. In our approach we use a multimodal framework, responsible for the communication between modalities, and a generic speech modality allowing developers to quickly implement new speech enabled applications. As part of our methodology, in order to inform development, we consider two different applications, one targeting smartphones and the other tablets or home computers. These adopt a multimodal architecture and provide different scenarios for testing the proposed speech modality. © 2014 Springer International Publishing.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Elderly centered design for interaction - The case of the S4S Medication Assistant",
        "doc_scopus_id": "84897816217",
        "doc_doi": "10.1016/j.procs.2014.02.044",
        "doc_eid": "2-s2.0-84897816217",
        "doc_date": "2014-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Development method",
            "Elderly evaluation",
            "Interaction",
            "Medication",
            "Mobile applications",
            "User-centred"
        ],
        "doc_abstract": "Several aspects of older adults' life can benefit from recent technological developments, but success in harnessing this potential depends on careful design and accessible, easy to use products. Design and development must be centered on the elderly and adequately consider interaction. In this paper we follow this design approach and put it to the test in developing a concrete application, aimed to contribute to lower the high levels of non-adherence to medication in the elderly population. The \"Medication Assistant\" application was developed following an iterative method centered, from the start, on the elderly and interaction design. The method repeats short-time development cycles integrating definition of scenarios and goals, requirements engineering, design, prototyping and evaluation. Evaluation, by end-users, of the increasingly refined prototypes, is a key characteristic of the method. The evaluation results provide information related to strengths and weaknesses of the application and yield suggestions regarding changes and improvements, valuable support further development. Results regarding evaluation of the second prototype of \"Medication Assistant\" are presented. © 2013 The Authors. Published by Elsevier B.V.",
        "available": true,
        "clean_text": "serial JL 280203 291210 291871 31 90 Procedia Computer Science PROCEDIACOMPUTERSCIENCE 2014-02-25 2014-02-25 2014-10-23T08:54:46 S1877-0509(14)00046-5 S1877050914000465 10.1016/j.procs.2014.02.044 S300 S300.2 HEAD-AND-TAIL 2021-10-14T13:20:00.670388Z 0 0 20140101 20141231 2014 2014-02-25T00:00:00Z rawtext articleinfo articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids confeditor contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid hubeid indexeddate issn issnnorm itemstage itemtransactionid itemweight oauserlicense openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sortorder srctitle srctitlenorm srctype ssids alllist content oa subj suppl tomb vol volfirst volissue volumelist yearnav affil articletitle auth authfirstini authfull authkeywords authlast primabst ref 1877-0509 18770509 false 27 27 C Volume 27 45 398 408 398 408 2014 2014 2014-01-01 2014-12-31 2014 5th International Conference on Software Development and Technologies for Enhancing Accessibility and Fighting Info-exclusion, DSAI 2013 Dr. Manuel Pérez Cota Dr. João Barroso Dr. Simone Bacellar Leal Ferreira Dr. Benjamim Fonseca Dr. Tassos Mikropoulos Dr. Hugo Paredes article fla Copyright © 2013 The Authors. Published by Elsevier B.V. ELDERLYCENTEREDDESIGNFORINTERACTIONCASES4SMEDICATIONASSISTANT FERREIRA F FERREIRAX2014X398 FERREIRAX2014X398X408 FERREIRAX2014X398XF FERREIRAX2014X398X408XF Full 2014-02-25T10:44:25Z OA-Window ElsevierWaived 0 item S1877-0509(14)00046-5 S1877050914000465 10.1016/j.procs.2014.02.044 280203 2014-10-23T04:53:38.277668-04:00 2014-01-01 2014-12-31 true 770861 MAIN 11 52416 849 656 IMAGE-WEB-PDF 1 P r o c e d i a C o m p u t e r S c i e n c e 2 7 ( 2 0 1 4 ) 3 9 8 4 0 8 1877-0509 ' 2013 The Authors. Published by Elsevier B.V. Open access under CC BY-NC-ND license. Selection and peer-review under responsibility of the Scientific Programme Committee of the 5th International Conference on Software Development and Technologies for Enhancing Accessibility and Fighting Info-exclusion (DSAI 2013). doi: 10.1016/j.procs.2014.02.044 ScienceDirect Available online at www.sciencedirect.com 5th International Conference on Software Development and Technologies for Enhancing Accessibility and Fighting Info-exclusion, DSAI 2013 Elderly centered design for Interaction â€“ the case of the S4S Medication Assistant FlÃ¡vio Ferreira a , Nuno Almeida a,b , Ana Filipa Rosa a , AndrÃ© Oliveira a , JosÃ© Casimiro c , Samuel Silva a,b , AntÃ³nio Teixeira a,b, * a Institute of Electronics and Telematics Engineering of Aveiro (IEETA), 3810-193 Aveiro, Portugal b Dep. of Electronics Telecommunications and Informatics, University of Aveiro, 3810-193 Aveiro, Portugal c Polytecnic Institute of Tomar, 2300-531 Tomar, Portugal Abstract Several aspects of older adultsâ€™ life can benefit from recent technological developments, but success in harnessing this potential depends on careful design and accessible, easy to use products. Design and development must be centered on the elderly and adequately consider interaction. In this paper we follow this design approach and put it to the test in developing a concrete application, aimed to contribute to lower the high levels of non-adherence to medication in the elderly population. The â€œMedication Assistantâ€� application was developed following an iterative method centered, from the start, on the elderly and interaction design. The method repeats short-time development cycles integrating definition of scenarios and goals, requirements engineering, design, prototyping and evaluation. Evaluation, by end-users, of the increasingly refined prototypes, is a key characteristic of the method. The evaluation results provide information related to strengths and weaknesses of the application and yield suggestions regarding changes and improvements, valuable support further development. Results regarding evaluation of the second prototype of â€œMedication Assistantâ€� are presented. Â© 2013 The Authors. Published by Elsevier B.V. Selection and/or peer-review under responsibility of Scientific Programme Committee of the 5th International Conference on Software Development and Technologies for Enhancing Accessibility and Fighting Info-exclusion (DSAI 2013) * Corresponding author. Tel.: +351 234370500; fax: +351 234370545. E-mail address: ajst@ua.pt. ' 2013 The Authors. Published by Elsevier B.V. Open access under CC BY-NC-ND license. Selection and peer-review under responsibility of the Scientific Programme Com ittee of the 5th International Conference on Soft are Development and Technologies for Enhancing Accessibility and Fighting Info-exclusion (DSAI 2013). 399 FlÃ†vio Ferreira et al. / Procedia Computer Science 27 ( 2014 ) 398 408 \"Keywords: development method; interaction; user centred; elderly evaluation; mobile applications; medication\" 1. Introduction The impact of using advanced technologies has been very positive for the general population. Due to the continuous increase in the elderly population worldwide [1], development starts to contemplate this group, taking into account the significant contribution that new technologies may provide to improve the quality of life of these population. This meets the guidelines of the EU countries for the elderly population, which highlight active aging and independent living, by the development of services based on the specific needs of the population, helping them to live in community [2]. Developers know the importance of involving the target users in the design process [3] and this is even more important when the target users are elderly [4]. Throughout the design process of products suitable for and usable by elderly it must be taken into account their unique needs, limitations and capabilities [5]. To accomplish this, it is essential to know and use effective approaches for interaction and gather data on how they are used. This data will give information about the features and attributes that elderly prefer, and consequently allow an understanding of which factors can improve the usability of the product [6]. The design process in this perspective arises in the literature as User Centered Design (UCD), but the traditional user centered design provides little guidance on how to involve the elderly [3]. UCD is a collection of methods that aim to involve the users in an appropriate way during development. The basic principle of this approach is placing users in the focus of the design process through the use of various techniques, first to collect information from them and then to initiate the design of prototypes which they will be asked to test [7]. â€œNeeds assessment and requirements analysis are the most important activities for initiating system improvement because, done well, they are the foundation upon which all other activities build\" [5]. With the continuous progress and sophistication of the prototypes, the user should be asked to perform tasks with minimum guidance by the testers. The results of this tests, according to the iterative process inherited from UCD, are analyzed and will guide the design of subsequent prototypes [7]. Product development based in UCD should adhere to the following principles [8, 9]: knowledge gathering concerning usersâ€™ needs, capabilities, attitudes and characteristics; active involvement of users; prototypes redesign, as often as necessary; iterations of design solutions (repetition of a cyclic process of design, evaluation and redesign as often as necessary); multidisciplinary design teams. According to the international standard ISO 13407 this process should be developed through four stages in the following order: specify the context of use, define the requirements, design and evaluation [8]. One of the important contributions to guide the process of product development according to the principles of UCD, particularly at an early stage of requirement definition, is the creation of Personas [10]. Personas are fictional persons, with name, occupations, age, gender, socioeconomic status, hobbies, stories and goals and are used to personify the principal characteristics and functions for the product design [11, 12]. There are various data-driven Personas for elderly based on European statistics, which should be followed by teams that intend to develop products to the elderly [13]. Personas are an important and valuable tool, mainly if the objective of the team is to test and evaluate the usability and effectiveness of a product. The Personas â€œallow us to see the scope and nature of the design problem. They make it clear exactly what the user's goals are, so we can see what the product must do\" [13]. Despite the general applicability of the UCD development method, it must be tuned and adapted when developing applications for older adults. With the increased use of new interaction modalities (e.g. touch), multimodal interaction requirements, design, development and evaluation must also be part of the development process. 400 FlÃ†vio Ferreira et al. / Procedia Computer Science 27 ( 2014 ) 398 408 Considering the elderly population, one important issue affecting their daily life and health, concerns medication non-adherence [14]. This is often due to the increasing number of medicines to take, to age related changes (such as memory loss, or different levels of physical and cognitive impairment), to lack of information on its usefulness and transient side-effects and to demotivation. The impact of medication non-adherence on the quality of life and associated costs dealing, for example, with reduced or unwanted therapeutic effects (e.g. antibiotic resistance and longer treatment timespans) [15], configure this as a very important problem to tackle in which mobile devices and adequate interaction design can play an important role. This, we argue, is a context were the UCD development method can prove its mettle. In this paper, we present an UCD development method centered on the elderly and interaction, aimed at increased usability and accessibility [9], and its application to the development of a concrete system, the â€œMedication Assistantâ€�, that allows voice and touch interaction to facilitate the access by elderly. The main features of this system are the alerts of medication to intake, the visualization of information of each medication and the advice service that allows users to obtain information about what to do in case of forgetting to take a medication. The prototype of this application has been already evaluated in two tests, with two different groups of users, in order to detect problems and collect opinions and suggestions to further meet the needs and specificities of the users. This paper starts by providing an overview of the proposed development method. After, a description of the primary Persona, context scenarios and application requirements for the â€œMedication Assistantâ€� are presented. It is also discussed how the application meets the requirements, followed by the evaluation method, main results and the conclusions. 2. Elderly Centered Development Method The proposed development method is aligned with the methodology described in [16]. After obtaining the requirements (phase 1), a prototype is proposed (phase 2) and evaluated (phase 3), in order to refine the requirements. This iterative methodology continues with additional prototypes and evaluations towards an increasingly refined application. In order to get system Personas, the context scenarios and the system requirements for phase 1 we adopted a five stages method aligned with Cooper and collaborators [17]. The first stage aims at identifying the behavioral variables, such as age and demographic localization, activities, attitudes, aptitudes, motivations and skills and significant behavior patterns, by analyzing the interview results. Following these guides, it is possible to synthetize the characteristics and relevant goals for the Persona. After, the description of the Persona is expanded in order to have a small story about the Persona and its daily life. Finally, Persona types are designated. At the beginning only the primary Persona should be created. On the second stage, to get the requirements and context scenarios a problem and vision statement must me produced. The third stage consists in brainstorming with people from different domains and end-users. The brainstorming should last a couple of hours and comprise a few questions in order to stimulate the ideas flow. After the brainstorming the main ideas should be filtered. On the fourth stage Persona expectations are set by the same people who brainstormed earlier. This is very important in order to understand the main end-user and its expectations. At the end of this stage, context scenarios are defined, typically as a group of short stories. They should be simple and represent use of the application by end-users. Finally, the requirements analysis should be made. To create the requirements it is important to be aware of the information gathered in the previous stages. It is important to note that the Persona and the scenarios should always be present during the development process (phase 2) and not only in requirements elicitation. 401 FlÃ†vio Ferreira et al. / Procedia Computer Science 27 ( 2014 ) 398 408 Towards the development of an application designed taking into account the accessibility and usability features of end users, the application is evaluated along all the development process (several iterations of phase 3). The evaluation method adopted is based on a methodology recently proposed [16]. This methodology is adapted to the characteristics of the application and its end users. The evaluation consists of three phases: conceptual validation, prototype test and pilot test. These three phases are connected, in a cyclic process, as the results of the several evaluations will influence the development process of the application. The first phase of evaluation aims at collecting information to verify the viability of the application interface and functions. The second phase comprises a test performed by the users through interaction with the application prototype, with the presence of an evaluator to register opinions and suggestions of the user. The pilot test is similar to the prototype test, but it adds the assessment of the impact the application has on the lives of its end users. 3. Application to a Medication Assistant for the Elderly In this section, after the generic presentation of the method in the previous section, we show how it can be applied in a real scenario using, as an example, the development of a new multimodal application for Smartphones, named â€œMedication Assistantâ€�. The main purpose of this application is to make elders become healthier, addressing the problem of medication non-adherence due to age related factors such as the inherent medication increase, cognitive losses and demotivation. It helps them with medication management, providing multimodality and context awareness, fully advising and supporting with the medication. 3.1. Personas, Context Scenarios and Requirements As already explained, Personas and Scenarios have a key role in supporting requirement analysis. Information on the Persona and scenarios developed for â€œMedication Assistantâ€� are presented below. 3.1.1. Persona Our Persona should live in Portugal, does not need to have the aptitude to use electronic devices, must be an elder person with health problems (although it is not necessary to have regular doctor appointments), and should have the desire to control its own medication. Furthermore, the Persona does not need to have a family, but commonly speaks with friends and family through a computer or mobile device. In the first phase we are developing our application in order to respond to the requirements of the Primary Persona. The Primary Persona is the Persona at which the application should address all the requirements. We identified the following expectations: the Persona wants to be able to use the same application with arthritis; the application should help prevent gaps in medication, report medication, report side effects, and provide alerts. Furthermore, the Persona wants to use the application even with little aptitude for working with electronic devices. Thereafter, we created the context scenarios, after which we identified the requirements. Primary Persona, Mrs. EmÃ­lia, lives in Coimbra with her husband Filipe Rodrigues. Sheâ€™s a housewife and does not have experience with electronic devices. She is right handed. She is diabetic and has arthritis in her right superior member. Her health condition requires a regular and daily medication. Mrs. EmÃ­lia has the habit to call her daughter during dinner preparation. However, she has some difficulty in doing the two activities simultaneously due to her limitation in the right superior member. She has weekly appointments in her local health center for surveillance. Mrs. EmÃ­lia would like to buy equipment that facilitates the contact with her daughter and allows her to control her medication, which she often forgets to take. 402 FlÃ†vio Ferreira et al. / Procedia Computer Science 27 ( 2014 ) 398 408 3.1.2. An example of a context scenario Our context scenarios intend to describe several scenarios of application usage. These scenarios outline different ways to interact with the application, as well as its features. Each scenario is represented by a short story. Two scenario examples are presented below. Mrs. EmÃ­lia waked up to prepare breakfast. The application showed an alert (with the medication names and dosage) warning that Mrs. EmÃ­lia needed to take her medication in the fasted state. Mrs. EmÃ­lia, warned that she had to take the medication, took it immediately and then prepared breakfast. After a while, the application asked Mrs. EmÃ­lia if she had already taken the medication. The application interacted through speech, since Mrs. EmÃ­lia hands were busy. She answered â€œYes, I took my medicationâ€�. A few hours later Mrs. EmÃ­lia starts to feel unwell. She felt concern and, through speech, she asked the application if that condition was normal. In order to answer that, the application explained that she took a medication that could induce a feeling of being unwell, also giving information about what is the reason to take the medication and what are the side effects of it. Thereafter, Mrs. EmÃ­lia felt relieved and returned to her tasks. Table 1 - Context Scenario Mrs. EmÃ­lia Action Action on smartphone application Output from smartphone application to user Wakes up and prepares breakfast. Prepares an alert to show The application triggers an alert: â€œYou need to take medication in the fasted stateâ€� Takes the smartphone and read the alert. The user opens the alert [IM=Touch]. Opens the alert. Shows the list of medications to take [IM=Text and Images] Takes the medication and lock de mobile. Closes application and lock. Locks Screen Eats the breakfast. Needs to know if the medication was taken. Prepares a speech message. Shows a message: â€œDid you take the medication in fasted state?â€� [IM=Text and Speech] Answers â€œYes, I took my medicationâ€� [IM=Speech] Recognizes the answer. Notes the take of the medication. Locks. Locks Screen. A few hours later, starts to feel unwell. The user unlocks the mobile and asks â€œIâ€™m felling unwell, is it normal?â€� [IM=Speech] Recognizes the sentence. Find if any medication taken has side effects and prepares the response. Shows a message: â€œYes, the MEDX could induce a feeling of being unwell. It can induce nauseas too. But you should take it for arthritis.â€� [IM=Text and Speech] Feels relieved. 3.2. Main requirements The requirements were divided in two main groups: the functional requirements and the user requirements. The main functional requirements are: (1) the application should provide medication insertion and management by third parties, so that seniors do not need to perform this task since it can be complicated; (2) the application should provide medication alerts to remember users about medication schedules; (3) the application should provide medication advice to help elders in daily medication questions. It must be able to respond to commands given in Portuguese expressing questions such as â€œWhat should I do if I forget to take 403 FlÃ†vio Ferreira et al. / Procedia Computer Science 27 ( 2014 ) 398 408 my medication?â€�, â€œPlan the day because Iâ€™m leavingâ€� or â€œIâ€™m with headaches. Is it a side effect?â€�; (4) the application should provide configurable interaction; (5) the application should provide multimodal interaction; (6) the application should allow registry of medication taken. The main user requirements are: (1) the application should inform users in an everyday language since technical language could be misunderstood; (2) the application should provide touch and speech interaction for everything in order to facilitate user interaction since some users may have physical or cognitive limitations; (3) the application should be reliable and credible because the user must trust its advices and alerts; (4) as elders usually have low proficiency with technology and vision problems it is crucial that the application avoids overloading content and small icons; (5) the application should have extra care with language and dimension; (6) the application should adapt to the user and the context; (7) the application should provide personalization; (8) the application should avoid information overload; (9) the application should be able to provide more information when the user wants it; (10) the application should provide help to the elder when they present difficulties interacting with the application; (11) the application should provide a group of â€œhow to use guidesâ€�. 3.3. Prototype 2 â€“ Meeting the requirements After completing one development cycle, which resulted in a first prototype, the data gathered during its evaluation was used to feed the following development cycle. Furthermore, beyond the consideration of user feedback, existing features have been expanded and new features added, resulting in a second application prototype. In order to enable the insertion of medication and its management by third parties, we created an external service. The smartphone uses the service to get all the information related to the medication. When the application is open for the first time it will ask for a login that will be used to get the elderly medication plan. In the second prototype the insertion was made by a formal or informal caregiver, i.e., the elderly didnâ€™t need to perform this task. This has the advantage of preventing the elderly from getting bored and demotivated to use the application, since this task can be tiresome and time consuming. However, this feature needs to be improved in order to simplify the insertion process. The application provides medication alerts using both Windows Phone push notification and local notification. If the application is connected to the Internet, the user can receive push notifications. However, when the application opens, it creates local notifications for the next four alerts and informs the push notification service that it only needs to work for the fifth alert. This process is executed whenever the application opens. Therefore, the push notification service is only required when the elderly do not open the application for the next four straight alerts. This way it is very likely that the application will inform the user in the need of taking the medication in a timely fashion, even without constant access to the Internet, creating a high level of credibility and reliability, very important for older adults. Furthermore, the application allows the elderly to see the next alerts list. 404 FlÃ†vio Ferreira et al. / Procedia Computer Science 27 ( 2014 ) 398 408 When the elderly forget to take medication, or want to know what its side effects are, they can refer to the application. All the medication should have information about what to do if the user forgets to take it, what are the side effects, and why the elderly needs to take it. In this way, the application can give that information to the elderly when needed. In the prototype, it is possible to know the reason of taking that medication, what are the side effects, the expiration date of the medication, and what to do if a medication intake was forgotten. We will add additional information to the medication in order to allow the elderly to get more advice about it. This information is based on the medicines leaflets, increasing the credibility and reliability of the information given. The application provides a set of options so the elderly can change the application settings. The user can allow noise control features, change the font size, change between dark and light mode and activate the help mode. Regarding the noise control feature, for example, if it is activated the application will automatically detect the user context noise and adapt its volume. The user can also change interaction features such as how speech commands are input (touch-to-speak or use of speech by voice activation) and activate the auto-zoom. The touch-to-speak feature will allow elderly to touch a button and speak to the application. The application can also be configured to automatically detect speech inputs without any type of touch interaction. However, this alternative is not so precise and has not yet been carefully evaluated. The auto-zoom feature adapts the size of text and images to the user distance to the smartphone. If this feature is activated, the size of the items on the screen will automatically increase when the user moves away or closer to the smartphone depending on the user context: if the user has nearsightedness, when approaching the screen the size of the images/text will increase; if the elderly has astigmatism, when moving farther from the screen the size of the images/text will increase too. Furthermore, when the elderly needs to know more information about a specific medication, the application will adapt to the needs. Thereby, the application provides personalization, configurable interaction, extra information and user/context adaptation. The elderly can use touch or speech as input in order to interact with the application. The speech can be used to get advice (e.g. â€œI forgot to take the lunch medicationâ€�) or to get extra information (e.g. â€œWhat are the side effects of this medication?â€�). The advantage of speech is that it normally provides a faster and more intuitive way to get response from the system than touch. As output we use text, speech and images. Thus, in the second prototype we already used multiple modalities both for input and output, making it really multimodal [18]. As the elders usually have low proficiency with technology and vision problems, we created a User Interface based in big text and big items/images. The UI follows the Metro Style guidelines, avoiding extra bars, icons, buttons, etc. [19]. The application has a simple and clear layout that gives the user the opportunity to get more information when required (through speech) to avoid information overload in the views. Furthermore, the auto- zoom feature will be aware of the user difficulties and adapts the UI to it. On the other hand, the application tries to give information in a common and informal language avoiding the technical one. However, this is a requirement that needs more improvement since it is hard to replace the medication names and side effects by informal and common names. Lastly, the application provides auto adaptable help. When the elderly are inexperienced, the application offers many suggestions, but when they learn to interact with the application it will stop providing them. However, if an expert user starts to show some difficulty (e.g. increasing time to perform tasks) using one of the features, the application adapts and starts offering suggestions again. In addition, the application provides a Fig. 1 - Medication Assistant example views: (a) application starting; (b) main menu; (c) advice menu; (d) next alerts; (e) about the medication. 405 FlÃ†vio Ferreira et al. / Procedia Computer Science 27 ( 2014 ) 398 408 group of â€œhow to use guidesâ€� composed by some example phrases about how to interact with it through speech. In the future, we will add video guides in order to help inexperienced users. 3.4. Evaluation 3.4.1. Methodology As mentioned, the evaluation method adopted for â€œMedication Assistantâ€� is based on a methodology proposed recently in [16]. A first evaluation of the prototype was conducted with a heterogeneous group of engineers and health professionals, with the intent of gathering an extended number of opinions and suggestions to validate the general design options and guide the following development. In the first prototype test the user was accompanied by an evaluator, member of the project, to explain the test and respond to user doubts. During this test the think aloud method was used and the audio was recorded. The group was composed by three women and one man with age ranges between 25 and 60 years. The results of this first evaluation of prototype was presented in [20] and used to support the development of a second prototype, for which evaluation results are presented in this paper. The second evaluation was made with a group of end users and followed a previously defined structured plan of evaluation with a set of tasks. The evaluation consisted of two phases: the interaction assessment phase and the usability evaluation phase. In both phases the user is accompanied by an evaluator to explain the evaluation method. The interaction phase is composed by a set of tasks requiring the user to interact with the application: for instance â€œSee the list of medications to be taken at breakfastâ€� and â€œInform the application that you missed the last medicationâ€�. In this phase the think aloud method is used and the evaluator takes notes regarding users behavior and their main difficulties, comments, doubts, suggestions and problems during the completion of the tasks. In the second phase, pertaining usability, the evaluator applies a questionnaire about the user interaction experience with the application. In this stage the user answers some questions about the application, such as â€œIn your opinion what are the strengths and weaknesses of the application?â€� and â€œWhat would you change in the application?â€�. The user should give an opinion about some aspects of the application such as the layout, font size and color, the features and the interaction. The second evaluation of the prototype was with a group of three women and one man, with ages between 57 and 76 years. Accordingly to [21], the sample size is appropriate to a qualitative evaluation, considered adequate for a second prototype evaluation. 3.4.2. Results In this section we present the results of the evaluation. Regarding usability evaluation, through the analysis of the opinion questionnaires, the results that stand out are the strengths and weaknesses of the application and the suggestions of changes to be made. Fig. 2 shows the strengths and weaknesses of the â€œMedication Assistantâ€�. In the tag clouds the words with larger font size are the most referred by the users and the smaller ones are the least identified by the sample. Fig. 2 â€“ (left box) strengths of the application; (right box) weaknesses of the application 406 FlÃ†vio Ferreira et al. / Procedia Computer Science 27 ( 2014 ) 398 408 The changes suggested by the users are presented in the following table (In each type of alteration are presented the object and the action to be taken, accordingly to the user suggestions. The last column presents the priority of the alteration, according to the development team opinion. Regarding interaction evaluation, based on the data collected from observation and notes of the evaluators several features were identified that users considered more difficult or easier to use. The overall results presented in the two graphics depicted in Fig. 3, showing the number of users that considered each feature difficult or easy to use. ) and organized by types. In each type of alteration are presented the object and the action to be taken, accordingly to the user suggestions. The last column presents the priority of the alteration, according to the development team opinion. Regarding interaction evaluation, based on the data collected from observation and notes of the evaluators several features were identified that users considered more difficult or easier to use. The overall results presented in the two graphics depicted in Fig. 3, showing the number of users that considered each feature difficult or easy to use. Table 2 - Application improvements suggested by users on the evaluation questionnaire Type Object Action Comment New features Tutorial Add Priority Register Add Priority Interaction Speech input Improve Priority Design/Layout Panoramic view Improve Nonpriority Real menu Improve Nonpriority 4 3 4 2 1 Difficulties 3 4 2 4 Easy to use 407 FlÃ†vio Ferreira et al. / Procedia Computer Science 27 ( 2014 ) 398 408 4. Conclusions Since the beginning of the â€œMedication Assistantâ€� application development, one of the main focuses was the inclusion of end-users. User intervention is crucial since the initial phase, mostly with their participation in brainstorming sessions to generate ideas and support the definition of Persona and scenarios. During the continuous development process of the application users have an active role, by participating in the process of evaluation, thus enabling the application to be shaped accordingly to the usersâ€™ needs and capabilities, suffering a continuous process of redesign. In this paper all this process is explained and the results of the second prototype are presented. The data analysis was qualitative, taking into account the size of the evaluation sample. In the data analysis priority was given to the questionnaires, which provide information related to strengths and weaknesses of the application and give suggestions of changes proposed by users. By analyzing the strengths of the application we can say that the application is already useful, even being on a prototype development phase. Features like forgetfulness support, medication images and the expiration date were proposed in the brainstorming, and as we can see they seem to be of interest for the end-users. The Help menu feature is a result of the first prototype evaluation. It shows that our method can lead to the development of useful applications for end-users. The weaknesses can provide important information too. First, they provide basis for the next iteration and prototype. Second, they show that interaction is really important as we defend in our proposed method. Since we are in the second prototype, the interaction features are only in the initial phase of development, unlike other features of the application, being the reported weaknesses expected. With the intent tackle the needs identified in the evaluation of the second prototype, the future work should focus, mainly, in the development of a new prototype, considering particularly touch and speech interaction. Acknowledgements This work is part of the Smart Phones for Seniors (S4S) project, a QREN project (QREN 21541), co-funded by COMPETE and FEDER. References [1] DESA. (2013). Available: [2] H. Matlabi, S. Parker, and K. McKee, \"The contribution of home-based technology to older people's quality of life in extra care housing,\" BMC Geriatrics, vol. 11, p. 68, 2011. [3] A. Newell, J. Arnott, A. Carmichael, and M. Morgan, \"Methodologies for Involving Older Adults in the Design Process,\" in Universal Acess in Human Computer Interaction. Coping with Diversity. vol. 4554, C. Stephanidis, Ed., ed: Springer Berlin Heidelberg, 2007, pp. 982-989. [4] R. Eisma, A. Dickinson, J. Goodman, O. Mival, A. Syme, and L. Tiwari, \"Mutual inspiration in the development of new technology for older people,\" in In Proceedings of Include 2003, 2003, pp. 7--252. [5] E. Mynatt and W. Rogers, \"Developing technology to support the functional independence of older adults,\" Ageing International, vol. 27, pp. 24-41, 2001/12/01 2001. [6] R. Eisma, A. Dickinson, J. Goodman, A. Syme, L. Tiwari, and F. Newell, \"Early user involvement in the development of information technology-related products for older people,\" Univers. Access Inf. Soc., vol. 3, pp. 131-140, 2004. [7] S. Chamberlain, H. Sharp, and N. Maiden, \"Towards a framework for integrating agile development and user-centred design,\" presented at the Proceedings of the 7th international conference on Extreme Programming and Agile Processes in Software Engineering, Oulu, Finland, 2006. [8] J. Gulliksen, A. Lantz, and I. Boivie, User Centered Design in Practice - Problems and Possibilities, 1999. [9] R. D. Buurman, \"User-centred design of smart products,\" Ergonomics, vol. 40, pp. 1159-1169, 1997/10/01 1997. [10] J. Pruitt and J. Grudin, \"Personas: practice and theory,\" presented at the Proceedings of the 2003 conference on Designing for user experiences, San Francisco, California, 2003. [11] J. Grudin and J. Pruitt. (2002, Personas, Participatory Design and Product Development: An Infrastructure for Engagement. Fig. 3 â€“ Application features and corresponding number of users who considered them difficult (left) and easy (right). 408 FlÃ†vio Ferreira et al. / Procedia Computer Science 27 ( 2014 ) 398 408 [12] R. Sinha, \"Persona development for information-rich domains,\" presented at the CHI '03 Extended Abstracts on Human Factors in Computing Systems, Ft. Lauderdale, Florida, USA, 2003. [13] R. Casas, R. B. Maro, A. Robinet, A. R. Delgado, A. R. Yarza, J. Mcginn, R. Picking, and V. Grout, \"User Modelling in Ambient Intelligence for Elderly and Disabled People,\" presented at the Proceedings of the 11th international conference on Computers Helping People with Special Needs, linz, Austria, 2008. [14] C. M. Hughes, \"Medication non-adherence in the elderly: how big is the problem?,\" Drugs Aging, vol. 21, pp. 793-811, 2004. [15] M. BÃ¶hm, H. Schumacher, U. Laufs, P. Sleight, R. Schmieder, T. Unger, K. Teo, and S. Yusuf, \" Effects of nonpersistence with medication on outcomes in high-risk patients with cardiovascular disease,\" American Heart Journal, vol. 166, 2013. [16] A. I. Martins, A. QueirÃ³s, M. Cerqueira, N. P. da Rocha, and A. J. S. Teixeira, \"The International Classification of Functioning, Disability and Health as a Conceptual Model for the Evaluation of Environmental Factors.,\" Procedia CS, vol. 14, pp. 293-300, 2012. [17] A. Cooper, R. Reimann, and D. Cronin, About Face 3: The Essentials of Interaction Design: Wiley Pub., 2007. [18] A. J. S. Teixeira, F. Ferreira, N. Almeida, A. F. Rosa, J. Casimiro, S. Silva, A. QueirÃ³s, and A. Oliveira, \"Multimodality and Adaptation for an Enhanced Mobile Medication Assistant for the Elderly,\" in Third Mobile Accessibility Workshop (MOBACC), CHI 2013 Extended Abstracts, France, 2013. [19] Microsoft. (2013, Metro Design Language of Windows Phone 7 | Microsoft Design .toolbox. Available: [20] F. Ferreira, N. Almeida, J. C. Pereira, A. F. Rosa, A. Oliveira, and A. Teixeira, \"Multimodal and Adaptable Medication Assistant for the Elderly - A prototype for Interaction and Usability in Smartphones,\" presented at the CISTI'2013 - 8Âª ConferÃªncia IbÃ©rica de Sistemas e Tecnologias de InformaÃ§Ã£o, Lisbon, 2013. [21] J. Nielsen. (2012, How Many Test Users in a Usability Study? Jakob Nielsen's Alertbox. Available: odologies for Involving Older Adults in the Design Process,\" in Universal Acess in Human Computer Interaction. Coping with Diversity. vol. 4554, C. Stephanidis, Ed., ed: Springer Berlin Heidelberg, 2007, pp. 982-989. [4] R. Eisma, A. Dickinson, J. Goodman, O. Mival, A. Syme, and L. Tiwari, \"Mutual inspiration in the development of new technology for older people,\" in In Proceedings of Include 2003, 2003, pp. 7--252. [5] E. Mynatt and W. Rogers, \"Developing technology to support the functional independence of older adults,\" Ageing International, vol. 27, pp. 24-41, 2001/12/01 2001. [6] R. Eisma, A. Dickinson, J. Goodman, A. Syme, L. Tiwari, and F. Newell, \"Early user involvement in the development of information technology-related products for older people,\" Univers. Access Inf. Soc., vol. 3, pp. 131-140, 2004. [7] S. Chamberlain, H. Sharp, and N. Maiden, \"Towards a framework for integrating agile development and user-centred design,\" presented at the Proceedings of the 7th international conference on Extreme Programming and Agile Processes in Software Engineering, Oulu, Finland, 2006. [8] J. Gulliksen, A. Lantz, and I. Boivie, User Centered Design in Practice - Problems and Possibilities, 1999. [9] R. D. Buurman, \"User-centred design of smart products,\" Ergonomics, vol. 40, pp. 1159-1169, 1997/10/01 1997. [10] J. Pruitt and J. Grudin, \"Personas: practice and theory,\" presented at the Proceedings of the 2003 conference on Designing for user experiences, San Francisco, California, 2003. [11] J. Grudin and J. Pruitt. (2002, Personas, Participatory Design and Product Development: An Infrastructure for Engagement. Fig. 3 â€“ Application features and corresponding number of users who considered them difficult (left) and easy (right). 408 FlÃ†vio Ferreira et al. / Procedia Computer Science 27 ( 2014 ) 398 408 [12] R. Sinha, \"Persona development for information-rich domains,\" presented at the CHI '03 Extended Abstracts on Human Factors in Computing Systems, Ft. Lauderdale, Florida, USA, 2 PROCS 2894 S1877-0509(14)00046-5 10.1016/j.procs.2014.02.044 The Authors ☆ Selection and peer-review under responsibility of the Scientific Programme Committee of the 5th International Conference on Software Development and Technologies for Enhancing Accessibility and Fighting Info-exclusion (DSAI 2013). Elderly Centered Design for Interaction – The Case of the S4S Medication Assistant Flávio Ferreira a Nuno Almeida a b Ana Filipa Rosa a André Oliveira a José Casimiro c Samuel Silva a b António Teixeira a b ⁎ a Institute of Electronics and Telematics Engineering of Aveiro (IEETA), 3810-193 Aveiro, Portugal b Dep. of Electronics Telecommunications and Informatics, University of Aveiro, 3810-193 Aveiro, Portugal c Polytecnic Institute of Tomar, 2300-531 Tomar, Portugal ⁎ Corresponding author. Tel.: +351 234370500; fax: +351 234370545. Several aspects of older adults’ life can benefit from recent technological developments, but success in harnessing this potential depends on careful design and accessible, easy to use products. Design and development must be centered on the elderly and adequately consider interaction. In this paper we follow this design approach and put it to the test in developing a concrete application, aimed to contribute to lower the high levels of non-adherence to medication in the elderly population. The “Medication Assistant” application was developed following an iterative method centered, from the start, on the elderly and interaction design. The method repeats short-time development cycles integrating definition of scenarios and goals, requirements engineering, design, prototyping and evaluation. Evaluation, by end-users, of the increasingly refined prototypes, is a key characteristic of the method. The evaluation results provide information related to strengths and weaknesses of the application and yield suggestions regarding changes and improvements, valuable support further development. Results regarding evaluation of the second prototype of “Medication Assistant” are presented. Keywords development method interaction user centred elderly evaluation mobile applications medication References [1] DESA. (2013). Available: [2] H. Matlabi, S. Parker, and K. McKee, “The contribution of home-based technology to older people's quality of life in extra care housing,” BMC Geriatrics, vol. 11, p. 68, 2011. [3] A. Newell, J. Arnott, A. Carmichael, and M. Morgan, “Methodologies for Involving Older Adults in the Design Process,” in Universal Acess in Human Computer Interaction. Coping with Diversity. vol. 4554, C. Stephanidis, Ed., ed: Springer Berlin Heidelberg, 2007, pp. 982-989. [4] R. Eisma, A. Dickinson, J. Goodman, O. Mival, A. Syme, and L. Tiwari, “Mutual inspiration in the development of new technology for older people,” in In Proceedings of Include 2003, 2003, pp. 7--252. [5] E. Mynatt and W. Rogers, “Developing technology to support the functional independence of older adults,” Ageing International, vol. 27, pp. 24-41, 2001/12/01 2001. [6] R. Eisma, A. Dickinson, J. Goodman, A. Syme, L. Tiwari, and F. Newell, “Early user involvement in the development of information technology-related products for older people,” Univers. Access Inf. Soc., vol. 3, pp. 131-140, 2004. [7] S. Chamberlain, H. Sharp, and N. Maiden, “Towards a framework for integrating agile development and user-centred design,” presented at the Proceedings of the 7th international conference on Extreme Programming and Agile Processes in Software Engineering, Oulu, Finland, 2006. [8] J. Gulliksen, A. Lantz, and I. Boivie, User Centered Design in Practice - Problems and Possibilities, 1999. [9] R. D. Buurman, “User-centred design of smart products,” Ergonomics, vol. 40, pp. 1159-1169, 1997/10/01 1997. [10] J. Pruitt and J. Grudin, “Personas: practice and theory,” presented at the Proceedings of the 2003 conference on Designing for user experiences, San Francisco, California, 2003. [11] J. Grudin and J. Pruitt. (2002, Personas, Participatory Design and Product Development: An Infrastructure for Engagement. [12] R. Sinha, “Persona development for information-rich domains,” presented at the CHI’03 Extended Abstracts on Human Factors in Computing Systems, Ft. Lauderdale, Florida, USA, 2003. [13] R. Casas, R.B. Maro, A. Robinet, A.R. Delgado, A.R. Yarza, J. Mcginn, R. Picking, and V. Grout, “User Modelling in Ambient Intelligence for Elderly and Disabled People,” presented at the Proceedings of the 11th international conference on Computers Helping People with Special Needs, linz, Austria, 2008. [14] C. M. Hughes, “Medication non-adherence in the elderly: how big is the problem?,” Drugs Aging, vol. 21, pp. 793-811, 2004. [15] M. Böhm, H. Schumacher, U. Laufs, P. Sleight, R. Schmieder, T. Unger, K. Teo, and S. Yusuf, “Effects of nonpersistence with. medication on outcomes in high-risk patients with cardiovascular disease,” American Heart Journal, vol. 166, 2013. [16] A. I. Martins, A. Queirós, M. Cerqueira, N.P. da Rocha, and A. J. S. Teixeira, “The International Classification of Functioning, Disability and Health as a Conceptual Model for the Evaluation of Environmental Factors.,” Procedia CS, vol. 14, pp. 293-300, 2012. [17] A. Cooper, R. Reimann, and D. Cronin, About Face 3: The Essentials of Interaction Design: Wiley Pub., 2007. [18] A. J. S. Teixeira, F. Ferreira, N. Almeida, A.F. Rosa, J. Casimiro, S. Silva, A. Queirós, and A. Oliveira, “Multimodality and Adaptation for an Enhanced Mobile Medication Assistant for the Elderly,” in Third Mobile Accessibility Workshop (MOBACC), CHI 2013 Extended Abstracts, France, 2013. [19] Microsoft. (2013, Metro Design Language of Windows Phone 7 | Microsoft Design .toolbox. Available: [20] F. Ferreira, N. Almeida, J.C. Pereira, A.F. Rosa, A. Oliveira, and A. Teixeira, “Multimodal and Adaptable Medication Assistant for the Elderly - A prototype for Interaction and Usability in Smartphones,” presented at the CISTI’2013-8ª Conferência Ibérica de Sistemas e Tecnologias de Informação, Lisbon, 2013. [21] J. Nielsen. (2012, How Many Test Users in a Usability Study? Jakob Nielsen's Alertbox. Available: "
    },
    {
        "doc_title": "Speech-centric multimodal interaction for easy-to-access online services - A personal life assistant for the elderly",
        "doc_scopus_id": "84897750559",
        "doc_doi": "10.1016/j.procs.2014.02.043",
        "doc_eid": "2-s2.0-84897750559",
        "doc_date": "2014-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Automatic speech recognition",
            "Elderly",
            "Multi-Modal Interactions",
            "Multilingual",
            "Personal assistants",
            "Social interactions",
            "Spoken languages",
            "Synthetic voices"
        ],
        "doc_abstract": "The PaeLife project is a European industry-academia collaboration whose goal is to provide the elderly with easy access to online services that make their life easier and encourage their continued participation in the society. To reach this goal, the project partners are developing a multimodal virtual personal life assistant (PLA) offering a wide range of services from weather information to social networking. This paper presents the multimodal architecture of the PLA, the services provided by the PLA, and the work done in the area of speech input and output modalities, which play a key role in the application. © 2013 The Authors. Published by Elsevier B.V.",
        "available": true,
        "clean_text": "serial JL 280203 291210 291871 31 90 Procedia Computer Science PROCEDIACOMPUTERSCIENCE 2014-02-25 2014-02-25 2014-10-23T08:54:46 S1877-0509(14)00045-3 S1877050914000453 10.1016/j.procs.2014.02.043 S300 S300.2 HEAD-AND-TAIL 2021-10-18T13:04:21.805003Z 0 0 20140101 20141231 2014 2014-02-25T00:00:00Z rawtext articleinfo articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids confeditor contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid hubeid indexeddate issn issnnorm itemstage itemtransactionid itemweight oauserlicense openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sortorder srctitle srctitlenorm srctype ssids alllist content oa subj suppl tomb vol volfirst volissue volumelist yearnav affil articletitle auth authfirstini authfull authkeywords authlast primabst ref 1877-0509 18770509 false 27 27 C Volume 27 44 389 397 389 397 2014 2014 2014-01-01 2014-12-31 2014 5th International Conference on Software Development and Technologies for Enhancing Accessibility and Fighting Info-exclusion, DSAI 2013 Dr. Manuel Pérez Cota Dr. João Barroso Dr. Simone Bacellar Leal Ferreira Dr. Benjamim Fonseca Dr. Tassos Mikropoulos Dr. Hugo Paredes article fla Copyright © 2013 The Authors. Published by Elsevier B.V. SPEECHCENTRICMULTIMODALINTERACTIONFOREASYTOACCESSONLINESERVICESAPERSONALLIFEASSISTANTFORELDERLY TEIXEIRA A TEIXEIRAX2014X389 TEIXEIRAX2014X389X397 TEIXEIRAX2014X389XA TEIXEIRAX2014X389X397XA Full 2014-02-25T10:44:25Z OA-Window ElsevierWaived 0 item S1877-0509(14)00045-3 S1877050914000453 10.1016/j.procs.2014.02.043 280203 2014-10-23T04:53:38.247626-04:00 2014-01-01 2014-12-31 true 688643 MAIN 9 47855 849 656 IMAGE-WEB-PDF 1 P r o c e d i a C o m p u t e r S c i e n c e 2 7 ( 2 0 1 4 ) 3 8 9 3 9 7 1877-0509 ' 2013 The Authors. Published by Elsevier B.V. Open access under CC BY-NC-ND license. Selection and peer-review under responsibility of the Scientific Programme Committee of the 5th International Conference on Software Development and Technologies for Enhancing Accessibility and Fighting Info-exclusion (DSAI 2013). doi: 10.1016/j.procs.2014.02.043 ScienceDirect 5th International Conference on Software Development and Technologies for Enhancing Accessibility and Fighting Info-exclusion, DSAI 2013 Speech-Centric Multimodal Interaction for Easy-To-Access Online Services â€“ A Personal Life Assistant for the Elderly AntÃ³nio Teixeira a , Annika HÃ¤mÃ¤lÃ¤inen b,c , Jairo Avelar b,c , Nuno Almeida a , GÃ©za NÃ©meth d , Tibor FegyÃ³ d , Csaba ZainkÃ³ d , TamÃ¡s CsapÃ³ d , BÃ¡lint TÃ³th d , AndrÃ© Oliveira a , Miguel Sales Dias b,c a Department of Electronics Telecom. & Informatics/IEETA, University of Aveiro, Aveiro, Portugal b Microsoft Language Development Center, Lisbon, Portugal c ISCTE - University Institute of Lisbon/ADETTI-IUL, Portugall d Department of Telecommunications & Media Informatics, Budapest University of Technology & Economics, Budapest, Hungary Abstract The PaeLife project is a European industry-academia collaboration whose goal is to provide the elderly with easy access to online services that make their life easier and encourage their continued participation in the society. To reach this goal, the project partners are developing a multimodal virtual personal life assistant (PLA) offering a wide range of services from weather information to social networking. This paper presents the multimodal architecture of the PLA, the services provided by the PLA, and the work done in the area of speech input and output modalities, which play a key role in the application. Â© 2013 The Authors. Published by Elsevier B.V. Selection and peer-review under responsibility of the Scientific Programme Committee of the 5th International Conference on Software Development and Technologies for Enhancing Accessibility and Fighting Info-exclusion (DSAI 2013). Keywords: active aging, automatic speech recognition, elderly, multilingual, multimodal interaction, personalized synthetic voices, personal assistant, social interaction, spoken language modalities. Available online at www.sciencedirect.com ' 2013 The Authors. Published by Elsevier B.V. Open access under CC BY-NC-ND license. election and peer-review under responsibility of the Scientific Progra me Co mittee of the 5th International Conference on Software Development and Technologies for E han ing Accessibility and Fighting Info-exclusion (DSAI 2013). 390 Ant nio Teixeira et al. / Procedia Computer Science 27 ( 2014 ) 389 397 1. Introduction The population aged over 60 is rapidly growing worldwide [1]. This social change is so dramatic that the World Health Organization is actively promoting policies and programs to keep the older generations active, productive and independent as long as possible. From the point of view of information and communication technology (ICT), ensuring active ageing translates into developing applications that enhance the health, the social participation and the security of the elderly. Previous research suggests that the elderly have more difficulties using ICT than younger adults do [2], [3]. The main reasons for this are the complexity of the existing user interfaces and the limited set of available interaction modalities caused by the technology mainly being designed with younger users in mind. One of the most promising ways of adapting the technology to better suit the needs of the elderly is to increase the choice of available interaction modalities. Adding speech to the available modalities is a particularly interesting alternative. The advantages of speech include it offering a natural and fast (about 150-250 words/minute) form of communication, and it requiring neither visual attention nor the use of hands [4]. In fact, speech is part of the three most popular input modality combinations mentioned in [5]: 1) speech and lip movements, 2) speech and gestures, and 3) speech, gestures and facial expressions. Several popular output modality combinations also include speech: 1) speech and graphics, 2) speech plus avatar, and 3) speech, text and graphics [5]. Usability evaluation studies (e.g. [6]) also suggest that speech is the easiest and most natural modality of human-computer interaction (HCI). There is growing international interest, both in academia and in industry, in developing speech-driven applications aimed at improving the quality of life of the elderly. Past R&D projects in the area include, for instance, the Living Usability Lab (LUL) project [7], which developed a telerehabilitation service for the elderly [8], with a toolkit for multimodal interaction (including speech), and the possibility to adapt speech and graphical output to the context and to the user [9]. Speech input and output have recently also been used, for example, in a medication assistant for smartphones [10]. The PaeLife project, an ongoing industry-academia collaboration that is part of the Ambient Assisted Living (AAL) Joint Programme [11], is aimed at keeping the European elderly active and socially integrated. To this end, the project is developing a multimodal personal life assistant (PLA) offering the elderly a wide set of services from unified messaging (e.g. email, twitter, videoconferencing) through to relevant feeds (e.g. the latest news, weather information). The platform of the PLA comprises a personal computer connected to a TV-like big screen, as well as a portable device (a tablet) for mobility. One of the key modalities of the PLA is speech; speech input and output will be available in four European languages: French, Hungarian, Polish, and Portuguese. Apart from the challenges of developing speech technology for use in multimodal interaction in several languages, the project partners are faced with the challenges of customizing it for the elderly. It is well known that current speech recognizers do not work well with elderly speech. This is (in part) because many parameters of the speech signal (such as the fundamental frequency) change with age [12], and because most current speech recognizers have been optimized to recognize younger adult speech. To address this issue, we are collecting large databases of elderly speech for the four target languages, and training elderly-specific speech recognizers using those data. A successful speech interface should also be able to take into account the usersâ€™ preferences. This is particularly important in the case of the elderly who might not be very familiar with technology. For increased user acceptance of speech output (speech synthesis), we are providing the elderly users with several synthesized voices to choose from based on their personal preferences [13]. In this paper, we present the multimodal architecture adopted for the PLA, the services planned and already available in the PLA, as well as the work aimed at tailoring automatic speech recognition and speech synthesis to the elderly and at making these technologies available to the four languages targeted by the project. 391 Ant nio Teixeira et al. / Procedia Computer Science 27 ( 2014 ) 389 397 2. The PaeLife Personal Life Assistant 2.1. User-Centric Design The PaeLife project adopted a user-centric approach for designing the PLA. We carried out extensive user studies amongst the elderly in France, Hungary and Poland to try to identify what kinds of online services the elderly are interested in, and what kinds of limitations and preferences they might have when it comes to HCI [14]. Based on the user studies, we made up personas (archetypal users of the application) and use scenarios to explore the set of tasks and interactions required for the application, and to help us evaluate the application in the future. The PaeLife personas are aged 60 or over and have some experience in using computers â€“ although most of them are not expert users. While they do not have major health issues, they might suffer from typical age-related ailments (reduced dexterity, some degree of visual impairment etc.). In other words, they do not have any serious health-related conditions that would require physiological interfaces (e.g. electromyography), which are cumbersome, intrusive and difficult to use. However, as they might not be very proficient in using traditional user interfaces, we considered it very important to provide them with easy-to-use, natural interaction modalities â€“ such as speech, touch and gestures. Table 1 presents part of an example use scenario featuring MÃ¡ria KovÃ¡cs, a relatively healthy 68-year-old Polish woman who still works part-time and, apart from her proofreading work, mainly uses the computer for social networking and for looking for new recipes and information about local cultural events. Table 1: Example use scenario with MÃ¡ria KovÃ¡cs, a 68-year-old Polish woman with basic computer skills MÃ¡ria is watching TV in the living-room. She decides to use the tablet to check the latest posts of her Facebook friends. As one of the posts contains a video, MÃ¡ria says, â€œWatch videoâ€�. The video starts playing on the TV screen, and the TV channel that she was watching now appears as a miniature window in the corner of the TV screen. The tablet continues displaying the latest posts but the controls for the video are shown at the bottom of the screen, allowing the user to pause, stop, fast-forward and rewind the video. At the end of the video, three buttons appear on the TV: â€œLikeâ€�, â€œDonâ€™t Likeâ€� and â€œLeaveâ€�. MÃ¡ria says â€œLikeâ€�, and the video is tagged with her like. MÃ¡ria then decides to use the tablet to search for a friend on Facebook by her name. She chooses the option â€œSearchâ€� and uses the tablet as a virtual keyboard; the results of her search are shown on the TV screen. MÃ¡ria uses a swiping hand gesture to see the full list of results. When the photo of her friend shows up on the TV screen, she asks for more information by saying, â€œSee the profile of the second photoâ€�. The profile of the friend now gets displayed on the TV screen. MÃ¡ria says, â€œSend friend requestâ€�. Figure 1: The W3C-recommended architecture adopted for supporting multimodal interaction in the personal life assistant (PLA). 392 Ant nio Teixeira et al. / Procedia Computer Science 27 ( 2014 ) 389 397 2.2. Multimodal Interaction Based on the user studies, we identified the following key requirements for HCI in the PLA: 1) support for several input and output modalities, 2) support for the distribution of modalities across different devices (PCs, tablets etc.), 3) adhering to international standards and avoiding closed solutions, and 4) possibility to change or add modules (supporting services or interaction) without the rest of the system being affected. These requirements were met by developing an integrated framework that supports multimodal interaction specifically tailored to the elderly, with the available interaction modalities including speech, touch, gestures, keyboard and mouse. The framework is based on the recent recommendations of the World Wide Web Consortium (W3C) regarding multimodal interaction [15] â€“ a choice motivated by the open-standard nature of the recommended architecture and the ease of integrating new modules and already existing tools into the system. The architecture (see Figure 1) has three major components: Î¾ The Interaction Manager (IM), which manages the different interaction modalities Î¾ The Modality Components, which represent the input and output modalities Î¾ The Runtime Framework, which acts as a container for all other components and provides communication between the different modalities and the IM From the point of view of the PLA, the Modality Components are the most important components of the architecture because they provide a simple way to integrate the chosen input and output technologies â€“ including speech input and output, which are discussed in more detail in Section 3 â€“ into the system. 2.3. The PLA and the Available Online Services The PLA itself comprises a stationary main unit that runs on a desktop computer, as well as a portable unit that runs on a tablet (see Figure 2). In the main unit, a big screen (e.g. an LCD TV) supports graphical output, the internal microphone and speakers support speech input and output, and a Kinect sensor supports gesture input. In the portable unit, on the other hand, the display supports graphical output, the internal microphone and speakers enable speech input and output, and the multi-touch support of the operating system makes touch input possible. The main unit and the portable units work together and can be connected to the internet and to the cloud for providing the user with online services. The two units can also work as stand-alone devices. As illustrated in Figure 2, two different types of tablets can be used as the portable unit: premium tablets, with all the services available for the PLA, and low-cost tablets, with a subset of those services. Apart from a more limited set of services, the low- cost tablets might have to use remote or cloud-based services, for example, for handling speech input and output. 393 Ant nio Teixeira et al. / Procedia Computer Science 27 ( 2014 ) 389 397 Main Unit Home computer Screen PLA Database Portable Unit Portable Unit (Premium Tablet) l i i l Portable Unit (Low Cost Tablet) l i l Home Office 365 Voice SearchAutomatic Speech Recognition Internet authentification services Text to Speech kinect Figure 2: The architecture of the PLA. In practice, the PLA functions as the multimodal assistant for the elderly and supports a wide range of services, for instance, in the areas of social interaction and entertainment.The PLA is divided into modules that are responsible for delivering different types of services. The modules and the corresponding services are presented in Table 2. Table 2: The modules and services of the PLA. Module Services Unified messaging 1. Quasi-instant messaging 2. Voice call 3. Videoconferencing on Skype 4. Messaging using email, Facebook and/or Twitter 5. Voice mail Calendar 1. To-do list 2. Birthday reminders 3. Name day reminders 4. Cultural events Social networking 1. Geographical location of contacts 2. Graphical representation of contactsâ€™ availability 3. Email, Facebook and/or Twitter activity with contacts 4. Visualisation of the time that has passed from previous contact (e.g. photos of contacts getting larger), aimed at encouraging regular communication 5. Information about contacts (e.g. status) TV schedule Weather information 394 Ant nio Teixeira et al. / Procedia Computer Science 27 ( 2014 ) 389 397 Media manager 1. Photos 2. Videos 3. Music 4. Text documents etc. Relevant feeds Examples: latest news, accessibility of places for mobility-impaired users, local health care services and pharmacies Facebook groups of interest Examples: recipes, organised travel, and clubs 3. Towards Better Speech Recognition and Synthesis for the Elderly In the PLA, speech input (automatic speech recognition; ASR) and output (speech synthesis; TTS) are handled using two different speech platforms: one provided by Microsoft [16] and already supporting French, Polish and Portuguese, and another provided by the Budapest University of Technology & Economics (BME) and already supporting Hungarian. In this section, we describe how these speech technologies are optimized for the elderly users in the PaeLife project. ASR is technology that translates acoustic speech signal into a sequence of words. To be able to do that, automatic speech recognisers typically use three knowledge bases: 1) a language-specific language model (or grammar), which contains information on the possible sequences of words and their probability in the language in question (e.g. â€˜I use Bingâ€™ is a probable sequence of words, while â€˜I chair Bingâ€™ is not), 2) a language-specific pronunciation lexicon, which represents words in terms of individual speech sounds, or phonemes (e.g. Bing contains three phonemes: /b Éª Å‹/), and 3) language-specific acoustic models, which model the acoustic properties of the phonemes used in the pronunciation lexicon. Before a recognition task can be performed, the language model and the acoustic models must be trained using large corpora of language-specific texts and speech, respectively. Together, the language model, the lexicon and the acoustic models then â€˜modelâ€™ the acoustic realisations of all possible sentences in the language in question, and are used to find the most probable sequence of words to represent the incoming acoustic speech signal. To be able to train acoustic models that model the acoustic properties of phonemes as accurately as possible, the speech corpus used for the training must contain orthographic (word-level) transcriptions of the spoken material. The lexicon will then be used to identify the underlying phonemes, whose acoustic properties in the speech signal will be used to train the acoustic models. Standard speech recognisers are usually trained using speech corpora collected from younger adult speakers. Because the acoustic properties of speech produced by elderly speakers differ from those produced by younger adult speakers [12], they are not able to recognise elderly speech as well as they are able to recognise younger adult speech. To successfully recognise elderly speech, it is important to collect a sufficient amount of elderly speech for training elderly-specific acoustic models [17â€“19]. In the PaeLife project, we have already finished collecting large corpora of domain-specific speech from subjects aged 60 or over for two of the target languages: Portuguese (180 hours of read speech) [20], [21], and Polish (170 hours of read speech). At the time of writing this paper, we have also already collected about 46 and 35 hours of read speech for French and Hungarian, respectively. The goal is to collect 200 hours of read speech for both of those languages, as well as an additional 60 hours of spontaneous speech for Hungarian. One of the benefits of collecting read â€“ rather than spontaneous â€“ speech is that, apart from some small corrections, the sentences presented to the speakers can also be used as the orthographic transcriptions of the spoken material. On the other hand, spontaneous speech must be transcribed from scratch. We have already trained elderly-specific acoustic models for Portuguese, and integrated them into the ASR- based services that are already available in the PLA. We will do the same for the remaining three languages as soon as the data collection and/or the transcription work has ended; for now, the other languages are using standard acoustic models that have been trained using younger adult speech. TTS is technology that converts text into artificially produced speech. Users are more likely to identify with and accept synthesized voices that match their preferences and/or their own age group, gender etc. [13]. In terms of TTS, the main goal of the PaeLife project is to increase the user acceptance of synthesized voices by offering the elderly users of the PLA a wide variety of voices to choose from. In practice, they are currently provided with the 395 Ant nio Teixeira et al. / Procedia Computer Science 27 ( 2014 ) 389 397 younger adult voices (female and male) that the two project partners developing speech technologies for the PLA, Microsoft and BME, already have available in their speech platforms. In addition, one elderly voice will be developed for each target language, and the users of the PLA will also be offered the possibility to create personalised voices. To generate new synthesised voices, speech is usually recorded from people with the desired kind of voice, and the recorded speech is then manipulated to form new spoken words and sentences. As few as 200 sentences are enough to generate intelligible voices using the Microsoft methodology [22]. Therefore, personalised voices can even be the voices of the relatives of the users of the PLA â€“ an alternative that might be particularly attractive to the elderly. 4. Currently Available Speech-Driven Services in the PLA The speech-driven services that are already available and in integration in the PLA system include the following: Î¾ Weather information service. This service uses Hungarian TTS voices to read out weather information from a Hungarian weather information website. Î¾ Unified messaging. This service employs speech input and output for using email, Twitter, YouTube, Skype and Facebook via a single, simplified, easy-to-use interface. The service is currently available in French and Portuguese, with the Portuguese ASR already optimized for elderly speech. Î¾ News feeds. This service offers ASR- and gesture-driven interaction with news feeds. It is already possible to navigate news items in French, Polish, English and Portuguese using simple voice commands (e.g. â€œto the rightâ€�) and by starting to read the contents (e.g. the first 3-4 words) of a news item select that specific item. Hungarian news feeds are also already available in the system but can only be accessed using ASR when acoustic models have been trained for Hungarian. Figure 3 illustrates the easy-to-use multimodal interaction with news feeds. 396 Ant nio Teixeira et al. / Procedia Computer Science 27 ( 2014 ) 389 397 Figure 3: Interaction with the news module of the PLA. 5. Conclusions Due to the rapid, worldwide growth of the elderly population, it is of paramount importance to devise applications for enhancing the health, the social participation and the security of the elderly. Because of the special needs and limitations of the target population, such applications need to pay special attention to easy and natural human-computer interaction. In this paper, we presented a multimodal personal life assistant aimed at providing the elderly with easy access to a wide range of online services â€“ in particular, information services and services related to social interaction â€“ and, thus, making their lives easier and encouraging their continued participation in the society. As speech is one of the easiest and most natural modalities of human-computer interaction, speech input (automatic speech recognition) and output (speech synthesis) pay a key role in the application, and will be available 397 Ant nio Teixeira et al. / Procedia Computer Science 27 ( 2014 ) 389 397 in four European languages (besides English): French, Hungarian, Polish and Portuguese. In this paper, we discussed the framework that we have adopted for handling the interaction modalities available in the application (speech, touch, gestures, keyboard and mouse), the services planned and already available in the personal life assistant, as well as our approach to adapting automatic speech recognition and speech synthesis to the elderly and making these technologies available in the four target languages. Acknowledgments Authors acknowledge the funding from AAL JP and national agencies: MLDC was funded by Portuguese Government through the Ministry of Science, Technology and Higher Education (MCES); University of Aveiro was funded by FEDER, COMPETE and FCT in the context of AAL/0015/2009 and IEETA Research Unit funding FCOMP-01-0124-FEDER-022682 (FCT-PEstC/EEI/UI0127/2011). BME acknowledge the support of the FuturICT project (TÃ�MOP-4.2.2.C-11/1/KONV-2012- 0013) and the PAELIFE project (AAL-08-1-2011-0001). References [1] W. H. Organization, â€œActive aging: A policy framework,â€� in Second United Nations World Assembly on Ageing, 2002. [2] D. A. C. Stephanidis, â€œUniversal accessibility in HCI: Process-oriented design guidelines and tool requirements,â€� in ERCIM Workshop on User Interfaces for All, 1998. [3] V. Teixeira, C. Pires, F. Pinto, J. Freitas, M. S. Dias, and E. M. Rodrigues, â€œTowards elderly social integration using a multimodal human-computer interface,â€� in Proc. International Living Usability Lab Workshop on AAL Latest Solutions, Trends and Applications, AAL, 2012. [4] N. O. Bernsen, â€œTowards a tool for predicting speech functionality,â€� Speech Communication, vol. 23, no. 3, pp. 181â€“210, Nov. 1997. [5] T. H. Bui, â€œMultimodal Dialogue Management - State of the art,â€� 2006, no. TR-CTIT-06â€“01. [6] A. Teixeira, D. Braga, L. Coelho, A. Fonseca, J. AlvarelhÃ£o, I. MartÃ­n, A. QueirÃ³s, N. Rocha, A. Calado, and M. Dias, â€œSpeech as the Basic Interface for Assistive Technology,â€� in DSAI, 2009. [7] â€œLiving Usability Lab.â€� [Online]. Available: [Accessed: 18-Mar-2013]. [8] A. J. S. Teixeira, C. Pereira, M. Oliveira e Silva, J. AlvarelhÃ£o, A. Silva, M. Cerqueira, A. I. Martins, O. Pacheco, N. Almeida, C. Oliveira, R. Costa, and A. J. . Neves, â€œNew Telerehabilitation Services for the Elderly,â€� in I.M. Miranda and M.M. Cruz-Cunha [Eds], Handbook of research on ICTs for healthcare and social services: Developments and applications, IGI Global, 2013. [9] A. Teixeira, C. Pereira, M. Silva, O. Pacheco, A. Neves, and J. Casimiro, â€œAdaptO - Adaptive Multimodal Output,â€� in Proc. PECCS, 2011. [10] A. Teixeira, F. Ferreira, N. Almeida, A. Rosa, J. Casimiro, S. Silva, A. QueirÃ³s, and A. Oliveira, â€œMultimodality and Adaptation for an Enhanced Mobile Medication Assistant for the Elderly,â€� in Proc. Third Mobile Accessibility Workshop (MOBACC), CHI 2013, 2013. [11] â€œAmbient Assisted Living Joint Programme.â€� [Online]. Available: [Accessed: 11-Jul-2013]. [12] S. A. Xue and G. J. Hao, â€œChanges in the human vocal tract due to aging and the acoustic correlates of speech production: A pilot study.,â€� Journal of Speech, Language and Hearing Research, vol. 46, no. 3, pp. 689â€“701, 2003. [13] C. Nass and S. Brave, â€œWired for speech: How voice activates and advances the human-computer relationship,â€� in MIT Press, 2007. [14] N. Saldanha, J. Avelar, M. Dias, A. Teixeira, D. GonÃ§alves, E. Bonnet, K. Lan, N. GÃ©za, P. Csobanka, and A. Kolesinski, â€œA Personal Life Assistant for â€˜naturalâ€™ interaction: the PaeLife project,â€� in AAL Forum 2013 Forum, 2013. [15] M. Bodell, D. Dahl, I. Kliche, J. Larson, B. Porter, D. Raggett, T. Raman, B. H. Rodriguez, M. Selvaraj, R. Tumuluri, A. Wahbe, P. Wiechno, and M. Yudkowsky, â€œMultimodal architecture and interfaces: W3C Recommendation,â€� 2012. [Online]. Available: [Accessed: 18-Mar-2013]. [16] â€œMicrosoft Speech Platform 11.0.â€� [Online]. Available: [Accessed: 18-Mar-2013]. [17] R. Vipperla, S. Renals, and J. Frankel, â€œLongitudinal study of ASR performance on ageing voices,â€� in Proc. Interspeech, 2008. [18] A. Baba, S. Yoshizawa, M. Yamada, A. Lee, and K. Shikano, â€œAcoustic models of the elderly for large-vocabulary continuous speech recognition,â€� Electronics and Communications in Japan, vol. 87, no. 7, pp. 49â€“57, 2004. [19] T. Pellegrini, I. Trancoso, A. HÃ¤mÃ¤lÃ¤inen, A. Calado, M. Dias, and D. Braga, â€œImpact of age in ASR for the elderly: Preliminary experiments in European Portuguese,â€� in Proc. IberSPEECH, 2012. [20] A. HÃ¤mÃ¤lÃ¤inen, F. Pinto, M. Dias, A. JÃºdice, J. Freitas, C. Pires, V. Teixeira, A. Calado, and D. Braga, â€œThe first European Portuguese elderly speech corpus,â€� in Proc. IberSPEECH, 2012. [21] A. JÃºdice, J. Freitas, D. Braga, A. Calado, M. Sales Dias, A. J. S. Teixeira, and C. Oliveira, â€œElderly speech collection for speech recognition based on crowd sourcing.,â€� in Proc. DSAI, 2010. [22] D. Braga, P. Silva, M. Ribeiro, M. Henriques, and M. Dias, â€œHMM-based Brazilian Portuguese TTS,â€� in Propor 2008 Special Session: Applications of Portuguese Speech and Language Technologies, 2008. Workshop on User Interfaces for All, 1998. [3] V. Teixeira, C. Pires, F. Pinto, J. Freitas, M. S. Dias, and E. M. Rodrigues, â€œTowards elderly social integration using a multimodal human-computer interface,â€� in Proc. PROCS 2893 S1877-0509(14)00045-3 10.1016/j.procs.2014.02.043 The Authors ☆ Selection and peer-review under responsibility of the Scientific Programme Committee of the 5th International Conference on Software Development and Technologies for Enhancing Accessibility and Fighting Info-exclusion (DSAI 2013). Speech-centric Multimodal Interaction for Easy-to-access Online Services – A Personal Life Assistant for the Elderly António Teixeira a Annika Hämäläinen b c Jairo Avelar b c Nuno Almeida a Géza Németh d Tibor Fegyó d Csaba Zainkó d Tamás Csapó d Bálint Tóth d André Oliveira a Miguel Sales Dias b c a Department of Electronics Telecom. & Informatics/IEETA, University of Aveiro, Aveiro, Portugal b Microsoft Language Development Center, Lisbon, Portugal c ISCTE - University Institute of Lisbon/ADETTI-IUL, Portugall d Department of Telecommunications & Media Informatics, Budapest University of Technology & Economics, Budapest, Hungary The PaeLife project is a European industry-academia collaboration whose goal is to provide the elderly with easy access to online services that make their life easier and encourage their continued participation in the society. To reach this goal, the project partners are developing a multimodal virtual personal life assistant (PLA) offering a wide range of services from weather information to social networking. This paper presents the multimodal architecture of the PLA, the services provided by the PLA, and the work done in the area of speech input and output modalities, which play a key role in the application. Keywords active aging automatic speech recognition elderly multilingual multimodal interaction personalized synthetic voices personal assistant social interaction spoken language modalities References [1] W. H. Organization, “Active aging: A policy framework,” in Second United Nations World Assembly on Ageing, 2002. [2] D. A. C. Stephanidis, “Universal accessibility in HCI: Process-oriented design guidelines and tool requirements,” in ERCIM Workshop on User Interfaces for All, 1998. [3] V. Teixeira, C. Pires, F. Pinto, J. Freitas, M.S. Dias, and E. M. Rodrigues, “Towards elderly social integration using a multimodal human-computer interface,” in Proc. International Living Usability Lab Workshop on AAL Latest Solutions, Trends and Applications, AAL, 2012. [4] N. O. Bernsen, “Towards a tool for predicting speech functionality,” Speech Communication, vol. 23, no. 3, pp. 181-210, Nov. 1997. [5] T. H. Bui, “Multimodal Dialogue Management - State of the art,” 2006, no. TR-CTIT-06-01. [6] A. Teixeira, D. Braga, L. Coelho, A. Fonseca, J. Alvarelhão, I. Martín, A. Queirós, N. Rocha, A. Calado, and M. Dias, “Speech as the Basic Interface for Assistive Technology,” in DSAI,;1; 2009. [7] “Living Usability Lab.” [Online]. Available: [Accessed: 18-Mar-2013]. [8] A. J. S. Teixeira, C. Pereira, M. Oliveira e Silva, J. Alvarelhão, A. Silva, M. Cerqueira, A.I. Martins, O. Pacheco, N. Almeida, C. Oliveira, R. Costa, and A. J. Neves, “New Telerehabilitation Services for the Elderly,” in I.M. Miranda and M.M. Cruz-Cunha [Eds], Handbook of research on ICTs for healthcare and social services: Developments and applications, IGI Global, 2013. [9] A. Teixeira, C. Pereira, M. Silva, O. Pacheco, A. Neves, and J. Casimiro, “AdaptO - Adaptive Multimodal Output,” in Proc. PECCS,;1; 2011. [10] A. Teixeira, F. Ferreira, N. Almeida, A. Rosa, J. Casimiro, S. Silva, A. Queirós, and A. Oliveira, “Multimodality and Adaptation for an Enhanced Mobile Medication Assistant for the Elderly,” in Proc. Third Mobile Accessibility Workshop (MOBACC), CHI 2013, 2013. [11] “Ambient Assisted Living Joint Programme.” [Online]. Available: [Accessed: 11-Jul-2013]. [12] S. A. Xue and G. J. Hao, “Changes in the human vocal tract due to aging and the acoustic correlates of speech production: A pilot study.,” Journal of Speech, Language and Hearing Research, vol. 46, no. 3, pp. 689-701, 2003. [13] C. Nass and S. Brave, “Wired for speech: How voice activates and advances the human-computer relationship,” in MIT Press, 2007. [14] N. Saldanha, J. Avelar, M. Dias, A. Teixeira, D. Gonçalves, E. Bonnet, K. Lan, N. Géza, P. Csobanka, and A. Kolesinski, “A. Personal;1; Life Assistant for ‘natural’ interaction: the PaeLife project,” in AAL Forum 2013 Forum, 2013. [15] M. Bodell, D. Dahl, I. Kliche, J. Larson, B. Porter, D. Raggett, T. Raman, B.H. Rodriguez, M. Selvaraj, R. Tumuluri, A. Wahbe, P. Wiechno, and M. Yudkowsky, “Multimodal architecture and interfaces: W3C Recommendation,” 2012. [Online]. Available: [Accessed: 18-Mar-2013]. [16] “Microsoft Speech Platform 11.0.” [Online]. Available: [Accessed: 18-Mar-2013]. [17] R. Vipperla, S. Renals, and J. Frankel, “Longitudinal study of ASR performance on ageing voices,” in Proc. Interspeech, 2008. [18] A. Baba, S. Yoshizawa, M. Yamada, A. Lee, and K. Shikano, “Acoustic models of the elderly for large-vocabulary continuous speech recognition,” Electronics and Communications in Japan, vol. 87, no. 7, pp. 49-57, 2004. [19] T. Pellegrini, I. Trancoso, A. Hämäläinen, A. Calado, M. Dias, and D. Braga, “Impact of age in ASR for the elderly: Preliminary experiments in European Portuguese,” in Proc. IberSPEECH, 2012. [20] A. Hämäläinen, F. Pinto, M. Dias, A. Júdice, J. Freitas, C. Pires, V. Teixeira, A. Calado, and D. Braga, “The first European Portuguese elderly speech corpus,” in Proc. IberSPEECH, 2012. [21] A. Júdice, J. Freitas, D. Braga, A. Calado, M. Sales Dias, A.J. S. Teixeira, and C. Oliveira, “Elderly speech collection for speech recognition based on crowd sourcing.,” in Proc. DSAI, 2010. [22] D. Braga, P. Silva, M. Ribeiro, M. Henriques, and M. Dias, “HMM-based Brazilian Portuguese TTS,” in Propor 2008 Special Session: Applications of Portuguese Speech and Language Technologies, 2008. "
    },
    {
        "doc_title": "Multimodal and adaptable medication assistant for the elderly: A prototype for interaction and usability in smartphones",
        "doc_scopus_id": "84887888539",
        "doc_doi": null,
        "doc_eid": "2-s2.0-84887888539",
        "doc_date": "2013-11-25",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Computer Networks and Communications",
                "area_abbreviation": "COMP",
                "area_code": "1705"
            },
            {
                "area_name": "Information Systems",
                "area_abbreviation": "COMP",
                "area_code": "1710"
            }
        ],
        "doc_keywords": [
            "adaptation",
            "mobile",
            "Multi-modality",
            "Natural language generation",
            "Windows phones"
        ],
        "doc_abstract": "In order to address the elderly population higher levels of non-adherence to medication we present a mobile application to help them with medication management, providing multimodal interaction and context awareness. The application was developed following an iterative method. In each phase we identify some requirements, develop a prototype and evaluate it. The first prototype uses speech and touch as input and speech and graphical modalities as output. In addition to the traditional medication alerts, the application provides medication advices, and some provision for handling situations when the elder forgets to take the medication, in complement with classical functionalities on medication alerts to the user. Furthermore, it includes some adaptation mechanisms to the user and context of use. The results of the application tests and end-user evaluation have shown that the adaptation, the interaction based on spoken language and the recommendations had a positive impact in the users. © 2013 AISTI.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "New telerehabilitation services for the elderly",
        "doc_scopus_id": "84887892291",
        "doc_doi": "10.4018/978-1-4666-3990-4.ch006",
        "doc_eid": "2-s2.0-84887892291",
        "doc_date": "2013-04-30",
        "doc_type": "Book Chapter",
        "doc_areas": [
            {
                "area_name": "Medicine (all)",
                "area_abbreviation": "MEDI",
                "area_code": "2700"
            },
            {
                "area_name": "Health Professions (all)",
                "area_abbreviation": "HEAL",
                "area_code": "3600"
            }
        ],
        "doc_keywords": [
            "Cognitive capability",
            "Health-care system",
            "Multi-Modal Interactions",
            "Older People",
            "Telerehabilitation",
            "Unsolved problems",
            "Vision problems",
            "Work in progress"
        ],
        "doc_abstract": "© 2013 by IGI Global. All rights reserved.The world's population is getting older with the percentage of people over 60 increasing more rapidly than any other age group. Telerehabilitation may help minimise the pressure this puts on the traditional healthcare system, but recent studies showed ease of use, usability, and accessibility as unsolved problems, especially for older people who may have little experience or confidence in using technology. Current migration towards multimodal interaction has benefits for seniors, allowing hearing and vision problems to be addressed by exploring redundancy and complementarity of modalities. This chapter presents and contextualizes work in progress in a new telerehabilitation service targeting the combined needs of the elderly to have professionally monitored exercises without leaving their homes with their need regarding interaction, directly related to age-related effects on, for example, vision, hearing, and cognitive capabilities. After a brief general overview of the service, additional information on its two supporting applications are presented, including information on user interfaces. First results from a preliminary evaluation are also included.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "From an autonomous soccer robot to a robotic platform for elderly care",
        "doc_scopus_id": "84861984252",
        "doc_doi": null,
        "doc_eid": "2-s2.0-84861984252",
        "doc_date": "2012-06-13",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Biomedical Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2204"
            }
        ],
        "doc_keywords": [
            "Developed countries",
            "Elderly care",
            "Hardware and software",
            "Home care",
            "Independent living",
            "Innovative solutions",
            "Number of peoples",
            "Nursing homes",
            "Robotic platforms",
            "Robotic soccer",
            "Soccer robot"
        ],
        "doc_abstract": "Current societies in developed countries face a serious problem of aged population. The growing number of people with reduced health and capabilities, allied with the fact that elders are reluctant to leave their own homes to move to nursing homes, requires innovative solutions since continuous home care can be very expensive and dedicated 24/7 care can only be accomplished by more than one care-giver. This paper presents the proposal of a robotic platform for elderly care integrated in the Living Usability Lab for Next Generation Networks. The project aims at developing technologies and services tailored to enable the active aging and independent living of the elderly population. The proposed robotic platform is based on the CAMBADA robotic soccer platform, with the necessary modifications, both at hardware and software levels, while simultaneously applying the experiences achieved in the robotic soccer environment.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Health@Home scenario: Creating a new support system for home telerehabilitation",
        "doc_scopus_id": "84861978367",
        "doc_doi": null,
        "doc_eid": "2-s2.0-84861978367",
        "doc_date": "2012-06-13",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Biomedical Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2204"
            }
        ],
        "doc_keywords": [
            "Ambient assisted living",
            "Conceptual architecture",
            "Early evaluation",
            "Elderly people",
            "Innovative method",
            "Multi-modality",
            "Support systems",
            "Telerehabilitation",
            "User-centric",
            "Video surveillance"
        ],
        "doc_abstract": "The creation of innovative methods and technologies for elderly is the main purpose for Ambient Assisted Living. This paper provides a description on all the associated stages and development questions required for the establishment of a new telerehabilitation service. The service intends to provide elderly people with the possibility of performing rehabilitation sessions in their houses, with constant medical supervision via video surveillance. Following the principles of a new conceptual architecture for services, and developed according to user-centric paradigms such as multimodality and high usability criteria, early evaluation results point the service as an asset for remote rehabilitation.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Spoken communication with CAMBADA@Home service robot",
        "doc_scopus_id": "84861961543",
        "doc_doi": null,
        "doc_eid": "2-s2.0-84861961543",
        "doc_date": "2012-06-13",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Biomedical Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2204"
            }
        ],
        "doc_keywords": [
            "Automatic speech recognition",
            "Hands-free",
            "Home service robot",
            "In-line",
            "Mobile service robots",
            "NAtural language processing",
            "Natural response",
            "Robotic platforms",
            "Spoken languages",
            "Text to speech",
            "Two-component"
        ],
        "doc_abstract": "Spoken language is a natural way to control the human-robot interaction, especially for mobile service robots. It has some important advantages over other communication approaches: eyes and hands free, communication from a distance, even without being in line of sight and no need for additional learning for humans. In this paper, we present the spoken dialog framework integrated in our mobile service robot CAMBADA@Home, a robotic platform aimed at move into a living space and interact with users of that space. The proposed framework comprises three major spoken and natural language processing components: an Automatic Speech Recognition component to process the human requests, a Text-to-Speech component to generate more natural responses from the robot side, and a dialog manager to control how these two components work together.",
        "available": false,
        "clean_text": ""
    }
]