[
    {
        "doc_title": "Exploring the Age Effects on European Portuguese Vowel Production: An Ultrasound Study",
        "doc_scopus_id": "85123516451",
        "doc_doi": "10.3390/app12031396",
        "doc_eid": "2-s2.0-85123516451",
        "doc_date": "2022-02-01",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Materials Science (all)",
                "area_abbreviation": "MATE",
                "area_code": "2500"
            },
            {
                "area_name": "Instrumentation",
                "area_abbreviation": "PHYS",
                "area_code": "3105"
            },
            {
                "area_name": "Engineering (all)",
                "area_abbreviation": "ENGI",
                "area_code": "2200"
            },
            {
                "area_name": "Process Chemistry and Technology",
                "area_abbreviation": "CENG",
                "area_code": "1508"
            },
            {
                "area_name": "Computer Science Applications",
                "area_abbreviation": "COMP",
                "area_code": "1706"
            },
            {
                "area_name": "Fluid Flow and Transfer Processes",
                "area_abbreviation": "CENG",
                "area_code": "1507"
            }
        ],
        "doc_keywords": [],
        "doc_abstract": "© 2022 by the authors. Licensee MDPI, Basel, Switzerland.For aging speech, there is limited knowledge regarding the articulatory adjustments underlying the acoustic findings observed in previous studies. In order to investigate the age-related articulatory differences in European Portuguese (EP) vowels, the present study analyzes the tongue configuration of the nine EP oral vowels (isolated context and pseudoword context) produced by 10 female speakers of two different age groups (young and old). From the tongue contours automatically segmented from the US images and manually revised, the parameters (tongue height and tongue advancement) were extracted. The results suggest that the tongue tends to be higher and more advanced for the older females compared to the younger ones for almost all vowels. Thus, the vowel articulatory space tends to be higher, advanced, and bigger with age. For older females, unlike younger females that presented a sharp reduction in the articulatory vowel space in disyllabic sequences, the vowel space tends to be more advanced for isolated vowels compared with vowels produced in disyllabic sequences. This study extends our pilot research by reporting articulatory data from more speakers based on an improved automatic method of tongue contours tracing, and it performs an inter-speaker comparison through the application of a novel normalization procedure.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Association between acoustic speech features and non-severe levels of anxiety and depression symptoms across lifespan",
        "doc_scopus_id": "85104151098",
        "doc_doi": "10.1371/journal.pone.0248842",
        "doc_eid": "2-s2.0-85104151098",
        "doc_date": "2021-04-01",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Multidisciplinary",
                "area_abbreviation": "MULT",
                "area_code": "1000"
            }
        ],
        "doc_keywords": [
            "Adult",
            "Aged",
            "Aged, 80 and over",
            "Aging",
            "Anxiety",
            "Cross-Sectional Studies",
            "Depression",
            "Female",
            "Humans",
            "Male",
            "Middle Aged",
            "Portugal",
            "Speech Acoustics"
        ],
        "doc_abstract": "© 2021 Albuquerque et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.Background Several studies have investigated the acoustic effects of diagnosed anxiety and depression. Anxiety and depression are not characteristics of the typical aging process, but minimal or mild symptoms can appear and evolve with age. However, the knowledge about the association between speech and anxiety or depression is scarce for minimal/mild symptoms, typical of healthy aging. As longevity and aging are still a new phenomenon worldwide, posing also several clinical challenges, it is important to improve our understanding of non-severe mood symptoms' impact on acoustic features across lifetime. The purpose of this study was to determine if variations in acoustic measures of voice are associated with non-severe anxiety or depression symptoms in adult population across lifetime. Methods Two different speech tasks (reading vowels in disyllabic words and describing a picture) were produced by 112 individuals aged 35-97. To assess anxiety and depression symptoms, the Hospital Anxiety Depression Scale (HADS) was used. The association between the segmental and suprasegmental acoustic parameters and HADS scores were analyzed using the linear multiple regression technique. Results The number of participants with presence of anxiety or depression symptoms is low (>7: 26.8% and 10.7%, respectively) and non-severe (HADS-A: 5.4 ± 2.9 and HADS-D: 4.2 ± 2.7, respectively). Adults with higher anxiety symptoms did not present significant relationships associated with the acoustic parameters studied. Adults with increased depressive symptoms presented higher vowel duration, longer total pause duration and short total speech duration. Finally, age presented a positive and significant effect only for depressive symptoms, showing that older participants tend to have more depressive symptoms. Conclusions Non-severe depression symptoms can be related to some acoustic parameters and age. Depression symptoms can be explained by acoustic parameters even among individuals without severe symptom levels.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Prosodic Changes with Age: A Longitudinal Study on a Famous European Portuguese Native Speaker",
        "doc_scopus_id": "85116396250",
        "doc_doi": "10.1007/978-3-030-87802-3_65",
        "doc_eid": "2-s2.0-85116396250",
        "doc_date": "2021-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Different ages",
            "Human communications",
            "Longitudinal analysis",
            "Longitudinal study",
            "Pilot studies",
            "Prosodic features",
            "Prosodics",
            "Prosody",
            "Public figure",
            "Vocal aging"
        ],
        "doc_abstract": "© 2021, Springer Nature Switzerland AG.The understanding of human communication development throughout the lifetime involves the characterization of both segmental and suprasegmental parameters. This pilot study intends to analyse suprasegmental (i.e., prosodic) features in conversational longitudinal speech samples in uncontrolled environments. The ProsodyDescriptor Extractor was used to extract 17 prosodic features (intonation, intensity and rhythm measures) in a set of 90 speech intervals of 3 s to 6 s selected from three interviews collected in different ages of the same male public figure. Group mean comparison tests revealed that 14 prosodic features presented statistically significant differences between the three ages. In general, in comparison with his younger age, the speaker got a higher F0 mean level, more F0 variability, higher F0 peaks, more variable F0 peak values, less variable F0 falls, higher F0 min, less steeper F0 rises, less steeper F0 falls, less variable F0 rises, more energy in high frequencies, slower speech and articulation rate, less vocal effort and less variable global intensity. The longitudinal study of age-related changes in speech rhythm and intonation could contribute to the normal ageing process’ characterization, being a reference for clinical assessment and intervention.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Eppur si muove: Formant dynamics is relevant for the study of speech aging effects",
        "doc_scopus_id": "85103844634",
        "doc_doi": null,
        "doc_eid": "2-s2.0-85103844634",
        "doc_date": "2021-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Biomedical Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2204"
            },
            {
                "area_name": "Electrical and Electronic Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2208"
            }
        ],
        "doc_keywords": [
            "Age-related changes",
            "Automatic speech recognition system",
            "Dynamic information",
            "Formant dynamics",
            "Position papers",
            "Speech production",
            "Static approach",
            "Vowel perception"
        ],
        "doc_abstract": "Copyright © 2021 by SCITEPRESS – Science and Technology Publications, Lda. All rights reservedThe evidence have shown that speech change with age and the automatic speech recognition systems needs adaptation to older voices. Most of the acoustic studies about the age effects on speech production have focused on static approaches to obtain the vowel formants. However, vowel formant dynamics may also be important to characterize vowel quality and the age related changes. In this position paper the authors argue for the need to increase the use of dynamic information in acoustic studies. Among the main arguments, we can state that: speech is inherently dynamic; dynamic vowel formants improve the classification of vowels and dialects and play an important role in vowel perception; nowadays better tools allow to go beyond analysis of snapshots.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "A Comprehensive Analysis of Age and Gender Effects in European Portuguese Oral Vowels",
        "doc_scopus_id": "85097465521",
        "doc_doi": "10.1016/j.jvoice.2020.10.021",
        "doc_eid": "2-s2.0-85097465521",
        "doc_date": "2020-01-01",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Otorhinolaryngology",
                "area_abbreviation": "MEDI",
                "area_code": "2733"
            },
            {
                "area_name": "LPN and LVN",
                "area_abbreviation": "NURS",
                "area_code": "2912"
            },
            {
                "area_name": "Speech and Hearing",
                "area_abbreviation": "HEAL",
                "area_code": "3616"
            }
        ],
        "doc_keywords": [],
        "doc_abstract": "© 2020 The Voice FoundationThe knowledge about the age effects in speech acoustics is still disperse and incomplete. This study extends the analyses of the effects of age and gender on acoustics of European Portuguese (EP) oral vowels, in order to complement initial studies with limited sets of acoustic parameters, and to further investigate unclear or inconsistent results. A database of EP vowels produced by a group of 113 adults, aged between 35 and 97, was used. Duration, fundamental frequency (f0), formant frequencies (F1 to F3), and a selection of vowel space metrics (F1 and F2 range ratios, vowel articulation index [VAI] and formant centralization ratio [FCR]) were analyzed. To avoid the arguable division into age groups, the analyses considered age as a continuous variable. The most relevant age-related results included: vowel duration increase in both genders; a general tendency to formant frequencies decrease for females; changes that were consistent with vowel centralization for males, confirmed by the vowel space acoustic indexes; and no evidence of F3 decrease with age, in both genders. This study has contributed to knowledge on aging speech, providing new information for an additional language. The results corroborated that acoustic characteristics of speech change with age and present different patterns between genders.",
        "available": true,
        "clean_text": "serial JL 272877 291210 291723 291724 291743 31 Journal of Voice JOURNALVOICE 2020-12-05 2020-12-05 2020-12-05T19:39:43 S0892-1997(20)30412-4 S0892199720304124 10.1016/j.jvoice.2020.10.021 S200 S200.1 FULL-TEXT 2021-04-06T02:01:07.567985Z 0 0 20201205 2020 2020-12-05T21:42:09.803477Z aiptxt articleinfo articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid indexeddate issn issnnorm itemstage itemtransactionid itemweight openaccess openarchive pii piinorm pubdatestart pubdatetxt pubyr sortorder srctitle srctitlenorm srctype ssids alllist content subj subheadings tomb yearnav figure table body mmlmath acknowledge affil appendices articletitle auth authfirstini authfull authkeywords authlast primabst ref 0892-1997 08921997 In Press, Corrected Proof 0 Available online 5 December 2020 2020-12-05 2020 article fla © 2020 The Voice Foundation. Published by Elsevier Inc. All rights reserved. ACOMPREHENSIVEANALYSISAGEGENDEREFFECTSINEUROPEANPORTUGUESEORALVOWELS ALBUQUERQUE L Introduction Background Method Participants Corpus Recording protocol Segmentation Acoustic measurements Reliability in vowel segmentation Statistical analysis Results Vowel duration increased with age Age effects in f0 were gender dependent Age effects in formant frequencies were vowel and gender dependent Age and gender effects on acoustic vowel space Discussion Vowels Duration Fundamental Frequency Formant frequencies Study limitations and future work Conclusion Acknowledgments Appendix A Vowel Duration Appendix B Fundamental Frequency Appendix C Formant Frequencies References PORTUGAL 2019 S PORTUGAL 2015 S 2017 AGINGVOICE LINVILLE 2001 S VOCALAGING MAUTNER 2011 H ACROSSSYSTEMINSTRUMENTALVOICEPROFILEAGINGVOICECONSIDERATIONSJAWPOSTUREEFFECTS SCHOTZ 2006 S TRAVAUXDELINSTITUTDELINGUISTIQUEDELUND PERCEPTIONANALYSISSYNTHESISSPEAKERAGE LINVILLE 2001 323 330 S ALBUQUERQUE 2019 3965 3969 L INTERSPEECH AGERELATEDCHANGESINEUROPEANPORTUGUESEVOWELACOUSTICS ALBUQUERQUE 2014 940 944 L INTERSPEECH IMPACTAGEINPRODUCTIONEUROPEANPORTUGUESEVOWELS PELLEGRINI 2013 852 856 T INTERSPEECH ACORPUSBASEDSTUDYELDERLYYOUNGSPEAKERSEUROPEANPORTUGUESEACOUSTICCORRELATESIMPACTSPEECHRECOGNITIONPERFORMANCE GUIMARAES 2005 592 606 I MOU 2019 77 82 Z ARIASVERGARA 2017 731 748 T NEEL 2008 574 585 A MCCLOY 2014 060007 D MEETINGSACOUSTICS MODELINGINTRINSICINTELLIGIBILITYVARIATIONVOWELSPACESIZESTRUCTURE ROY 2009 124 135 N AUDIBERT 2015 5 9 N ICPHS15 DURATIONVSSTYLEDEPENDENTVOWELVARIATIONAMULTIPARAMETRICINVESTIGATION FOUGERON 2011 687 690 C ICPHSXVII TESTINGVARIOUSMETRICSFORDESCRIPTIONVOWELDISTORTIONINDYSARTHRIA GAHL 2019 42 54 S SAPIR 2011 173 175 S MAVEBA2011 ACOUSTICMETRICSVOWELARTICULATIONINPARKINSONSDISEASEVOWELSPACEAREAVSAVSVOWELARTICULATIONINDEXVAI SAPIR 2010 114 125 S RASTATTER 1990 312 319 M RASTATTER 1997 1 8 M ESCUDERO 2009 1379 1393 P OLIVEIRA 2012 129 138 C ADVANCESINSPEECHLANGUAGETECHNOLOGIESFORIBERIANLANGUAGESIBERSPEECH ACOUSTICANALYSISEUROPEANPORTUGUESEORALVOWELSPRODUCEDBYCHILDREN MARTINS 1973 303 314 M XUE 2003 689 701 S VIPPERLA 2010 1 10 R LANITIS 2010 34 52 A SATALOFF 1997 156 160 R JOHNSIII 2011 1 6 M GOY 2013 545 555 H EICHHORN 2018 644.e1 644.e9 J MA 2010 146 152 E NISHIO 2008 120 127 M TORREIII 2009 324 333 P YAMAUCHI 2014 525 531 A XUE 2001 159 168 S STATHOPOULOS 2011 1011 1021 E RAMIG 1983 22 30 L WATSON 2007 561 564 P ICPHSXVI ACOMPARISONVOWELACOUSTICSBETWEENOLDERYOUNGERADULTS HARRINGTON 2007 2753 2756 J INTERSPEECH AGERELATEDCHANGESINFUNDAMENTALFREQUENCYFORMANTSALONGITUDINALSTUDYFOURSPEAKERS ENDRES 1971 1842 1848 W DECOSTER 1999 1 5 F FLETCHER 2015 2132 2139 A SEBASTIAN 2012 81 84 S MERTENS 2020 J SECONDWORKSHOPSPEECHPERCEPTIONPRODUCTIONACROSSLIFESPANPOSTER AGINGEFFECTSPROSODICMARKINGINGERMANACOUSTICANALYSIS SMITH 1987 522 529 B BENJAMIN 1982 159 167 B SLAWINSKI 1994 2221 2230 E FOUGERON 2018 1905 C DRAXLER 2004 559 562 C LREC04 SPEECHRECORDERAUNIVERSALPLATFORMINDEPENDENTMULTICHANNELAUDIORECORDINGSOFTWARE KISLER 2017 326 347 T SCHIEL 1999 607 610 F 14THICPHS AUTOMATICPHONETICTRANSCRIPTIONNONPROMPTEDSPEECH SMILJANIC 2017 3081 3096 R SHROUT 1979 420 428 P LUTZROSS 2013 4107 A KENT 2018 74 97 R JACEWICZ 2009 233 256 E STEFFENS 2011 Y AGINGVOICE FIKKERT 2005 263 280 P MATEUS 2000 M PHONOLOGYPORTUGUESE VELOSO 2007 55 60 J JOURNEESDETUDESLINGUISTIQUES SCHWAINEUROPEANPORTUGUESEPHONOLOGICALSTATUSIMAGE32 VELOSO 2017 191 213 J SILVA 1994 79 84 D UTAWORKINGPAPERSINLINGUISTICS VARIABLEELISIONUNSTRESSEDVOWELSINEUROPEANPORTUGUESEACASESTUDY SILVA 1998 166 178 D REUBOLD 2010 638 651 U FERRAND 2002 480 487 C HIGGINS 1991 1000 1010 M PONTES 2005 84 94 P HOLLIEN 1972 155 159 H WIELING 2016 122 143 M SCUKANEC 1991 203 208 G FOX 2010 45 48 R EXLING2010 DIALECTGENERATIONALDIFFERENCESINVOWELSPACEAREAS © 2020 The Voice Foundation. Published by Elsevier Inc. All rights reserved. 2020-11-06T11:56:03.359Z FCT Fundação para a Ciência e a Tecnologia CIDMA Center for Research and Development in Mathematics and Applications item S0892-1997(20)30412-4 S0892199720304124 10.1016/j.jvoice.2020.10.021 272877 2021-04-06T02:01:07.567985Z 2020-12-05 true 1154464 MAIN 17 100645 849 656 IMAGE-WEB-PDF 1 gr1 46387 406 640 gr10 44690 453 678 gr11 42925 422 678 gr12 45790 422 678 gr2 42565 401 631 gr3 29795 260 339 gr4 49458 442 661 gr5 46010 443 678 gr6 47273 453 678 gr7 33929 258 339 gr8 48470 453 678 gr9 47240 446 678 fx32 322 7 4 gr1 5191 139 219 gr10 4763 146 219 gr11 4721 136 219 gr12 5069 136 219 gr2 5034 139 219 gr3 8309 164 213 gr4 5275 146 219 gr5 5199 143 219 gr6 5190 146 219 gr7 9965 164 215 gr8 5042 146 219 gr9 5212 144 219 fx32 439 37 20 gr1 436420 2159 3400 gr10 428778 2406 3600 gr11 397778 2241 3600 gr12 403756 2241 3600 gr2 393919 2129 3352 gr3 305801 1382 1800 gr4 448983 2348 3515 gr5 421754 2353 3600 gr6 444671 2405 3600 gr7 359754 1369 1800 gr8 444258 2405 3600 gr9 437950 2366 3600 fx32 572 37 20 si1 803 1 11 si10 2899 20 234 si11 1751 18 186 si12 2413 20 204 si13 3847 20 391 si14 2814 20 395 si15 2822 20 378 si16 2806 20 395 si17 2841 20 378 si18 4045 20 366 si19 2744 20 395 si2 966 16 32 si20 3944 20 387 si21 3979 20 387 si3 1064 16 32 si4 3949 20 440 si5 4025 20 439 si6 844 9 11 si7 862 9 12 si8 840 13 13 si9 2347 18 192 am 797869 YMVJ 3041 S0892-1997(20)30412-4 10.1016/j.jvoice.2020.10.021 The Voice Foundation Figure 1 Scatterplot and regression lines for vowels duration by age and gender. Each symbol corresponds to one speaker. Solid line and circles: females; dashed line and triangles: males. Fig. 1 Figure 2 Scatterplot and regression lines for mean f0 by age and gender. Each symbol corresponds to one speaker. Solid line and circles: females; dashed line and triangles: males. Fig. 2 Figure 3 Mean value of f0 as a function of vowel and age. Top: women; bottom: men. Solid lines: 35 years; dashed lines: 100 years. This figure was drawn using equations of linear regression (of each vowel by gender) replacing the variable age by 35 and 100 (as an approximation to the age of the oldest speaker of the sample). Fig. 3 Figure 4 Scatterplot and regression lines for mean F1 by age and gender. Each symbol corresponds to one speaker. Solid line and circles: females; dashed line and triangles: males. Fig. 4 Figure 5 Scatterplot and regression lines for mean F2 by age and gender. Each symbol corresponds to one speaker. Solid line and circles: females; dashed line and triangles: males. Fig. 5 Figure 6 Scatterplot and regression lines for mean F3 by age and gender. Each symbol corresponds to one speaker. Solid line and circles: females; dashed line and triangles: males. Fig. 6 Figure 7 Vowel Space for men and women as a function of age. Bold lines and symbols: women; non bold lines and symbols: men. Solid lines: 35 years; dashed lines: 100 years. This figure was drawn using equations of linear regression (of each vowel by gender for F1 and F2) replacing the variable age for 35 and 100 (as an approximation to the age of the oldest speaker of the sample). Fig. 7 Figure 8 Scatterplot of F1 as function of age and gender for vowel [a] with superimposed linear regression results. Each symbol corresponds to one speaker. Solid line and circles: females; dashed line and triangles: males. Fig. 8 Figure 9 Scatterplot of F2 as function of age and gender for vowel [u] with superimposed linear regression results. Each symbol corresponds to one speaker. Solid line and circles: females; dashed line and triangles: males. Fig. 9 Figure 10 Scatterplot and regression lines for F1RR by age and gender. Each symbol corresponds to one speaker. Solid line and circles: females; dashed line and triangles: males. Fig. 10 Figure 11 Scatterplot and regression lines for F2RR by age and gender. Each symbol corresponds to one speaker. Solid line and circles: females; dashed line and triangles: males. Fig. 11 Figure 12 Scatterplot and regression lines for VAI by age and gender. Each symbol corresponds to one speaker. Solid line and circles: females; dashed line and triangles: males. Fig. 12 Table 1 List of Words Per Vowel (International Phonetic Alphabet) Table 1 Oral vowels Words Stressed [i] [ˈfitɐ] (ribbon) [ˈbiku] (beak) [ˈfiɡu] (fig) [ˈpizɐ]* (pizza) [e] [ˈseʃtɐ] (basket) [ˈdedu] (finger) [ˈpezu] (weight) [ˈzebɾɐ] (zebra) [ɛ] [ˈsɛtɨ] (seven) [ˈtɛtu] (ceiling) [ˈsɛtɐ] (arrow) [ˈʃɛkɨ] (check) [a] [ˈʃavɨ] (key) [ˈfakɐ] (knife) [ˈɡatu] (cat) [ˈpatu] (duck) [ɔ] [ˈkɔpu] (glass) [ˈbɔtɐ] (boot) [ˈfɔkɐ] (seal) [ˈtɔʃɐ]* (torch) [o] [ˈbokɐ] (mouth) [ˈkoku] (coconut) [ˈposu] (well) [ˈɡotɐʃ] (drops) [u] [ˈʃuvɐ] (rain) [ˈʃupɐ]* (lollipop) [ˈkubu]* (cube) [ˈʒubɐ]* (mane) Unstressed [ɐ] [kɐˈfɛ] (coffee) [ʃɐˈpɛw] (hat) [pɐˈtĩʃ] (rollerblades) [pɐˈpɛɫ] (paper) [ɨ] [bɨˈbeɾ] (to drink) [dɨˈdaɫ] (thimble) [pɨˈdaɫ] (pedal) [pɨʃˈkaɾ]* (to fish) ⁎ The pictogram of this word presented a naming percentage of accuracy lower than 70%. Table 2 Results of Multiple Linear Regression: the Effect of Gender and Gender*Age Interaction on F1, F2, and F3 Values by Vowel Table 2 Intercept Gender (Male) Male * Age Female * Age Vowel B 95% CI B 95% CI B 95% CI B 95% CI F1 ɨ 371.54 329.35 413.73 − 52.17 − 112.77 8.42 0.46 − 0.21 1.14 0.11 − 0.55 0.78 ɐ 484.63 433.43 535.82 − 25.67 − 99.20 47.87 − 0.03 − 0.85 0.79 0.25 − 0.55 1.06 a 921.76 832.36 1011.17 − 99.06 − 227.47 29.36 − 1.96 − 3.39 − 0.53 − 1.05 − 2.45 0.36 e 409.51 375.87 443.14 − 62.75 − 111.06 − 14.45 0.62 0.08 1.16 − 0.04 − 0.57 0.49 ɛ 554.03 509.26 598.81 − 49.76 − 114.07 14.56 0.08 − 0.63 0.80 − 0.10 − 0.80 0.61 i 318.92 286.36 351.48 − 59.60 − 106.37 − 12.84 0.48 − 0.04 1.00 0.04 − 0.47 0.55 o 442.72 408.10 477.35 − 50.73 − 100.46 − 1.00 0.05 − 0.51 0.60 − 0.35 − 0.90 0.20 ɔ 674.54 618.92 730.16 − 96.78 − 176.66 − 16.89 − 0.75 − 1.64 0.14 − 1.21 − 2.08 − 0.33 u 382.67 349.98 415.36 − 74.90 − 121.85 − 27.95 0.06 − 0.46 0.58 − 0.65 − 1.16 − 0.14 Mean 506.70 476.77 536.64 − 63.49 − 106.49 − 20.49 − 0.11 − 0.59 0.37 − 0.33 − 0.80 0.14 F2 ɨ 1523.01 1390.08 1655.93 − 165.49 − 356.40 25.42 0.39 − 1.74 2.51 1.79 − 0.30 3.88 ɐ 1815.24 1710.26 1920.22 − 254.28 − 405.06 − 103.50 − 0.30 − 1.97 1.38 0.31 − 1.35 1.96 a 1563.46 1478.31 1648.62 − 287.37 − 409.67 − 165.06 1.07 − 0.29 2.43 − 0.06 − 1.41 1.28 e 2392.12 2239.69 2544.55 − 373.59 − 592.51 − 154.66 − 1.69 − 4.12 0.75 − 0.81 − 3.21 1.59 ɛ 2255.71 2121.54 2389.87 − 430.60 − 623.30 − 237.90 − 0.35 − 2.50 1.79 − 0.74 − 2.85 1.38 i 2642.45 2487.84 2797.06 − 264.11 − 486.18 − 42.05 − 2.85 − 5.32 − 0.38 − 0.37 − 2.80 2.07 o 924.77 859.08 990.46 − 114.96 − 209.31 − 20.61 0.40 − 0.65 1.45 − 0.31 − 1.34 0.73 ɔ 1133.93 1071.55 1196.31 − 220.95 − 310.55 − 131.36 0.56 − 0.44 1.56 − 1.19 − 2.18 − 0.21 u 1012.17 882.36 1141.98 − 219.64 − 406.08 − 33.20 2.30 0.23 4.38 − 0.14 − 2.18 1.91 Mean 1695.87 1628.39 1763.36 − 259.00 − 355.92 − 162.07 − 0.05 − 1.13 1.03 − 0.17 − 1.23 0.89 F3 ɨ 2875.24 2713.98 3036.49 − 271.48 − 503.08 − 39.88 − 1.89 − 4.47 0.69 0.47 − 2.07 3.01 ɐ 2805.99 2644.83 2967.15 − 366.92 − 598.39 − 135.46 − 1.40 − 3.98 1.17 − 0.74 − 3.28 1.80 a 2561.37 2354.48 2768.25 − 315.25 − 612.39 − 18.11 1.74 − 1.56 5.05 1.27 − 1.99 4.53 e 2912.49 2760.88 3064.10 − 424.42 − 642.17 − 206.67 − 0.11 − 2.53 2.31 − 0.02 − 2.41 2.36 ɛ 2903.41 2736.52 3070.30 − 502.15 − 741.85 − 262.44 0.82 − 1.85 3.49 − 1.15 − 3.77 1.48 i 3257.24 3024.54 3489.94 − 313.60 − 647.82 20.62 − 3.05 − 6.77 0.67 − 2.32 − 5.98 1.35 o 2913.92 2724.79 3103.05 − 484.69 − 756.33 − 213.05 − 0.37 − 3.39 2.66 − 0.98 − 3.96 2.00 ɔ 2766.86 2554.54 2979.18 − 447.83 − 752.78 − 142.88 0.62 − 2.78 4.01 − 0.69 − 4.03 2.65 u 3002.76 2819.95 3185.58 − 619.73 − 882.30 − 357.16 − 0.97 − 3.90 1.95 − 4.40 − 7.28 − 1.52 Mean 2888.81 2757.77 3019.84 − 416.23 − 604.43 − 228.03 − 0.51 − 2.61 1.58 − 0.95 − 3.01 1.11 B = Linear Coefficient ⁎ Grey cells represent significant results (P < 0.05). Table A1 Mean and Standard Deviation (SD) of Vowel Duration Values (ms) Table A1 Male Female [35–49] [50–64] [65–79] ≥ 80 [35–49] [50–64] [65–79] ≥ 80 Mean (SD) Mean (SD) Mean (SD) Mean (SD) Mean (SD) Mean (SD) Mean (SD) Mean (SD) ɨ 71.5 (14.3) 75.2 (13.3) 77.7 (15.4) 75.5 (15.8) 71.2 (9.8) 74.1 (12.8) 76.6 (17.2) 80.3 (14.6) ɐ 57.6 (10.0) 59.1 (7.5) 60.9 (10.6) 67.1 (11.0) 56.5 (9.3) 58.8 (5.6) 61.8 (10.6) 64.3 (12.1) a 135.0 (17.9) 136.4 (18.7) 138.6 (23.6) 151.2 (30.8) 132.2 (27.1) 143.2 (23.9) 156.3 (20.2) 159.4 (33.3) e 132.4 (17.3) 138.0 (16.9) 141.4 (23.1) 154.5 (29.1) 130.3 (23.1) 140.9 (20.1) 153.5 (14.3) 167.2 (38.2) ɛ 114.9 (15.9) 116.2 (16.8) 121.5 (25.6) 143.1 (31.0) 113.0 (20.2) 123.4 (18.2) 141.3 (18.2) 144.4 (32.4) i 107.6 (16.5) 111.9 (21.1) 118.1 (29.1) 140.5 (30.8) 101.7 (18.9) 112.5 (20.1) 131.8 (18.0) 143.8 (32.2) o 115.7 (10.4) 120.8 (18.2) 128.1 (25.0) 146.4 (29.9) 111.5 (20.1) 118.8 (22.9) 136.9 (19.7) 146.5 (38.7) ɔ 114.9 (17.6) 119.3 (16.6) 127.7 (27.0) 145.6 (32.0) 119.7 (25.6) 127.1 (24.6) 146.9 (15.6) 152.2 (37.4) u 110.3 (23.1) 119.9 (18.4) 118.5 (23.8) 140.5 (36.4) 107.2 (27.1) 112.1 (25.5) 136.9 (17.9) 145.6 (44.8) Mean 106.7 (12.8) 110.8 (14.0) 114.7 (19.9) 129.4 (23.8) 104.8 (17.8) 112.3 (16.4) 126.9 (12.5) 133.7 (28.5) Table B1 Mean and standard deviation of vowel f0 values. Table B1 Male Female [35-49] [50-64] [65-79] ≥ 80 [35-49] [50-64] [65-79] ≥ 80 Mean (SD) Mean (SD) Mean (SD) Mean (SD) Mean (SD) Mean (SD) Mean (SD) Mean (SD) ɨ 138.8 (22.3) 133.3 (27.9) 128.4 (27.5) 134.6 (19.4) 203.9 (31.3) 213.0 (45.2) 195.7 (32.5) 173.2 (17.9) ɐ 140.0 (25.6) 130.6 (23.4) 124.8 (26.2) 137.1 (19.8) 210.8 (29.7) 213.5 (41.4) 196.6 (33.0) 172.1 (14.8) a 133.1 (28.5) 126.6 (23.3) 127.5 (33.2) 143.0 (23.2) 180.8 (15.7) 188.8 (25.6) 170.0 (17.5) 174.0 (19.3) e 141.4 (29.3) 135.2 (27.9) 136.1 (36.7) 153.4 (28.3) 195.1 (21.6) 203.9 (30.9) 183.2 (20.3) 186.0 (18.6) ɛ 138.1 (31.6) 130.2 (24.2) 132.7 (34.3) 148.4 (25.8) 188.7 (19.6) 193.3 (28.3) 176.7 (22.1) 179.4 (16.3) i 146.7 (31.4) 138.6 (26.1) 143.5 (36.3) 158.9 (32.1) 202.7 (20.3) 212.8 (33.1) 192.6 (22.7) 193.2 (18.7) o 143.7 (30.6) 135.5 (25.8) 136.9 (33.0) 153.9 (28.4) 196.4 (20.2) 206.9 (33.2) 186.8 (24.3) 187.7 (18.0) ɔ 138.1 (29.3) 131.4 (25.1) 130.5 (34.6) 148.4 (24.9) 188.4 (17.7) 196.1 (29.4) 175.7 (20.9) 180.2 (18.2) u 149.3 (31.4) 142.2 (28.6) 145.8 (34.7) 160.6 (30.9) 206.2 (20.1) 214.9 (38.5) 194.8 (25.0) 195.0 (18.6) Mean 141.0 (27.6) 133.7 (25.0) 134.0 (31.7) 148.7 (25.3) 197.0 (19.3) 204.8 (30.7) 185.8 (20.9) 182.3 (15.7) Table C1 Mean and standard deviation of vowel F1, F2 and F3 values. Table C1 Male Female [35-49] [50-64] [65-79] ≥ 80 [35-49] [50-64] [65-79] ≥ 80 Mean (SD) Mean (SD) Mean (SD) Mean (SD) Mean (SD) Mean (SD) Mean (SD) Mean (SD) F1 ɨ 336.5 (32.2) 347.8 (25.9) 356.1 (35.5) 354.5 (44.6) 375.8 (44.8) 381.5 (45.0) 380.5 (52.0) 374.2 (27.7) ɐ 458.4 (37.9) 455.4 (34.7) 459.0 (38.3) 455.9 (41.5) 481.2 (39.2) 523.7 (74.9) 499.0 (54.2) 495.4 (37.5) a 741.7 (54.0) 698.8 (64.5) 682.5 (74.7) 668.1 (56.7) 885.4 (111.7) 860.2 (92.8) 842.1 (114.4) 835.6 (74.3) e 369.3 (34.0) 385.1 (28.3) 396.4 (36.4) 394.3 (30.8) 406.7 (24.5) 420.0 (33.3) 395.3 (27.5) 408.0 (31.2) ɛ 507.0 (39.3) 503.1 (37.2) 511.2 (50.5) 518.5 (21.9) 544.2 (37.3) 568.4 (52.3) 531.9 (40.0) 549.4 (36.4) i 288.0 (34.3) 280.3 (23.5) 286.6 (24.4) 308.6 (24.9) 312.8 (36.4) 331.3 (29.7) 323.3 (26.7) 316.7 (38.7) o 387.8 (33.9) 401.8 (29.1) 398.5 (34.4) 390.9 (34.9) 427.6 (28.8) 431.0 (35.0) 411.1 (31.3) 413.3 (28.6) ɔ 544.8 (41.3) 527.4 (38.4) 529.2 (51.4) 517.7 (33.7) 625.9 (63.1) 613.3 (68.6) 586.7 (48.6) 563.5 (60.2) u 314.8 (27.2) 308.4 (22.4) 306.2 (26.1) 319.2 (21.0) 348.6 (35.1) 359.9 (38.5) 327.4 (28.0) 332.5 (38.6) Mean 438.7 (26.5) 434.2 (25.4) 436.2 (30.6) 436.4 (22.0) 489.8 (25.8) 498.8 (33.8) 477.5 (30.8) 476.5 (21.4) F2 ɨ 1378.5 (131.8) 1366.1 (99.4) 1413.4 (115.5) 1363.6 (185.3) 1597.0 (127.1) 1607.6 (101.7) 1667.0 (131.2) 1671.9 (87.9) ɐ 1547.9 (114.2) 1534.5 (51.2) 1561.7 (96.7) 1519.8 (82.8) 1803.6 (84.1) 1835.1 (115.1) 1893.2 (89.5) 1784.3 (105.9) a 1331.5 (69.4) 1324.9 (60.4) 1358.1 (88.1) 1363.0 (104.6) 1543.3 (77.0) 1580.5 (87.4) 1548.9 (65.7) 1569.5 (90.1) e 1959.8 (99.7) 1912.2 (109.2) 1894.1 (155.9) 1875.3 (114.4) 2342.3 (162.5) 2343.8 (169.5) 2384.6 (161.8) 2272.7 (125.9) ɛ 1813.6 (110.4) 1809.1 (90.3) 1787.6 (126.7) 1801.5 (97.0) 2222.2 (146.4) 2200.8 (144.0) 2226.4 (143.6) 2181.4 (135.0) i 2256.7 (120.1) 2217.3 (113.3) 2173.2 (161.2) 2134.7 (121.4) 2623.1 (170.8) 2618.6 (147.4) 2621.5 (183.3) 2614.9 (115.9) o 825.8 (51.7) 849.3 (60.5) 825.8 (48.3) 840.4 (72.3) 908.2 (61.6) 917.5 (66.3) 887.6 (53.7) 913.5 (82.2) ɔ 945.4 (55.9) 941.8 (37.0) 951.2 (62.4) 955.4 (67.8) 1084.5 (72.6) 1071.0 (46.0) 1045.1 (56.0) 1033.1 (74.6) u 914.4 (102.3) 908.9 (65.7) 953.9 (126.5) 981.7 (136.4) 991.2 (134.6) 996.2 (147.2) 1045.4 (115.6) 967.9 (141.4) Mean 1441.5 (63.6) 1429.3 (41.3) 1435.4 (74.1) 1426.2 (72.7) 1679.5 (65.7) 1685.7 (61.6) 1702.2 (66.9) 1667.7 (52.1) F3 ɨ 2477.5 (142.4) 2532.8 (152.7) 2514.4 (146.7) 2392.5 (170.4) 2880.1 (111.9) 2930.8 (119.5) 2899.2 (202.8) 2907.3 (116.4) ɐ 2360.1 (185.0) 2355.2 (130.7) 2377.8 (120.6) 2297.3 (160.4) 2776.4 (125.7) 2733.1 (173.4) 2772.6 (183.2) 2759.1 (89.7) a 2298.1 (127.4) 2358.0 (189.4) 2402.8 (139.6) 2365.0 (215.2) 2625.5 (180.8) 2591.3 (209.1) 2668.9 (210.5) 2685.5 (279.1) e 2492.4 (110.0) 2480.1 (149.6) 2476.0 (128.3) 2474.4 (162.0) 2899.0 (97.7) 2912.9 (173.1) 2932.7 (162.5) 2891.2 (150.7) ɛ 2424.8 (178.2) 2481.7 (187.4) 2431.3 (91.2) 2479.9 (205.6) 2855.9 (105.4) 2826.5 (129.7) 2822.2 (176.4) 2825.3 (164.5) i 2777.7 (170.7) 2816.2 (223.1) 2699.2 (219.0) 2703.4 (222.0) 3175.7 (243.3) 3086.6 (194.6) 3130.9 (255.0) 3039.2 (205.9) o 2386.2 (125.5) 2429.5 (134.8) 2425.4 (123.8) 2376.2 (137.2) 2870.7 (209.1) 2860.1 (223.3) 2818.8 (238.0) 2873.5 (169.8) ɔ 2311.2 (156.0) 2389.4 (181.7) 2395.2 (136.3) 2326.5 (202.6) 2740.3 (192.4) 2709.7 (237.0) 2727.8 (259.7) 2716.6 (195.6) u 2325.7 (128.1) 2348.7 (144.5) 2328.6 (152.5) 2272.0 (153.1) 2768.9 (208.9) 2811.1 (215.4) 2698.7 (184.8) 2611.3 (158.6) Mean 2428.2 (84.0) 2465.7 (104.7) 2450.1 (112.4) 2409.7 (142.9) 2843.6 (120.0) 2829.1 (137.5) 2830.2 (162.6) 2812.1 (101.8) A Comprehensive Analysis of Age and Gender Effects in European Portuguese Oral Vowels A Comprehensive Analysis of Age and Gender Effects in European Portuguese Oral Vowels Luciana Albuquerque ⁎ ⁎ † ‡ § Catarina Oliveira ⁎ ║ António Teixeira ⁎ ‡ Pedro Sa-Couto ¶ # Daniela Figueiredo † ║ ⁎ Institute of Electronics and Informatics Engineering of Aveiro, University of Aveiro, Aveiro, Portugal Institute of Electronics and Informatics Engineering of Aveiro University of Aveiro Aveiro Portugal *Institute of Electronics and Informatics Engineering of Aveiro, University of Aveiro, Aveiro, Portugal † Center for Health Technology and Services Research, University of Aveiro, Aveiro, Portugal Center for Health Technology and Services Research University of Aveiro Aveiro Portugal †Center for Health Technology and Services Research, University of Aveiro, Aveiro, Portugal ‡ Department of Electronics Telecommunications and Informatics, University of Aveiro, Aveiro, Portugal Department of Electronics Telecommunications and Informatics University of Aveiro Aveiro Portugal ‡Department of Electronics Telecommunications and Informatics, University of Aveiro, Aveiro, Portugal § Department of Education and Psychology, University of Aveiro, Aveiro, Portugal Department of Education and Psychology University of Aveiro Aveiro Portugal §Department of Education and Psychology, University of Aveiro, Aveiro, Portugal ║ School of Health Science, University of Aveiro, Aveiro, Portugal School of Health Science University of Aveiro Aveiro Portugal ║School of Health Science, University of Aveiro, Aveiro, Portugal ¶ Center for Research and Development in Mathematics and Applications, University of Aveiro, Aveiro, Portugal Center for Research and Development in Mathematics and Applications University of Aveiro Aveiro Portugal ¶Center for Research and Development in Mathematics and Applications, University of Aveiro, Aveiro, Portugal # Department of Mathematics, University of Aveiro, Aveiro, Portugal Department of Mathematics University of Aveiro Aveiro Portugal #Department of Mathematics, University of Aveiro, Aveiro, Portugal ⁎ Address correspondence and reprint requests to: Luciana Albuquerque, IEETA, Universidade de Aveiro Departamento de Electronica Telecomunicacoes e Informatica, Campus Universito de Santiago, 3770-058 Aveiro, Portugal. IEETA, Universidade de Aveiro Departamento de Electronica Telecomunicacoes e Informatica, Campus Universito de Santiago Aveiro 3770-058 Portugal The knowledge about the age effects in speech acoustics is still disperse and incomplete. This study extends the analyses of the effects of age and gender on acoustics of European Portuguese (EP) oral vowels, in order to complement initial studies with limited sets of acoustic parameters, and to further investigate unclear or inconsistent results. A database of EP vowels produced by a group of 113 adults, aged between 35 and 97, was used. Duration, fundamental frequency (f0), formant frequencies (F1 to F3), and a selection of vowel space metrics (F1 and F2 range ratios, vowel articulation index [VAI] and formant centralization ratio [FCR]) were analyzed. To avoid the arguable division into age groups, the analyses considered age as a continuous variable. The most relevant age-related results included: vowel duration increase in both genders; a general tendency to formant frequencies decrease for females; changes that were consistent with vowel centralization for males, confirmed by the vowel space acoustic indexes; and no evidence of F3 decrease with age, in both genders. This study has contributed to knowledge on aging speech, providing new information for an additional language. The results corroborated that acoustic characteristics of speech change with age and present different patterns between genders. Key Words Aging voice Acoustic Oral vowel European Portuguese Introduction According to the World Health Organization 1,2 the number of people aged over 65 is increasing as a result of longer life expectancy and also of declining fertility rates. Portugal is one of the developed countries with the highest rate of older population (between 1970 and 2018, the percentage of people aged 65 and over increased from 9.7% to 21.8%). 3,4 Aging involves changes at physiological, cognitive, psychological, and social levels. Age-related changes take place in different tissues and organs, and the vocal system is no exception. 5 Moreover there are substantial gender differences in the extent and timing of the aging process. 5–8 The anatomical and physiological changes in the speech organs (eg, decreased lung capacity; ossification and calcification of the laryngeal cartilages and vocal fold atrophy) 5,8,9 are reflected in the variation of several acoustic parameters, namely in the decrease of the speaking rate, in the increase of speech pauses, in the variation of the fundamental frequency (f0), in the pattern changes of the formant frequencies and in the increase jitter and shimmer, among others. 8,9 Unlike other languages, in which age-related speech variations have been widely studied since the 1960s, 8 on what concerns European Portuguese (EP) there are only a few studies about segmental and supra-segmental changes motivated by aging. 10–13 For these reasons, the purpose of this study is to extend the analyses of the age effects on duration, f0 and formant frequencies (F1, F2, and F3) for all EP oral vowels produced by a large group of healthy speakers. A more in-depth analysis of the age effect on each vowel was performed, using the database created for the authors initial studies. 10 To complement the initial inconclusive results obtained with vowel space area (VSA), which is a well established acoustic metric, 14–18 other acoustic indexes were adopted to further investigate age and gender effects. The first formant range ratio (F1RR) and second formant range ratio (F2RR) were selected to model possible reduction in the articulatory capability of speakers. 19–21 Vowel articulation index (VAI) and formant centralization ratio (FCR) were included to maximize sensitivity to vowel formant centralization and minimize sensitivity to interspeaker variability. 22,23 The general assumption is that young speakers have a better articulation capability than older speakers, thus young adults are able to move their tongue with greater amplitudes and they are able to hold it longer in certain positions. 24,25 The present study extends the analyses of previous researches 10,11 by including F3 values and different vowel space metrics from Portuguese adults covering the age range of 35–97, which is essential to provide a more complete view of age-related changes in EP vowel acoustics. As novelty this study considers age as a continuous variable in the analysis avoiding the effects of arbitrary age groups division. Thus, age-related changes in vowel acoustics are analyzed using multiple linear regression. Since there is a paucity of literature on EP vowel acoustics and the available data were collected from a small number of speakers, 11,26–28 this study also provides valuable insights to an accurate description of these sounds. The natural process of aging has a significant impact on the acoustic measurements of speakers’ vocal output. 29 Accordingly, it is very important that voice clinicians be aware of such effects and use discretion when making acoustic diagnoses and clinical judgments of elderly clients’ voices. 29 A deeper knowledge of how speech changes with age is also essential for the development of automatic speech recognition systems suitable for elderly’s voices (eg, personalized reading aids and voice prostheses), 30 for the provision of information for biometric recognition 31 and forensics, and for clinical assessment and treatment of speech disorders. 32,33 Background Numerous studies have evaluated the effects of aging on the acoustic properties of speech. 6,8,30 Most of them have focused on f0 and have shown a decrease with aging in women 8,34–39 ; for men there is less agreement among researches, with some studies indicating that f0 significantly decreases above 60, 30,40 and others suggesting an f0 drop in men over the age range 30–50 and then an increase in f0 in older age. 6–8,35–38,41,42 Other studies have reported on age-related changes to formants (mostly F1 and F2, neglecting higher formants), particularly in the production of vowels. The conclusions across studies are inconsistent, with some studies showing an age-dependent formant frequency lowering 9,29,43–46 and others reporting no changes in formant frequencies. 47,48 In some cases the formant frequencies varied with vowel and a gender-vowel interaction was found. 8,35 In addition, some studies have referred a centralization of the vowel space in older speakers (which should result in movement to the centroid of formant space). 8,24,25,38,49 It has often been noted that older adults use slower speaking rates, 6,8,50 that is, vocal aging implies a decrease in the number of syllables and phonemes per second, which leads to the increase of segment duration. 6,8,47,51–53 The few data available for the EP have indicated an f0 drop of 20 Hz with advanced age in women, while for men no age-related changes were observed, when comparing young adults (aged 19–30) with two groups of older adults (aged 60–75 and over 75). 12 Another study 13 reported a trend of decrease in f0 with aging in both genders (comparing speakers aged between [19–40] and [41–67]) in different speech tasks, but those changes were not statistically significant. In addition, Pellegrini et al 12 showed a greater centralization of the vowel space in younger speakers, and a significant increase in vowels duration with age for both genders. Our previous studies 10,11 and Pellegrini et al, 12 presented consistent results concerning vowel duration, showing a significantly increase with aging. On the subject of f0 and formant frequencies, the results were not consistent and seemed to be different among vowels. 10,11 Given that those previous researches used different corpora and analysis procedures, and focused on different acoustic parameters, it is hard at this time to draw solid conclusions on the effects of age and gender on each EP oral vowel. In general, only the decrease in vowel duration in both genders and a trend for f0 decrease in women with aging seems to be more consensual. 10–12 Method This cross-sectional study was approved by the Ethics Committee Centro Hospitalar São João/ Faculty of Medicine, University of Porto, Portugal (approval number N38/18), and all participants agreed and signed the consent form before participating in the study. Participants A total of 113 native Portuguese speakers (56 men and 57 women), from the central region of Portugal, aged between 35 and 97, participated in this study. To ensure an equitable distribution of participants, the following age groups were covered: [35–49] (15 men, 15 women), [50–64] (15 men, 15 women), [65–79] (15 men, 16 women), and ≥ 80 (11 men, 11 women). A 80-year-old woman was excluded during the acoustic data analysis. Participants were recruited through personal contacts and through snowball technique in the community, and in Senior Universities from the center of Portugal, and also in the University of Aveiro. Each participant completed a written questionnaire to gather information about socio-demographic characteristics, medical and voice related history, smoking habits, alcohol, water and caffeine consumption, support device needs and environmental conditions. For more details about the study design see Albuquerque et al. 10 Corpus The speech corpus consisted of 36 words, with the EP vowels [i], [e], [ɛ], [a], [o], [ɔ], [u] in stressed position and the vowels [ɨ] and [ɐ] in unstressed position. Each vowel was produced in a disyllabic sequence, mostly CV.CV (C-consonant, V-vowel) (eg, “pato”, duck), where C was a voiced/ voiceless stop consonant ([p], [t], [k], [b], [d], [ɡ]) or a voiced/ voiceless fricative consonant ([f], [s], [ʃ], [v], [z], [ʒ]). The list of 36 words used in this study is listed in Table 1 . The speech stimuli were carefully chosen to allow easy and accurate formant measure since the vowel context is restricted to stop and fricative consonants. The corpus was also designed to collect data over the life span. So, the words were therefore chosen to be familiar to all ages, and also, easily represented by images (to avoid the interference of reading abilities in the words production). A pilot naming study was carried out for the selection of these images. Sixty-three pictures were selected from color pictograms of Palao 54 and presented to a group of 10 participants (5 males and 5 females), ranging from 28 to 86. The results indicated that adult participants were able to properly name most of the pictures (percentage of accuracy equal or higher than 70% excepted for 6 images) (see Table 1). However, these stimuli remained in the study due to the difficulty in finding alternative words that met the previously defined criteria. The stimuli were embedded in a carrier sentence “Diga... por favor” (“Say... please”). Recording protocol Recordings took place in quiet rooms in several institutions using an AKG condenser microphone and USB external soundcard (PreSonus), with a sampling rate of 44,100 Hz. The participants were seated at a table and the microphone was adjusted to each participant and positioned at an approximately 15–20 cm distance from the mouth. The sentences were randomized and presented on the computer screen with software system SpeechRecorder 55,56 using pictures together with the orthographic word. Participants were asked to read the sentences at comfortable pitch and loudness level, after familiarizing themselves with the structure of the sentences. Additionally, they could take a break at any time they wanted and each speaker attended a single recording session. Each carrier sentence was repeated three times. Thus, each participant produced 12 repetitions of each vowel, in a total of 108 productions by speaker (113 participants x 36 words x 3 repetitions = 12 204 recordings), and needed approx. 15 minutes to complete this task. The same researcher was present in all recording sessions. Segmentation The recorded data was first automatically segmented at word and phoneme level using WebMAUS General for Portuguese language (PT) 57,58 and then imported into Praat speech analysis software, 59 so that four trained analyzers could manually check the accuracy of the vowel boundaries. The start and end points of the vowel were determined by finding the first and last periods that had considerable amplitude and whose shape resembled that of more central periods, with both points of the selection chosen to be at a positive zero crossing of the waveform. A total of 736 recordings were discarded (approximately 6% of trials) due to problems with the recordings (eg, clipping, noise, misread, hoarseness or vocal fry) or vowel reduction (vowel [ɨ] was the most deleted vowel (359 vowels [ɨ] corresponding to 26.7%), mostly in the context of “pescar” ([pɨʃˈkaɾ] - to fish). Acoustic measurements Acoustic parameters (f0 and formant frequencies) were automatically extracted from the central 40% of each target vowel using Praat scripts. 26 Median f0 value of the vowels was estimated with the cross-correlation algorithm. 26 The pitch range for the analysis was set to 60–400 Hz for men and 120–400 Hz for women. If the analysis failed on any of the speaker’s vowel tokens, that token was excluded (31 vowels, most of them produced by an 80-year-old woman, which we decided to exclude from all the analysis). Burg-LPC algorithm, as provided by Praat, was used to compile values for F1, F2, and F3. A procedure (adapted from Escudero et al, 26 ) was applied to optimize the formant ceiling for a certain vowel of a certain speaker. The first three formants were determined 201 times for each vowel, for all ceilings between 4500 and 6500 Hz for female and between 4000 and 6000 Hz for male, in steps of 10 Hz. The chosen ceiling was the one that yielded the lowest variation. Thus, for each vowel produced by each speaker there is only one “optimal ceiling” (for more details see Escudero et al. 26 ). The duration measurements were computed from the label files with reference to the beginning and the ending points of each vowel. Vowels with duration values shorter than 20 ms were excluded (8 vowels), and outliers that exceeded 2.5 standard deviations from the mean for particular speaker by f0 and from their gender x vowel mean by F1 and F2 were also excluded from this analysis. 35,60 In this study, the measurements for duration, f0, F1–F3 were manually checked for possible extraction errors and these procedures yielded in 695 outliers removed (nearly 1.5% of the total data). The F1RR is defined as the ratio of the F1 of the low vowel [a] and the (geometric) average F1 of the high vowels [i] and [u] by speaker. 19,20,26 The F2RR is computed as the ratio of the F2 of vowel [i] and the F2 of the vowel [u] for each speaker. 19,20,23,26 The VAI is calculated using the formula: (1) VAI = ( F 2 [ i ] + F 1 [ a ] ) / ( F 2 [ u ] + F 2 [ a ] + F 1 [ u ] + F 1 [ i ] ) , and its inverse, the FCR, is calculated as: (2) FCR = ( F 2 [ u ] + F 2 [ a ] + F 1 [ u ] + F 1 [ i ] ) / ( F 2 [ i ] + F 1 [ a ] ) 18,22,23 Note that the F1 and F2 coordinates of the EP corner vowels [a], [i] and [u] were used to calculate the VAI and FCR metrics, so the FCR should increase with centralization and decrease with vowel expansion, and the opposite for VAI. 22,23 Reliability in vowel segmentation To determine inter- and intra-rater reliability of the measures, 36 textgrids of each analyzer (1 textgrid randomly selected from each word) were re-labeled for all analyzers. So, 144 (1.2%) of a total of 12 204 textgrids (113 participants * 36 stimulus * 3 repetitions) were manually re-labelled for reliability by the four judges. The scripts to obtain vowel duration and formant frequencies were then re-administered. Inter and intrarater reliability was assessed using the intraclass correlation coefficient (ICC) and two-way mixed model (the raters were considered fixed) with an absolute agreement definition. Reliability among the raters was considered excellent, with ICC values > 0.952 for all vowels/ acoustic parameters (duration, f0, F1, F2, F3), except F1 of [ɨ] where ICC was 0.846, but still considered good reliability. 61 To assess intra-rater reliability, a random sample of 36 textgrids (one of each stimuli) was manually rechecked by the same rater. Again, reliability was excellent with ICC values > 0.909 for all vowels/ acoustic parameters. 61 Statistical analysis The statistical analysis was conducted with the SPSS software package (SPSS 25.0 - SPSS Inc., Chicago, Illinois). The values of f0, F1, F2, and F3 were computed for all productions, and subsequently, the median of repetitions was performed for each vowel and speaker. Descriptive data reported the mean for age group. For each vowel and acoustic parameter (duration, f0, F1, F2, and F3), a multiple linear regression was conducted with the following explanatory variables: age (continuous), gender (male: reference group, female), and the interaction between age and gender. The model presented by the software considered age and gender (female) redundant (presenting instead the interactions “male*age” and “female*age”) and no values are presented for those (independent) variables. Also, a multiple linear regression was conducted with the same explanatory variables for F1RR, F2RR, VAI, FCR, and for mean values of all vowels by acoustic parameter. The regression coefficients and the correspondent 95% IC were calculated. The residuals Normality was tested (Kolmogorov-Smirnov Test) and verified with the visual inspection of the Q-Q plot. Results This section presents the detailed results of the acoustic measurements and statistical analysis aimed at investigating differences by age and gender for f0 and formant frequencies of all vowels. To avoid effects of arbitrary age groups division, correlation and regresssion analyses for all acoustic parameters were performed. To complement the results of the linear regression and also to provide normative acoustic data for speakers of EP, average values for all acoustic parameters by age group and vowel, separately for each gender are presented in Appendices (Tables A1, B1 and C1). Vowel duration increased with age Scatterplot and regression results for the duration are presented in Figure 1 , and show an increase of mean duration for all vowels with age, for both genders. For females duration increased from approximately 100 ms to more than 140 ms between the ages 35 and 100; the increase was lower for males, only reaching 130 ms at the age of 100. The multiple linear regression revealed a significant effect of age in both genders, for most vowels and for the mean of all vowels (males: B = 0.451; P = 0.004; IC95% = [0.144;0.759]; females: B = 0.730; P < 0.001; IC95% = [0.427;1.033]). Only vowel [ɨ] in both men (B = 0.138; P = 0.258; IC95% = [ − 0.103;0.379]) and women (B = 0.183; P = 0.129; IC95% = [ − 0.054;0.421]) did not seem significantly affected by age. There was not a significant effect of gender, with men (114.4 ms ± 19.0) and women (118.3 ms ± 21.2) producing vowels with similar mean duration (B = 12.754; P = 0.362; IC95% = [ − 14.854;40.362]). Age effects in f0 were gender dependent The scatterplot of f0 mean vowels is presented in Figure 2 and shows that mean f0 tended to decrease with age in women and slightly increase in men. Regression lines indicated a decrease for females of about 25 Hz between the ages 35 and 100, and an increase around 10 Hz for males between the same ages. Regression model revealed a main effect of gender ( B = − 88.482 ; P < 0.001 ; I C 95 % = [ − 128.000 ; − 48.964 ] ), since male speakers had significantly lower f0 (138.7 Hz ± 27.6) compared to female speakers (193.3 Hz ± 23.9), as expected. The effects of age in both genders were not significant for the majority of the vowels, except for the unstressed vowels in females ([ɨ]: B = − 0.766 ; P = 0.003 ; I C 95 % = [ − 1.271 ; − 0.262 ] ; [ɐ]: B = − 0.954 ; P < 0.001 ; I C 95 % = [ − 1.434 ; − 0.475 ] ). In these vowels f0 decreased very sharply with age. As illustrated in Figure 3 , which was drawn using equations of linear regression (of all vowels by gender and f0) replacing the variable age for 35 and 100. f0 frequencies of all vowels tended to decrease in women (mainly in unstressed vowels) and to slightly increase in men (except the unstressed vowels), with aging. So, f0 tended to approach between genders as age increase. Age effects in formant frequencies were vowel and gender dependent As in previous sections, analysis of vowel formants start by showing scatterplots and regression of mean frequencies ( Figures 4–6 ). Vowel space based on regression results by gender and age is presented in Figure 7 . Due to the complexity of the results, the multiple linear regression coefficients are displayed in Table 2 . Figure 4 shows that mean F1 tended to decrease with age in both genders, mainly in women. The results of multiple linear regression coefficients (Table 2) revealed significant differences between genders for all vowels (except for central vowels ([ɨ], [ɐ], and [a]) and [ɛ]), with women presenting significantly higher mean F1 (486.3 ms ± 29.7) than men (436.4 ms ± 25.9). There was a significant age effect: in males for vowels [a] (Figure 8 ) and [e]; and in females for vowels [ɔ] and [u]. Summing up, as illustrated in Figure 7, F1 decreased with age, especially for vowels [a] and [ɔ], but increased for vowels [e], [i], and [ɨ] in males. In females, F1 decreased with age, especially for vowels [u], [ɔ], and [a]. As shown in Figure 5, mean F2 did not reveal remarkable changes with age. The statistical analysis revealed a main effect of gender on F2 (see Table 2): women’s mean F2 frequencies (1685.5 Hz ± 62.3) were significantly higher than those of men (1433.6 Hz ± 62.1). Only vowel [ɨ] did not present significant differences between genders. A reliable effect of age was found for some vowels depending on gender. Considerable decrease in F2 was found for males in vowel [i] and an opposite tendency was observed in [u] (see Figure 9 ). Female [ɔ] displayed an F2 decrease with aging. Mean F3 of the vowels (Figure 6) tended to slightly decrease with age in both genders, mainly in women. As seen in Table 2, there was a significant effect of gender for F3, with males (2440.5 ms ± 109.3) to have lower F3 mean values than females (2830.3 ms ± 132.3). In addition, there was no significant age effect in men and women, except for female [u], that decreased sharply with age. Age and gender effects on acoustic vowel space Changes in vowel space size were computed in order to track the relationship between talker age and vowel centralization or expansion. The scatterplot of the F1RR is presented in Figure 10 . The regression lines show a decrease with age in both genders, mainly in males, whose F1RR decreased from 2.6 to 2.0 as age increased. The multiple linear regression results revealed that for F1RR only the age effect on males was significant ( B = − 0.009 ; P = 0.006 ; I C 95 % = [ − 0.015 ; − 0.003 ] ). Moreover, the average F1RR of women was 2.609 (SD = 0.422) and 2.345 (SD = 0.307) for men. The female F1 space was therefore 2.609/2.345 = 1.135 times bigger than the male F1 space, although statistical model did not reveal a main effect of gender ( B = 0.220 ; P = 0.433 ; I C 95 % = [ − 0.335 ; 0.775 ] ). Figure 11 presents the mean F2RR and indicates a decrease with age only in males (F2RR decreased around 0.5 points between the ages 35 and 100). The effect of age and gender on F2RR was also analyzed, and as with F1RR, the statistical analysis only revealed a main effect of age in males ( B = − 0.008 ; P = 0.016 ; I C 95 % = [ − 0.015 ; − 0.002 ] ). Similar to F1, the size of the F2 space was higher for women (2.662) than for men (2.382), ie, the female F2 space was therefore 1.118 times bigger than the male F2 space. Nonetheless, the model did not include a main effect of gender ( B = 0.204 ; P = 0.490 ; I C 95 % = [ − 0.380 ; 0.787 ] ). VAI (see Figure 12 ) and FCR were also analyzed. The regression lines of VAI show a decrease of approx. 18% between the ages of 35 and 100 for males. As expected, for males, the opposite trend was observed for FCR. For females, both parameters remained stable with age. The multiple linear regression results revealed that, for both parameters, the age effect is only significant for men (FCR: B = 0.003 ; P < 0.001 ; I C 95 % = [ 0.002 ; 0.005 ] ; VAI: B = − 0.003 ; P = 0.001 ; I C 95 % = [ − 0.005 ; − 0.001 ] ). As expected (they act as interspeaker normalization), the statistical model did not reveal a main effect of gender (FCR: B = − 0.127 ; P = 0.067 ; I C 95 % = [ − 0.263 ; 0.009 ] ; VAI: B = − 0.099 ; P = 0.185 ; I C 95 % = [ − 0.048 ; 0.247 ] ). Additionally, Figure 7 allows to verify that males and females showed different tendencies with age, which is reflected in differences in vowel space sizes. Discussion This study contributes to increase knowledge on EP aging speech, providing an acoustical perspective of the effects of age (as a continuous variable) in all oral vowels of the EP for several acoustic parameters. The present study extends in many ways our previous research 10 by reporting results for another formant (F3) and additional acoustic features (F1RR, F2RR, VAI and FCR). Additionally, this study aims to provide normative values for several acoustic vowel parameters of EP adult speakers. So, these normative data can be used as a database for clinical and research purposes (eg, a speech-language pathologist may wish to compare an impaired voice with a typical voice). Similarities and differences in EP vowel acoustics presented with aging by male and female speakers were analyzed. First, as in most studies, vowels’ duration increased with age. Second, a tendency for f0 to decrease in women and to slightly increase in men was observed. Thirdly, F1 and F2 space underwent a reduction in males with aging. Finally, the frequencies of F3 were essentially unchanged with age. The results obtained are in general in line with previous research. However, some features, specially f0, did not yield as much age-related variation as reported in previous studies. 12,35,38 It should be noted these studies used different methodologies and different criteria for participant selection, 35,62,63 and in this sense the differences in results are not surprising. The age-related changes on acoustical parameters are discussed in detail further below. Vowels Duration As in most studies, 8,11,12,50,51,64 vowels’ duration was the acoustic parameter mostly affected by aging. 8,50,51,64 This probably occurs as a consequence of the decrease in the speech rate 6,8,65 and seems to be related to the neuromuscular slowing, altered nerve supply, respiratory changes, increased cautiousness and to the adjustment by older speakers of their tempo to maintain speech fluency. 6,8 After the vowel [ɐ], the unstressed vowel [ɨ] had the lowest duration and tended to be deleted (26,7%). 12,66 The deletion of unstressed vowels, especially of [ɨ], has been reported for many languages and also for EP. 66–71 At the same time, [ɨ] duration remains almost unchanged with age. Fundamental Frequency The results of our study give additional support that age related changes in f0 are gender dependent, which leads to an approximation of f0 values between genders as age increases. As in the current study, most of the literature for other languages reported a lowering of f0 with age for women, and a raising of f0 for men (not always significant). 8,35,37,38,48,72 For the EP, previous studies were consistent with the decrease of f0 in females, 12,13 whereas in males no significant age-related changes in f0 were observed. 11–13 It has been suggested that the f0 drop in women with age results from the increase in vocal fold mass due to hormonal changes that occur during menopause. 6,7,32,36,73–75 The raise in f0 in men after middle age has been attributed to reduced vocal fold mass and stiffness of vocal fold tissues due to aging-induced atrophy of the internal thyroarytenoid. 6,37,48,74,76 Additionally, it is important to mention that unstressed vowels behaved differently from stressed vowels with age. So, in unstressed vowels, f0 tended to decrease in both genders (although only statistically significant for females) and presented different values than expected. In other words, [ɨ] and [ɐ] f0 tended to be lower than the f0 of vowel [a] with age in both genders. This finding raises questions about the usual physiological explanation for a rise of f0 in older men, 6,37,48,74,76 that is, it remains unclear why a reduced mass and/or stiffness of vocal folds should affect only stressed vowels, whereas unstressed vowels show quite an opposite pattern. Formant frequencies We also observed a general lowering of F1 and F2 frequencies for women in all stressed vowels (although significant differences occurred only for F1[u], F1[ɔ] and F2[ɔ]); as men showed: (1) a decrease in F1 for low vowels (specially in [a]) and an increase in high vowels (specially in [i]); (2) an F2 decrease with age for [i], and a raising of F2 for [u], which suggests that only older men showed formant frequency evidence of vowel centralization, reported in previous researches. 8,24,25,38,49 For EP, an opposite tendency was observed in Pellegrini et al, 12 which have shown a greater centralization of the vowel space in younger speakers (males and females aged 19–28). However, our study does not cover the same age range, for that it is difficult to draw solid conclusions. Although the VSA, in the previous study, 10 did not show centralization for both genders, all the vowel space ratios selected for this comprehensive study (F1RR, F2RR, VAI, and FCR) indicated significant changes consistent with the centralization of the vowel space for male speakers. These results corroborate the main hypothesis that young males have a better articulation precision than older males. 6,15,20 Also, F2RR reflect restricted movements of the tongue in the anterior-posterior direction and restricted movements of the lips (rounding for [u] and retraction for [i]). 23 For example, an increase in F2 can be caused by a more anterior tongue position, but also by a decrease in lip rounding or tongue body shape. 77 The present results tend to confirm that the F1RR, F2RR, VAI, and FCR metrics are more sensitive to mild vowel articulation changes with age than VSA. Several explanations have been advanced to account for age-related changes in vowel formant frequencies, 7,9,29,35,63 like altered dimensions of the back cavity, 29,78 changes of the shape of the oral cavity (loss of teeth and the introduction of dentures), 7,29 diachronic or intergenerational phonetic change 79 or slower tongue movements and loss of tongue strength. 6,43 Additionally, as in Schötz 8 and Eichhorn et al, 35 the frequencies of F3 were essentially unchanged with age. This result does not support the idea of vocal tract lengthening in older age reported in previous studies. 9,29,43–46 So, the lack of an aging effect on the F3 indicates that any changes found for F1 and F2 are related to specific articulatory effects. 35 And also, this claim could be corroborated by the findings about males’ patterns of f0 change in stressed vs. unstressed vowels. Study limitations and future work Given the methodological differences across previous studies, variable results are not surprising. For that, it is difficult to fix a particular age or age range where changes occur in either gender. 63 Speaker age leaves traces in all phonetic dimensions and its impact on the voice is influenced by numerous factors, such as physiological condition, occupations and lifestyle habits, 5,8 which were not handled in this study. Also the type of speech samples used could affect the results. In more conversational contexts, speakers tend to show decreases in average vowel duration coupled with a higher degree of vowel centralization. 47 It is possible that, in order to see differences in vowel centralization with age, a task which demands greater movement of speakers’ vocal tracts might be required. 47 And finally, vowel duration was not controlled, which renders comparisons across studies to be problematic in several ways. An open and interesting question remains: whether the changes that we have observed in our data are the result of passive physiological changes to the vocal tract, or whether speech production is actively modified with increasing age, in order to compensate perceptually for the influences of the age-related decline on vowel quality. For that, the relation between the vowel acoustic and the articulatory changes with aging will be addressed in future work using instrumental techniques, such as ultrasonography. Additionally, dynamic measurements of vowels’ formant would be highly desirable, to provide a more complete view of vowel characteristics, and to avoid a necessarily arbitrary choice of selecting a specific time point where the measurements are taken. Given that in cross-sectional studies speakers include various factors other than age alone, that could affect the results. In future, we plan to develop a longitudinal research study that traces the acoustic features of the same speaker over a long period of time. Conclusion The results of this study provide a base of information to establish vowel acoustics normal patterns of aging among Portuguese adults. So, this study adds to the growing body of data on the effects of age on the acoustic properties of speech, providing information on vowel acoustics from adults who speak a language different from English. In that sense, it might help to better understand cross-linguistic similarities and language-particular features of vowel aging. Summing up, the statistical analyses have shown which vowels are more affected by aging: (1) the unstressed oral vowels f0, mainly for females; (2) formants of vowels [u] and [ɔ] for females; (3) vowels [i], [u], [a], and [e] males’ formants. The acoustic changes resulting from the natural process of aging are an important basis to understand speech and voice disorders associated with health conditions that affect older individuals (eg, hearing loss, dentofacial alterations, neurodegenerative diseases, stroke, cancer, or psychological distress). 35 Wherefore, it is very important that voice clinicians are aware of such effects and take these into account in their intervention. Furthermore, the correlates of speaker age reported in this study may further be helpful for the development of methods for the automatic detection of speaker age, as well as for the synthesis of speaker age. Thereby, better age recognizers or classifiers may be achieved, as well as better and more natural-sounding synthesis of speaker age. 8 Acknowledgments This research was financially supported by the project Vox Senes POCI-01-0145-FEDER-03082 (funded by FEDER, through COMPETE2020 - Programa Operacional Competitividade e Internacionalização (POCI), and by national funds (OE), through FCT/MCTES), by the grant SFRH/BD/115381/2016, and by IEETA (UIDB/00127/2020), and by CIDMA (UID/MAT/04106/2019). We are very grateful to the institutions for having made possible the data collection, and also to all the adults who contributed as speakers. Appendix A Vowel Duration Appendix B Fundamental Frequency Appendix C Formant Frequencies References 1 World Health Organization. Ageing. 2012a. 2 World Health Organization. Definition of an older or elderly person. 2012b. 3 S. Portugal Estimativas de População Residente em Portugal - 2018 (Estimates of resident population in Portugal - 2018) Destaque: informação à comunicação social 2019 Portugal S.. Estimativas de População Residente em Portugal - 2018 (Estimates of resident population in Portugal - 2018). Destaque: informação à comunicação social 2019;. 4 S. Portugal Envelhecimento da população residente em Portugal e na União Europeia (Aging population living in Portugal and in the European Union) Destaque: informação comunicação social 2015 Portugal S.. Envelhecimento da população residente em Portugal e na União Europeia (Aging population living in Portugal and in the European Union). Destaque: informação comunicação social 2015;. 5 Aging Voice Makiyama K. Hirano S. 2017 Springer Singapore Makiyama K., Hirano S., editors. Aging Voice. Singapore: Springer; 2017. 6 S.E. Linville Vocal aging 2001 Singular Thomson Learning Australia, San Diego Linville S. E.. Vocal aging. Australia, San Diego: Singular Thomson Learning; 2001. 7 H. Mautner A Cross-System Instrumental Voice Profile of the Aging Voice: With Considerations of Jaw Posture Effects 2011 University of Canterbury Ph.D. thesis Mautner H.. A Cross-System Instrumental Voice Profile of the Aging Voice: With Considerations of Jaw Posture Effects. Ph.D. thesis; University of Canterbury; 2011. 8 S. Schötz Perception, analysis and synthesis of speaker age Travaux de l’Institut de Linguistique de Lund vol. 47 2006 Linguistics and Phonetics Lund University Schötz S.. Perception, analysis and synthesis of speaker age; vol. 47 of Travaux de l’Institut de Linguistique de Lund. Lund University: Linguistics and Phonetics; 2006. 9 S.E. Linville J. Rens Vocal tract resonance analysis of aging voice using long-term average spectra J Voice 15 2001 323 330 Linville S. E., Rens J.. Vocal Tract Resonance Analysis of Aging Voice Using Long-Term Average Spectra. Journal of Voice 2001;15(3):323–330. 10 L. Albuquerque C. Oliveira A. Teixeira Age-related changes in European Portuguese vowel acoustics INTERSPEECH 2019 ISCA Graz 3965 3969 Albuquerque L., Oliveira C., Teixeira A., Sa-Couto P., Figueiredo D.. Age-related changes in European Portuguese vowel acoustics. In: INTERSPEECH. 2019, p. 3965–3969. 11 L. Albuquerque C. Oliveira A. Teixeira Impact of age in the production of European Portuguese vowels INTERSPEECH 2014 ISCA Singapore 940 944 Albuquerque L., Oliveira C., Teixeira A., Sa-Couto P., Freitas J., Dias M. S.. Impact of age in the production of European Portuguese vowels. In: INTERSPEECH. Singapore: ISCA; 2014, p. 940–944. 12 T. Pellegrini A. Hömölöinen P.B. de Mareüil A corpus-based study of elderly and young speakers of European Portuguese: acoustic correlates and their impact on speech recognition performance INTERSPEECH 2013 852 856 Pellegrini T., Hömölöinen A., de Mareüil P. B., Tjalve M., Trancoso I., Candeias S., et al. A corpus-based study of elderly and young speakers of European Portuguese: acoustic correlates and their impact on speech recognition performance. In: INTERSPEECH. Lyon, France; 2013, p. 852–856. Lyon, France 13 I. Guimarães E. Abberton Fundamental frequency in speakers of Portuguese for different voice samples J Voice 19 2005 592 606 Guimarães I., Abberton E.. Fundamental frequency in speakers of Portuguese for different voice samples. Journal of voice 2005;19(4):592–606. 14 Z. Mou W. Teng H. Ouyang Quantitative analysis of vowel production in cerebral palsy children with dysarthria J Clin Neurosci 66 2019 77 82 Mou Z., Teng W., Ouyang H., Chen Y., Liu Y., Jiang C., et al. Quantitative analysis of vowel production in cerebral palsy children with dysarthria. Journal of Clinical Neuroscience 2019;66:77–82. 15 T. Arias-Vergara J.C. Vásquez-Correa J.R. Orozco-Arroyave Parkinson’s disease and aging: analysis of their effect in phonation and articulation of speech Cognit Comput 9 2017 731 748 Arias-Vergara T., Vásquez-Correa J. C., Orozco-Arroyave J. R.. Parkinson’s disease and aging: analysis of their effect in phonation and articulation of speech. Cognitive Computation 2017;9(6):731–748. 16 A.T. Neel Vowel space characteristics and vowel identification accuracy J Speech Lang Hear Res 51 2008 574 585 Neel A. T.. Vowel space characteristics and vowel identification accuracy. J Speech Lang Hear Res 2008;51(3):574–585. 17 D. McCloy R. Wright P. Souza Modeling intrinsic intelligibility variation: vowel-space size and structure Meetings on acoustics vol. 18 2014 ASA 060007 McCloy D., Wright R., Souza P.. Modeling intrinsic intelligibility variation: vowel-space size and structure. In: Meetings on Acoustics; vol. 18. ASA; 2014, p. 060007. 18 N. Roy S.L. Nissen C. Dromey Articulatory changes in muscle tension dysphonia: evidence of vowel space expansion following manual circumlaryngeal therapy J Commun Disord 42 2009 124 135 Roy N., Nissen S. L., Dromey C., Sapir S.. Articulatory changes in muscle tension dysphonia: Evidence of vowel space expansion following manual circumlaryngeal therapy. Journal of Communication Disorders 2009;42(2):124–135. 19 N. Audibert C. Fougeron C. Gendrot Duration-vs. style-dependent vowel variation: a multiparametric investigation ICPhS’15 2015 Glasgow 5 9 Audibert N., Fougeron C., Gendrot C., Adda-Decker M.. Duration-vs. style-dependent vowel variation: A multiparametric investigation. In: ICPhS’15. Glasgow; 2015, p. 5–9. 20 C. Fougeron N. Audibert Testing various metrics for the description of vowel distortion in dysarthria ICPhS XVII 2011 City University of Hong Kong Hong Kong 687 690 Fougeron C., Audibert N.. Testing various metrics for the description of vowel distortion in dysarthria. In: ICPhS. 2011, p. 687–690. 21 S. Gahl R.H. Baayen Twenty-eight years of vowels: tracking phonetic variation through young to middle age adulthood J Phonet 74 2019 42 54 Gahl S., Baayen R. H.. Twenty-eight years of vowels: Tracking phonetic variation through young to middle age adulthood. Journal of Phonetics 2019;74:42–54. 22 S. Sapir L.O. Ramig J. Spielman Acoustic metrics of vowel articulation in Parkinson’s disease: vowel space area (VSA) vs. vowel articulation index (VAI) MAVEBA-2011 2011 ISCA Firenze 173 175 Sapir S., Ramig L. O., Spielman J., Fox C.. Acoustic metrics of vowel articulation in Parkinson’s disease: vowel space area (VSA) vs. vowel articulation index (VAI). In: MAVEBA-2011. Firenze; 2011, p. 173–175. Firenze 23 S. Sapir L.O. Ramig J.L. Spielman Formant centralization ratio: a proposal for a new acoustic measure of dysarthric speech J Speech Lang Hear Res 53 2010 114 125 Sapir S., Ramig L. O., Spielman J. L., Fox C.. Formant Centralization Ratio: A Proposal for a New Acoustic Measure of Dysarthric Speech. J Speech Lang Hear Res 2010;53:114–125. 24 M.P. Rastatter R.D. Jacques Formant frequency structure of the aging male and female vocal tract Folia Phoniatrica 42 1990 312 319 Rastatter M. P., Jacques R. D.. Formant frequency structure of the aging male and female vocal tract. Folia phoniatrica 1990;42(6):312–319. 25 M.P. Rastatter R.A. McGuire J. Kalinowski Formant frequency characteristics of elderly speakers in contextual speech Folia Phoniatrica et Logopaedica 49 1997 1 8 Rastatter M. P., McGuire R. A., Kalinowski J., Stuart A.. Formant frequency characteristics of elderly speakers in contextual speech. Folia Phoniatrica et Logopaedica 1997;49(1):1–8. 26 P. Escudero P. Boersma A.S. Rauber A cross-dialect acoustic description of vowels: Brazilian and European Portuguese J Acoust Soc Am 126 2009 1379 1393 Escudero P., Boersma P., Rauber A. S., Bion R.. A cross-dialect acoustic description of vowels: Brazilian and European Portuguese. J Acoust Soc Am 2009;126(3):1379–1393. 27 C. Oliveira M.M. Cunha S. Silva Acoustic analysis of European Portuguese oral vowels produced by children Advances in Speech and Language Technologies for Iberian Languages: IberSPEECH vol. 328 2012 Springer Madrid, Spain 129 138 Oliveira C., Cunha M. M., Silva S., Teixeira A., Sa-Couto P.. Acoustic analysis of European Portuguese oral vowels produced by children. In: Advances in Speech and Language Technologies for Iberian Languages: IberSPEECH; vol. 328. Madrid, Spain: Springer; 2012, p. 129–138. 28 M.R.D. Martins Análise acústica das vogais orais tónicas em Português (Acoustic analysis of stressed oral vowels in Portuguese) Boletim de Filologia 22 1973 303 314 Martins M. R. D.. Análise acústica das vogais orais tónicas em Português (Acoustic analysis of stressed oral vowels in Portuguese). Boletim de Filologia 1973;22:303–314. 29 S.A. Xue G.J. Hao Changes in the Human vocal tact due to aging and the acoustic correlates of speech production: a pilot study J Speech Lang Hear Res 46 2003 689 701 Xue S. A., Hao G. J.. Changes in the Human vocal tact due to aging and the acoustic correlates of speech production: a pilot study. J Speech Lang Hear Res 2003;46(3):689–701. 30 R. Vipperla S. Renals J. Frankel Ageing voices: the effect of changes in voice parameters on ASR performance EURASIP J Aud Speech Music Process 2010 2010 1 10 10.1155/2010/525783 Vipperla R., Renals S., Frankel J.. Ageing voices: The effect of changes in voice parameters on ASR performance. EURASIP J Aud Speech Music Process 2010;2010:1–10. 31 A. Lanitis A survey of the effects of aging on biometric identity verification Int J Biometr 2 2010 34 52 Lanitis A.. A survey of the effects of aging on biometric identity verification. International Journal of Biometrics 2010;2(1):34–52. 32 R.T. Sataloff D. Caputo Rosen M. Hawkshaw The aging adult voice J Voice 11 1997 156 160 Sataloff R. T., Caputo Rosen D., Hawkshaw M., Spiegel J. R.. The aging adult voice. Journal of Voice 1997;11(2):156–160. 33 M.M. Johns III L.C. Arviso F. Ramadan Challenges and opportunities in the management of the aging voice Otolaryngol 145 2011 1 6 Johns III M. M., Arviso L. C., Ramadan F.. Challenges and opportunities in the management of the aging voice. Otolaryngology - Head and Neck Surgery 2011;145(1):1–6. 34 H. Goy D.N. Fernandes M.K. Pichora-Fuller Normative voice data for younger and older adults J Voice 27 2013 545 555 Goy H., Fernandes D. N., Pichora-Fuller M. K., van Lieshout P.. Normative voice data for younger and older adults. Journal of Voice 2013;27(5):545–555. 35 J.T. Eichhorn R.D. Kent D. Austin Effects of aging on vocal fundamental frequency and vowel formants in men and women J Voice 32 2018 644.e1 644.e9 Eichhorn J. T., Kent R. D., Austin D., Vorperian H. K.. Effects of aging on vocal fundamental frequency and vowel formants in men and women. Journal of Voice 2018;32(5):644.e1–644.e9. 36 E.P.M. Ma A.L. Love Electroglottographic evaluation of age and gender effects during sustained phonation and connected speech J Voice 24 2010 146 152 Ma E. P. M., Love A. L.. Electroglottographic Evaluation of Age and Gender Effects During Sustained Phonation and Connected Speech. Journal of Voice 2010;24(2):146–152. 37 M. Nishio S. Niimi Changes in speaking fundamental frequency characteristics with aging Folia Phoniatrica et Logopaedica 60 2008 120 127 Nishio M., Niimi S.. Changes in speaking fundamental frequency characteristics with aging. Folia Phoniatrica et Logopaedica 2008;60(3):120–127. 38 P. Torre III J.A. Barlow Age-related changes in acoustic characteristics of adult speech J Commun Disord 42 2009 324 333 Torre III P., Barlow J. A.. Age-related changes in acoustic characteristics of adult speech. Journal of Communication Disorders 2009;42:324–333. 39 A. Yamauchi H. Yokonishi H. Imagawa Age-and gender-related difference of vocal fold vibration and glottal configuration in normal speakers: analysis with glottal area waveform J Voice 28 2014 525 531 Yamauchi A., Yokonishi H., Imagawa H., Sakakibara K.-I., Nito T., Tayama N., et al. Age-and gender-related difference of vocal fold vibration and glottal configuration in normal speakers: analysis with glottal area waveform. Journal of Voice 2014;28(5):525–531. 40 S.A. Xue D. Deliyski Effects of aging on selected acoustic voice parameters: preliminary normative data and educational implications Educ Gerontol 27 2001 159 168 Xue S. A., Deliyski D.. Effects of aging on selected acoustic voice parameters: preliminary normative data and educational implications. Educational Gerontology 2001;27(2):159–168. 41 E.T. Stathopoulos J.E. Huber J.E. Sussman Changes in acoustic characteristics of the voice across the life span: measures from individuals 4–93 years of age J Speech Lang Hear Res 54 2011 1011 1021 Stathopoulos E. T., Huber J. E., Sussman J. E.. Changes in acoustic characteristics of the voice across the life span: measures from individuals 4-93 years of age. J Speech Lang Hear Res 2011;54(4):1011–1021. 42 L. Ramig R. Ringel Effects of physiological aging on selected acoustic characteristics of voice J Speech Hear Res 26 1983 22 30 Ramig L., Ringel R.. Effects of Physiological Aging on Selected Acoustic Characteristics of Voice. J Speech Hear Res 1983;26(1):22–30. 43 P.J. Watson B. Munson A comparison of vowel acoustics between older and younger adults ICPhS XVI 2007 Saarbrücken 561 564 Watson P. J., Munson B.. A comparison of vowel acoustics between older and younger adults. In: ICPhS XVI. Saarbrücken; 2007, p. 561–564. 44 J. Harrington S. Palethorpe C.I. Watson Age-related changes in fundamental frequency and formants: a longitudinal study of four speakers INTERSPEECH 2007 Belgium 2753 2756 Harrington J., Palethorpe S., Watson C. I.. Age-related changes in fundamental frequency and formants: a longitudinal study of four speakers. In: INTERSPEECH. Belgium; 2007, p. 2753–2756. 45 W. Endres W. Bambach G. Flösser Voice spectrograms as a function of age, voice disguise, and voice imitation J Acoust Soc of Am 49 6B 1971 1842 1848 Endres W., Bambach W., Flösser G.. Voice spectrograms as a function of age, voice disguise, and voice imitation. J Acoust Soc of Am 1971;49(6B):1842–1848. 46 F. Decoster W. Debruyne Acoustic differences between sustained vowels perceived as young or old Log Phon Vocol 24 1999 1 5 Decoster F., Debruyne W.. Acoustic differences between sustained vowels perceived as young or old. Log Phon Vocol 1999;24(1):1–5. 47 A.R. Fletcher M.J. McAuliffe K.L. Lansford The relationship between speech segment duration and vowel centralization in a group of older speakers J Acoust Soc Am 138 2015 2132 2139 Fletcher A. R., McAuliffe M. J., Lansford K. L., Liss J. M.. The relationship between speech segment duration and vowel centralization in a group of older speakers. J Acoust Soc Am 2015;138(4):2132–2139. 48 S. Sebastian S. Babu N.E. Oommen A. Ballraj Acoustic measurements of geriatric voice J Laryngol Voice 2 2012 81 84 Sebastian S., Babu S., Oommen N. E., Ballraj A.. Acoustic measurements of geriatric voice. Journal of Laryngology and Voice 2012;2(2):81–84. 49 J. Mertens D. Mücke A. Hermes Aging effects on prosodic marking in German: an acoustic analysis Second workshop on speech perception and production across the lifespan (poster) 2020 UCL London Mertens J., Mücke D., Hermes A.. Aging effects on prosodic marking in German: An acoustic analysis. In: 2nd Workshop on Speech Perception and Production across the Lifespan (Poster). London: UCL; 2020, p. Poster. 50 B.L. Smith J. Wasowicz J. Preston Temporal characteristics of the speech of normal elderly adults J Speech Hear Res 30 1987 522 529 Smith B. L., Wasowicz J., Preston J.. Temporal characteristics of the speech of normal elderly adults. J Speech Hear Res 1987;30(4):522–529. 51 B.J. Benjamin Phonological performance in gerontological speech J Psycholinguist Res 11 1982 159 167 Benjamin B. J.. Phonological performance in gerontological speech. Journal of Psycholinguistic Research 1982;11(2):159–167. 52 E.B. Slawinski Acoustic correlates of [b] and [w] produced by normal young to elderly adults J Acoust Soc of Am 95 1994 2221 2230 10.1121/1.408682 Slawinski E. B.. Acoustic correlates of [b] and [w] produced by normal young to elderly adults. J Acoust Soc of Am 1994;95(4):2221–2230. 10.1121/1.408682. 10.1121/1.408682 53 C. Fougeron D. D’Alessandro L. Lancia Reduced coarticulation and aging J Acoust Soc Am 144 2018 1905 10.1121/1.5068348 Fougeron C., D’Alessandro D., Lancia L.. Reduced coarticulation and aging. J Acoust Soc Am 2018;144(3):1905. 10.1121/1.5068348. 10.1121/1.5068348 54 Palao, S. (2017). Color Pictograms ARASAAC. Aragonese Portal of Augmentative and Alternative Communication. 55 C. Draxler K. Jönsch SpeechRecorder - a universal platform independent multi-channel audio recording software LREC’04 2004 ELRA Lisbon 559 562 Draxler C., Jönsch K.. SpeechRecorder - A universal platform independent multi-channel audio recording software. In: LREC’04. Lisbon, Portugal; 2004, p. 559–562. 56 Draxler C., Jönsch K.. SpeechRecorder. 2017. 57 T. Kisler U. Reichel F. Schiel Multilingual processing of speech via web services Comput Speech Lang 45 2017 326 347 Kisler T., Reichel U., Schiel F.. Multilingual processing of speech via web services. Computer Speech & Language 2017;45:326–347. 58 F. Schiel Automatic phonetic transcription of non-prompted speech 14th ICPhS 1999 University of California San Francisco 607 610 Schiel F.. Automatic phonetic transcription of non-prompted speech. In: 14th ICPhS. San Francisco; 1999, p. 607–610. 59 Boersma P., Weenink D.. Praat: doing phonetics by computer. 2012. 60 R. Smiljanic R.C. Gilbert Acoustics of clear and noise-adapted speech in children, young, and older adults J Speech Lang Hear Res 60 2017 3081 3096 Smiljanic R., Gilbert R. C.. Acoustics of clear and noise-adapted speech in children, young, and older adults. J Speech Lang Hear Res 2017;60(11):3081–3096. 61 P.E. Shrout J.L. Fleiss Intraclass correlations: uses in assessing rater reliability Psychol Bull 86 1979 420 428 Shrout P. E., Fleiss J. L.. Intraclass correlations: uses in assessing rater reliability. Psychological bulletin 1979;86(2):420–428. 62 A. Lutzross W. Schuerman R. Sprouse Development of vowel spaces from age 21 to age 49 in a group of 8 talkers J Acoust Soc Am 134 2013 4107 Lutzross A., Schuerman W., Sprouse R., Gahl S.. Development of vowel spaces from age 21 to age 49 in a group of 8 talkers. J Acoust Soc Am 2013;134(5):4107. 63 R.D. Kent H.K. Vorperian Static measurements of vowel formant frequencies and bandwidths: a review J Commun Disord 74 2018 74 97 Kent R. D., Vorperian H. K.. Static Measurements of Vowel Formant Frequencies and Bandwidths: A Review. Journal of communication disorders 2018;74:74–97. 64 E. Jacewicz R.A. Fox C. O’Neill Articulation rate across dialect, age, and gender Lang Variation Change 21 2009 233 256 Jacewicz E., Fox R. A., O’Neill C., Salmons J.. Articulation rate across dialect, age, and gender. Language variation and change 2009;21(02):233–256. 65 Y. Steffens The Aging Voice 2011 GRIN Verlag Steffens Y.. The Aging Voice. GRIN Verlag; 2011. 66 P. Fikkert From phonetic categories to phonological features specification: acquiring the European Portuguese vowel system Lingue e linguaggio 4 2005 263 280 Fikkert P.. From phonetic categories to phonological features specification: Acquiring the European Portuguese vowel system. Lingue e linguaggio 2005;4(2):263–280. 67 M.H.M. Mateus E. D’Andrade The phonology of Portuguese 2000 Oxford University Press Oxford Mateus M. H. M., D’Andrade E.. The phonology of Portuguese. Oxford: Oxford University Press; 2000. 68 J. Veloso Schwa in European Portuguese: the phonological status of [ Image 32 ] Journees d’Etudes Linguistiques 2007 55 60 Veloso J.. Schwa in European Portuguese: the phonological status of [1]. In: Journees d’Etudes Linguistiques. Nantes; 2007, p. 55–60. Nantes 69 J. Veloso Central, epenthetic, unmarked vowels and schwas: a brief outline of some essential differences Linguística: Revista de Estudos Linguísticos da Universidade do Porto 5 2017 191 213 Veloso J.. Central, epenthetic, unmarked vowels and schwas: a brief outline of some essential differences. Linguística: Revista de Estudos Linguísticos da Universidade do Porto 2017;5:191–213. 70 D.J. Silva The variable elision of unstressed vowels in European Portuguese: a case study Herring S.C. Paolillo J.C. UTA working papers in linguistics vol. 1 1994 Program in Linguistics University of Texas at Arlington 79 84 Silva D. J.. The variable elision of unstressed vowels in European Portuguese: A case study. In: Herring S. C., Paolillo J. C., editors. UTA Working Papers in Linguistics; vol. 1. University of Texas at Arlington: Program in Linguistics; 1994, p. 79–84. 71 D.J. Silva Vowel lenition in São Miguel Portuguese Hispania 81 1998 166 178 Silva D. J.. Vowel lenition in São Miguel Portuguese. Hispania 1998;81(1):166–178. 72 U. Reubold J. Harrington F. Kleber Vocal aging effects on F0 and the first formant: a longitudinal analysis in adult speakers Speech Commun 52 2010 638 651 Reubold U., Harrington J., Kleber F.. Vocal aging effects on F0 and the first formant: A longitudinal analysis in adult speakers. Speech Communication 2010;52:638–651. 73 C.T. Ferrand Harmonics-to-noise ratio: an index of vocal aging J Voice 16 2002 480 487 Ferrand C. T.. Harmonics-to-Noise Ratio: An index of vocal aging. Journal of Voice 2002;16(4):480–487. 74 M.B. Higgins J.H. Saxman A comparison of selected phonatory behaviors of healthy aged and young adults J Speech Hear Res 34 1991 1000 1010 Higgins M. B., Saxman J. H.. A Comparison of Selected Phonatory Behaviors of Healthy Aged and Young Adults. J Speech Hear Res 1991;34(5):1000–1010. 75 P. Pontes A. Brasolotto M. Behlau Glottic characteristics and voice complaint in the elderly J Voice 19 2005 84 94 Pontes P., Brasolotto A., Behlau M.. Glottic characteristics and voice complaint in the elderly. Journal of Voice 2005;19(1):84–94. 76 H. Hollien T. Shipp Speaking fundamental frequency and chronologic age in males J Speech Hear Res 15 1972 155 159 Hollien H., Shipp T.. Speaking Fundamental Frequency and Chronologic Age in Males. J Speech Hear Res 1972;15(1):155–159. 77 M. Wieling F. Tomaschek D. Arnold Investigating dialectal differences using articulography J Phonet 59 2016 122 143 Wieling M., Tomaschek F., Arnold D., Tiede M., Bröker F., Thiele S., et al. Investigating dialectal differences using articulography. Journal of Phonetics 2016;59:122–143. 78 G.P. Scukanec L. Petrosino K. Squibb Formant frequency characteristics of children, young adult, and aged female speakers Percept Motor Skills 73 1991 203 208 Scukanec G. P., Petrosino L., Squibb K.. Formant frequency characteristics of children, young adult, and aged female speakers. Perceptual and motor skills 1991;73(1):203–208. 79 R.A. Fox E. Jacewicz Dialect and generational differences in vowel space areas ExLing2010 2010 ISCA Athens, Greece 45 48 Fox R. A., Jacewicz E.. Dialect and generational differences in vowel space areas. In: ExLing2010. Athens, Greece: ISCA; 2010, p. 45–48. "
    },
    {
        "doc_title": "Contributions to a quantitative unsupervised processing and analysis of tongue in ultrasound images",
        "doc_scopus_id": "85087274917",
        "doc_doi": "10.1007/978-3-030-50516-5_15",
        "doc_eid": "2-s2.0-85087274917",
        "doc_date": "2020-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Automatic analysis",
            "Computational approach",
            "Electromagnetic articulography",
            "Speech motor control",
            "Speech production",
            "Temporal coherence",
            "Tongue segmentation",
            "Ultrasound imaging"
        ],
        "doc_abstract": "© Springer Nature Switzerland AG 2020.Speech production studies and the knowledge they bring forward are of paramount importance to advance a wide range of areas including Phonetics, speech therapy, synthesis and interaction. Several technologies have been considered to study static and dynamic features of the articulators and speech motor control, such as electromagnetic articulography (EMA), real-time magnetic resonance (RTMRI) and ultrasound (US) imaging. While the latest advances in RTMRI provide a wealth of data of the full vocal tract, it is an expensive resource that requires specialized facilities. In this sense, US is a more affordable alternative for several contexts, enabling the acquisition of larger datasets, but demands adequate computational approaches for processing and analysis. While the literature is prolific in proposing methods for tongue segmentation from US, the noisy nature of the images and the specificities of the equipment often dictate a poor performance on novel datasets, a matter that needs to be assessed, before large data acquisition, to devise suitable acquisition and processing methods. In the scope of a line of research studying speech changes with age, this work describes the first results of an automatic tongue segmentation method from US, along with a characterization of the main challenges posed by the image data. Even though improvements are still needed, particularly to ensure temporal coherence, at its current stage, this method can already provide the required data for an automatic analysis of maximum tongue height, a relevant parameter to assess speech changes on vowel production.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "JavaScript multimedia game space letters - A journey through the voice",
        "doc_scopus_id": "85070083319",
        "doc_doi": "10.23919/CISTI.2019.8760983",
        "doc_eid": "2-s2.0-85070083319",
        "doc_date": "2019-06-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Computer Networks and Communications",
                "area_abbreviation": "COMP",
                "area_code": "1705"
            },
            {
                "area_name": "Information Systems",
                "area_abbreviation": "COMP",
                "area_code": "1710"
            }
        ],
        "doc_keywords": [
            "Endless run",
            "Game",
            "Game space",
            "Graphical elements",
            "Health promotion",
            "Javascript",
            "Multimedia games",
            "Pedagogical tools"
        ],
        "doc_abstract": "© 2019 AISTI.Pediatric dysphonia has a high prevalence, and adhesion to vocal rehabilitation is a challenge for speech therapists. This paper aims to present the development of the endless run game Space Letters- A Journey Through the Voice. The game is aimed at children from 6 to 10 years and its purpose is the vocal health promotion. The user will have to pick up letters to complete words, which indicate a benefit or a harm to the voice health. In the meantime, graphical elements that represent obstacles and reduce the player's score will appear. The game combines the pedagogical value with the playfulness and presents great potential as a pedagogical tool to promote voice health and also in clinical rehabilitation.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Usability and acceptability of an online tool to promote health of the teacher's voice: Pilot study",
        "doc_scopus_id": "85070075920",
        "doc_doi": "10.23919/CISTI.2019.8760678",
        "doc_eid": "2-s2.0-85070075920",
        "doc_date": "2019-06-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Computer Networks and Communications",
                "area_abbreviation": "COMP",
                "area_code": "1705"
            },
            {
                "area_name": "Information Systems",
                "area_abbreviation": "COMP",
                "area_code": "1710"
            }
        ],
        "doc_keywords": [
            "Cross-sectional study",
            "Data collection",
            "Descriptive statistics",
            "Health promotion",
            "On-line tools",
            "Pilot studies",
            "System Usability Scale (SUS)",
            "Teacher"
        ],
        "doc_abstract": "© 2019 AISTI.Aim: To analyze the usability and acceptability of an online tool to promote the health of the teacher's voice. Method: A cross-sectional study will be performed with a convenience sample. Data collection was done through an acceptability questionnaire and the Portuguese version of the System Usability Scale (SUS), after using the online tool (developed by the researchers). Data were analyzed using descriptive statistics. Results: Twenty-six volunteers participated including teachers and master's students in Education. The majority of the sample was female (80.8%), with a mean age of 27.4 years and is in internship with children in the first grade (76.9%). A global score of 70 to 100 points in SUS was obtained, with an average of 87.3 points, indicating good satisfaction with usability. Regarding acceptability, of the 13 acceptability questions, eight were positively evaluated by all respondents and five by most respondents suggesting good acceptability. Conclusion: Satisfaction with the usability and acceptability of the Online tool to promote health to the teacher's voice' is high, revealing the health-promoting mhealth technology capable of disseminating information and voice care to teachers and students of Teaching.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "On the role of oral configurations in European Portuguese nasal vowels",
        "doc_scopus_id": "85074699107",
        "doc_doi": "10.21437/Interspeech.2019-2232",
        "doc_eid": "2-s2.0-85074699107",
        "doc_date": "2019-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Language and Linguistics",
                "area_abbreviation": "ARTS",
                "area_code": "1203"
            },
            {
                "area_name": "Human-Computer Interaction",
                "area_abbreviation": "COMP",
                "area_code": "1709"
            },
            {
                "area_name": "Signal Processing",
                "area_abbreviation": "COMP",
                "area_code": "1711"
            },
            {
                "area_name": "Software",
                "area_abbreviation": "COMP",
                "area_code": "1712"
            },
            {
                "area_name": "Modeling and Simulation",
                "area_abbreviation": "MATH",
                "area_code": "2611"
            }
        ],
        "doc_keywords": [],
        "doc_abstract": "Copyright © 2019 ISCAThe characterisation of nasal vowels is not only a question of studying velar aperture. Recent work shows that oropharyngeal articulatory adjustments enhance the acoustics of nasal coupling or, at least, magnify differences between oral/nasal vowel congeners. Despite preliminary studies on the oral configurations of nasal vowels, for European Portuguese, a quantitative analysis is missing, particularly one to be applied systematically to a desirably large number of speakers. The main objective of this study is to adapt and extend previous methodological advances for the analysis of MRI data to further investigate: how velar changes affect oral configurations; the changes to the articulators and constrictions when compared with oral counterparts; and the closest oral counterpart. High framerate RT-MRI images (50fps) are automatically processed to extract the vocal tract contours and the position/configuration for the different articulators. These data are processed by evolving a quantitative articulatory analysis framework, previously proposed by the authors, extended to include information regarding constrictions (degree and place) and nasal port. For this study, while the analysis of data for more speakers is ongoing, we considered a set of two EP native speakers and addressed the study of oral and nasal vowels mainly in the context of stop consonants.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Age-related changes in European Portuguese vowel acoustics",
        "doc_scopus_id": "85074694647",
        "doc_doi": "10.21437/Interspeech.2019-1818",
        "doc_eid": "2-s2.0-85074694647",
        "doc_date": "2019-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Language and Linguistics",
                "area_abbreviation": "ARTS",
                "area_code": "1203"
            },
            {
                "area_name": "Human-Computer Interaction",
                "area_abbreviation": "COMP",
                "area_code": "1709"
            },
            {
                "area_name": "Signal Processing",
                "area_abbreviation": "COMP",
                "area_code": "1711"
            },
            {
                "area_name": "Software",
                "area_abbreviation": "COMP",
                "area_code": "1712"
            },
            {
                "area_name": "Modeling and Simulation",
                "area_abbreviation": "MATH",
                "area_code": "2611"
            }
        ],
        "doc_keywords": [],
        "doc_abstract": "Copyright © 2019 ISCAThis study addresses effects of age and gender on acoustics of European Portuguese oral vowels, given to the fact of conflicting findings reported in prior research. Fundamental frequency (F0), formant frequencies (F1 and F2) and duration of vowels produced by a group of 113 adults, aged between 35 and 97 years old, were measured. Vowel space area (VSA) according to gender and age was also analysed. The results revealed that the most consistent age-related effect was an increase in vowel duration in both genders. F0 decreases above [50-64] for female and for male data suggests a slight drop over the age range [35-64] and then an increase in an older age. That is, F0 tends to be closer between genders as age increases. In general, there is no evidence that F1 and F2 frequencies were lowering as age increased. Furthermore, there were no changes to VSA with ageing. These results provide a base of information to establish vowel acoustics normal patterns of ageing among Portuguese adults.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Inner Speech in Portuguese: Acquisition Methods, Database and First Results",
        "doc_scopus_id": "85053911262",
        "doc_doi": "10.1007/978-3-319-99722-3_44",
        "doc_eid": "2-s2.0-85053911262",
        "doc_date": "2018-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Brain functions",
            "Exploratory analysis",
            "Functional magnetic resonance imaging",
            "Human speech",
            "Inferior frontal gyrus",
            "Intervention strategy",
            "Resources",
            "Supplementary motor areas"
        ],
        "doc_abstract": "© 2018, Springer Nature Switzerland AG.In this paper, we present a database developed for studying inner speech brain related areas using functional Magnetic Resonance Imaging (fMRI) in the context of the European Portuguese. First, we addressed the type of stimuli used in inner speech studies. In this sense, considering a preliminary study using a picture naming task, we defined a corpus. The corpus was designed based on cardinal vowels, syllable, disyllabic words and sentences with structure S(ubject)V(erb)O(bject) which were balanced in syllable number (six to ten). All the words used are common words from the Portuguese lexicon and possible ambiguities were excluded. Currently, the dataset includes data from twenty healthy participants native Portuguese speakers. Preliminary, exploratory analysis on the data allowed us to identify the most relevant areas part of the inner speech network, that include inferior frontal gyrus (including Broca’s area), supplementary motor area and precentral gyrus. Ultimately, the better understanding of the inner speech mechanisms will pave way to the development of novel intervention strategies in linguistic disorders.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Detecting nasal vowels in speech interfaces based on surface electromyography",
        "doc_scopus_id": "84936817954",
        "doc_doi": "10.1371/journal.pone.0127040",
        "doc_eid": "2-s2.0-84936817954",
        "doc_date": "2015-06-12",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Multidisciplinary",
                "area_abbreviation": "MULT",
                "area_code": "1000"
            }
        ],
        "doc_keywords": [
            "Adult",
            "Electromyography",
            "Female",
            "Humans",
            "Magnetic Resonance Imaging",
            "Phonetics",
            "Reproducibility of Results",
            "Speech Acoustics",
            "User-Computer Interface",
            "Young Adult"
        ],
        "doc_abstract": "© 2015 Freitas et al.Nasality is a very important characteristic of several languages, European Portuguese being one of them. This paper addresses the challenge of nasality detection in surface electromyography (EMG) based speech interfaces. We explore the existence of useful information about the velum movement and also assess if muscles deeper down in the face and neck region can be measured using surface electrodes, and the best electrode location to do so. The procedure we adopted uses Real-Time Magnetic Resonance Imaging (RT-MRI), collected from a set of speakers, providing a method to interpret EMG data. By ensuring compatible data recording conditions, and proper time alignment between the EMG and the RT-MRI data, we are able to accurately estimate the time when the velum moves and the type of movement when a nasal vowel occurs. The combination of these two sources revealed interesting and distinct characteristics in the EMG signal when a nasal vowel is uttered, which motivated a classification experiment. Overall results of this experiment provide evidence that it is possible to detect velum movement using sensors positioned below the ear, between mastoid process and the mandible, in the upper neck region. In a frame-based classification scenario, error rates as low as 32.5% for all speakers and 23.4% for the best speaker have been achieved, for nasal vowel detection. This outcome stands as an encouraging result, fostering the grounds for deeper exploration of the proposed approach as a promising route to the development of an EMG-based speech interface for languages with strong nasal characteristics.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Velar movement assessment for speech interfaces: An exploratory study using surface electromyography",
        "doc_scopus_id": "84955320352",
        "doc_doi": "10.1007/978-3-319-26129-4_16",
        "doc_eid": "2-s2.0-84955320352",
        "doc_date": "2015-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            },
            {
                "area_name": "Mathematics (all)",
                "area_abbreviation": "MATH",
                "area_code": "2600"
            }
        ],
        "doc_keywords": [
            "Exploratory studies",
            "Movement detection",
            "Nasal vowels",
            "Neck region",
            "Noninvasive methods",
            "Silent speech interfaces",
            "Speech interface",
            "Surface electromyography"
        ],
        "doc_abstract": "© Springer International Publishing Switzerland 2015.In the literature several silent speech interfaces based on Surface Electromyography (EMG) can be found. However, it is yet unclear if we are able to sense muscles activity related to nasal port opening/closing. Detecting the nasality phenomena, would increase the performance of languages with strong nasal characteristics such as European Portuguese. In this paper we explore the use of surface EMG electrodes, a non-invasive method, positioned in the face and neck regions to explore the existence of useful information about the velum movement. For an accurate interpretation and validation of the proposed method, we use velum movement information extracted from Real-Time Magnetic Resonance Imaging (RT-MRI) data. Overall, results of this study show that differences can be found in the EMG signals for the case of nasal vowels, by sensors positioned below the ear between the mastoid process and the mandible in the upper neck region.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Quantitative analysis of /l/ production from RT-MRI: First results",
        "doc_scopus_id": "84921383919",
        "doc_doi": "10.1007/978-3-319-13623-3_4",
        "doc_eid": "2-s2.0-84921383919",
        "doc_date": "2014-01-01",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Co-articulation",
            "Dynamic property",
            "Large amounts of data",
            "Laterals",
            "Position effect",
            "Quantitative frameworks",
            "Systematic analysis",
            "Temporal aspects"
        ],
        "doc_abstract": "© Springer International Publishing Switzerland 2014.Lateral consonants are complex and variable sounds. Static MRI provides relevant information regarding /l/ geometry, but does not address dynamic properties. Real-time MRI is a well suited technique for dealing with temporal aspects. However, large amounts of data have to be processed to harness its full potential. The main goal of this paper is to extend a recently proposed quantitative framework to the analysis of real-time MRI data for European Portuguese /l/. Several vocal tract configurations of the alveolar consonant, acquired in different syllable positions and vocalic contexts, were compared. The quantitative framework revealed itself capable of dealing with the data for the /l/, allowing a systematic analysis of the multiple realisations. The results regarding syllable position effects and coarticulation of /l/ with adjacent vowels are in line with previous findings.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Impact of age in the production of European Portuguese vowels",
        "doc_scopus_id": "84910031154",
        "doc_doi": null,
        "doc_eid": "2-s2.0-84910031154",
        "doc_date": "2014-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Language and Linguistics",
                "area_abbreviation": "ARTS",
                "area_code": "1203"
            },
            {
                "area_name": "Human-Computer Interaction",
                "area_abbreviation": "COMP",
                "area_code": "1709"
            },
            {
                "area_name": "Signal Processing",
                "area_abbreviation": "COMP",
                "area_code": "1711"
            },
            {
                "area_name": "Software",
                "area_abbreviation": "COMP",
                "area_code": "1712"
            },
            {
                "area_name": "Modeling and Simulation",
                "area_abbreviation": "MATH",
                "area_code": "2611"
            }
        ],
        "doc_keywords": [
            "Acoustic characteristic",
            "Developed countries",
            "Elderly populations",
            "European portuguese",
            "Fundamental frequencies",
            "Language development",
            "Oral vowels",
            "Speech acoustics"
        ],
        "doc_abstract": "Copyright © 2014 ISCA.The elderly population is quickly increasing in the developed countries. However, in European Portuguese (EP) no studies have examined the impact of age-related structural changes in speech acoustics. The purpose of this paper is to analyse the effect of age ([60-70], [71-80] and [81-90]), gender and type of vowel in the acoustic characteristics (fundamental frequency (F0), first formant (F1), second formant (F2) and duration) of the EP vowels. A sample of 78 speakers was selected from the database of elderly speech collected by Microsoft Language Development Center (MLDC) within the Living Usability Lab (LUL) project. It was observed that duration is the only parameter that significantly changes with ageing, being the highest value found in the [81-90] group. Moreover, F0 decreases in females and increases in males with ageing. In general, F1 and F2 decreases with ageing, mainly in females. Comparing the data obtained with the results of previous studies with adult speakers, a trend towards the centralization of vowels with ageing is observed. This investigation is the starting point for a broader study which will allow to analyse the changes in vowels acoustics from childhood to old age in EP.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Velum movement detection based on surface electromyography for speech interface",
        "doc_scopus_id": "84902334838",
        "doc_doi": "10.5220/0004741100130020",
        "doc_eid": "2-s2.0-84902334838",
        "doc_date": "2014-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Biomedical Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2204"
            },
            {
                "area_name": "Signal Processing",
                "area_abbreviation": "COMP",
                "area_code": "1711"
            }
        ],
        "doc_keywords": [
            "Acoustic signals",
            "Movement detection",
            "Nasal vowels",
            "Noisy environment",
            "Noninvasive methods",
            "Silent speech interfaces",
            "Speech interface",
            "Surface electromyography"
        ],
        "doc_abstract": "Conventional speech communication systems do not perform well in the absence of an intelligible acoustic signal. Silent Speech Interfaces enable speech communication to take place with speech-handicapped users and in noisy environments. However, since no acoustic signal is available, information on nasality may be absent, which is an important and relevant characteristic of several languages, particularly European Portuguese. In this paper we propose a non-invasive method - surface Electromyography (EMG) electrodes - positioned in the face and neck regions to explore the existence of useful information about the velum movement. The applied procedure takes advantage of Real-Time Magnetic Resonance Imaging (RT-MRI) data, collected from the same speakers, to interpret and validate EMG data. By ensuring compatible scenario conditions and proper alignment between the EMG and RT-MRI data, we are able to estimate when the velum moves and the probable type of movement under a nasality occurrence. Overall results of this experiment revealed interesting and distinct characteristics in the EMG signal when a nasal vowel is uttered and that it is possible to detect velum movement, particularly by sensors positioned below the ear between the mastoid process and the mandible in the upper neck region. Copyright © 2014 SCITEPRESS - Science and Technology Publications. All rights reserved.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Integrated development and evaluation of innovative AAL services - A Living Lab approach",
        "doc_scopus_id": "84887956835",
        "doc_doi": null,
        "doc_eid": "2-s2.0-84887956835",
        "doc_date": "2013-11-25",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Computer Networks and Communications",
                "area_abbreviation": "COMP",
                "area_code": "1705"
            },
            {
                "area_name": "Information Systems",
                "area_abbreviation": "COMP",
                "area_code": "1710"
            }
        ],
        "doc_keywords": [
            "Ambient assisted living",
            "Ambient assisted living (AAL)",
            "General architectures",
            "Integrated development",
            "Living lab",
            "Methodological approach",
            "services evaluation",
            "usability"
        ],
        "doc_abstract": "The paper aims to systematize the work associated with the consolidation of the geographically distributed Living Lab for the development of Ambient Assisted Living (AAL) systems and services. The paper presents the developed methodological approach, the general architecture that supports the development of AAL applications, the implemented physical infrastructure and also an instantiation of the existing infrastructure for the implementation of a telerehabilitation service. © 2013 AISTI.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Segmentation and analysis of vocal tract from midsagittal real-time MRI",
        "doc_scopus_id": "84884492397",
        "doc_doi": "10.1007/978-3-642-39094-4_52",
        "doc_eid": "2-s2.0-84884492397",
        "doc_date": "2013-09-26",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Anatomical structures",
            "Data processing and analysis",
            "Dynamic aspects",
            "Large amounts",
            "Nasal vowels",
            "Real-Time MRI",
            "Speech production",
            "Vocal-tracts"
        ],
        "doc_abstract": "The articulatory description of European Portuguese (EP) requires the analysis of different anatomical structures (e.g. tongue dorsum and velum), and the study of dynamic aspects of speech production. The use of real-time magnetic resonance imaging (RT-MRI), with frame rates above 10 frames/s, provides adequate support for these studies and results in a large amount of images that need to be processed to extract relevant data to be analysed by linguists. To tackle the required data processing and analysis this article presents methods to perform segmentation of the vocal tract from midsagittal real-time MR image sequences and provide researchers with visualizations of the relevant extracted data. Examples are provided illustrating the analysis of dynamic aspects of EP nasal vowels. © 2013 Springer-Verlag.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "New telerehabilitation services for the elderly",
        "doc_scopus_id": "84887892291",
        "doc_doi": "10.4018/978-1-4666-3990-4.ch006",
        "doc_eid": "2-s2.0-84887892291",
        "doc_date": "2013-04-30",
        "doc_type": "Book Chapter",
        "doc_areas": [
            {
                "area_name": "Medicine (all)",
                "area_abbreviation": "MEDI",
                "area_code": "2700"
            },
            {
                "area_name": "Health Professions (all)",
                "area_abbreviation": "HEAL",
                "area_code": "3600"
            }
        ],
        "doc_keywords": [
            "Cognitive capability",
            "Health-care system",
            "Multi-Modal Interactions",
            "Older People",
            "Telerehabilitation",
            "Unsolved problems",
            "Vision problems",
            "Work in progress"
        ],
        "doc_abstract": "© 2013 by IGI Global. All rights reserved.The world's population is getting older with the percentage of people over 60 increasing more rapidly than any other age group. Telerehabilitation may help minimise the pressure this puts on the traditional healthcare system, but recent studies showed ease of use, usability, and accessibility as unsolved problems, especially for older people who may have little experience or confidence in using technology. Current migration towards multimodal interaction has benefits for seniors, allowing hearing and vision problems to be addressed by exploring redundancy and complementarity of modalities. This chapter presents and contextualizes work in progress in a new telerehabilitation service targeting the combined needs of the elderly to have professionally monitored exercises without leaving their homes with their need regarding interaction, directly related to age-related effects on, for example, vision, hearing, and cognitive capabilities. After a brief general overview of the service, additional information on its two supporting applications are presented, including information on user interfaces. First results from a preliminary evaluation are also included.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Towards a systematic and quantitative analysis of vocal tract data",
        "doc_scopus_id": "84906221888",
        "doc_doi": null,
        "doc_eid": "2-s2.0-84906221888",
        "doc_date": "2013-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Language and Linguistics",
                "area_abbreviation": "ARTS",
                "area_code": "1203"
            },
            {
                "area_name": "Human-Computer Interaction",
                "area_abbreviation": "COMP",
                "area_code": "1709"
            },
            {
                "area_name": "Signal Processing",
                "area_abbreviation": "COMP",
                "area_code": "1711"
            },
            {
                "area_name": "Software",
                "area_abbreviation": "COMP",
                "area_code": "1712"
            },
            {
                "area_name": "Modeling and Simulation",
                "area_abbreviation": "MATH",
                "area_code": "2611"
            }
        ],
        "doc_keywords": [
            "Application examples",
            "Large amounts of data",
            "Quantitative approach",
            "Quantitative comparison",
            "Real-Time MRI",
            "Traditional approaches",
            "Visual representations",
            "Vocal-tracts"
        ],
        "doc_abstract": "Articulatory data can nowadays be obtained using a wide range of techniques, such as real-time magnetic resonance (RT-MRI), enabling acquisitions of large amounts of data. A major challenge arises: Analysing these new large data sets to extract meaningful information regarding speech production in an expedite and replicable way. Traditional approaches such as superimposing vocal tract profiles and qualitatively characterizing relevant properties and differences, although providing valuable information, are rather inefficient and subjective. Therefore, analysis must evolve towards a more automated, quantitative approach. To tackle this issue we propose the use of objective measures to compare the configurations assumed by the vocal tract during the production of different sounds. The proposed framework provides quantitative data regarding differences pertaining meaningful regions under the influence of various articulators. Visual representation of such data is a key part of the proposal and some concrete forms of visualization are proposed to depict the differences found and corresponding direction of change. Application examples concerning the articulatory characterization of EP vowels are presented with promising results, paving the way towards automated and objective analyses of articulatory data. Copyright © 2013 ISCA.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Acoustic analysis of European Portuguese oral vowels produced by children",
        "doc_scopus_id": "84871478257",
        "doc_doi": "10.1007/978-3-642-35292-8_14",
        "doc_eid": "2-s2.0-84871478257",
        "doc_date": "2012-12-28",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            },
            {
                "area_name": "Mathematics (all)",
                "area_abbreviation": "MATH",
                "area_code": "2600"
            }
        ],
        "doc_keywords": [
            "Acoustic analysis",
            "Age effects",
            "Formant frequency",
            "Fundamental frequencies",
            "Male speakers"
        ],
        "doc_abstract": "This study investigates acoustic changes in the speech of European Portuguese children, as a function of age and gender. Fundamental frequency, formant frequencies and duration of vowels produced by a group of 30 children, ages 7 and 10 years, were measured. The results revealed that, for male speakers, F0, F1 and F2 decrease as age increases, although the age effect was not statistically significant for F0 and F1. A similar trend was observed for female speakers, but only in F2. Moreover, F0 and formant frequencies were found to be similar between male and female children. Between ages 7 and 10, vowel durations decreased significantly, and the values for females were higher than those for males. These results provide a base of information for establishing the normal pattern of development in European Portuguese children. © 2012 Springer-Verlag.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "An MRI study of the oral articulation of European Portuguese nasal vowels",
        "doc_scopus_id": "84878599176",
        "doc_doi": null,
        "doc_eid": "2-s2.0-84878599176",
        "doc_date": "2012-12-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Computer Networks and Communications",
                "area_abbreviation": "COMP",
                "area_code": "1705"
            },
            {
                "area_name": "Communication",
                "area_abbreviation": "SOCI",
                "area_code": "3315"
            }
        ],
        "doc_keywords": [
            "European Portuguese",
            "Imaging data",
            "Magnetic Resonance Imaging (MRI)",
            "Nasal vowels",
            "Production of",
            "Real-Time MRI",
            "Vocal-tracts",
            "Vowel production"
        ],
        "doc_abstract": "There is increasing evidence that, in addition to velopharyngeal coupling, lingual position may also change during production of phonemic nasal vowels. In order to investigate differences in oral articulation between European Portuguese (EP) nasal vowels and oral counterparts, imaging data (both static and real-time MRI) of several EP speakers (male and female) are used. Superimposition of outlines of the vocal tract profiles, semi-automatically extracted from MRI images, were used to compare the position of tongue and lips during nasal and oral vowel production. The results suggest that lingual and labial differences between nasal vowels and their oral counterparts are quite subtle in EP. Nasal vowels [ã], [õ] exhibited more articulatory adjustments with respect to oral congeners than [1̃] and [ũ].",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Segmentation and analysis of the oral and nasal cavities from MR time sequences",
        "doc_scopus_id": "84864125184",
        "doc_doi": "10.1007/978-3-642-31298-4_26",
        "doc_eid": "2-s2.0-84864125184",
        "doc_date": "2012-07-27",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Dynamic aspects",
            "Large images",
            "MR images",
            "Nasal cavity",
            "Nasal vowels",
            "Oral cavity",
            "Real-Time MRI",
            "Segmentation tool",
            "Speech production",
            "Temporal resolution",
            "Time sequences",
            "Time-consuming tasks",
            "Vocal-tracts"
        ],
        "doc_abstract": "The study of dynamic aspects of speech production in Portuguese is very important to characterize vowel nasalization. In this context, the analysis of velum movement remains a challenging task and only a few studies present articulatory descriptions of Portuguese nasal vowels. Advances in real-time MRI (magnetic resonance imaging) allow the acquisition of vocal tract images with reasonable spatial and temporal resolution to enable observation and quantification of articulatory movements. The resulting data consists of large image sequences and the structures of interest (e.g., oral cavity) have to be identified (segmented) throughout to enable analysis which can be a time consuming task. This article presents a segmentation tool for real-time MR image sequences of the oral and nasal cavities. The proposed tool has been implemented using MevisLab and provides features for the analysis of the resulting data. © 2012 Springer-Verlag.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Production and modeling of the European Portuguese palatal lateral",
        "doc_scopus_id": "84858404691",
        "doc_doi": "10.1007/978-3-642-28885-2_36",
        "doc_eid": "2-s2.0-84858404691",
        "doc_date": "2012-03-22",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Acoustic modeling",
            "Area function",
            "Convex shapes",
            "Cross sectional area",
            "European Portuguese",
            "Frequency ranges",
            "Lateral compression",
            "magnetic ressonance",
            "MRI Image",
            "palatal lateral",
            "Pole-zero",
            "Vocal-tracts"
        ],
        "doc_abstract": "In this study, an articulatory characterization of the palatal lateral is provided, using MRI images of the vocal tract acquired during the production of /L/ by several speakers of European Portuguese. The production of this sound involves: a complete linguo-alveolopalatal closure; inward lateral compression of the tongue and a convex shape of the posterior tongue body, allowing airflow around the sides of the tongue; large cross-sectional areas in the upper pharyngeal and velar regions. The lengths and area functions derived from MRI are analysed and used to model the articulatory-acoustic relations involved in the production of /L/. The results obtained in the first simulations show that the vocal-tract model (VTAR) is reasonably able to estimate the frequencies of the first formants and zeros. The lateral channels combined with the supralingual cavity create pole-zero clusters around and above F3, in the frequency range of 2-4.5 kHz. © 2012 Springer-Verlag.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Real-time MRI for Portuguese: Database, methods and applications",
        "doc_scopus_id": "84858377622",
        "doc_doi": "10.1007/978-3-642-28885-2_35",
        "doc_eid": "2-s2.0-84858377622",
        "doc_date": "2012-03-22",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "European Portuguese",
            "laterals",
            "nasal vowels",
            "Real-Time MRI",
            "trills"
        ],
        "doc_abstract": "In this paper, we present a database of synchronized audio and Real-Time Magnetic Resonance Imaging (RT-MRI) in order to study dynamic aspects of the production of European Portuguese (EP) sounds. Currently, data have been acquired from one native speaker of European Portuguese. The speech corpus was primarily designed to investigate nasal vowels in a wide range of phonological contexts, but also includes examples of other EP sounds. The RT-MRI protocol developed for the acquisition of the data is detailed. Midsagittal and oblique images were acquired with a frame rate of 14 frames/s, resulting in a temporal resolution of 72 ms. Different image processing tools (automatic and semi-automatic) applied for inspection and analysis of the data are described. We demonstrate the potential of this database and processing techniques with some illustrative examples of Portuguese nasal vowels, taps, trills and laterals. © 2012 Springer-Verlag.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Tongue segmentation from MRI images using ITK-SNAP: Preliminary evaluation",
        "doc_scopus_id": "84864986322",
        "doc_doi": null,
        "doc_eid": "2-s2.0-84864986322",
        "doc_date": "2011-12-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Computer Graphics and Computer-Aided Design",
                "area_abbreviation": "COMP",
                "area_code": "1704"
            },
            {
                "area_name": "Computer Vision and Pattern Recognition",
                "area_abbreviation": "COMP",
                "area_code": "1707"
            },
            {
                "area_name": "Information Systems",
                "area_abbreviation": "COMP",
                "area_code": "1710"
            }
        ],
        "doc_keywords": [
            "3D Visualization",
            "European Portuguese",
            "Jaccard coefficients",
            "Magnetic resonance images",
            "Manual segmentation",
            "MRI Image",
            "Region competition",
            "Semi-automatic segmentation",
            "Semi-automatics",
            "Semiautomatic methods",
            "Similarity metrics",
            "Speech production",
            "Speech synthesizer",
            "Tongue segmentation",
            "Validation",
            "Volumetric data"
        ],
        "doc_abstract": "The purpose of this study was to evaluate and compare the efficiency, reliability and accuracy of manual and semiautomatic segmentation techniques to segment tongue images. This work is included in a vast framework (HERON II) that aims to improve an articulatory-based speech synthesizer (SAP-Windows), for European Portuguese (EP). Volumetric data from Magnetic resonance images (MRI) were used to extract tongue configurations from several speakers uttering different EP sounds, or the same sound produced in different contexts or syllabic positions, in a speech production study. Segmentations were performed manually and using a semi-automatic approach implemented in ITK-SNAP (Region Competition Snakes). Results from similarity metrics (Jaccard coefficient and voxelwise comparison) revealed that the semi-automatic (SA) method presents good agreement with the manual segmentation method (Jaccard=0.9002 and 10.495 voxel error). Furthermore, the semi-automatic method is more reproducible (Jaccard=0.9382 and 6.388 voxel error) than manual segmentation method (Jaccard= 0.9170 and 8.662 voxel error). The semi-automatic approach provides an efficient and reliable method to segment tongue images providing 3D visualizations that allows description and comparison of tongue configurations during the production of different sounds. This information is of great relevance in speech production field contributing to a better understanding of speech production mechanisms. © 2011 IADIS.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "A new living lab for usability evaluation of ICT and next generation networks for elderly@home",
        "doc_scopus_id": "79960543375",
        "doc_doi": null,
        "doc_eid": "2-s2.0-79960543375",
        "doc_date": "2011-07-25",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Computational Theory and Mathematics",
                "area_abbreviation": "COMP",
                "area_code": "1703"
            },
            {
                "area_name": "Applied Mathematics",
                "area_abbreviation": "MATH",
                "area_code": "2604"
            }
        ],
        "doc_keywords": [
            "Conceptual model",
            "General population",
            "Living lab",
            "Next generation network",
            "Universal Design",
            "Usability evaluation",
            "Usability testing",
            "Work in progress"
        ],
        "doc_abstract": "Living Usability Lab for Next Generation Networks (www.livinglab.pt) is a Portuguese industry-academia collaborative R&D project, active in the field of live usability testing, focusing on the development of technologies and services to support healthy, productive and active citizens. The project adopts the principles of universal design and natural user interfaces (speech, gesture) making use of the benefits of next generation networks and distributed computing. Therefore, it will have impact on the general population, including the elderly and citizens with permanent or situational special needs. This paper presents project motivations, conceptual model, architecture and work in progress.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "An MRI study of consonantal coarticulation resistance in Portuguese",
        "doc_scopus_id": "84926296637",
        "doc_doi": null,
        "doc_eid": "2-s2.0-84926296637",
        "doc_date": "2011-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Language and Linguistics",
                "area_abbreviation": "ARTS",
                "area_code": "1203"
            },
            {
                "area_name": "Linguistics and Language",
                "area_abbreviation": "SOCI",
                "area_code": "3310"
            },
            {
                "area_name": "Computer Science Applications",
                "area_abbreviation": "COMP",
                "area_code": "1706"
            }
        ],
        "doc_keywords": [
            "Co-articulation",
            "MR images",
            "Qualitative evaluations",
            "Quantitative evaluation",
            "Quantitative result",
            "Semi-automatic segmentation",
            "Similarity metrics"
        ],
        "doc_abstract": "This study aimed to evaluate the effect of vocalic context, particularly at tongue level, on the articulation of European Portuguese (EP) consonants. Magnetic Resonance (MR) images were acquired for three speakers (two male and one female) during the production of consonants in a symmetric VCV context, with the cardinal vowels [i,a,u], Midsagittal contours of the tongue were extracted from MR images (by using a semi-automatic segmentation technique) and superimposed in order to allow a qualitative evaluation. Furthermore, a quantitative evaluation using a similarity metric (Pratt Index) was also conducted. Qualitative and quantitative results showed that stop consonants and nasals were especially sensitive to the vocalic context. Also, labial consonants were clearly more influenced by surrounding vowels than alveolars and dorsals. In comparison with all the consonantal segments analyzed, the fricatives [3 ∫] and the lateral [γ] were minimally affected by vowel context.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "3D MRI and semi-automatic segmentation techniques applied to the study of European Portuguese lateral sounds",
        "doc_scopus_id": "84910077128",
        "doc_doi": null,
        "doc_eid": "2-s2.0-84910077128",
        "doc_date": "2011-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Language and Linguistics",
                "area_abbreviation": "ARTS",
                "area_code": "1203"
            },
            {
                "area_name": "Linguistics and Language",
                "area_abbreviation": "SOCI",
                "area_code": "3310"
            },
            {
                "area_name": "Computer Science Applications",
                "area_abbreviation": "COMP",
                "area_code": "1706"
            }
        ],
        "doc_keywords": [
            "Common property",
            "Context effects",
            "Lateral compression",
            "MR images",
            "Reliable methods",
            "Semi-automatic segmentation",
            "Semi-automatics",
            "Vocal-tracts"
        ],
        "doc_abstract": "This study used 3D MR images and explored semi-automatic segmentation techniques to investigate the articulatory characteristics of European Portuguese (EP) laterals. Syllabic position and vowel context effects were also evaluated. Seven speakers of EP were scanned while uttering the consonants /I, U in the context of the cardinal vowels/i, a, u/. The semi-automatic approach provided an efficient and reliable method to segment tongue and vocal tract images. The analysis of MR images revealed several common properties for both /l/ and /U: lateral compression of the tongue and a convex tongue body, which enables the creation of lateral channels. However, /U exhibited greater lateral compression, when compared to /I/, and also larger lateral channels. The EP laterals were also distinguished from each other by means of the extension of constriction. For most of the speakers, /// exhibited a similar tongue body configuration at the word edges, with small pharyngeal/velar areas due to tongue-root retraction and/or raising the tongue dorsum. Vocalic effects were more evident in the alveolar lateral than in /IV. c.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Speech rate effects on European Portuguese nasal vowels",
        "doc_scopus_id": "70450179792",
        "doc_doi": null,
        "doc_eid": "2-s2.0-70450179792",
        "doc_date": "2009-11-26",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Human-Computer Interaction",
                "area_abbreviation": "COMP",
                "area_code": "1709"
            },
            {
                "area_name": "Signal Processing",
                "area_abbreviation": "COMP",
                "area_code": "1711"
            },
            {
                "area_name": "Software",
                "area_abbreviation": "COMP",
                "area_code": "1712"
            },
            {
                "area_name": "Sensory Systems",
                "area_abbreviation": "NEUR",
                "area_code": "2809"
            }
        ],
        "doc_keywords": [
            "Gestures",
            "Nasal vowels",
            "Speech rates",
            "Temporal characteristics",
            "Temporal information"
        ],
        "doc_abstract": "This paper presents new temporal information regarding the production of European Portuguese (EP) nasal vowels, based on new EMMA data. The influence of speech rate on duration of velum gestures and their coordination with consonantic and glottal gestures were analyzed. As information on relative speed of articulators is scarce, the parameter stiffness for the nasal gestures was also calculated and analyzed. Results show clear effects of speech rate on temporal characteristics of EP nasal vowels. Speech rate reduces the duration of velum gestures, increases the stiffness and inter-gestural overlap. Copyright © 2009 ISCA.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "European Portuguese articulatory based text-to-speech: First results",
        "doc_scopus_id": "52949109223",
        "doc_doi": "10.1007/978-3-540-85980-2_11",
        "doc_eid": "2-s2.0-52949109223",
        "doc_date": "2008-10-06",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Computational processing",
            "European",
            "International conferences",
            "Linguistic modeling",
            "Perceptual evaluation",
            "System capabilities",
            "Text-to-speech",
            "TTS systems"
        ],
        "doc_abstract": "In this paper we present recent work on the development of Linguistic Models, resulting in a first \"complete\" articulatory-based TTS system for Portuguese. The system, based on TADA system, integrates our past work in automatic syllabification and grapheme-phone conversion plus a first gestural specification of European Portuguese sounds. The system was integrated with SAPWindows, an articulatory synthesizer for Portuguese. A demonstration of the system capabilities and a first perceptual evaluation are presented. © 2008 Springer-Verlag Berlin Heidelberg.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "On the use of machine learning and syllable information in European Portuguese grapheme-phone conversion",
        "doc_scopus_id": "33745809812",
        "doc_doi": "10.1007/11751984_24",
        "doc_eid": "2-s2.0-33745809812",
        "doc_date": "2006-07-17",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "European Portuguese grapheme-phone conversion",
            "Parallel combinations",
            "Self-learning methods",
            "Syllable information"
        ],
        "doc_abstract": "In this study evaluation of two self-learning methods (MBL and TBL) on European Portuguese grapheme-to-phone conversion is presented. Combinations (parallel and cascade) of the two systems were also tested. The usefulness of syllable information is also investigated. Systems with good performance were obtained both using a single self-learning method and combinations. Best performance was obtained with MBL and the parallel combination. The use of syllable information contributes to a better performance in all systems tested. © Springer-Verlag Berlin Heidelberg 2006.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "On European Portuguese automatic syllabification",
        "doc_scopus_id": "33745210111",
        "doc_doi": null,
        "doc_eid": "2-s2.0-33745210111",
        "doc_date": "2005-12-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Engineering (all)",
                "area_abbreviation": "ENGI",
                "area_code": "2200"
            }
        ],
        "doc_keywords": [
            "Automatic syllabification",
            "Language processing systems",
            "Syllable boundaries",
            "Syllable structures"
        ],
        "doc_abstract": "This paper presents three methods for dividing European Portuguese (EP) words into syllables, two of them handling graphemes as input, the other processing phone sequences. All three try to incorporate linguistic knowledge about EP syllable structure, but in different degrees. Experimental results showed, for the best method, percentage of correctly recognized syllable boundaries above 99.5 %, and comparable word accuracy. The much simpler finite state transducer based method also achieved a good performance, making it suitable for applications more interested in speed and memory footprint. Being syllabification an essential component of many speech and language processing systems, proposed methods can be useful to researchers working with the EP language.",
        "available": false,
        "clean_text": ""
    }
]