[
    {
        "doc_title": "Robust biped locomotion using deep reinforcement learning on top of an analytical control approach",
        "doc_scopus_id": "85117070684",
        "doc_doi": "10.1016/j.robot.2021.103900",
        "doc_eid": "2-s2.0-85117070684",
        "doc_date": "2021-12-01",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Software",
                "area_abbreviation": "COMP",
                "area_code": "1712"
            },
            {
                "area_name": "Control and Systems Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2207"
            },
            {
                "area_name": "Mathematics (all)",
                "area_abbreviation": "MATH",
                "area_code": "2600"
            },
            {
                "area_name": "Computer Science Applications",
                "area_abbreviation": "COMP",
                "area_code": "1706"
            }
        ],
        "doc_keywords": [
            "Deep reinforcement learning",
            "Dynamics models",
            "Genetic algorithm",
            "Humanoid robot",
            "Linear quadratic Gaussian",
            "Linear–quadratic–gaussian",
            "Modular walk engine",
            "Modulars",
            "Policy optimization",
            "Proximal policy optimization"
        ],
        "doc_abstract": "© 2021 Elsevier B.V.This paper proposes a modular framework to generate robust biped locomotion using a tight coupling between an analytical walking approach and deep reinforcement learning. This framework is composed of six main modules which are hierarchically connected to reduce the overall complexity and increase its flexibility. The core of this framework is a specific dynamics model which abstracts a humanoid's dynamics model into two masses for modeling upper and lower body. This dynamics model is used to design an adaptive reference trajectories planner and an optimal controller which are fully parametric. Furthermore, a learning framework is developed based on Genetic Algorithm (GA) and Proximal Policy Optimization (PPO) to find the optimum parameters and to learn how to improve the stability of the robot by moving the arms and changing its center of mass height. A set of simulations are performed to validate the performance of the framework using the official RoboCup 3D League simulation environment. The results validate the performance of the framework, not only in creating a fast and stable gait but also in learning to improve the upper body efficiency.",
        "available": true,
        "clean_text": "serial JL 271599 291210 291866 291870 291882 291883 31 Robotics and Autonomous Systems ROBOTICSAUTONOMOUSSYSTEMS 2021-10-01 2021-10-01 2021-10-14 2021-10-14 2021-11-01T10:55:17 S0921-8890(21)00185-8 S0921889021001858 10.1016/j.robot.2021.103900 S300 S300.1 FULL-TEXT 2022-02-09T11:58:40.089314Z 0 0 20211201 20211231 2021 2021-10-01T04:54:03.279527Z articleinfo articlenumber articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid hubeid indexeddate issn issnnorm itemstage itemtransactionid itemweight openaccess openarchive pg pgfirst pii piinorm pubdateend pubdatestart pubdatetxt pubyr sortorder srctitle srctitlenorm srctype ssids alllist content subj subheadings suppl tomb volfirst volissue volumelist yearnav figure table body mmlmath acknowledge affil articletitle auth authfirstini authfull authkeywords authlast footnotes grantnumber grantsponsor grantsponsorid highlightsabst orcid primabst ref vitae 0921-8890 09218890 true 146 146 C Volume 146 15 103900 103900 103900 202112 December 2021 2021-12-01 2021-12-31 2021 article fla © 2021 Elsevier B.V. All rights reserved. ROBUSTBIPEDLOCOMOTIONUSINGDEEPREINFORCEMENTLEARNINGTOPANALYTICALCONTROLAPPROACH KASAEI M 1 Introduction 2 Related work 2.1 Combination of model-based walking and ML algorithms 2.2 Combination of CPG-based Walking and ML algorithms 2.3 Combination of CPG-ZMP based walking and ML algorithms 2.4 Learning to walk from scratch 3 Dynamics model and stability criteria 3.1 Zero momentum point 3.2 Dynamics model 4 Controller 4.1 State estimator 4.2 Optimal gain 5 Reference trajectories planner 6 Learning framework 7 Overall structure 8 Simulations 8.1 Omnidirectional walk 8.2 Optimizing the walking parameters 8.3 Learning to improve the upper body efficiency 8.3.1 Original scenario results 8.3.2 Straightforward path results 9 Discussion 9.1 Features 9.2 Limitations 10 Conclusion Acknowledgment References KAJITA 1991 1405 1411 S ROBOTICSAUTOMATION1991PROCEEDINGS1991IEEEINTERNATIONALCONFERENCE STUDYDYNAMICBIPEDLOCOMOTIONRUGGEDTERRAINDERIVATIONAPPLICATIONLINEARINVERTEDPENDULUMMODE KAJITA 2003 1620 1626 S ROBOTICSAUTOMATION2003PROCEEDINGSICRA03IEEEINTERNATIONALCONFERENCEVOL2 BIPEDWALKINGPATTERNGENERATIONBYUSINGPREVIEWCONTROLZEROMOMENTPOINT KAJITA 2010 4489 4496 S INTELLIGENTROBOTSSYSTEMSIROS2010IEEERSJINTERNATIONALCONFERENCE BIPEDWALKINGSTABILIZATIONBASEDLINEARINVERTEDPENDULUMTRACKING SHIMMYO 2013 5137 5147 S FARAJI 2017 436 455 S GRIFFIN 2017 667 673 R 2017IEEERSJINTERNATIONALCONFERENCEINTELLIGENTROBOTSSYSTEMSIROS WALKINGSTABILIZATIONUSINGSTEPTIMINGLOCATIONADJUSTMENTHUMANOIDROBOTATLAS KASAEI 2019 1429 1434 M 2019IEEERSJINTERNATIONALCONFERENCEINTELLIGENTROBOTSSYSTEMS AROBUSTBIPEDLOCOMOTIONBASEDLINEARQUADRATICGAUSSIANCONTROLLERDIVERGENTCOMPONENTMOTION KASAEI 2019 1 6 M 2019IEEEINTERNATIONALCONFERENCEAUTONOMOUSROBOTSYSTEMSCOMPETITIONSICARSC AMODELBASEDBIPEDWALKINGCONTROLLERBASEDDIVERGENTCOMPONENTMOTION YAMAGUCHI 1999 368 374 J PROCEEDINGS1999IEEEINTERNATIONALCONFERENCEROBOTICSAUTOMATIONCATNO99CH36288CVOL1 DEVELOPMENTABIPEDALHUMANOIDROBOTCONTROLMETHODWHOLEBODYCOOPERATIVEDYNAMICBIPEDWALKING KHATIB 2008 303 312 O EUROPEANROBOTICSSYMPOSIUM2008 AUNIFIEDFRAMEWORKFORWHOLEBODYHUMANOIDROBOTCONTROLMULTIPLECONSTRAINTSCONTACTS ISHIHARA 2019 119 126 K SHAN 2000 1930 1935 J PROCEEDINGS2000IEEERSJINTERNATIONALCONFERENCEINTELLIGENTROBOTSSYSTEMSIROS2000CATNO00CH37113VOL3 DESIGNCENTRALPATTERNGENERATORFORHUMANOIDROBOTWALKINGBASEDMULTIOBJECTIVEGA LEE 2013 360 365 J LIU 2013 1206 1215 C YU 2013 441 456 J GUERTIN 2009 45 56 P ZHONG 2012 4735 4759 G MENELAOU 2019 1 12 E KASAEI 2019 99 111 M ROBOCUP2019ROBOTWORLDCUPXXIII AFASTSTABLEOMNIDIRECTIONALWALKINGENGINEFORNAOHUMANOIDROBOT ENDO 2008 213 228 G ABREU 2019 3 15 M ROBOTWORLDCUP LEARNINGRUNFASTERINAHUMANOIDROBOTSOCCERENVIRONMENTTHROUGHREINFORCEMENTLEARNING MACALPINE 2012 P TWENTYSIXTHAAAICONFERENCEARTIFICIALINTELLIGENCE DESIGNOPTIMIZATIONOMNIDIRECTIONALHUMANOIDWALKAWINNINGAPPROACHROBOCUP20113DSIMULATIONCOMPETITION OR 2010 452 460 J HE 2014 160 B KASAEI 2017 743 755 S IBERIANROBOTICSCONFERENCE AHYBRIDZMPCPGBASEDWALKENGINEFORBIPEDROBOTS CARPENTIER 2016 3555 3561 J 2016IEEEINTERNATIONALCONFERENCEROBOTICSAUTOMATIONICRA AVERSATILEEFFICIENTPATTERNGENERATORFORGENERALIZEDLEGGEDLOCOMOTION KORYAKOVSKIY 2018 2471 2477 I SONG 2014 5109 5114 K 2014IEEEINTERNATIONALCONFERENCEROBOTICSAUTOMATIONICRA CPGBASEDCONTROLDESIGNFORBIPEDALWALKINGUNKNOWNSLOPESURFACES MISSURA 2015 387 392 M 2015IEEERSJINTERNATIONALCONFERENCEINTELLIGENTROBOTSSYSTEMSIROS GRADIENTDRIVENONLINELEARNINGBIPEDALPUSHRECOVERY MASSAH 2013 3473 3486 A LIU 2016 39 54 J ABDOLMALEKI 2016 94 99 A 2016INTERNATIONALCONFERENCEAUTONOMOUSROBOTSYSTEMSCOMPETITIONSICARSC CONTEXTUALRELATIVEENTROPYPOLICYSEARCHCOVARIANCEMATRIXADAPTATION DHARIWAL 2017 P OPENAIBASELINES VUKOBRATOVIC 1970 25 36 M WINTER 1990 534 541 D MULTIPLEMUSCLESYSTEMS CONTROLBALANCEUPPERBODYDURINGGAIT KAJITA 2019 17 24 S 2019IEEERAS19THINTERNATIONALCONFERENCEHUMANOIDROBOTSHUMANOIDS POSITIONBASEDLATERALBALANCECONTROLFORKNEESTRETCHEDBIPEDROBOT CARVALHOMELO 2019 37 42 L 2019LATINAMERICANROBOTICSSYMPOSIUMLARS2019BRAZILIANSYMPOSIUMROBOTICSSBR2019WORKSHOPROBOTICSINEDUCATIONWRE LEARNINGHUMANOIDROBOTRUNNINGSKILLSTHROUGHPROXIMALPOLICYOPTIMIZATION TEIXEIRA 2020 34 39 H 2020IEEEINTERNATIONALCONFERENCEAUTONOMOUSROBOTSYSTEMSCOMPETITIONSICARSC HUMANOIDROBOTKICKINMOTIONABILITYFORPLAYINGROBOTICSOCCER MELO 2020 240 245 D 2020LATINAMERICANROBOTICSSYMPOSIUMLARS2020BRAZILIANSYMPOSIUMROBOTICSSBR2020WORKSHOPROBOTICSINEDUCATIONWRE PUSHRECOVERYSTRATEGIESTHROUGHDEEPREINFORCEMENTLEARNING ABREU 2019 1 8 M 2019IEEEINTERNATIONALCONFERENCEAUTONOMOUSROBOTSYSTEMSCOMPETITIONSICARSC LEARNINGLOWLEVELSKILLSSCRATCHFORHUMANOIDROBOTSOCCERUSINGDEEPREINFORCEMENTLEARNING MUZIO 2020 246 251 A 2020LATINAMERICANROBOTICSSYMPOSIUMLARS2020BRAZILIANSYMPOSIUMROBOTICSSBR2020WORKSHOPROBOTICSINEDUCATIONWRE DEEPREINFORCEMENTLEARNINGFORHUMANOIDROBOTDRIBBLING PICADO 2009 805 812 H BIOINSPIREDSYSTEMSCOMPUTATIONALAMBIENTINTELLIGENCE AUTOMATICGENERATIONBIPEDWALKBEHAVIORUSINGGENETICALGORITHMS SHAFII 2010 324 335 N ROBOCUP2010ROBOTSOCCERWORLDCUPXIV BIPEDWALKINGUSINGCORONALSAGITTALMOVEMENTSBASEDTRUNCATEDFOURIERSERIES DIEDAM 2008 1121 1126 H 2008IEEERSJINTERNATIONALCONFERENCEINTELLIGENTROBOTSSYSTEMS ONLINEWALKINGGAITGENERATIONADAPTIVEFOOTPOSITIONINGTHROUGHLINEARMODELPREDICTIVECONTROL HERDT 2010 719 737 A GRIFFIN 2016 1763 1768 R 2016IEEEINTERNATIONALCONFERENCEROBOTICSAUTOMATIONICRA MODELPREDICTIVECONTROLFORDYNAMICFOOTSTEPADJUSTMENTUSINGDIVERGENTCOMPONENTMOTION ASTA 2011 434 443 S EUROPEANCONFERENCEAPPLICATIONSEVOLUTIONARYCOMPUTATION NATUREINSPIREDOPTIMIZATIONFORBIPEDROBOTLOCOMOTIONGAITPLANNING MACALPINE 2017 473 485 P ROBOTWORLDCUP UTAUSTINVILLAROBOCUP20173DSIMULATIONLEAGUECOMPETITIONTECHNICALCHALLENGESCHAMPIONS KASAEI 2020 257 262 M 2020IEEEINTERNATIONALCONFERENCEAUTONOMOUSROBOTSYSTEMSCOMPETITIONSICARSC AROBUSTMODELBASEDBIPEDLOCOMOTIONFRAMEWORKBASEDTHREEMASSMODELPLANNINGCONTROL HAARNOJA 2018 1861 1870 T INTERNATIONALCONFERENCEMACHINELEARNING SOFTACTORCRITICOFFPOLICYMAXIMUMENTROPYDEEPREINFORCEMENTLEARNINGASTOCHASTICACTOR KASAEIX2021X103900 KASAEIX2021X103900XM 2023-10-14T00:00:00.000Z 2023-10-14T00:00:00.000Z © 2021 Elsevier B.V. All rights reserved. 2021-10-19T23:08:26.218Z FCT, Portugal Foundation for Science and Technology SFRH/BD/118438/2016 SFRH/BD/139926/2018 FCT Fundação para a Ciência e a Tecnologia This research is supported by Portuguese National Funds through Foundation for Science and Technology (FCT), Portugal through FCT scholarship SFRH/BD/118438/2016 . The second author is supported by FCT, Portugal under grant SFRH/BD/139926/2018 . 0 item S0921-8890(21)00185-8 S0921889021001858 10.1016/j.robot.2021.103900 271599 2022-02-09T11:58:40.089314Z 2021-12-01 2021-12-31 true 2788065 MAIN 13 67688 849 656 IMAGE-WEB-PDF 1 gr11 16780 145 328 fx1 5642 132 113 gr6 92251 361 659 fx3 5678 132 113 fx5 5798 132 113 gr5 55395 177 678 gr3 16573 147 386 fx2 8721 132 113 gr2 23530 199 464 gr10 29071 212 378 gr7 31450 192 379 gr9 29007 201 376 gr1 33011 192 614 gr4 50638 177 678 fx4 6185 132 113 gr12 15103 143 376 gr13 41919 210 535 gr8 26304 217 386 gr11 5236 97 219 fx1 13070 163 140 gr6 15478 120 219 fx3 17502 163 140 fx5 14995 163 140 gr5 5673 57 219 gr3 5129 83 219 fx2 21018 163 140 gr2 7615 94 219 gr10 18017 123 219 gr7 16760 111 219 gr9 17729 117 219 gr1 4578 68 219 gr4 5361 57 219 fx4 19141 163 140 gr12 3154 83 219 gr13 5909 86 219 gr8 4181 123 219 gr11 125477 643 1455 fx1 53948 583 500 gr6 731261 1596 2916 fx3 56853 583 500 fx5 55103 583 500 gr5 547646 785 3000 gr3 123084 651 1711 fx2 84459 583 500 gr2 196575 881 2055 gr10 357260 938 1673 gr7 371628 851 1677 gr9 373975 893 1667 gr1 247182 849 2720 gr4 510980 784 3000 fx4 57994 583 500 gr12 106692 634 1668 gr13 344359 928 2369 gr8 185114 960 1708 si19 20470 si187 2514 si103 23911 si23 3114 si70 1677 si1 2457 si11 3084 si141 3594 si131 4271 si174 2953 si121 23654 si71 18003 si182 9289 si136 3913 si56 6790 si83 7347 si189 11578 si132 4013 si102 8190 si175 2891 si94 9318 si185 1662 si173 4536 si95 4115 si73 1896 si155 12175 si179 5756 si57 7511 si9 6294 si84 6799 si139 4025 si142 3809 si61 6055 si129 1606 si190 749 si10 3680 si143 3896 si193 999 si138 4663 si112 7658 si170 5998 si99 3853 si67 2997 si47 18918 si2 6289 si105 2324 si144 2004 si145 2446 si125 5573 si28 40521 si79 4410 si100 1323 si186 6820 si184 2372 si62 4442 si167 2014 si81 1522 si117 2107 si113 1644 si158 3131 si78 8374 si72 8432 si25 3561 si127 4082 si5 3500 si128 1867 si171 4907 si12 23572 si7 6847 si106 2641 si166 2577 si134 3567 si135 5103 si16 8582 si181 1991 si24 3769 si119 1726 si192 14315 si96 4096 si86 2771 si68 3367 si15 1576 si118 1593 si188 3647 si60 1666 si22 1208 si101 6548 si80 1153 si69 3440 si165 5326 si97 3756 si20 3739 si77 12950 si59 9443 si133 7212 si26 2906 si164 2445 si162 2736 si180 2333 si13 2992 si169 1582 si58 12427 si168 1670 si114 1371 si108 3487 si116 16322 si122 2740 si107 3170 si126 1474 si21 2935 si3 21809 si172 3605 si6 6791 si8 12141 si18 19583 si124 5363 si74 1593 si82 7278 si63 10818 si4 1781 si157 3389 si85 2430 si64 10250 si111 6592 si176 916 si104 24765 si87 32014 si161 3772 si120 23929 am 2037839 ROBOT 103900 103900 S0921-8890(21)00185-8 10.1016/j.robot.2021.103900 Elsevier B.V. Fig. 1 An abstract overview of the proposed framework. The highlighted boxes represent functional modules and the white boxes correspond to exchange data among them. Fig. 2 Schematics of the dynamics models: (a) LIPM; (b) LIPM with vertical motion of COM; (c) Proposed model. Fig. 3 Overall architecture of the proposed controller. Fig. 4 Simulation results of examining the state estimator performance. In this simulation, the measurements are affected by a Gaussian noise N ( 0, 6.25e−4 ) to simulate uncertainties. In these plots, light-blue and light-red lines represent the measurements, solid-blue and solid-red lines are the estimated values, dashed black lines represent the references. (For interpretation of the references to color in this figure legend, the reader is referred to the web version of this article.) Fig. 5 Simulation results of examining the controller performance in presence of noises. In this simulation, the controller should track a references trajectories in presence of the noise N ( 0, 6.25e−4 ) . Fig. 6 Overall architecture of the proposed framework. The highlighted boxes represent the main modules and the exchanged information among them is represented by the white boxes. Fig. 7 Omnidirectional walk scenario. In this scenario, the simulated robot should follow the commands that are generated by an operator: dashed arrows show a set of commands that has been generated for this simulation, including forward walk, side walk, diagonal walk and turning while performing diagonal walking. Fig. 8 Evolution of the fitness. Fig. 9 The optimization scenario and the results of an exemplary test after optimizing the parameters. In this test, the simulated robot has been placed at a specific point which is 10 m far from the center of the field and it should walk towards the center as fast as possible. The results showed that the robot touched the midline at t = 11 . 52 s. Fig. 10 Stability optimization scenario. The robot exploits the most common walking patterns — forward walking and turning — to keep itself within a predefined squared area of side length 2 m. When inside that area, the robot walks forward as fast as possible. Otherwise, it turns at a random rate until it is directed towards the area. Fig. 11 Learning curves considering only the arms (blue) and considering arms and COM height (red). (For interpretation of the references to color in this figure legend, the reader is referred to the web version of this article.) Fig. 12 Mean speed comparison between the baseline (on the left) with the best optimization using the Arms & COM Height controller (on the right). These values were averaged for 500 successful episodes, where the robot runs for 12 m in a straight line. Fig. 13 Angular displacement performed by all arms joints (sum) during an episode, averaged for 500 successful episodes (on the left). The linear path described by the robot was divided into sections of 1 m, which are represented by each bar. The baseline is represented by the dotted red bars while the optimized version is represented by the solid blue bars. The same sort of analysis for all joints is depicted on the right. (For interpretation of the references to color in this figure legend, the reader is referred to the web version of this article.) Table 1 The best parameters. Parameter Symbol Value Step duration T s s 0.1274 s Step length x 0.09059 m Step width y 0.010086 m Step angle α − 0 . 2899 deg Height of swing z s w 0.038 m Torso inclination T I t o 5 . 601 deg Amplitude of height of COM A z −0.004 Amplitude of torso movement A t o −1.9195 Table 2 Summary of the results in the maximum speed scenario. Dynamics model Maximum speed LIPM 0.590 m/s LIPM + vertical motion of COM 0.630 m/s LIPM + vertical motion of COM + Torso 0.866 m/s Table 3 State space for the stability optimization. Parameter Data size (×32b) α 1 Gyroscope 3 Accelerometer 3 Joints position 20 Joints speed 20 Controller actions 20 Table 4 Original scenario results — average duration and speed ± SD, and success rate (30 s). Parameter Ep. length mean (s) Reach 30 s (%) Speed mean (m/s) Baseline 5.1 ± 2.9 0 0.602 ± 0.027 Arms 51.6 ± 31.8 68.8 0.710 ± 0.037 Arms & COM height 148.2 ± 153.0 87.6 0.956 ± 0.060 Table 5 Comparison results. Maximum speed Ability of changing direction Proposed framework 0.956 m/s Yes [19] 0.805 m/s Yes [46] 0.770 m/s Yes [25] 0.590 m/s Yes [38] 3.910 m/s No [21] 2.500 m/s No [51] 1.188 m/s No [41] 1.340 m/s No [50] 0.550 m/s No [45] 0.510 m/s No Table 6 Summary of the results in the maximum speed scenario. Dynamics model ML algorithm Maximum speed LIPM GA 0.590 m/s LIPM + vertical motion of COM GA 0.630 m/s LIPM + vertical motion of COM + Torso GA 0.866 m/s LIPM GA + PPO 0.710 m/s LIPM + vertical motion of COM GA + PPO 0.741 m/s LIPM + vertical motion of COM + Torso GA + PPO 0.956 m/s Robust biped locomotion using deep reinforcement learning on top of an analytical control approach Mohammadreza Kasaei a ⁎ Miguel Abreu b Nuno Lau a Artur Pereira a Luis Paulo Reis b a IEETA/DETI University of Aveiro, 3810-193 Aveiro, Portugal IEETA/DETI University of Aveiro Aveiro 3810-193 Portugal IEETA / DETI University of Aveiro 3810-193 Aveiro, Portugal b University of Porto, LIACC/FEUP, Artificial Intelligence and Computer Science Lab, Faculty of Engineering of the University of Porto, Portugal University of Porto, LIACC/FEUP, Artificial Intelligence and Computer Science Lab, Faculty of Engineering of the University of Porto Portugal bUniversity of Porto, LIACC/FEUP, Artificial Intelligence and Computer Science Lab, Faculty of Engineering of the University of Porto, Portugal ⁎ Corresponding author. This paper proposes a modular framework to generate robust biped locomotion using a tight coupling between an analytical walking approach and deep reinforcement learning. This framework is composed of six main modules which are hierarchically connected to reduce the overall complexity and increase its flexibility. The core of this framework is a specific dynamics model which abstracts a humanoid’s dynamics model into two masses for modeling upper and lower body. This dynamics model is used to design an adaptive reference trajectories planner and an optimal controller which are fully parametric. Furthermore, a learning framework is developed based on Genetic Algorithm (GA) and Proximal Policy Optimization (PPO) to find the optimum parameters and to learn how to improve the stability of the robot by moving the arms and changing its center of mass height. A set of simulations are performed to validate the performance of the framework using the official RoboCup 3D League simulation environment. The results validate the performance of the framework, not only in creating a fast and stable gait but also in learning to improve the upper body efficiency. Keywords Humanoid robots Modular walk engine Linear–Quadratic–Gaussian (LQG) Genetic Algorithm (GA) Proximal Policy Optimization (PPO) Deep Reinforcement Learning (DRL) 1 Introduction Developing a robust locomotion for bipedal robots is a challenging problem which has been investigated for decades. Although several walking approaches have been proposed and walking performance has considerably improved, it still falls short of expectations in certain domains, such as speed and stability. The question is how is it that humans can constantly change their direction when running, while keeping their stability, but humanoids cannot? To find a good answer for this question, we start by reviewing recently proposed walking frameworks, consequently identifying four points of view related with the development of a fast and stable gait. In the first point of view, the fundamental framework’s core is a dynamics model of the robot, based on which the walking planner and controller are designed. In this type of framework, to reduce the complexity of developing a whole body dynamics model, some constraints are considered. Based on these constraints, an abstract model is designed instead of a real whole body dynamics model [1–8]. It should be mentioned that several studies exist where a whole body dynamics model is developed [9–11]. In the second point of view, the core of the framework is a set of signal generators which are coupled together to generate endogenously rhythmic signals [12–15]. This type of framework is called Central Pattern Generator (CPG)-based framework and is inspired by the neurophysiological studies on invertebrate and vertebrate animals [16–18]. These studies showed that rhythmic locomotion like walking, running and swimming are generated by CPGs at the spinal cord that are connected together in a particular arrangement. In this type of framework, oscillators are assigned to each limb, typically to generate the setpoints (position, torque, etc.). Most humanoid robots have more than 20 Degrees of Freedom (DOF), therefore, adjusting the parameters of the oscillators is not only difficult but also trial-intensive [19]. Moreover, there is not a straight way to adapt sensory information to the oscillators. In the third point of view, the generation of walking trajectories is based on reinforcement learning (RL) or a heuristic algorithm [12,20,21]. In this type of framework, the walking trajectories will be generated after a training period which needs many samples and takes a considerable amount of time. During training, the framework tries to learn how to generate the walking trajectories, subject to an objective function. In the fourth point of view, the framework is designed by combining the aforementioned approaches [19,22–25]. This type of framework is generally known as a hybrid walking framework. It tries to leverage the different capabilities of each approach to improve the final performance. After studying all types of humanoid walking frameworks, to find the answer for the question raised in the beginning of this section, let us look at how a baby starts to walk. It starts by learning to stand for a few seconds. It then improves the stability after many experiments, takes a few steps, learns how to maintain equilibrium while moving; until finally, after a long process of trial and error, a robust walking behavior emerges. This process shows how a human learns from previous experiences to improve its walking performance. Based on these explanations, we believe that the ability to learn from past experiences is the most important difference between human walking and robot walking. Particularly, a robot should be able to learn how to generate efficient locomotion according to different situations (e.g., learning to recover its balance from postural perturbations). In the first two types of framework, the knowledge of robots is static, generally, and does not evolve from past experiences. Therefore, they need to at least re-tune the parameters to be able to adapt to new environments. In the third type of framework, the learning process typically does not consider any dynamics model and is designed based on learning from scratch, which is trial intensive and not applicable to a real robot directly. Several research groups have been exploring how to learn from previous experiences to improve stability and robustness. We believe the fourth type is the best approach to develop a robust biped locomotion framework. In this paper, we propose a tight coupling between analytical control approaches and machine learning (ML) algorithms to develop a robust walking framework. Particularly, our contribution is a biped locomotion framework composed of two major components — an analytical planner and controller; and a fully connected neural network. The former is responsible for optimally controlling the overall state of the robot based on an abstract dynamics model. It is also responsible for generating reference trajectories using dynamic planners with genetically optimized parameters and overcome uncertainties up to a certain degree. The latter component – a fully connected network – is optimized with reinforcement learning to control the arms residuals and the COM height of the robot, thus improving the upper body efficiency, which impacts the overall stability and speed of the robot. The remainder of this paper is structured as follows: Section 2 provides an overview of related work. In Section 3, the concept of ZMP will be used to define a specific dynamics model which is composed of two masses. Afterwards, in Section 4, this dynamics model will be used to design an optimal controller which is able to track the walking reference trajectories, even in the presence of uncertainties. Section 5 explains how the problem of generating walking reference trajectories can be decomposed into five distinct planners. In Section 6, we will describe our learning approach and explain its structure. The overall architecture of the proposed framework will be presented in Section 7. In Section 8, three simulations scenarios will be designed to validate the performance of the proposed framework. According to the simulation results, its discussion and comparison with related work will be provided in Section 9. Finally, conclusions and future research are presented in Section 10. 2 Related work Several of the proposed walking frameworks are based on learning approaches to generate a stable locomotion for biped and multi-legged robots. Using ML algorithms for biped locomotion has made remarkable progress recently. These studies showed that using these algorithms on top of analytical approaches can improve robustness and performance significantly [19,22]. In the remainder of this section, some recent proposed walking frameworks will be categorized and reviewed, focusing on those that use ML algorithms to improve their performance. 2.1 Combination of model-based walking and ML algorithms MacAlpine et al. [22] designed and implemented a learning architecture to enable a humanoid soccer agent to perform omnidirectional walk. In their architecture, the overall dynamics of a humanoid robot is abstracted by a double inverted pendulum model which is parameterized to be able to learn a set of parameters for different tasks. The performance of their framework has been validated using a set of simulations that have been designed using SimSpark, 1 1 a generic physical multiagent system simulator. The simulations results showed that their framework is able to learn multiple parameter sets according to the specified tasks. Kasaei et al. [19] proposed a closed-loop model-based walking framework. Their dynamics model is composed of two masses that takes into account the lower and upper body dynamics of the robot. Based on this dynamics model, they generate walking reference trajectories and also designed an optimal controller to track these references. They showed the performance of their framework by performing a set of simulations using a simulated NAO robot in SimSpark. Moreover, they optimized the parameters using a genetic algorithm (GA) and showed that the maximum forward walking speed of the simulated robot reached 80.5 cm/s. Carpentier et al. [26] proposed a generic and efficient walking pattern generator which is able to generate dynamically consistent motions. They argued that their approach is fast enough to generate the trajectory of COM along with the angular momentum according to the given configuration of contacts while the previous step is executing. Their method has been implemented on a real HRP-2 robot to demonstrate its interest. The experiment results showed that their method is able to generate long-step walking and climbing a staircase with handrail support. Koryakovskiy et al. [27] proposed two approaches for combining a Nonlinear Model Predictive Control (NMPC) with reinforcement learning to compensate model-mismatch. The first approach deals with learning a policy to compensate control actions to minimize the same performance measure as their NMPC. The second approach was focused on learning a policy based on the difference of a transition predicted by NMPC and the actual transition. They performed a set of simulations to show the feasibility of both approaches and to compare their performances. The simulation results showed that the second approach was better than the first one. Moreover, They deployed the second approach on a real humanoid robot named Robot Leo to perform squat motion to validate the performance of their approach. 2.2 Combination of CPG-based Walking and ML algorithms Song et al. [28] designed CPG-Based Control walking framework which is able to generate stable walking, even on unknown sloped surfaces. In their framework, the walking patterns are generated based on CPG theory and a PI controller is designed according to gyroscope and accelerometer information, allowing the adjustment of the upper body’s tilt angle to keep the robot’s stability. They performed some experiments using a real NAO humanoid robot and the results showed that the robot is able to walk successfully on unknown slopes. Missura et al. [29] proposed a walking framework which bootstraps a learning algorithm with a CPG-based walk engine. Their framework is composed of a feed-forward walking pattern generator, a state estimator and a balance controller. In their framework, while the robot is walking, the balance controller adjusts the step size based on the estimated error and also learns how to improve the walking performance by adjusting the swing leg parameters. The performance of their framework has been validated using a set of experiments on a real humanoid robot. The results showed that their framework is able to keep the robot’s stability even after applying a severe push. 2.3 Combination of CPG-ZMP based walking and ML algorithms Massah et al. [30] developed a hybrid CPG-ZMP controller to generate stable locomotion for humanoid robots. In their approach, a set of non-linear oscillators were used to generate walking trajectories and two controllers were developed to handle small and large disturbances. They optimized the walking parameters using the differential evolution (DE) algorithm. The performance of their approach was demonstrated in the Webots robot simulator using the NAO humanoid robot. Liu et al. [31] proposed a CPG-ZMP based walking framework which is inspired by biomechanical studies on human walking. In their framework, walking reference trajectories are generated offline according to a point mass model. They used a PD controller to modify the reference walking patterns to keep the robot’s stability. Moreover, their framework takes the vertical motion of the upper body into account to generate almost stretched knees. The performance of their framework has been validated using a set of experiments on a real NAO humanoid robot. The results proved the improvement of walking stability and energy efficiency. Kasaei et al. [25] developed a hybrid CPG-ZMP based walk engine for biped robots. Their walk engine has a hierarchical structure and it is fully parametric. They argued that this structure allows using a policy search algorithm to find the optimum walking parameters. To show this ability, they used an optimization technique based on Contextual Relative Entropy Policy Search with Covariance Matrix Adaptation (CREPS-CMA) [32] to tune the walking parameters. The performance of their walk engine has been validated by showing a fast and stable omnidirectional walk using a simulated Nao robot in Simspark ( 59 cm/s). 2.4 Learning to walk from scratch Abreu et al. [21] applied a reinforcement learning algorithm to develop a fast and stable running behavior from scratch. In their approach, the environment has been represented by 80 states and the action space is composed of 20 actions which were all the joints of a simulated humanoid robot. They used the Proximal Policy Optimization (PPO) based on the implementation provided by OpenAI [33]. The performance of their approach was shown by learning sprinting and stopping behaviors. The results demonstrated that both behaviors are stable and the sprinting speed stabilizes around 2 . 5 m/s which was a considerable improvement. Most of the aforementioned works combine a simplified model-based or a model-free approach with ML approaches to improve the performance of their walking. In the rest of this paper, we develop an optimal closed-loop walking pattern generator based on a more complex dynamics model which takes into account the vertical motion of the COM and the torso’s dynamics. Besides, we use the PPO algorithm which is one of the most successful deep reinforcement learning methods, on top of our walking pattern generator to improve its robustness and efficiency and also to provide more human-like walking. An abstract overview of the proposed framework is depicted in Fig. 1. 3 Dynamics model and stability criteria When designing a model-based walking, two general perspectives exist: (i) considering an abstract dynamics model which takes into account a trade-off between accuracy and simplicity; (ii) considering a whole-body dynamics model which is more accurate but, not only is it platform dependent but also resource-intensive due to its non-linear nature. In the rest of this section, the concept of Zero Momentum Point (ZMP) will be reviewed and then used to define an abstract dynamics model of a humanoid robot. 3.1 Zero momentum point ZMP has been proposed in [34] and is currently one of the most successful metrics in the walking literature. Particularly, it is a point on the ground where the ground reaction force (GRF) acts to cancel the gravity and the inertia. Normal human walking is a periodic motion which can be decomposed into two main phases: (i) Single Support (SS) and (ii) Double Support (DS) [35]. During SS phase, only one foot is in contact with the ground and the other foot swings towards the next planned foot position. In this paper, we used the ZMP as our main criterion for analyzing the stability of the robot while performing walking and it can be defined using the following equation: (1) p x = ∑ k = 1 n m k x k ( z ̈ k + g ) − ∑ k = 1 n m k z k x ̈ k ∑ k = 1 n m k ( z ̈ k + g ) , where n represents the number of parts that are considered in the dynamics model, m k is the mass of each part, ( x k , x ̇ k ) , are the horizontal position and acceleration, and ( z k , z ̈ k ) are the vertical position and acceleration of each mass, respectively. 3.2 Dynamics model Although considering a full body dynamics model is not impossible, it generally needs powerful computational resources. Therefore, it is not affordable for real-time implementation. To reduce the complexity of the model and its computation cost, the overall dynamics is approximated by an abstract model. Kajita and Tani [1] proposed an abstract model named Linear Inverted Pendulum Model (LIPM) which is a well-known abstract model in the community. LIPM is popular because it provides a simple, fast and efficient solution for walking dynamics that is suitable for real-time implementation. In this model, the overall dynamics of the robot is abstracted to a single mass that is connected to ground via a massless rod. Additionally, this model assumes that the vertical motion of the mass is restricted by a horizontally defined plane. According to these assumptions and using a set of predefined footsteps, the trajectory of Center of Mass (COM) can be obtained from a straightforward analytical solution which guarantees long-term stability. It should be mentioned that based on these assumptions, the equations in sagittal and frontal planes are equivalent and independent, therefore we just derive the equation in the sagittal plane. The schematic of this model is depicted in Fig. 2(a). Using (1) and considering the LIPM’s assumptions, the COM’s motion equation can be obtained as follows: (2) x ̈ c = ω 2 ( x c − p x ) , where ω = g z is the natural frequency of the pendulum, p x and x c represent the positions of ZMP and COM, respectively. As aforementioned, LIPM tries to keep the COM’s vertical position at a predefined position which causes the knee joints to be always bent. Indeed, walking with bent knees consumes more energy and does not resemble human walking [36]. To release this constraint and generate more energy efficient and human-like walking, a sinusoidal motion is assigned to the vertical motion of the COM: (3) z c = z 0 + A z cos ( 2 π S t e p T i m e t + ϕ ) , where z 0 denotes the COM’s initial height, A z is the amplitude, and ϕ represents the phase shift of the COM’s vertical sinusoidal motion. The initial value of these parameters are determined by an expert. Additionally, a controller can be designed to adjust these parameters based on sensory feedback. Although the current version of the dynamics model is able to provide fast and stable walking, it is not good enough to generate a very fast walking. In fact, in some situations like when a push is applied, the COM accelerates forward, and, as a consequence, the ZMP goes behind the Center of Gravity (COG). In this situation, the robot tries to decelerate the COM by applying a compensating torque at its ankles, keeping the ZMP inside the support polygon. The compensating torque will be saturated once the ZMP is at the support polygon’s boundary and, consequently, the robot is going to be unstable. In such situations, a human moves its torso to keep the ZMP inside the support polygon and prevent falling. To consider the effect of the torso’s motion in the dynamics model, another mass should be added to the dynamic model. This modification changes the dynamics model to be non-linear. Therefore, it does not have an analytical solution and it should be solved numerically. Biomechanical analysis of human walking showed that the torso motion can be represented by a sinusoidal function whose motion parameters are dependent on the current robot state, and terrain conditions. The interesting point is that if the torso is considered as a mass with a small sinusoidal movement relative to the hip ( sin ( θ t o ) = θ t o ), the dynamics model can keep its linearity. The schematic of this model is depicted in Fig. 2(c) and it can be represented by the following equation: (4) x ̈ c = μ ( x c + α l 1 + α θ t o − p x ) − α β l 1 + α β θ ̈ t o , α = m t o m c , β = z t o z c , μ = 1 + α 1 + α β ω 2 , x t o = x c + l θ t o , where x t o denotes the position of torso, θ t o , l are the angle of torso and length of torso, m c , m t o represent the masses of lower body and torso, z t o , z c are the torso and COM height, respectively. 4 Controller In this section, an optimal controller will be designed for tracking the reference trajectories to minimize the tracking error. To do that, Eq. (4) will be represented as a linear state space system. Then, this system will be discretized to be used in a discrete-time implementation. Afterwards, we will explain how this system can be used to design an optimal controller. The process of designing the controller starts by defining a linear state space system based on Eq. (4): (5) d d t x c x ̇ c θ t o θ ̇ t o ︸ X = 0 1 0 0 μ 0 μ α l 1 + α 0 0 0 0 1 0 0 0 0 ︸ A x c x ̇ c θ t o θ ̇ t o ︸ X + 0 0 − μ − α β l 1 + α β 0 0 0 1 ︸ B p x θ ̈ t o ︸ u , y = 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 ︸ C x c x ̇ c θ t o θ ̇ t o ︸ X . The presented system is a continuous system and should be discretized for implementation in discrete time. To discretize this system, we assume that x ̇ c , θ ̇ t o are linear. Therefore p x , θ ̈ t o are constant within a control cycle. Thus, the discretized system can be represented as follows: X ( k + 1 ) = A d X ( k ) + B d u ( k ) , (6) y ( k ) = C d X ( k ) , where k represents the current sampling instance, A d , B d , C d are the discretized versions of the A , B , C matrices in (5), respectively. According to this discretized dynamics model, an optimal closed-loop controller can be designed to track the reference trajectories. This controller is a Linear–Quadratic–Gaussian (LQG) which is composed of two main modules: a state estimator and an optimal controller gain. The overall architecture of this controller is depicted in Fig. 3. In the remaining of this section, each module will be explained and the overall performance of the controller will be validated. 4.1 State estimator An LQG controller is able to track the reference trajectories even in the presence of measurement noise. This controller uses a state estimator to cancel the effect of uncertainties which can be raised because of many aspects like errors in modeling the system, sensor noise, backlash of the gears, etc. In particular, this controller uses a state estimator to estimate the current state of the system according to the control inputs and the observations. In our target framework, we considered that the position of the joints is available through measurements and the torso orientation can be obtained based on an Inertial Measurement Unit (IMU) information which is mounted on the torso. Based on the joint information and using a Forward Kinematic (FK) model of the robot, the current configuration of the robot can be estimated. In this estimation, the support foot is considered to be in flat contact with the ground, which is not always true. Therefore, the whole body orientation with respect to the ground should be added to this estimation. To do so, the IMU information is used to rotate the current configuration. Based on this configuration, the COM position can be estimated at each control cycle and its velocity can be obtained from its position’s derivative, followed by a first-order lag filter. To validate the performance of this module, a simulation has been designed. In this simulation, the observations are modeled as a stochastic process by applying additive Gaussian noise to the measured states. The simulation results are shown in Fig. 4. According to the simulation results, the state estimator is able to estimate the states perfectly. 4.2 Optimal gain As shown in Fig. 3, the optimal control law is obtained using the following formulation: (7) u = − K x ̃ − x r x i , where x ̃ , x r denote the estimated states and the reference states, respectively. x i is the integration of error which is used to eliminate the steady-state error, K represents the optimal gain of the controller that should be designed to minimize the following cost function: (8) J ( u ) = ∫ 0 ∞ { z ⊺ Q z + u ⊺ R u } d t , where z = [ x ̃ x i ] ⊺ , R and Q are positive-semidefinite and positive-definite matrices which are determined by an expert. In fact, these matrices determine a trade-off between cost of control effort and tracking performance. Therefore, the performance of the controller is sensitive to these matrices. It should be noted that there is a straightforward solution to determine K based on solving a differential equation named Riccati Differential Equation (RDE). To check the performance of the proposed controller, a simulation has been performed. In this simulation, a set of reference trajectories has been generated and the controller should track this reference in presence of measurement noise. The simulation results are shown in Fig. 5. The results showed that the controller is able to track the references even when the measurements are affected by noise. In the next section, we explain how the reference trajectories are generated. 5 Reference trajectories planner Our walking reference trajectories planner is composed of five sub planners which are connected together hierarchically. The first level of this hierarchy is a footstep planner which generates a set of foot positions based on given step information and some predefined constraints (e.g., maximum and minimum step length, step width, distance between feet, etc.). To do so, we consider a state variable to represent the current state of the robot’s feet: (9) s = ( x l , y l , θ l , ϕ l , x r , y r , θ r , ϕ r ) , where x l , y l , θ l , x r , y r , θ r are the position and orientation of the left and right foots, respectively. ϕ l , ϕ r represent the current state of feet which is 1 if the foot is the swing foot and − 1 otherwise. Walking is a period motion which is generated by moving the right and the left legs alternating. Therefore, we parametrize a step action by a length and an angle from the swing foot position at the beginning of steps a = ( R , σ ) . According to the input parameters and the current state of the feet, an action should be taken and the state transits to a new state, s ′ = t ( s , a ) . Afterwards, the current footstep will be saved ( f i i ∈ N ) and ϕ l and ϕ r will be toggled. The second planner is the ZMP planner that uses the planned footstep information to generate ZMP reference trajectories. In our target framework, the ZMP reference planner is formulated as follows: (10) r z m p = f i , x f i , y 0 ≤ t < T s s f i , x + L s x × ( t − T s s ) T d s f i , y + L s y × ( t − T s s ) T d s T s s ≤ t < T s s + T d s , where f i = [ f i , x f i , y ] are the planned footsteps on a 2D surface ( i ∈ N ), L s x and L s y represent the step length and width, T s s , T d s are the single support and double support durations, respectively, and t is the time which will be reset at the end of each step ( t ≥ T s s + T d s ). The third planner is the swing leg planner which generates the swing leg trajectory using a cubic spline function. This planner uses three control points that are the position of the swing leg at the beginning of the step, the next footstep position and a point between them with a predefined height ( Z s w i n g ). The fourth planner is the global sinusoidal planner which generates three sinusoidal trajectories for the COM height, the torso angles and the arm positions. The fifth planner is the hip planner which uses the generated ZMP and torso trajectories to generate hip trajectory. Indeed, these trajectories are used to determine the positions of the hip at the begging and the end of step. Using these positions, Eq. (4) can be solved as a boundary value problem as follows: (11) x ( t ) = g x + ( g x − x f ) sinh ( μ ( t − t 0 ) ) + ( x 0 − g x ) sinh ( μ ( t − t f ) ) sinh ( μ ( t 0 − t f ) ) , where g x = r z m p x − α l 1 + α θ t o + α β l μ ( 1 + α β ) θ ̈ t o , and t 0 , t f , x 0 , x f are the times and corresponding positions of the hip at the beginning and end of a step, respectively. In this work, T d s is considered to be zero, which means ZMP transits to the next step at the end of each step instantaneously. Moreover, x f is assumed to be in the middle of current support foot and next support foot ( f i + f i + 1 2 ). 6 Learning framework The learning framework optimizes problems that are formalized as a Markov Decision Process (MDP) — a 4-tuple S , A , p , R — where S denotes the set of states, A the set of actions, and R the set of numerical rewards. The dynamics of the MDP is given by the state-transition probability function p ( s ′ | s , a ) : S × S × A ( s ) → [ 0 , 1 ] , which gives the probability of ending in state s ′ given the current state s and action a . The framework employs the Proximal Policy Optimization (PPO) algorithm, introduced by Schulman et al. [37], which was chosen due to its success in optimizing low-level skills concerning the NAO robot [21,38–41], and high-level skills [42], where it outperformed other algorithms such as TRPO or DDPG. The chosen implementation uses the clipped surrogate objective: L ( θ ) = E ˆ t m i n r t ( θ ) A ˆ t , c l i p ( r t ( θ ) , 1 − ε , 1 + ε ) A ˆ t , (12) with r t ( θ ) = π θ ( a t | s t ) π θ o l d ( a t | s t ) , where A ˆ t is an estimator of the advantage function at timestep t . The clip function clips the probability ratio r t ( θ ) in the interval given by [ 1 − ε , 1 + ε ] . This implementation alternates between sampling data from multiple parallel sources, and performing several epochs of stochastic gradient ascent on the sampled data, to optimize the objective function. The clipping parameter ε was set to 0.2, as suggested by Schulman et al. [37]. Also, as in the implementations published by OpenAI for the 3D humanoid environment [33], the entropy bonus was not used, and the number of optimization epochs and batches was set to 10 and 64, respectively. Some other hyperparameters were tuned using grid search: step size (2.5 × 10−4); batch size ( 4096 ); and the Adaptive Moment Estimation (Adam) [43] optimizer was set to use a constant scheduler. Finally, the Generalized Advantage Estimation (GAE) [44] algorithm’s parameters — gamma and lambda — were set to 0.99 and 0.95, respectively, accordingly to the ranges established by the GAE’s authors as best-performing for 3D biped locomotion. The policy is represented by a multilayer perceptron with two hidden layers of 64 neurons. The number of inputs, outputs, and the maximum number of time steps for the optimization are dependent on the scenario and will be described in Section 8.3. The training session was parallelized to improve the optimization duration. 7 Overall structure In this section, the previously introduced planner and controller will be coupled together to generate stable locomotion. To do that, we designed a modular framework composed of six main modules. Two modules are concerned with optimization algorithms — GA and PPO. The former optimizes the planners’ parameters based on a reward function that can be defined for specific purposes (e.g. maximum walking speed). On top of the resulting model, the PPO algorithm is used to adjust the COM height and optimize joint residuals. The optimization setup for both algorithms is described in Section 8. The overall architecture of this framework is depicted in Fig. 6. As shown in this figure, the walking process is controlled by a state machine which abstracts the process into four distinct states: Idle, Initialize, Single Support and Double Support. In this state machine, the transitions are triggered by a timer that is associated to each state. Additionally, it can be triggered by an emergency signal generated according to the controller’s state in key moments, such as when a swift move is necessary to regain equilibrium after a strong external perturbation. The Idle state is the initial state in which the robot is standing in place and waiting to receive a walking signal, which can be generated by an operator or a path planning algorithm. That signal triggers the Initialize state, in which the walking parameters and configurations are loaded from a data base. Afterwards, the robot is ready to walk by shifting its COM towards the first support foot. The next state is triggered after a predefined time. During Single Support State and Double Support State, the dynamics planner generates the walking reference trajectories according to the generated walking signal and the controller tries to track these references. At the same time, the neural network receives a set of observations, including data from inertial sensors, joints’ position and speed, target joint positions generated by the LGQ controller, and the target turning rate. The network outputs residuals which are added to the target joint positions before being fed to the simulator, which runs the next simulation step. The neural network also adjusts the height of the COM, which is then used by the dynamic planners in the following iteration. In the next section, a set of simulations will be carried out to verify the framework’s performance. Moreover, we will show how the planners parameters are optimized using a genetic learning approach, and what is the impact of the policy gradient algorithm on the performance of the framework. 8 Simulations In this section, we introduce a set of simulation scenarios to validate the performance of the proposed framework. The simulation scenarios have been designed using the official RoboCup 3D simulation environment which is based on SimSpark, a multi-agent simulator. This simulator relies on the Open Dynamics Engine (ODE) to simulate rigid body dynamics. The physics engine is updated every 0.02 s. The simulator can also be configured to update the physics engine just after receiving commands from all agents. This greatly improves simulation speed and provides a better environment for learning approaches. 8.1 Omnidirectional walk This scenario is designed to demonstrate the performance of the framework in providing an omnidirectional walk. The simulated robot starts from an idle state and follows a command comprising length ( X ), width ( Y ) and angle ( α ) of the step, which is determined by an operator. Note that the step time is constant and set to 0.2 s. To avoid discontinuity in the input command, a first-order lag filter is used, yielding a smooth transition. At the beginning of this scenario, the robot is walking in place and all the setpoints are zero ( X = 0 . 0 m, Y = 0 . 0 m, α = 0 . 0 deg /s). At t = 10 s, the operator sets the step length ( X = 0 . 05 m) to generate forward walking; at t = 20 s, the operator resets the step length ( X = 0 . 0 m) and sets the step width ( Y = 0 . 04 m) to generate side walking; at t = 30 s, while the robot is performing side walking, the operator sets the step length ( X = 0 . 05 m) to generate diagonal walking; at t = 40 s, while the robot is performing diagonal walking, the robot is commanded to turn right simultaneously, by setting the step angle ( α = 10 deg); and finally, at t = 60 s, all the set points are reset and the robot starts walking in place. A set of snapshots of this simulation is depicted in Fig. 7. The simulation results showed that the framework was able to generate omnidirectional walking according to the input commands. A video of this simulation is available online at: 8.2 Optimizing the walking parameters This scenario is focused on optimizing the walking parameters to generate the fastest stable forward walk. This process is executed before applying the reinforcement learning algorithm, which means that all the residual arm target joints are set to zero, and the height of the COM is computed by the dynamic planners. In this scenario, the robot is placed 10 m away from the halfway line and it should walk straight forward towards that line as fast as possible. Initially, the best parameters were hand-tuned and, after several attempts, the maximum walking speed did not exceed 53 cm/s. Afterwards, based on the parametric nature of the proposed planner, a GA is used to optimize the parameters to improve the walking speed. To do that, 8 parameters of the framework have been selected to be optimized. These parameters are the step length ( x ), step width ( y ), step angle ( α ), height of the swing leg ( z s w ), duration of a step ( T s s ), torso inclination T I t o , amplitude of the COM ( A z ) and amplitude of the torso movement ( A t o ). In our optimization scenario, the simulated robot should walk forward for 10 seconds and its performance will be evaluated based on the following cost function: (13) f ( ϕ ) = − | δ x | + | δ y | + ε , where ϕ represents the selected parameters, δ X , δ Y are the distance covered in X-axis and Y -axis, respectively, ε is used to penalize the robot when it falls during walking ( ε = 100 ) otherwise it is zero. According to this cost function, the simulated robot is rewarded for straight forward walk and it is penalized for deviation and falling. A slow and stable forward walking (0.11 m/s) is used as an initial solution to start the optimization process. It should be noted that, each iteration has been repeated three times and the average of the finesses was used to be sure about the walking performance. The fitness values have been recorded for each iteration and the average fitness values can be visualized in Fig. 8. The average fitness value starts at around 85 and after about 2000 iterations, it drops under 10 , which is much better than the first solution. The optimization has been executed for 6000 iterations. After optimizing the parameters, the walking velocity reaches 0.866 m/s, which is 61 % faster than the best hand-tuned solution. The best parameters found by the GA are shown in Table 1. The optimization scenario and a set of snapshots of a test are shown in Fig. 9. A video of this simulated scenario is available online at: To compare the effectiveness of the dynamics model, this scenario has been repeated for the dynamics models (a) and (b) presented in Fig. 2. To do so, the planner and the controller have been adjusted according to the dynamics models and then their parameters have been refined manually. Finally, this simulation scenario has been repeated to find the maximum forward speed of each model. The simulation results are summarized in Table 2. The simulation results validated that the sinusoidal motion of the height of COM improves the stability and allows the robot to move faster in comparison with fixed COM. 8.3 Learning to improve the upper body efficiency This scenario was designed to improve the efficiency of the walking gait in terms of speed and stability during the most common walking patterns — forward walking and turning. To mitigate the effects of the learning process on the maneuverability and predictability of the walking trajectory, only the arms actuators and COM height were optimized. The robot is initially placed in an arbitrary position within a squared area of side length 2 m, as depicted in Fig. 10. It then starts walking forward with the best parameters found in Section 8.2. When the robot steps out of the predefined area, it starts to turn in either direction at a random rate | α | ∈ [ 30 deg/s, 60 deg/s], until it is facing the square again. This process is repeated continuously until the episode ends with the robot falling (detected when its z coordinate drops below 0.3 m). The fact that the robot runs at full speed when changing direction, and that it needs to constantly adapt to different turning rates makes this a very challenging scenario. The interaction between agent and environment is performed at discrete time steps ( t = { 0 , 0 . 02 , 0 . 04 , … } ). The robot’s behavior was optimized by the PPO algorithm, using 67 observed variables, as listed in Table 3. The first parameter indicates the current turning rate. The inertial sensors (gyroscope and accelerometer) are both composed of 1 variable per axis in a three-dimensional space. The position and speed of all joints (excluding the head) is important to obtain a correct state representation, even though the action space only controls a limited number of these joints. Finally, the joint positions computed by the analytical controller are fed to the algorithm, and later added as residuals to the output values. These positions can be used by the network to predict the next analytical state, so that the produced residuals can be adjusted accordingly. In preliminary tests, removing this information from the state space results in a loss of performance between 5 % and 20 %, depending on possible action space combinations. The action space encompasses four angle variables per arm (shoulder roll, shoulder pitch, elbow yaw, elbow roll) and one variable to define the setpoint of the COM height at each step. The arm joints angles are computed by summing the analytical controller’s output to the neural network’s corresponding output. This forms a controller which uses the planner’s arms control signals both as state data and action bias. The objective of this scenario is to improve forward speed and stability at all times (i.e., when moving forward or turning). The former requirement is met by rewarding the agent for stepping forward and not sideways, which can be numerically translated into the scalar projection of its velocity vector v → in the direction of its orientation unit vector o → . Let v → = P t − P t − 1 , where P t and P t − 1 are the current and previous positions of the robot, respectively. The partial reward to motivate forward speed is then max ( v → ⋅ o → , 0 ) , where ⋅ denotes the dot product. The minimum reward value is limited to zero because walking backward or sideways is not worse than falling. The second requirement — stability — is motivated by a constant k , set empirically to 0.01, that rewards the agent for staying alive. More precisely, it favors stability at the cost of lowering the speed. The complete immediate reward can then be formulated as: (14) r = max ( v → ⋅ o → , 0 ) + k . The learning algorithm was first applied to the arms actuators and later extended to the COM height. Fig. 11 shows the average return evolution when learning only the arms (blue line) and after adding the COM height (red line). The former optimization plateaued at around 20 million time steps, and the latter at around 26 million time steps. It is important to note that the return obtained during the optimization was based on a stochastic policy whereas in the following tests, we used the corresponding deterministic policy. The results were divided into two sections: Original scenario — the robot is tested in the same scenario used for learning (see Fig. 10) and the analysis delves into the same metrics used to define the reward function; Straightforward path — the robot’s direction is constantly corrected to describe a linear path and the resulting behavior is analyzed in terms of efficiency. 8.3.1 Original scenario results The robot was evaluated with regard to stability and speed in the same scenario where the learning algorithm was applied. Stability was measured by the episode length, since it terminates once the robot falls to the ground. No time limitation was imposed per episode. Speed was measured at every iteration and averaged at the end of the episode. Table 4 lists the average speed and duration results for 500 episodes, as well as the success rate in reaching the 30 s mark without falling. The first line corresponds to the walk optimized in Section 8.2, which is used as a baseline. The robot walks on average for 5.1 s, with a standard deviation (SD) of 2.9 s before falling, generally on the first or second sharp change of direction, never being able to reach 30 s. The mean speed, from a stand-still position to the end of each episode, was 0.602 m/s with a SD of 0.027 m/s. After learning how to control the arms, the episode duration increased tenfold, on average, and the mean speed rose to 0.710 m/s. Most falls occur at an advanced stage or during the initial sharp turns, hence the larger standard deviation. Adding the COM height to the group of controlled variables increased the episode length to almost 15 times the initial value. When compared to the version without the COM height adaptation, this metric improved approximately 3 times, and the percentage of episodes in which the robot walked for at least 30 s went from 68.8 % to 87.6 %. The mean speed rose to 0.956 m/s, a gain of almost 60 % in relation to the baseline. In every episode the robot eventually falls. As aforementioned, when the robot steps out of the predefined area, it starts to turn with a random turning rate between 30 and 60 deg/s, in either direction. Most falls occur when approximating the upper limit or when the rotation direction is inverted after the robot enters and exits the predefined area in a short time (e.g. when stepping over a corner of that area). A video comparing the baseline with the Arms & COM height optimization is available online at: 8.3.2 Straightforward path results To evaluate the gait efficiency without taking stability into account, the displacement of certain joints as well as the average speed were analyzed, as discussed later in this section. Due to the challenging nature of the learning scenario, and to provide a fair comparison with the baseline algorithm, a simplified setup was developed. The objective is to compare the baseline and best optimization algorithms while the robot tries to describe a straight path of 12 m length. The turning parameter is computed at every iteration to maximize the path’s linearity using a reactive proportional controller. After 12 m, if the robot has not fallen, the episode is considered successful. Fig. 12 compares the baseline’s mean speed for the entire path with its improved version using the Arms & COM height controller. In both cases, the speed values were averaged for 500 successful episodes. In comparison with Table 4, the baseline algorithm improved its mean speed from 0.602 m/s to 0.704 m/s. The Arms & COM height optimization went from 0.956 m/s to 0.958 m/s, indicating that the robot has a virtually constant speed, whether turning or not. The improvement of the optimized version in relation to the baseline is about 36 %. The total angular displacement performed by certain groups of joints during a successful episode was analyzed, as this metric provides a reasonable indicator of energy consumption, considering that the actuators load is not disclosed by the server. Fig. 13 compares the displacement sum of the arms joints with the displacement sum of all robot joints (except for the head). This analysis was performed for different stages of the linear path described by the robot. In the first meter, as expected, the robot spends more energy while gaining momentum, and then it stabilizes. Considering only the arms joints (shoulder roll, shoulder pitch, elbow yaw, elbow roll), the average angular displacement for the entire episode rose 49 %. Despite this result, the same analysis performed for all joints yields an increment of only 10 %. Therefore, without considering stability gains, the ratio of relative speed improvement to relative displacement increment in successful episodes is 3.6. In essence, the robot became much more energy efficient, as a small raise in energy consumption led to a considerably faster gait. 9 Discussion Simulation results showed that the framework is able to generate a fast and stable omnidirectional walk and improve its performance by learning how to control the arms and the height of the COM. Indeed, the results showed that providing a tight coupling between analytical approaches and ML improves the performance considerably. In the remaining of this section, we point out the features and limitations of the proposed framework and provide comparisons with the results of previous works. 9.1 Features • Architecture: the modular architecture of the proposed framework provides some important properties such as reducing the complexity and increasing the flexibility. In comparison with approaches that are based on heuristic methods [12–15,45,46] or based on learning from scratch [12,20,21], our framework is expected to be able to migrate to different humanoid platforms with small changes to the control module. • Computational efficiency: unlike the approaches presented in [6,27,47–49] which are based on online optimization (e.g., MPC), our controller was designed on top of an offline optimization algorithm. Therefore, it does not need powerful computational resources and it can be deployed on any platform easily. • Considering the upper body dynamics: most of the presented approaches in the literature used LIPM as their dynamics model, mainly due to its linearity and simplicity. Unlike LIPM-based approaches, we take into account the robot’s upper body dynamics and we showed how this consideration helps to enhance the stability and speed of the robot, while improving the energy efficiency as a ratio of mean speed to total angular displacement. • Release the height of COM constraint: LIPM-based approaches assume a fixed vertical position for the COM. According to this assumption, the knee joints have to be bent while the robot is walking, which is harmful for the knee joints and causes additional energy consumption. Additionally, walking with bent knees is not very human-like. We released this constraint by assuming a sinusoidal movement for the vertical position of the COM. We showed that this assumption not only cancels the explained limitations but it also improves the stability. • Performance: to have an entirely fair comparison, the performance of our framework should be compared with other frameworks in the same scenario and simulator. To do so, we took into consideration the maximum forward speed, and our proposed framework provides a faster walk than the agents in [19,25,45,46,50] and slower than [21,38,41,51]. However, the faster examples are solely focused on sprinting forward, without the basic ability of changing direction. The comparison results are summarized in Table 5. • Learning flexibility: we believe that a humanoid robot should be able to learn from experience, not only to create a new behavior but also to improve its skills. Additionally, it should be able to reuse its knowledge in different scenarios. Learning how to control the arms and the COM height had a positive effect under different conditions in which the robot was not explicitly trained. The robot preserved its stability and speed when subjected to constant orientation adjustments to move in a straight line. Furthermore, we kept the learning module on top of the others to allow situations where generalization is not a conceivable solution. This is an improvement over learning from scratch approaches, as it builds upon a logical and reliable initial solution. This analytical layer is less prone to modeling errors than the learning layer, which is critical when transferring the knowledge to a real robot. After tuning the control module to new conditions, the neural network can be partially retrained by leveraging existing knowledge of similar tasks. This architecture allows for a plethora of modular optimizations aimed at stability, speed, energy efficiency, path optimization, context awareness problems (including prevention and recovery), etc. • Controller and robustness: some approaches [22,25] used a dynamics model just to generate a feed-forward walk and did not consider any controller to track the references. Other approaches that are based on learning from scratch [12,20,21] do not take into account any controller explicitly. Instead, they use a learning algorithm to develop a controller implicitly. Unlike these approaches, we believe that a robust controller is an essential module of a walking framework due to the unstable nature of a humanoid robot. More specifically, when deploying the framework on a real robot, using a closed-loop walking is the best approach because it provides a better stability guarantee. Moreover, as we showed, the ML algorithms can be used on top of this controller to improve its performance. The summary of the results in the maximum speed scenario are presented in the Table 6. 9.2 Limitations • Swing leg dynamics: the legs of a humanoid robot are generally composed of six joints and have non-negligible masses. In our dynamics models, the swing leg is considered to be massless, which affects the controller performance. Taking into account the inertia and mass of the swing leg can minimize tracking errors and improve the controller’s performance [5,52]. • Reality gap: the disparity between reality and simulation is a matter of concern when employing offline ML techniques. Learning to improve the upper body efficiency took between 20 and 26 million time steps. Other works have shown the optimization of robotic tasks, such as squatting [27], using RL combined with an analytical controller, in under 10 million time steps. Haarnoja et al. also demonstrated that learning humanoid tasks from scratch can also be performed in about the same period of time [53]. However, it must be noted that these approaches employed distinct environments with different robots, directly influencing the complexity of the task. Learning to run using the NAO robot in SimSpark can take close to 200 million time steps [21,38]. Nevertheless, 20–26 million time steps can still be characterized as poor sample efficiency, as it takes a considerable amount of time and must be performed in a simulated environment. The gap between both worlds largely affects the transferability of knowledge to the real robot. Despite the scientific community’s considerable effort to reduce this gap, it remains an issue when dealing with intricate robot models. Additionally, it is not possible to learn directly on the real robot due to the high potential of mechanical damage. 10 Conclusion In this paper, we have tackled the problem of developing a robust biped locomotion framework by proposing a tight coupling between an analytical control approach and a reinforcement learning approach. The overall architecture of the framework was composed of six distinct modules which were hierarchically structured. We abstracted the overall dynamics of a humanoid robot into two masses. Then, we used the ZMP concept and some assumptions to represent this dynamics model as a linear state space system. The system was composed of four states and we explained how it can be used to plan and control the walking reference trajectories. Particularly, the planner was composed of five sub-planners and the controller was formulated as an LQG controller, which is not only robust against uncertainties but also provides a promising solution using an offline optimization. We analyzed the performance of the controller in the presence of uncertainties using simulations and the results validated its performance. Moreover, we illustrated how the parametric nature of the framework allows us to use the PPO algorithm on top of an analytical control approach to improve the performance of the framework. Finally, the performance of the proposed framework was validated in several simulated scenarios. The first two scenarios were focused on examining the ability of the framework in generating an omnidirectional walk and finding the maximum velocity of the forward walk. The third scenario was designed to assess the capability of the learning module in improving the framework’s performance. The robot learned how to move its arms and COM height in order to improve the stability, speed and energy efficiency. This limited action space enabled the robot to learn how to walk without falling for much longer periods (almost 15 times longer), while also improving the speed by 60 % when walking forward or turning. As future work, we would like to design a more accurate dynamics model by considering the mass of the swing leg to improve the framework’s performance, and test it on a more realistic simulator. Additionally, we would like to extend our framework by adding another module that learns a set of specific actions to handle emergency conditions . Declaration of Competing Interest The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper. Acknowledgment This research is supported by Portuguese National Funds through Foundation for Science and Technology (FCT), Portugal through FCT scholarship SFRH/BD/118438/2016. The second author is supported by FCT, Portugal under grant SFRH/BD/139926/2018. References [1] Kajita S. Tani K. Study of dynamic biped locomotion on rugged terrain-derivation and application of the linear inverted pendulum mode Robotics and Automation, 1991. Proceedings., 1991 IEEE International Conference on 1991 IEEE 1405 1411 S. Kajita, K. Tani, Study of dynamic biped locomotion on rugged terrain-derivation and application of the linear inverted pendulum mode, in: Robotics and Automation, 1991. Proceedings., 1991 IEEE International Conference on, IEEE, 1991, 1405–1411. [2] Kajita S. Kanehiro F. Kaneko K. Fujiwara K. Harada K. Yokoi K. Hirukawa H. Biped walking pattern generation by using preview control of zero-moment point : Robotics and Automation, 2003. Proceedings. ICRA’03. IEEE International Conference on, Vol. 2 2003 IEEE 1620 1626 S. Kajita, F. Kanehiro, K. Kaneko, K. Fujiwara, K. Harada, K. Yokoi, H. Hirukawa, Biped walking pattern generation by using preview control of zero-moment point, in: Robotics and Automation, 2003. Proceedings. ICRA’03. IEEE International Conference on, 2, IEEE, 2003, 1620–1626. [3] Kajita S. Morisawa M. Miura K. Nakaoka S. Harada K. Kaneko K. Kanehiro F. Yokoi K. Biped walking stabilization based on linear inverted pendulum tracking Intelligent Robots and Systems (IROS), 2010 IEEE/RSJ International Conference on 2010 IEEE 4489 4496 S. Kajita, M. Morisawa, K. Miura, S. Nakaoka, K. Harada, K. Kaneko, F. Kanehiro, K. Yokoi, Biped walking stabilization based on linear inverted pendulum tracking, in: Intelligent Robots and Systems (IROS), 2010 IEEE/RSJ International Conference on, IEEE, 2010, 4489–4496. [4] Shimmyo S. Sato T. Ohnishi K. Biped walking pattern generation by using preview control based on three-mass model IEEE Trans. Ind. Electron. 60 11 2013 5137 5147 S. Shimmyo, T. Sato, K. Ohnishi, Biped walking pattern generation by using preview control based on three-mass model, Industrial Electronics, IEEE Transactions on 60 (11) (2013) 5137–5147. [5] Faraji S. Ijspeert A.J. 3LP: A linear 3D-walking model including torso and swing dynamics Int. J. Robot. Res. 36 4 2017 436 455 S. Faraji, A. J. Ijspeert, 3LP: A linear 3D-walking model including torso and swing dynamics, the international journal of robotics research 36 (4) (2017) 436–455. [6] Griffin R.J. Wiedebach G. Bertrand S. Leonessa A. Pratt J. Walking stabilization using step timing and location adjustment on the humanoid robot, atlas 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) 2017 IEEE 667 673 R. J. Griffin, G. Wiedebach, S. Bertrand, A. Leonessa, J. Pratt, Walking stabilization using step timing and location adjustment on the humanoid robot, atlas, in: 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), IEEE, 2017, 667–673. [7] Kasaei M. Lau N. Pereira A. A robust biped locomotion based on linear-quadratic-gaussian controller and divergent component of motion 2019 IEEE/RSJ International Conference on Intelligent Robots and Systems 2019 IEEE 1429 1434 M. Kasaei, N. Lau, A. Pereira, A robust biped locomotion based on linear-quadratic-gaussian controller and divergent component of motion, in: 2019 IEEE/RSJ International Conference on Intelligent Robots and Systems, IEEE, 2019, 1429–1434. [8] Kasaei M.M. Lau N. Pereira A. A model-based biped walking controller based on divergent component of motion 2019 IEEE International Conference on Autonomous Robot Systems and Competitions (ICARSC) 2019 IEEE 1 6 M. M. Kasaei, N. Lau, A. Pereira, A model-based biped walking controller based on divergent component of motion, in: 2019 IEEE International Conference on Autonomous Robot Systems and Competitions (ICARSC), IEEE, 2019, 1–6. [9] Yamaguchi J. Soga E. Inoue S. Takanishi A. Development of a bipedal humanoid robot-control method of whole body cooperative dynamic biped walking Proceedings 1999 IEEE International Conference on Robotics and Automation (Cat. No. 99CH36288C), Vol. 1 1999 IEEE 368 374 J. Yamaguchi, E. Soga, S. Inoue, A. Takanishi, Development of a bipedal humanoid robot-control method of whole body cooperative dynamic biped walking, in: Proceedings 1999 IEEE International Conference on Robotics and Automation (Cat. No. 99CH36288C), 1, IEEE, 1999, 368–374. [10] Khatib O. Sentis L. Park J.-H. A unified framework for whole-body humanoid robot control with multiple constraints and contacts European Robotics Symposium 2008 2008 Springer 303 312 O. Khatib, L. Sentis, J.-H. Park, A unified framework for whole-body humanoid robot control with multiple constraints and contacts, in: European Robotics Symposium 2008, Springer, 2008, 303–312. [11] Ishihara K. Itoh T.D. Morimoto J. Full-body optimal control toward versatile and agile behaviors in a humanoid robot IEEE Robot. Autom. Lett. 5 1 2019 119 126 K. Ishihara, T. D. Itoh, J. Morimoto, Full-body optimal control toward versatile and agile behaviors in a humanoid robot, IEEE Robotics and Automation Letters 5 (1) (2019) 119–126. [12] Shan J. Junshi C. Jiapin C. Design of central pattern generator for humanoid robot walking based on multi-objective ga Proceedings. 2000 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2000)(Cat. No. 00CH37113), Vol. 3 2000 IEEE 1930 1935 J. Shan, C. Junshi, C. Jiapin, Design of central pattern generator for humanoid robot walking based on multi-objective ga, in: Proceedings. 2000 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2000)(Cat. No. 00CH37113), 3, IEEE, 2000, 1930–1935. [13] Lee J. Seo K. Generation of walking trajectory of humanoid robot using cpg J. Korean Inst. Intell. Syst. 23 4 2013 360 365 J. Lee, K. Seo, Generation of walking trajectory of humanoid robot using cpg, Journal of Korean Institute of Intelligent Systems 23 (4) (2013) 360–365. [14] Liu C. Wang D. Chen Q. Central pattern generator inspired control for adaptive walking of biped robots IEEE Trans. Syst. Man Cybern.: Syst. 43 5 2013 1206 1215 C. Liu, D. Wang, Q. Chen, Central pattern generator inspired control for adaptive walking of biped robots, IEEE Transactions on Systems, Man, and Cybernetics: Systems 43 (5) (2013) 1206–1215. [15] Yu J. Tan M. Chen J. Zhang J. A survey on cpg-inspired control models and system implementation IEEE Trans. Neural Netw. Learn. Syst. 25 3 2013 441 456 J. Yu, M. Tan, J. Chen, J. Zhang, A survey on cpg-inspired control models and system implementation, IEEE transactions on neural networks and learning systems 25 (3) (2013) 441–456. [16] Guertin P.A. The mammalian central pattern generator for locomotion Brain Res. Rev. 62 1 2009 45 56 P. A. Guertin, The mammalian central pattern generator for locomotion, Brain research reviews 62 (1) (2009) 45–56. [17] Zhong G. Shevtsova N.A. Rybak I.A. Harris-Warrick R.M. Neuronal activity in the isolated mouse spinal cord during spontaneous deletions in fictive locomotion: insights into locomotor central pattern generator organization J. Physiol. 590 19 2012 4735 4759 G. Zhong, N. A. Shevtsova, I. A. Rybak, R. M. Harris-Warrick, Neuronal activity in the isolated mouse spinal cord during spontaneous deletions in fictive locomotion: insights into locomotor central pattern generator organization, The Journal of physiology 590 (19) (2012) 4735–4759. [18] Menelaou E. McLean D.L. Hierarchical control of locomotion by distinct types of spinal v2a interneurons in zebrafish Nature Commun. 10 1 2019 1 12 E. Menelaou, D. L. McLean, Hierarchical control of locomotion by distinct types of spinal v2a interneurons in zebrafish, Nature communications 10 (1) (2019) 1–12. [19] Kasaei M. Lau N. Pereira A. A fast and stable omnidirectional walking engine for the nao humanoid robot Chalup S. Niemueller T. Suthakorn J. Williams M.-A. RoboCup 2019: Robot World Cup XXIII 2019 Springer International Publishing Cham 99 111 M. Kasaei, N. Lau, A. Pereira, A fast and stable omnidirectional walking engine for the nao humanoid robot, in: S. Chalup, T. Niemueller, J. Suthakorn, M.-A. Williams (Eds.), RoboCup 2019: Robot World Cup XXIII, Springer International Publishing, Cham, 2019, 99–111. [20] Endo G. Morimoto J. Matsubara T. Nakanishi J. Cheng G. Learning cpg-based biped locomotion with a policy gradient method: Application to a humanoid robot Int. J. Robot. Res. 27 2 2008 213 228 G. Endo, J. Morimoto, T. Matsubara, J. Nakanishi, G. Cheng, Learning cpg-based biped locomotion with a policy gradient method: Application to a humanoid robot, The International Journal of Robotics Research 27 (2) (2008) 213–228. [21] Abreu M. Reis L.P. Lau N. Learning to run faster in a humanoid robot soccer environment through reinforcement learning Robot World Cup 2019 Springer 3 15 M. Abreu, L. P. Reis, N. Lau, Learning to run faster in a humanoid robot soccer environment through reinforcement learning, in: Robot World Cup, Springer, 2019, 3–15. [22] MacAlpine P. Barrett S. Urieli D. Vu V. Stone P. Design and optimization of an omnidirectional humanoid walk: A winning approach at the robocup 2011 3d simulation competition Twenty-Sixth AAAI Conference on Artificial Intelligence 2012 P. MacAlpine, S. Barrett, D. Urieli, V. Vu, P. Stone, Design and optimization of an omnidirectional humanoid walk: A winning approach at the robocup 2011 3d simulation competition, in: Twenty-Sixth AAAI Conference on Artificial Intelligence, 2012. [23] Or J. A hybrid cpg–zmp control system for stable walking of a simulated flexible spine humanoid robot Neural Netw. 23 3 2010 452 460 J. Or, A hybrid cpg–zmp control system for stable walking of a simulated flexible spine humanoid robot, Neural Networks 23 (3) (2010) 452–460. [24] He B. Wang Z. Shen R. Hu S. Real-time walking pattern generation for a biped robot with hybrid cpg-zmp algorithm Int. J. Adv. Robot. Syst. 11 10 2014 160 B. He, Z. Wang, R. Shen, S. Hu, Real-time walking pattern generation for a biped robot with hybrid cpg-zmp algorithm, International Journal of Advanced Robotic Systems 11 (10) (2014) 160. [25] Kasaei S.M. Simões D. Lau N. Pereira A. A hybrid zmp-cpg based walk engine for biped robots Iberian Robotics Conference 2017 Springer 743 755 S. M. Kasaei, D. Simões, N. Lau, A. Pereira, A hybrid zmp-cpg based walk engine for biped robots, in: Iberian Robotics conference, Springer, 2017, pp. 743–755. [26] Carpentier J. Tonneau S. Naveau M. Stasse O. Mansard N. A versatile and efficient pattern generator for generalized legged locomotion 2016 IEEE International Conference on Robotics and Automation (ICRA) 2016 IEEE 3555 3561 J. Carpentier, S. Tonneau, M. Naveau, O. Stasse, N. Mansard, A versatile and efficient pattern generator for generalized legged locomotion, in: 2016 IEEE International Conference on Robotics and Automation (ICRA), IEEE, 2016, pp. 3555–3561. [27] Koryakovskiy I. Kudruss M. Vallery H. Babuška R. Caarls W. Model-plant mismatch compensation using reinforcement learning IEEE Robot. Autom. Lett. 3 3 2018 2471 2477 I. Koryakovskiy, M. Kudruss, H. Vallery, R. Babuška, W. Caarls, Model-plant mismatch compensation using reinforcement learning, IEEE Robotics and Automation Letters 3 (3) (2018) 2471–2477. [28] Song K.-T. Hsieh C.-H. Cpg-based control design for bipedal walking on unknown slope surfaces 2014 IEEE International Conference on Robotics and Automation (ICRA) 2014 IEEE 5109 5114 K.-T. Song, C.-H. Hsieh, Cpg-based control design for bipedal walking on unknown slope surfaces, in: 2014 IEEE International Conference on Robotics and Automation (ICRA), IEEE, 2014, 5109–5114. [29] Missura M. Behnke S. Gradient-driven online learning of bipedal push recovery 2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) 2015 IEEE 387 392 M. Missura, S. Behnke, Gradient-driven online learning of bipedal push recovery, in: 2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), IEEE, 2015, 387–392. [30] Massah A. Zamani A. Salehinia Y. Sh M.A. Teshnehlab M. A hybrid controller based on cpg and zmp for biped locomotion J. Mech. Sci. Technol. 27 11 2013 3473 3486 A. Massah, A. Zamani, Y. Salehinia, M. A. Sh, M. Teshnehlab, A hybrid controller based on cpg and zmp for biped locomotion, Journal of Mechanical science and technology 27 (11) (2013) 3473–3486. [31] Liu J. Urbann O. Bipedal walking with dynamic balance that involves three-dimensional upper body motion Robot. Auton. Syst. 77 2016 39 54 J. Liu, O. Urbann, Bipedal walking with dynamic balance that involves three-dimensional upper body motion, Robotics and Autonomous Systems 77 (2016) 39–54. [32] Abdolmaleki A. Simoes D. Lau N. Reis L.P. Neumann G. Contextual relative entropy policy search with covariance matrix adaptation 2016 International Conference on Autonomous Robot Systems and Competitions (ICARSC) 2016 IEEE 94 99 A. Abdolmaleki, D. Simoes, N. Lau, L. P. Reis, G. Neumann, Contextual relative entropy policy search with covariance matrix adaptation, in: 2016 International Conference on Autonomous Robot Systems and Competitions (ICARSC), IEEE, 2016, 94–99. [33] Dhariwal P. Hesse C. Klimov O. Nichol A. Plappert M. Radford A. Schulman J. Sidor S. Wu Y. Zhokhov P. Openai baselines 2017 P. Dhariwal, C. Hesse, O. Klimov, A. Nichol, M. Plappert, A. Radford, J. Schulman, S. Sidor, Y. Wu, P. Zhokhov, Openai baselines, (2017). [34] Vukobratovic M. Frank A. Juricic D. On the stability of biped locomotion IEEE Trans. Biomed. Eng. BME-17 1 1970 25 36 M. Vukobratovic, A. Frank, D. Juricic, On the stability of biped locomotion, IEEE Transactions on Biomedical Engineering BME-17 (1) (1970) 25–36. [35] Winter D.A. Ruder G.K. MacKinnon C.D. Control of balance of upper body during gait Multiple Muscle Systems 1990 Springer 534 541 D. A. Winter, G. K. Ruder, C. D. MacKinnon, Control of balance of upper body during gait, in: Multiple muscle systems, Springer, 1990, 534–541. [36] Kajita S. Benallegue M. Cisneros R. Sakaguchi T. Morisawa M. Kaminaga H. Kumagai I. Kaneko K. Kanehiro F. Position-based lateral balance control for knee-stretched biped robot 2019 IEEE-RAS 19th International Conference on Humanoid Robots (Humanoids) 2019 IEEE 17 24 S. Kajita, M. Benallegue, R. Cisneros, T. Sakaguchi, M. Morisawa, H. Kaminaga, I. Kumagai, K. Kaneko, F. Kanehiro, Position-based lateral balance control for knee-stretched biped robot, in: 2019 IEEE-RAS 19th International Conference on Humanoid Robots (Humanoids), IEEE, 2019, 17–24. [37] J. Schulman, F. Wolski, P. Dhariwal, A. Radford, O. Klimov, Proximal policy optimization algorithms, CoRR 1707.06347. [38] Carvalho Melo L. Omena Albuquerque Máximo M.R. Learning humanoid robot running skills through proximal policy optimization 2019 Latin American Robotics Symposium (LARS), 2019 Brazilian Symposium on Robotics (SBR) and 2019 Workshop on Robotics in Education (WRE) 2019 37 42 L. Carvalho Melo, M. R. Omena Albuquerque Máximo, Learning humanoid robot running skills through proximal policy optimization, in: 2019 Latin American Robotics Symposium (LARS), 2019 Brazilian Symposium on Robotics (SBR) and 2019 Workshop on Robotics in Education (WRE), 2019, 37–42. [39] Teixeira H. Silva T. Abreu M. Reis L.P. Humanoid robot kick in motion ability for playing robotic soccer 2020 IEEE International Conference on Autonomous Robot Systems and Competitions (ICARSC) 2020 IEEE 34 39 H. Teixeira, T. Silva, M. Abreu, L. P. Reis, Humanoid robot kick in motion ability for playing robotic soccer, in: 2020 IEEE International Conference on Autonomous Robot Systems and Competitions (ICARSC), IEEE, 2020, 34–39. [40] Melo D.C. Máximo M.R.O.A da Cunha A.M. Push recovery strategies through deep reinforcement learning 2020 Latin American Robotics Symposium (LARS), 2020 Brazilian Symposium on Robotics (SBR) and 2020 Workshop on Robotics in Education (WRE) 2020 IEEE 240 245 D. C. Melo, M. R. O. A. Máximo, A. M. da Cunha, Push recovery strategies through deep reinforcement learning, in: 2020 Latin American Robotics Symposium (LARS), 2020 Brazilian Symposium on Robotics (SBR) and 2020 Workshop on Robotics in Education (WRE), IEEE, 2020, 240–245. [41] Abreu M. Lau N. Sousa A. Reis L.P. Learning low level skills from scratch for humanoid robot soccer using deep reinforcement learning 2019 IEEE International Conference on Autonomous Robot Systems and Competitions (ICARSC) 2019 IEEE 1 8 M. Abreu, N. Lau, A. Sousa, L. P. Reis, Learning low level skills from scratch for humanoid robot soccer using deep reinforcement learning, in: 2019 IEEE International Conference on Autonomous Robot Systems and Competitions (ICARSC), IEEE, 2019, 1–8. [42] Muzio A.F.V. Maximo M.R.O.A Yoneyama T. Deep reinforcement learning for humanoid robot dribbling 2020 Latin American Robotics Symposium (LARS), 2020 Brazilian Symposium on Robotics (SBR) and 2020 Workshop on Robotics in Education (WRE) 2020 IEEE 246 251 A. F. V. Muzio, M. R. O. A. Maximo, T. Yoneyama, Deep reinforcement learning for humanoid robot dribbling, in: 2020 Latin American Robotics Symposium (LARS), 2020 Brazilian Symposium on Robotics (SBR) and 2020 Workshop on Robotics in Education (WRE), IEEE, 2020, 246–251. [43] D.P. Kingma, J. Ba, Adam: A method for stochastic optimization, CoRR 1412.6980. [44] J. Schulman, P. Moritz, S. Levine, M. Jordan, P. Abbeel, High-dimensional continuous control using generalized advantage estimation, CoRR 1506.02438. [45] Picado H. Gestal M. Lau N. Reis L. Tomé A. Automatic generation of biped walk behavior using genetic algorithms Bio-Inspired Systems: Computational and Ambient Intelligence 2009 805 812 H. Picado, M. Gestal, N. Lau, L. Reis, A. Tomé, Automatic generation of biped walk behavior using genetic algorithms, Bio-inspired systems: Computational and ambient intelligence (2009) 805–812. [46] Shafii N. Reis L.P. Lau N. Biped walking using coronal and sagittal movements based on truncated fourier series Ruiz-del Solar J. Chown E. Plöger P.G. RoboCup 2010: Robot Soccer World Cup XIV 2010 Springer Berlin Heidelberg Berlin, Heidelberg 324 335 N. Shafii, L. P. Reis, N. Lau, Biped walking using coronal and sagittal movements based on truncated fourier series, in: J. Ruiz-del Solar, E. Chown, P. G. Plöger (Eds.), RoboCup 2010: Robot Soccer World Cup XIV, Springer Berlin Heidelberg, Berlin, Heidelberg, 2011, 324–335. [47] Diedam H. Dimitrov D. Wieber P.-B. Mombaur K. Diehl M. Online walking gait generation with adaptive foot positioning through linear model predictive control 2008 IEEE/RSJ International Conference on Intelligent Robots and Systems 2008 IEEE 1121 1126 H. Diedam, D. Dimitrov, P.-B. Wieber, K. Mombaur, M. Diehl, Online walking gait generation with adaptive foot positioning through linear model predictive control, in: 2008 IEEE/RSJ International Conference on Intelligent Robots and Systems, IEEE, 2008, 1121–1126. [48] Herdt A. Diedam H. Wieber P.-B. Dimitrov D. Mombaur K. Diehl M. Online walking motion generation with automatic footstep placement Adv. Robot. 24 5–6 2010 719 737 A. Herdt, H. Diedam, P.-B. Wieber, D. Dimitrov, K. Mombaur, M. Diehl, Online walking motion generation with automatic footstep placement, Advanced Robotics 24 (5-6) (2010) 719–737. [49] Griffin R.J. Leonessa A. Model predictive control for dynamic footstep adjustment using the divergent component of motion 2016 IEEE International Conference on Robotics and Automation (ICRA) 2016 IEEE 1763 1768 R. J. Griffin, A. Leonessa, Model predictive control for dynamic footstep adjustment using the divergent component of motion, in: 2016 IEEE International Conference on Robotics and Automation (ICRA), IEEE, 2016, pp. 1763–1768. [50] Asta S. Sariel-Talay S. Nature-inspired optimization for biped robot locomotion and gait planning European Conference on the Applications of Evolutionary Computation 2011 Springer 434 443 S. Asta, S. Sariel-Talay, Nature-inspired optimization for biped robot locomotion and gait planning, in: European Conference on the Applications of Evolutionary Computation, Springer, 2011, 434–443. [51] MacAlpine P. Stone P. UT Austin Villa: RoboCup 2017 3D simulation league competition and technical challenges champions Robot World Cup 2017 Springer 473 485 P. MacAlpine, P. Stone, UT Austin Villa: RoboCup 2017 3D simulation league competition and technical challenges champions, in: Robot World Cup, Springer, 2017, 473–485. [52] Kasaei M. Ahmadi A. Lau N. Pereira A. A robust model-based biped locomotion framework based on three-mass model: From planning to control 2020 IEEE International Conference on Autonomous Robot Systems and Competitions (ICARSC) 2020 IEEE 257 262 M. Kasaei, A. Ahmadi, N. Lau, A. Pereira, A robust model-based biped locomotion framework based on three-mass model: From planning to control, in: 2020 IEEE International Conference on Autonomous Robot Systems and Competitions (ICARSC), IEEE, 2020, 257–262. [53] Haarnoja T. Zhou A. Abbeel P. Levine S. Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor International Conference on Machine Learning 2018 PMLR 1861 1870 T. Haarnoja, A. Zhou, P. Abbeel, S. Levine, Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor, in: International Conference on Machine Learning, PMLR, 2018, 1861–1870. Mohammadreza Kasaei joined the Department of Electronics, Telecommunications and Informatics (IEETA) of the University of Aveiro in 2016 as a Ph.D. student. His Ph.D. aims to propose a hybrid walking framework by coupling a model-based walk engine with DRL algorithms to combine the potential of both approaches. This hybrid framework aims at generating robust, versatile, and agile omnidirectional walking gaits by exploring the full potential of the robot, taking advantage of the analytical solution’s consistency and the flexibility of residual learning. Miguel Abreu is currently a Ph.D. student at the Faculty of Engineering of the University of Porto (FEUP), Portugal. He received his M.Sc. degree in Electronics and Computers Engineering from the University of Minho, in 2017. His interests include applied mathematics, reinforcement learning, bioinspired artificial intelligence, and autonomous systems in the field of robotics. He is currently focused on improving reinforcement learning algorithms applied to symmetrical models. Nuno Lau is associate professor at Aveiro University, Portugal, and Researcher at the Institute of Electrical and Informatics Engineering of Aveiro (IEETA), where he leads the Intelligent Robotics and Systems group (IRIS). His research interests are focused on Intelligent Robotics, Artificial Intelligence, Multi-Agent Systems and Simulation. Nuno Lau participated in more than 15 international and national research projects, having the tasks of general or local coordinator in about half of them. Nuno Lau won more than 50 scientific awards in robotic competitions, conferences (best papers) and education. Nuno Lau is the author of more than one 150 publications in international conferences and journals. Artur Pereira was born in Vila Nova de Famalicão, Portugal, in April 1960. He received the Ph.D. degree in Electrical Engineering from the University of Aveiro, Portugal, in 2003. He is currently an Assistant Professor at the Department of Electronics, Telecommunications and Informatics of the University of Aveiro and a researcher at the Intelligent Robotics and Systems group (IRIS Lab) of the Institute of Electronics and Informatics Engineering of Aveiro (IEETA). The main focus of his research is robotics at the architectural and software levels, with emphasis on simulation, navigation, localization, mapping, and machine learning. Luis Paulo Reis is Associate Professor and Director of LIACC - Artificial Intelligence and Computer Science Laboratory at the University of Porto in Portugal. He is an IEEE Senior Member and President of APPIA - Portuguese Association for Artificial Intelligence. His research interests are on Artificial Intelligence, Intelligent Robotics, Multi-Agent Systems, Intelligent Simulation and Machine Learning. He was the principal investigator of more than 10 research projects and supervised 21 Ph.D. and 120 M.Sc. theses to completion. He organized more than 50 international scientific events and belonged to the Program Committee of more than 250 scientific events. He is the author of more than 400 publications in international conferences and journals. "
    },
    {
        "doc_title": "A modular framework to generate robust biped locomotion: from planning to control",
        "doc_scopus_id": "85112248611",
        "doc_doi": "10.1007/s42452-021-04752-9",
        "doc_eid": "2-s2.0-85112248611",
        "doc_date": "2021-09-01",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Engineering (all)",
                "area_abbreviation": "ENGI",
                "area_code": "2200"
            },
            {
                "area_name": "Environmental Science (all)",
                "area_abbreviation": "ENVI",
                "area_code": "2300"
            },
            {
                "area_name": "Materials Science (all)",
                "area_abbreviation": "MATE",
                "area_code": "2500"
            },
            {
                "area_name": "Physics and Astronomy (all)",
                "area_abbreviation": "PHYS",
                "area_code": "3100"
            },
            {
                "area_name": "Chemical Engineering (all)",
                "area_abbreviation": "CENG",
                "area_code": "1500"
            },
            {
                "area_name": "Earth and Planetary Sciences (all)",
                "area_abbreviation": "EART",
                "area_code": "1900"
            }
        ],
        "doc_keywords": [
            "Biped Robot",
            "Dynamics modeling",
            "Input-output",
            "Model-based OPC",
            "Modular framework",
            "Reference trajectories",
            "Research efforts",
            "Tracking problem"
        ],
        "doc_abstract": "© 2021, The Author(s).Biped robots are inherently unstable because of their complex kinematics as well as dynamics. Despite many research efforts in developing biped locomotion, the performance of biped locomotion is still far from the expectations. This paper proposes a model-based framework to generate stable biped locomotion. The core of this framework is an abstract dynamics model which is composed of three masses to consider the dynamics of stance leg, torso, and swing leg for minimizing the tracking problems. According to this dynamics model, we propose a modular walking reference trajectories planner which takes into account obstacles to plan all the references. Moreover, this dynamics model is used to formulate the controller as a Model Predictive Control (MPC) scheme which can consider some constraints in the states of the system, inputs, outputs, and also mixed input-output. The performance and the robustness of the proposed framework are validated by performing several numerical simulations using MATLAB. Moreover, the framework is deployed on a simulated torque-controlled humanoid to verify its performance and robustness. The simulation results show that the proposed framework is capable of generating biped locomotion robustly.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Segmentation and Manipulation of Cork Strips in Bulk",
        "doc_scopus_id": "85107151302",
        "doc_doi": "10.1109/ICARSC52212.2021.9429769",
        "doc_eid": "2-s2.0-85107151302",
        "doc_date": "2021-04-28",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            },
            {
                "area_name": "Computer Vision and Pattern Recognition",
                "area_abbreviation": "COMP",
                "area_code": "1707"
            },
            {
                "area_name": "Human-Computer Interaction",
                "area_abbreviation": "COMP",
                "area_code": "1709"
            },
            {
                "area_name": "Mechanical Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2210"
            },
            {
                "area_name": "Control and Optimization",
                "area_abbreviation": "MATH",
                "area_code": "2606"
            }
        ],
        "doc_keywords": [
            "Computer vision techniques",
            "Conveyor belts",
            "Cork stoppers",
            "Industry sectors",
            "Motion planners",
            "Natural cork",
            "Punching machine",
            "Rgb-d cameras"
        ],
        "doc_abstract": "© 2021 IEEE.The production of cork stoppers is the largest application of natural cork, which is an ever-growing industry sector. Many attempts have been made to increase the automation of this process, such as the use of automated cork punching machines, but not all steps of this process are fully efficient such as the manipulation of cork strips prior to perforation, which is still a hand labor. This paper presents a system based on an RGBD camera and a 6 DoF robotic arm that manipulates cork strips which are disposed in bulk, either in a container or in a conveyor belt. It uses computer vision techniques to segment a single cork strip from the bunch and motion planners to control the robotic arm in order to grab the selected cork strip. On the experiments made, the system was able to correctly grab a cork strip with 92% success rate and with a frequency of 6 strips per minute.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Neural Network Classifier and Robotic Manipulation for an Autonomous Industrial Cork Feeder",
        "doc_scopus_id": "85115444254",
        "doc_doi": "10.1007/978-3-030-86230-5_34",
        "doc_eid": "2-s2.0-85115444254",
        "doc_date": "2021-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Convolutional neural network",
            "Cork",
            "Deep learning",
            "High quality",
            "Image processing technique",
            "Network robotics",
            "Neural networks classifiers",
            "Robotic manipulation",
            "Specific orientation",
            "Universal robot"
        ],
        "doc_abstract": "© 2021, Springer Nature Switzerland AG.This paper presents a solution for an autonomous cork puncher feeder with a robotic arm using image processing techniques and a convolutional neural network. Due to the need for cork strips to be inserted into the puncher with a specific orientation, to produce high quality cork stoppers, the identification of the orientation of each cork strip on the conveyor belt is a necessity. In response to this problem a convolutional neural network is used to analyse images processed with subtracted background, to create a robust solution for cork strips classification. In the tests carried out, a classification accuracy of 100% was obtained in a test data set with 12 different cork strips.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "A survey of planning and learning in games",
        "doc_scopus_id": "85087795422",
        "doc_doi": "10.3390/app10134529",
        "doc_eid": "2-s2.0-85087795422",
        "doc_date": "2020-07-01",
        "doc_type": "Review",
        "doc_areas": [
            {
                "area_name": "Materials Science (all)",
                "area_abbreviation": "MATE",
                "area_code": "2500"
            },
            {
                "area_name": "Instrumentation",
                "area_abbreviation": "PHYS",
                "area_code": "3105"
            },
            {
                "area_name": "Engineering (all)",
                "area_abbreviation": "ENGI",
                "area_code": "2200"
            },
            {
                "area_name": "Process Chemistry and Technology",
                "area_abbreviation": "CENG",
                "area_code": "1508"
            },
            {
                "area_name": "Computer Science Applications",
                "area_abbreviation": "COMP",
                "area_code": "1706"
            },
            {
                "area_name": "Fluid Flow and Transfer Processes",
                "area_abbreviation": "CENG",
                "area_code": "1507"
            }
        ],
        "doc_keywords": [],
        "doc_abstract": "© 2020 by the authors. Licensee MDPI, Basel, Switzerland.In general, games pose interesting and complex problems for the implementation of intelligent agents and are a popular domain in the study of artificial intelligence. In fact, games have been at the center of some of the most well-known achievements in artificial intelligence. From classical board games such as chess, checkers, backgammon and Go, to video games such as Dota 2 and StarCraft II, artificial intelligence research has devised computer programs that can play at the level of a human master and even at a human world champion level. Planning and learning, two well-known and successful paradigms of artificial intelligence, have greatly contributed to these achievements. Although representing distinct approaches, planning and learning try to solve similar problems and share some similarities. They can even complement each other. This has led to research on methodologies to combine the strengths of both approaches to derive better solutions. This paper presents a survey of the multiple methodologies that have been proposed to integrate planning and learning in the context of games. In order to provide a richer contextualization, the paper also presents learning and planning techniques commonly used in games, both in terms of their theoretical foundations and applications.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Fast Grid SLAM based on particle filter with scan matching and multithreading",
        "doc_scopus_id": "85085940206",
        "doc_doi": "10.1109/ICARSC49921.2020.9096191",
        "doc_eid": "2-s2.0-85085940206",
        "doc_date": "2020-04-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            },
            {
                "area_name": "Mechanical Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2210"
            },
            {
                "area_name": "Control and Optimization",
                "area_abbreviation": "MATH",
                "area_code": "2606"
            }
        ],
        "doc_keywords": [
            "Fast scan",
            "Multi-threading",
            "Particle filter",
            "Pose refinement",
            "Rao-blackwellized particle filter",
            "Real-time operation",
            "Scan matching",
            "Space management"
        ],
        "doc_abstract": "© 2020 IEEE.This paper presents a SLAM solution based on Rao-Blackwellized particle filters supported by a fast scan matching algorithm for pose refinement and a flexible space management data structure. By taking advantage of independence between particles its computational efficiency is further improved through multithreading. We have evaluated the efficiency of the solution by using several publicly available datasets and compared the results with the popular solution GMapping. The obtained results show the proposed approach provides a fast and accurate particle filter SLAM suitable for real-time operations.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "A robust model-based biped locomotion framework based on three-mass model: From planning to control",
        "doc_scopus_id": "85085910734",
        "doc_doi": "10.1109/ICARSC49921.2020.9096150",
        "doc_eid": "2-s2.0-85085910734",
        "doc_date": "2020-04-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            },
            {
                "area_name": "Mechanical Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2210"
            },
            {
                "area_name": "Control and Optimization",
                "area_abbreviation": "MATH",
                "area_code": "2606"
            }
        ],
        "doc_keywords": [
            "Biped Robot",
            "Dynamics modeling",
            "Model-based OPC",
            "Reference trajectories",
            "Robust modeling",
            "Three-mass model",
            "Tracking problem"
        ],
        "doc_abstract": "© 2020 IEEE.Biped robots are inherently unstable because of their complex kinematics as well as dynamics. Despite types of research in developing biped locomotion, the performance of biped locomotion is still far from the expectations.This paper proposes a model-based framework to generate stable biped locomotion. The core of this framework is an abstract dynamics model which is composed of three masses to consider the dynamics of stance leg, torso and swing leg for minimizing the tracking problems. According to this dynamics model, we propose a modular walking reference trajectories planner which takes into account obstacles to plan all the references. Moreover, this dynamics model is used to formulate the controller as a Model Predictive Control (MPC) scheme which can consider some constraints in the states of the system, inputs, outputs and also mixed input-output.The performance and the robustness of the proposed framework are validated by performing several simulations using MATLAB. The simulation results show that the proposed framework is capable of generating the biped locomotion robustly.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "TIMAIRIS: Autonomous Blank Feeding for Packaging Machines",
        "doc_scopus_id": "85087543982",
        "doc_doi": "10.1007/978-3-030-34507-5_7",
        "doc_eid": "2-s2.0-85087543982",
        "doc_date": "2020-01-01",
        "doc_type": "Book Chapter",
        "doc_areas": [
            {
                "area_name": "Electrical and Electronic Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2208"
            },
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            }
        ],
        "doc_keywords": [
            "Alternative solutions",
            "Computer vision system",
            "Current packaging",
            "Different shapes",
            "Industrial environments",
            "Mobile manipulator",
            "Modes of operation",
            "Multi-Modal Interactions"
        ],
        "doc_abstract": "© 2020, Springer Nature Switzerland AG.Current packaging machine vendors do not provide any automated mechanism for blank feeding and the state of the art is to have a human operator dedicated to feed the blank piles to the packaging machine. This is a tedious, repetitive and tiring task. This also results in problems with unintentional errors, such as using the wrong pile of blanks. An alternative solution is the use of a fixed robotic arm surrounded by a protective cage. However, this solution is restricted to a single packaging machine, a unique type of blank shapes and does not cooperate with humans. TIMAIRIS is a joint effort between IMA S.p.A., Italy, (IMA) and the Universidade de Aveiro, Portugal, (UAVR), promoted by the European Robotics Challenges (EuRoC) project. Together, we propose a system based on a mobile manipulator for flexible, autonomous and collaborative blank feeding of packaging machines on industrial shop floor. The system provides a software architecture that allows a mobile robot to take high level decisions on how the task should be executed, which can depend on variables such as the number of packaging machines to feed and the rate of blank consumption at each one. Through a computer vision system, blanks of different shapes and sizes are correctly identified for adequate manipulation. The manipulation of the piles of blanks is performed using a single arm using compliant modes of operation to increase manipulation safety and robustness. Additionally, it has a safe navigation system that allows the robot to be integrated in an industrial environment where humans are present. Finally, it provides an enhanced multimodal interaction between human and robot that can be adapted to the environment and operator characteristics to make communication intuitive, redundant and safe.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Benchmarking Deep and Non-deep Reinforcement Learning Algorithms for Discrete Environments",
        "doc_scopus_id": "85079092068",
        "doc_doi": "10.1007/978-3-030-36150-1_22",
        "doc_eid": "2-s2.0-85079092068",
        "doc_date": "2020-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Control and Systems Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2207"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Benchmark study",
            "Learning environments",
            "Network algorithms",
            "Neural Fitted Q-Iteration",
            "Policy gradient",
            "Q-learning",
            "Value iteration"
        ],
        "doc_abstract": "© 2020, Springer Nature Switzerland AG.Given the plethora of Reinforcement Learning algorithms available in the literature, it can prove challenging to decide on the most appropriate one to use in order to solve a given Reinforcement Learning task. This work presents a benchmark study on the performance of several Reinforcement Learning algorithms for discrete learning environments. The study includes several deep as well as non-deep learning algorithms, with special focus on the Deep Q-Network algorithm and its variants. Neural Fitted Q-Iteration, the predecessor of Deep Q-Network as well as Vanilla Policy Gradient and a planner were also included in this assessment in order to provide a wider range of comparison between different approaches and paradigms. Three learning environments were used in order to carry out the tests, including a 2D maze and two OpenAI Gym environments, namely a custom-built Foraging/Tagging environment and the CartPole environment.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "A Robust Biped Locomotion Based on Linear-Quadratic-Gaussian Controller and Divergent Component of Motion",
        "doc_scopus_id": "85081157666",
        "doc_doi": "10.1109/IROS40897.2019.8967778",
        "doc_eid": "2-s2.0-85081157666",
        "doc_date": "2019-11-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Control and Systems Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2207"
            },
            {
                "area_name": "Software",
                "area_abbreviation": "COMP",
                "area_code": "1712"
            },
            {
                "area_name": "Computer Vision and Pattern Recognition",
                "area_abbreviation": "COMP",
                "area_code": "1707"
            },
            {
                "area_name": "Computer Science Applications",
                "area_abbreviation": "COMP",
                "area_code": "1706"
            }
        ],
        "doc_keywords": [
            "Closed loop controllers",
            "Humanoid robot",
            "Inverted pendulum",
            "Inverted pendulum model",
            "Landing locations",
            "Linear quadratic Gaussian",
            "Linear Quadratic Gaussian controllers",
            "Number of degrees of freedom"
        ],
        "doc_abstract": "© 2019 IEEE.Generating robust locomotion for a humanoid robot in the presence of disturbances is difficult because of its high number of degrees of freedom and its unstable nature. In this paper, we used the concept of Divergent Component of Motion (DCM) and propose an optimal closed-loop controller based on Linear-Quadratic-Gaussian to generate a robust and stable walking for humanoid robots. The biped robot dynamics has been approximated using the Linear Inverted Pendulum Model (LIPM). Moreover, we propose a controller to adjust the landing location of the swing leg to increase the withstanding level of the robot against a severe external push. The performance and also the robustness of the proposed controller is analyzed and verified by performing a set of simulations using MATLAB. The simulation results showed that the proposed controller is capable of providing a robust walking even in the presence of disturbances and in challenging situations.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Skill-based anytime agent architecture for European Robotics Challenges in realistic environments: EuRoC Challenge 2, Stage II — realistic labs",
        "doc_scopus_id": "85070213536",
        "doc_doi": "10.1016/j.robot.2019.06.006",
        "doc_eid": "2-s2.0-85070213536",
        "doc_date": "2019-10-01",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Software",
                "area_abbreviation": "COMP",
                "area_code": "1712"
            },
            {
                "area_name": "Control and Systems Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2207"
            },
            {
                "area_name": "Mathematics (all)",
                "area_abbreviation": "MATH",
                "area_code": "2600"
            },
            {
                "area_name": "Computer Science Applications",
                "area_abbreviation": "COMP",
                "area_code": "1706"
            }
        ],
        "doc_keywords": [
            "Agent architectures",
            "European robotics challenges (EuRoC)",
            "Manufacturing industries",
            "Mobile manipulation",
            "Realistic environments",
            "Robotics technology",
            "Scientific competition",
            "Skill-based"
        ],
        "doc_abstract": "© 2019As demands on pragmatic solutions of robotics technology increase in the manufacturing industry, deep affinities between research experts and industry users are required. The European Robotics Challenges (EuRoC) research project has proposed a scientific competition and matched up research labs with industrial end users to establish challenger teams to develop and test solutions that will be applied in the real context of the industrial end-users. The paper reports the result of TIMAIRIS who is one of 6 challenger teams to advance to the final stage out of 103 teams and technical details used in the Challenge 2 - Shop Floor Logistics and Manipulation. To address the requirements and achieve the objectives of the challenge, a skill-based anytime agent architecture has been developed and extended to make the team focus on the challenging research that addresses real issues in the user environments. Finally, shop floor logistics and manipulation scenarios have been developed and demonstrated in a realistic environment for autonomous packaging.",
        "available": true,
        "clean_text": "serial JL 271599 291210 291866 291870 291882 291883 31 Robotics and Autonomous Systems ROBOTICSAUTONOMOUSSYSTEMS 2019-08-02 2019-08-02 2019-08-08 2019-08-08 2019-09-13T06:57:28 S0921-8890(17)30794-7 S0921889017307947 10.1016/j.robot.2019.06.006 S300 S300.1 FULL-TEXT 2020-01-13T11:13:04.440713Z 0 0 20191001 20191031 2019 2019-08-02T15:14:58.064687Z articleinfo articlenumber articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid hubeid indexeddate issn issnnorm itemstage itemtransactionid itemweight openaccess openarchive pg pgfirst pii piinorm pubdateend pubdatestart pubdatetxt pubyr sortorder srctitle srctitlenorm srctype ssids alllist content subj subheadings suppl tomb volfirst volissue volumelist yearnav figure table body mmlmath acknowledge affil articletitle auth authfirstini authfull authkeywords authlast footnotes grantnumber grantsponsor grantsponsorid highlightsabst orcid primabst ref vitae 0921-8890 09218890 true 120 120 C Volume 120 9 103227 103227 103227 201910 October 2019 2019-10-01 2019-10-31 2019 article fla © 2019 Published by Elsevier B.V. SKILLBASEDANYTIMEAGENTARCHITECTUREFOREUROPEANROBOTICSCHALLENGESINREALISTICENVIRONMENTSEUROCCHALLENGE2STAGEIIREALISTICLABS LIM G 1 Introduction 1.1 Motivation 1.2 Related work 2 European robotics challenges (EuRoC) 2.1 Challenge 2: shop floor logistics and manipulation 2.1.1 Benchmarking 2.1.2 Showcase: autonomous packaging 2.2 EuRoC platform 2.3 TIMAIRIS software architecture 3 Agent architecture 3.1 Skill-based anytime agent architecture 3.2 Resource management scheme 4 Solving benchmarking tasks 4.1 Task 1: production logistics 4.1.1 SLC detection 4.1.2 Manipulation and planning strategy 4.2 Task 2: product assembly 4.2.1 Fixture detection 4.2.2 Bolt, nut and washer detection 4.3 Manipulation and planning strategy 5 Solving showcase tasks 5.1 Manipulation of stacked non rigid objects 5.2 Manipulator for packaging 5.3 Showcase perception 5.4 Motion planing 5.5 Task planning 5.6 Safe human–robot collaboration 6 Challenge evaluation 6.1 Benchmark evaluation 6.2 Showcase evaluation 7 Conclusion Acknowledgments References PRATT 2013 10 12 G KITANO 1997 340 347 H PROCEEDINGSFIRSTINTERNATIONALCONFERENCEAUTONOMOUSAGENTS ROBOCUPROBOTWORLDCUPINITIATIVE SICILIANO 2014 1 7 B ISRROBOTIK201441STINTERNATIONALSYMPOSIUMROBOTICSPROCEEDINGS EUROCTHECHALLENGEINITIATIVEFOREUROPEANROBOTICS BISCHOFF 2010 15 16 R CULLY 2015 503 A HILDEBRANDT 2016 21 27 A AUTONOMOUSROBOTSYSTEMSCOMPETITIONSICARSC2016INTERNATIONALCONFERENCE AFLEXIBLEROBOTICFRAMEWORKFORAUTONOMOUSMANUFACTURINGPROCESSESREPORTEUROPEANROBOTICSCHALLENGESTAGE1 ZADEH 2017 81 103 S BAKLOUTI 2017 9 14 E NILSSON 1999 205 226 K CHATZILYGEROUDIS 2018 236 250 K INSAURRALDE 2015 87 104 C DEAN 1988 49 54 T AAAIVOL88 ANALYSISTIMEDEPENDENTPLANNING GREFENSTETTE 1992 189 195 J MACHINELEARNINGPROCEEDINGS1992 APPROACHANYTIMELEARNING PEDROSA 2015 457 468 E PROGRESSINARTIFICIALINTELLIGENCE17THPORTUGUESECONFERENCEARTIFICIALINTELLIGENCEEPIA2015 ASKILLBASEDARCHITECTUREFORPICKPLACEMANIPULATIONTASKS AMARAL 2017 198 203 F AUTONOMOUSROBOTSYSTEMSCOMPETITIONSICARSC2017IEEEINTERNATIONALCONFERENCE SKILLBASEDANYTIMEAGENTARCHITECTUREFORLOGISTICSMANIPULATIONTASKSEUROCCHALLENGE2STAGEIIREALISTICLABSBENCHMARKING LIM 2017 159 164 G AUTONOMOUSROBOTSYSTEMSCOMPETITIONSICARSC2017IEEEINTERNATIONALCONFERENCE RICHROBUSTHUMANROBOTINTERACTIONGESTURERECOGNITIONFORASSEMBLYTASKS LIM 2017 15 27 G IBERIANROBOTICSCONFERENCE HUMANROBOTCOLLABORATIONSAFETYMANAGEMENTFORLOGISTICSMANIPULATIONTASKS MOKHTARI 2016 993 1005 V INTELLIGENTAUTONOMOUSSYSTEMS13 GATHERINGCONCEPTUALIZINGPLANBASEDROBOTACTIVITYEXPERIENCES LIM 2019 G BALOGH 2005 17 R THRUN 2006 661 692 S BUEHLER 2009 M DARPAURBANCHALLENGEAUTONOMOUSVEHICLESINCITYTRAFFICVOL56 LIM 2017 336 341 G 2017IEEEINTERNATIONALCONFERENCEMULTISENSORFUSIONINTEGRATIONFORINTELLIGENTSYSTEMSMFI NEURALREGULARIZATIONJOINTLYINVOLVINGNEURONSCONNECTIONSFORROBUSTIMAGECLASSIFICATION RUSSELL 2010 S ARTIFICIALINTELLIGENCEAMODERNAPPROACH LIM 2018 231 236 G 2018IEEEINTERNATIONALCONFERENCEAUTONOMOUSROBOTSYSTEMSCOMPETITIONSICARSC MOBILEMANIPULATIONFORAUTONOMOUSPACKAGINGINREALISTICENVIRONMENTSEUROCCHALLENGE2STAGEIISHOWCASE LIM 2019 1 11 G LIM 2013 387 395 G INTELLIGENTAUTONOMOUSSYSTEMSVOL12 ONTOLOGYREPRESENTATIONINSTANTIATIONFORSEMANTICMAPBUILDINGBYAMOBILEROBOT LIM 2011 492 509 G RUSU 2008 927 941 R RUSU 2009 R SEMANTIC3DOBJECTMAPSFOREVERYDAYMANIPULATIONINHUMANLIVINGENVIRONMENTS OLIVEIRA 2016 614 626 M PEDROSA 2016 35 40 E 2016INTERNATIONALCONFERENCEAUTONOMOUSROBOTSYSTEMSCOMPETITIONSICARSC ASCANMATCHINGAPPROACHSLAMADYNAMICLIKELIHOODFIELD COHENOR 1995 453 461 D RUSU 2011 1 4 R ROBOTICSAUTOMATIONICRA2011IEEEINTERNATIONALCONFERENCE 3DPOINTCLOUDLIBRARYPCL LOWE 1999 1150 1157 D COMPUTERVISION1999PROCEEDINGSSEVENTHIEEEINTERNATIONALCONFERENCEVOL2 OBJECTRECOGNITIONLOCALSCALEINVARIANTFEATURES TUDICO 2017 498 509 A PORTUGUESECONFERENCEARTIFICIALINTELLIGENCE IMPROVINGBENCHMARKINGMOTIONPLANNINGFORAMOBILEMANIPULATOROPERATINGINUNSTRUCTUREDENVIRONMENTS LIMX2019X103227 LIMX2019X103227XG 2021-08-08T00:00:00.000Z 2021-08-08T00:00:00.000Z © 2019 Published by Elsevier B.V. 2019-08-10T21:40:24.934Z S0921889017307947 National Funds China National Funds for Distinguished Young Scientists FCT - Foundation for Science and Technology UID/CEC/00127/2013 This work was supported by the EuRoC Project under Grant no. 608849 and by National Funds through the FCT - Foundation for Science and Technology , in the context of the project UID/CEC/00127/2013 . Dr. Gi Hyun Lim received the B.S. degree in metallurgical engineering and the M.S. and Ph.D. degrees in electronics and computer engineering from Hanyang University, Seoul, Korea, in 1997, 2007 and 2010, respectively. He is currently a Marie Curie individual fellow in the School of Computer Science at University of Manchester, UK. His research interests lie in the area of artificial intelligence and machine learning for autonomous robots, including perception, semantics, cognition and spatiotemporal representations on neuromorphic architectures. Eurico Pedrosa is a Post-Doc Researcher at the Institute of Electronics and Informatics Engineering of Aveiro (IEETA) integrated in Intelligent Robotics and Systems group (IRIS). He got his Informatics Engineering degree from University of Aveiro in 2010 and a Computer Science Ph.D. degree from Aveiro University in 2018. His research interest are focused on intelligent robotics, robotic navigation including localization and mapping (SLAM), space representation using volumetric grids and most recently the application of radar sensors in indoor robotics. Filipe Amaral is a Research Fellow at the Institute of Electronics and Informatics Engineering of Aveiro (IEETA) integrated in Intelligent Robotics and Systems group (IRIS). He got his MSc degree in Computer and Telematics Engineering from University of Aveiro in 2014. His current research interests are in the area of autonomous mobile robotics. Prof. Dr. Artur Pereira was born in Vila Nova de Famalicão, Portugal, in April 1960. He received the Ph.D. degree in Electrical Engineering from the University of Aveiro, Portugal, in 2003. He is currently an Assistant Professor at the Department of Electronics, Telecommunications and Informatics of the University of Aveiro and a researcher at the Intelligent Robotics and Systems group (IRIS Lab) of the Instituto de Engenharia Electrónica e Informática de Aveiro. The main focus of his research is robotics at the architectural and software levels, with emphasis on simulation, navigation, localization, mapping, and machine learning. Nuno Lau is Assistant Professor at Aveiro University, Portugal and Researcher at the Institute of Electronics and Informatics Engineering of Aveiro (IEETA), where he leads the Intelligent Robotics and Systems group (IRIS). He got is Electrical Engineering Degree from Oporto University in 1993, a DEA degree in Biomedical Engineering from Claude Bernard University, France, in 1994 and the Ph.D. from Aveiro University in 2003. His research interests are focused on Intelligent Robotics, Artificial Intelligence, Multi-Agent Systems and Simulation. Nuno Lau participated in more than 15 international and national research projects, having the tasks of general or local coordinator in about half of them. Nuno Lau won more than 50 scientific awards in robotic competitions, conferences (best papers) and education. He has lectured courses at Phd and MSc levels on Intelligent Robotics, Distributed Artificial Intelligence, Computer Architecture, Programming, etc. Nuno Lau is the author of more than 150 publications in international conferences and journals. He was President of the Portuguese Robotics Society from 2015 to 2017, and is currently the Vice-President of this Society. Prof. Dr. José Luís Azevedo is currently Assistant Professor at the Department of Electronics, Telecommunications and Informatics of the University of Aveiro and a researcher at the Intelligent Robotics and Systems group (IRIS Lab) of the Institute of Electronics and Informatics Engineering of Aveiro (IEETA). He received the Ph.D. degree in Electrical Engineering from the University of Aveiro, Portugal, in 1998. His current research interests are in the area of cooperative autonomous mobile robotics. Prof. Dr. Bernardo Cunha was born in 1959 in Porto, Portugal. He earned his doctoral degree in electrical engineering at the University of Aveiro, Portugal, in 1999. He is a full time teacher at Universidade de Aveiro in the computer architecture area and an investigator at the Instituto de Engenharia Electrónica e Informática de Aveiro. Current research interests are centered in the area of cooperative autonomous mobile robotics. Simone Badini is a Mechanical Designer in the Research and Development department of IMA Spa since 2013. IMA Spa is a world leader company in the design and manufacture of automatic machines for the processing and packaging of pharmaceuticals, cosmetics, food, tea and coffee and tobacco. He got is M.Sc. degree in Mechanical Engineering from University of Bologna, Italy in 2012. He is currently project manager for the integration of cobot and autonomous mobile robot in the production lines for the IMA group. item S0921-8890(17)30794-7 S0921889017307947 10.1016/j.robot.2019.06.006 271599 2020-01-13T11:13:04.440713Z 2019-10-01 2019-10-31 true 3280747 MAIN 14 53587 849 656 IMAGE-WEB-PDF 1 gr11 88037 82 219 gr6 76125 134 219 gr10 99763 151 219 gr1 84425 55 219 gr12 78236 62 219 pic3 95379 163 140 gr13 84239 60 219 gr17 92453 164 193 gr2 91612 129 219 gr19 18466 78 219 fx1002 5080 40 219 gr9 80285 162 219 pic5 90620 164 140 pic8 92385 164 140 gr4 86357 129 219 gr7 83216 163 155 gr8 78279 144 219 pic4 91410 163 140 gr5 84112 164 138 gr3 101514 163 219 gr18 77492 164 204 pic1 90433 163 140 gr16 82949 47 219 fx1001 5682 68 219 gr14 84362 115 219 gr20 34694 98 219 pic2 92082 164 140 pic6 88104 163 140 gr21 22647 162 219 gr15 93327 108 219 pic7 96532 163 140 gr11 115147 142 378 gr6 102249 210 342 gr10 127663 261 378 gr1 119793 128 506 gr12 100014 106 376 pic3 101319 132 113 gr13 105403 103 376 gr17 149053 321 378 gr2 129409 223 378 gr19 42698 110 309 fx1002 27829 150 816 gr9 109290 277 375 pic5 98434 132 113 pic8 101766 132 113 gr4 113348 190 323 gr7 120919 318 302 gr8 117887 327 496 pic4 97712 132 113 gr5 117350 225 189 gr3 125523 242 325 gr18 101664 243 302 pic1 99455 132 113 gr16 120354 112 525 fx1001 36645 252 816 gr14 114768 194 370 gr20 52488 146 325 pic2 99552 131 112 pic6 98208 132 113 gr21 59417 279 378 gr15 119748 187 378 pic7 107374 132 113 gr11 364806 629 1674 gr6 175979 929 1514 gr10 495261 1154 1674 gr1 351578 568 2243 gr12 185445 470 1668 pic3 169551 583 500 gr13 214287 455 1666 gr17 622945 1422 1674 gr2 342433 988 1675 gr19 90504 487 1369 fx1002 103050 398 2169 gr9 245828 1230 1663 pic5 158735 584 500 pic8 168594 584 500 gr4 258891 842 1433 gr7 296978 1410 1339 gr8 281811 1449 2197 pic4 140145 583 500 gr5 232097 999 840 gr3 443350 1074 1440 gr18 160189 1077 1340 pic1 155377 583 500 gr16 409379 497 2326 fx1001 144071 670 2169 gr14 245424 859 1639 gr20 178264 647 1440 pic2 165958 583 499 pic6 138608 583 500 gr21 195782 1237 1675 gr15 306022 828 1676 pic7 174577 583 500 si27 26913 si33 1898 si34 1618 si31 7355 si3 2005 si14 1133 si6 2114 si38 3009 si21 1832 si37 4191 si18 3593 si36 1780 si16 8122 si2 1418 si8 1661 si1 1607 si9 4591 si26 2321 si19 1613 si32 6363 am 19107071 ROBOT 3227 103227 S0921-8890(17)30794-7 10.1016/j.robot.2019.06.006 Fig. 1 Human operators in a packaging industry. Fig. 2 KUKA KMR mobile manipulator. Fig. 3 Initial setup of the table for task 2. Fig. 4 Showcase environment in the gazebo simulator. Fig. 5 EuRoC software framework for C2 [23]. Fig. 6 Use case diagram of skill-based anytime agent architecture (SAAA). Fig. 7 A higher level overview of SAAA. Fig. 8 Sequence diagram of SAAA. Fig. 9 A skill-based architecture for safe human–robot collaboration. Fig. 10 Example of detection of two SLCs on a shelf. The top image is what is perceived by our detection system (plus depth). The bottom image contains a superimposed 3D model of the SLC for each detection, including the center of the SLC (red dot) and a possible pick point (green dot) . (For interpretation of the references to color in this figure legend, the reader is referred to the web version of this article.) Fig. 11 Example of nut and bolt detection. The top image contains the detection of a nut and the bottom image contains the detection of a bolt. The same detection algorithm is used for nuts and bolts. Fig. 12 Washer detection in the fixture. The top image is what is acquired by the camera. The bottom image is the result of the segmentation by intensity. Fig. 13 Snapshots of bent blank piles. Fig. 14 Gripper and blank magazine in simulator. Fig. 15 Grpeer and blank magazine in the realistic environment. Fig. 16 Two pallets and blank piles and their detection results. The red lines in center and right images indicate the pose of pallets, while the green circles indicate the positions of blank piles. Fig. 17 A sequential result of the pose estimation of a blank pile. Fig. 18 Drawing pin filter to detect outlines. Fig. 19 A task plan for 9 blank piles on two pallets. Fig. 20 Human tracking and HRI during the EuRoC evaluation. Fig. 21 Interaction tree for the showcase task. Table 1 Benckmark task 1. Team Metric 1 Metric 2 Bonus Time AutoMAP 5 5 6.22 4:56 MTC-LU-UoB-Airbus 5 4 0 18:13 RSAII 5 5 3.32 9:14 NimbRo Logistics 5 5 3.45 8:54 TIMAIRIS 5 5 10 3:04 Table 2 Benckmark task 2. Team Metric 1 Metric 2 Bonus Time AutoMAP 5 5 4.16 15.01 MTC-LU-UoB-Airbus 0 1 0 8:54 RSAII 5 5 3.78 16:31 NimbRo Logistics 4 4 0 41:27 TIMAIRIS 5 5 10 6:15 Table 3 Quantifiable evaluation. Objectives Metrics Targets Events Percent (%) O1 O1M1 6+5+3 6+5+3 100 O1 O1M2 6 6 100 O1 O1M3 5 5 100 O1 O1M4 2 2 100 O2 O2M1 6 6 100 O2 O2M2 6 6 100 O2 O2M3 6 6 100 O2 O2M4 2 2 100 O3 O3M1 3 3 100 O3 O3M2 12 12 100 O4 O4M1 4 4 100 O4 O4M2 2 2 100 Skill-based anytime agent architecture for European Robotics Challenges in realistic environments: EuRoC Challenge 2, Stage II — realistic labs Gi Hyun Lim a 1 Eurico Pedrosa a 1 Filipe Amaral a Artur Pereira a ⁎ Nuno Lau a ⁎ José Luís Azevedo a Bernardo Cunha a Simone Badini b a IEETA, Universidade de Aveiro, Aveiro, Portugal IEETA, Universidade de Aveiro Aveiro Portugal IEETA,Universidade de Aveiro, Aveiro, Portugal b IMA, Via Emilia 428-442, 40064 Ozzano dell’Emilia, Italy IMA Via Emilia 428-442 Ozzano dell’Emilia 40064 Italy IMA,Via Emilia 428-442, 40064 Ozzano dellEmilia, Italy ⁎ Corresponding authors. 1 These authors contributed equally to this work. As demands on pragmatic solutions of robotics technology increase in the manufacturing industry, deep affinities between research experts and industry users are required. The European Robotics Challenges (EuRoC) research project has proposed a scientific competition and matched up research labs with industrial end users to establish challenger teams to develop and test solutions that will be applied in the real context of the industrial end-users. The paper reports the result of TIMAIRIS who is one of 6 challenger teams to advance to the final stage out of 103 teams and technical details used in the Challenge 2 - Shop Floor Logistics and Manipulation. To address the requirements and achieve the objectives of the challenge, a skill-based anytime agent architecture has been developed and extended to make the team focus on the challenging research that addresses real issues in the user environments. Finally, shop floor logistics and manipulation scenarios have been developed and demonstrated in a realistic environment for autonomous packaging. Keywords Skill-based Anytime agent architecture Mobile manipulation Autonomous packaging European robotics challenges (EuRoC) 1 Introduction 1.1 Motivation Several robotics challenges and competitions have been launched for the exchange of research results and for comparative evaluations including manipulation, such as the DARPA Robotics Challenge [1], the RoboCup leagues [2] and the European Robotics challenges (EuRoC) project [3], since neither resources such as robots’ platforms, source codes and datasets are available to the public nor are simulators sufficiently mature to present real environments. To obtain a good result in a robotics challenge or competition, challengers need to develop a robotic system that completes given challenge tasks within a limited time. EuRoC is a research project where a robotic competition is conducted with the aim to develop and present solutions to the European manufacturing industry [3]. The EuRoC consortium has launched three industry-relevant challenges: C1 - Reconfigurable Interactive Manufacturing Cell, C2 - Shop Floor Logistics and Manipulation, and C3 - Plant Servicing and Inspection. In particular, the Challenge 2 (C2) addresses the SRA2009 [4] scenarios: Logistics and Robotic Co-Workers. Mobile manipulators are provided by the EuRoC host as a suggested solution to utilize as logistic carriers and dexterous manipulators. Each challenge team should consist of both a research group and an industry partner to show the use case in a realistic environment. Our work is being developed within the Challenge 2 context. The Challenge 2 host especially set the working time regulations to share the resources among all challenger teams and to make sure that they have the same amount of effective lab time in the realistic environment where the challengers access robotics platforms and benchmark infrastructures. As the use case scenario of TIMAIRIS, which is a collaborative challenge team between the Intelligent Robotics and Intelligent Systems (IRIS) research group from the University of Aveiro (UAVR) in Portugal and IMA S.p.A industry from Italy, an autonomous blank feeding task is investigated because it is not easily solved by a robot. Proof of such assumption is that the industrial state-of-the-art solution for this problem is to use human operators to perform it, as shown in Fig. 1. This is a tedious, repetitive and tiring task and human operators may occasionally refrain from collecting blank piles from more distance pallets. This paper presents a skill-based anytime agent architecture (SAAA) and the result of TIMAIRIS team in the second stage of C2. TIMAIRIS is one of 6 challenger teams advancing to the final stage out of 103 teams in the simulation contest, The second stage consists of three phases to be performed in a real environment: Benchmarking, Freestyle and Showcase. In the realistic labs of the EuRoC challenge tasks, the main constraint is time, not only the running time (online efficiency) in an evaluation matrix but also development time (offline efficiency) to complete the tasks in a limited time. Each challenger team is allowed to take a limited fixed time to access an experimental environment in which EuRoC hosts offer support and the mandatory robot platform is available. Especially, for the three phases of the stage II, each team has evenly-distributed eleven weeks (54 working days) to exclusively access the environment. Challenger teams are required to find efficient and robust skills and complete evaluations in the given time. SAAA provides opportunities to increase efficiency not only in autonomous execution for shop floor logistics and manipulation but also in its use of development during the challenge competition. 1.2 Related work To meet the requirements and constraints on a robotic challenge, challenger teams need an adaptive, flexible, robust and efficient robotics architecture [5,6]. Several reactive architectures are proposed to find a solution that makes a robot complete tasks on-time. By managing mission time, Zadeh et al. [7] developed an autonomous reactive architecture of unmanned vehicles in realistic ocean environment. Synchronization between high level mission and low level path planning is configured to control mission time and to guarantee termination of the mission with the best sequence of tasks fitted to available time. Baklouti et al. [8] proposed a reactive control architecture for wheelchair robot navigation without human intervention and prior knowledge of the world. Nilsson and Johansson [9] introduced a layered Open Robot Control (ORC) architecture to meet industrial demands such as computing efficiency and simple factory-floor operation with integration of online and offline robot programming. Offline programming typically done by robot programmers requires abstract modeling, whereas online programming typically done by production engineers or robot operators utilizes physical robots in real environments. Recently several trial and error methods are proposed to adapt for use by damaged robots [5,10]. Those focus on the online time challenge by reducing the number of trials to recover from damage to complete tasks. Cully et al. [5] introduced an intelligent trial and error algorithm which enables a robot to discover a compensatory behavior from damage without requiring pre-programmed contingency plans. The algorithm conducts experiments based on high-performing policies for the intact robot work on the damaged robot. While traditional reinforcement learning (RC) methods for robots need to reset their learning environments and robots to an initial state, Chatzilygeroudis et al. [10] proposed a reset-free trial-and-error learning for robot damage recovery. Insaurralde and Petillot [11] proposed a capability-oriented robot architecture that enables multiple unmanned vehicles to collaborate to autonomously carry out underwater intervention missions in a fault-tolerant manner. On the other hand, anytime approaches use iterative improvement techniques in problem solving, planning, scheduling [12] and learning [13]. Those address the online time challenge by returning results at any time. To adapt to realistic industrial environments, this paper proposes a skill-based anytime agent architecture (SAAA) by integrating previous work [14–17]. The architecture consists of a solver, modular skills and task representations. The separation of task s that organize orders of objects to assemble into graphs from an agent processing algorithm [18,19] allows a robot to start at any task state. It is not necessary to reset the robot and its environment to run from an initial state. During development, a robotics challenger team needs to repeat a subtask or to execute a skill from a specific state to refine the subtask or the skill until the time of evaluation. On the other hand a human co-worker will continue or restart a task after a task failure or a task completion at the runtime. To the best of our knowledge, robotic system architectures and anytime algorithms consider only online efficiency while the proposed architecture also takes offline efficiency into account. 2 European robotics challenges (EuRoC) Many robotic challenges have been so far launched to find competitive solutions for their applications [20]. The DARPA Grand Challenge [21] and its successive events, DARPA Urban Challenge [22] and DARPA Robotics Challenge [1], have drawn worldwide attention as robotic competitions for autonomous ground vehicles on an off-road course, for autonomous operation in a urban environment and for autonomous emergency maintenance robots, respectively. The main objective of the DARPA challenges is bridging the gap between fundamental discoveries of academia and military use. Since 1997, RoboCup [2] has been held annually to foster AI and intelligent robotics research. Initially the target of competition was a world cup with real robots, nowadays there are also other leagues such as RoboCup Industrial, RoboCup Rescue and RoboCup@Home. Especially, the RoboCup Industrial league defines two tasks: logistics and manipulation; but robots in this league have size constraints. To match the Strategic Research Agenda (SRA) for robotics [4], the EuRoC project was launched in 2014. It aims at exploiting synergies among all the actors of robotics and manufacturing to accelerate the transference of state-of-the-art technologies from academia to industry. After qualification, the members of each team are required to organize from both communities. The main motivation of the European Robotics Challenges (EuRoC) is to make use of robotics products and services by strengthening collaboration between the industrial and the research community [3]. The EuRoC is a research project based on robotics competitions that drives innovation in robotics and manufacturing through a number of application experiments. The Challenge Advisory Board of EuRoC is in charge of the evaluation of the competition project empowered on robotic platforms and benchmark infrastructures to get rid of contestants’ burden on platform-related low-level problems and maintenance. As a realization in this context, the EuRoC initiative has launched and run three challenges in parallel with different motivations and objectives. The Shop Floor Logistics and Manipulation or Challenge 2 (C2) covers application scenarios about robotic co-workers and logistics robots in industrial, professional service and domestic service sectors, which is matched to the Strategic Research Agenda (SRA) for robotics in Europe [4]. In the co-worker scenario, a robot becomes an assistant or collaborator that works literally hand-in-hand with its human counterparts in unstructured environments. Here, the robot needs to communicate with a human to take an order, to ask confirmation, and to reply to a question. Each EuRoC challenge is structured in three successive stages, over the period of 4 years: Stage I QUALIFYING: Simulation Contest, Stage II REALISTIC LABS: Benchmarking, Freestyle and Showcase and Stage III FIELD TESTS: Pilot Experiments. 2.1 Challenge 2: shop floor logistics and manipulation The Shop Floor Logistics and Manipulation challenge or Challenge 2 of EuRoC project consists of a assembly of tasks designed to be solved by a mobile robotic platform operating in industrial environment. This challenge is divided in three main stages where three different scenarios were designed and considered. Stages I and II were already completed and the Stage III will be done at the end of the EuRoC project. Briefly, the first stage was based on a stationary platform and the achieved solutions were integrated in a simulation environment. The Stage II consists in a scenario where a real Light-Weight-Robot (LBR iiwa) equipped with a two-finger jaw-gripper mounted on a mobile base (KUKA omniRob) was controlled through an intranet-based framework (similar to the one that was used in Stage I), as shown in Fig. 2. The final stage, Stage III, will be an application of all the achieved solutions in a real scenario of industry with real work pieces provided by an end-user, showing the real capabilities of this innovative solution and the contribution to the manufacturing dynamics improvement. 2.1.1 Benchmarking For the Stage II in the Challenge 2, the EuRoC host has provided a benchmark environment at DLR in a realistic factory set-up with elements from real end users. It consists of two tasks in simplified manufacturing environment: logistics and assembly. The first task of the Benchmarking phase addresses production logistics. In this task, the mobile manipulator has to bring 5 Small Load Carriers (SLCs) which are distributed in the room to a fixed target area on a table. One SLC is placed on the goal table out of the target area, two are placed on another table and two are located in a shelf. The room has enough space for the robot to move between the tables and the shelf. The start position is in the middle of the room. The setup of the room will be static over the development and evaluation. The SLCs are filled with a various number of nuts and washers from the Benchmarking task 2. For each correctly delivered SLC (its footprint has to be inside the target area) one point is awarded (max 5 points). For each SLC, if all parts in it remain within it during the transport to the goal area, another point is awarded (max 5 points). If the task is completed successfully extra points could be awarded for the execution time. The amount of points is inversely related to the best teams time (max 10 points). The second task of Benchmarking is about mobile manipulation for basic pre-assembly of products. In this task, the robot has to assemble five bolts. The layout of the room and the start position of the robot are the same as in the previous benchmark task. The assembly table is identified as “Pickup table”. On that table, there are 5 nuts, 5 bolts and 5 washers within a fixed area. Next to the parts are two fixtures attached to the table. One of the fixtures holds the washers and the other has a gap with the bolt’s head shape to allow the nut to be screwed. The parts are arranged to minimize occlusions (see Fig. 3). The bolts are upright, the nuts are flat and the washers are placed in the fixture to give a good orientation for grasping. The translation between the different parts may vary. The nuts and bolts are touching a virtual line parallel to the fixtures 10 cm and 20 cm behind, respectively. For each nut correctly screwed, one point is awarded (max 5 points). Applying a washer onto the bolt before screwing a nut gives another point (max 5 points). As in the previous task, if the task is completed successfully extra points are awarded for the execution time. Again, the amount of points is inversely related to the best teams time (max 10 points). 2.1.2 Showcase: autonomous packaging As the third and final challenge of the Stage II, the showcase runs in an simplified environment that, although not located in an industrial plant, includes the most important elements of the real environment where the task will be executed as a final product, as shown in Fig. 4. It uses real pallets with real piles of blanks and a prototype of the blank feeding mechanism of a packaging machine that includes all relevant features for the task to be performed. In this task the following issues are going to be covered: the platform will be able to recognize empty pallets, plan and replan its actions; an initial version of the multimodal interface will be used, integrating the possibility of gesture commands in the interaction with the platform (gestures will be used mostly for safe navigation); the robot will be able to navigate in an environment that includes a few humans and interact with them; the manipulation of the selected type of blanks will be demonstrated. To solve the blank feeding task using a mobile robot, several technical issues are identified. • Manipulation of stacked objects: The blank pile is not a unique rigid solid object. Not only it can bend under its own weight, but blanks can also easily break free from the pile due to the fact that a considerable amount of low friction blanks are stacked on top of each other. • Single arm manipulation: The manipulation of a blank pile is performed using a single arm with a gripper. In order not to miss any blanks out of a stack on a pallet, picking up the blank pile requires several manipulation steps and a specialized gripper. • Smooth placing of the blank pile: Blank piles have to be placed in the feeding mechanism avoiding hard collisions with the blanks that are already there and with the four blank guiding rods that prevent blanks from slipping out of the inclined magazine surface. • Shared workspace with humans: The robot has to be able to navigate in an environment that is shared with humans. This introduces safety concerns but, at the same time, it also rises the opportunity to take advantage of the human–robot proximity to explore human–robot interactions (HRI) to control the robot [16]. • Robust detection of blanks: Blanks are provided in untied piles, piled up on pallets close to each other, which can cause erroneous detection. • Handling global localization errors: The feeding of the blank magazine is an example of a manipulation action that requires a high level of precision for a proper feeding while preventing collisions between the blank magazine and the manipulator. 2.2 EuRoC platform As an objective of the EuRoC, robotics platforms and benchmark infrastructures have been developed to make challengers focus on the challenging research without efforts on platform-related low-level problems and maintenance. Especially for C2, two mobile manipulators are suggested to address logistics and robotic co-workers scenarios, as shown in Fig. 2. EuRoC hosts and robot manufacturers also provide programming and simulation frameworks, and open interfaces on lowest levels. Available EuRoC SW tools 2 2 are also provided for use in the EuRoC. Fig. 5 shows the EuRoC software framework for C2. Challengers are required to develop high-level software components with the similar functionalities but different scenarios to test and validate in meaningful contexts typically for shop floor logistics and manipulation in C2. 2.3 TIMAIRIS software architecture TIMAIRIS software is composed of three main components: a skill-based agent architecture (SAAA) [15], a human tracker and safety manager subsystem [17] and a realistic simulator [14]. TIMAIRIS software uses a skill-based anytime agent architecture [15] that has been evolving from the one used for Stage I simulation tasks [14]. The separation of task-dependent representations and a generic agent processing algorithm allow the robot to start at any task state. Human collaborators or robot operators need to repeat a task after recovering from failure or to test the skill from a given starting point. Having the same architecture performing successfully for such a different set of tasks demonstrates that this team solution is remarkably flexible and well adapted for EuRoC C2 platform and its capabilities. Ensuring safety, industrial robots need to share an environment with humans and to work hand in hand. To realize safe human–robot collaboration, a human tracker and safety manager subsystem has been integrated into the SAAA [17]. The human tracker keeps on tracking humans in a workspace. The safety manager infers whether it is in a safe state or not based on system states and human tracking information. Then, human–robot interaction module takes an order from the operator to resume or stop the paused task using gestures [16,24]. A realistic simulator has been developed for the Challenge 2 (see Fig. 4), using, as starting point, the Stage II simulator provided by the EuRoC host. The simulator allows the execution of the complete Challenge 2 tasks and was an essential tool in the development of TIMAIRIS’ Challenge 2 software. 3 Agent architecture 3.1 Skill-based anytime agent architecture To address the requirements and achieve the objectives of C2, a skill-based anytime agent architecture (SAAA) has been developed to solve the logistics and manipulation tasks [15]. This paper extends the previous architecture in the way that a plan manages more than one object and a robot explores workspace that cannot be covered by its cameras without moving the platform. In particular, the new architecture has been used to solve the Production Logistics and Product Assembly tasks previously described. These tasks have four objectives: perception, manipulation, planning and human robot interaction. Fig. 6 shows the use case diagram of SAAA at development time and/or runtime for human–robot collaboration. A robot and two types of humans are involved in the use case: a developer and a co-worker in a scenario for autonomous packaging. A robot developer sets a robot state to refine a skill which is executed at the state. It is possible that the developer repeat to execute the skill to improve performance and reduce runtime without reseting the robot and its environment. For example, a placing skill will be executed after picking and transport skills in pick-and-place tasks. To refine the placing skill, it is not efficient to run whole pick-and-place task by reseting to an initial state. A human co-worker may provide a command to start and stop a task or to change a sequence of objects to be delivered. A mobile manipulator (see Fig. 2) sequentially executes skills to complete the Production Logistics and Product Assembly task. In a higher level view of the skill-based framework, as shown in Fig. 7, the functional components are represented by boxes. A Perception module collects sensory data and processes them to extract information used by high-level modules. A Skill is the capacity of doing a particular task, such as, picking and placing an object or moving the end-effector of the manipulator to a desired pose. Perception modules and Skills collect and transmit sensory-motor data via Sensor interface and Effector interface, respectively. The Action Planner provides a plan for the target object. A plan contains a sequence of skills and their corresponding objects. The Solver is responsible for taking decisions on how to solve the current task based on the current sensory data and available Skills. To solve these tasks, an agent is required to perceive the environment through sensors and act upon that environment using actuators [25]. A skill-based agent architecture is implemented to develop a generic solution capable of handling shop floor logistics and assembly tasks by analyzing the properties of the environment. Henceforth, the proposed method has been utilized for several packing scenarios by increasing the realization during the EuRoC challenges [16,17,24,26,27]. Fig. 8 shows the sequence diagram of SAAA for autonomous packaging. To complete a task, a robot developer can set the state of a robot to start a new task from the initial state or to repeat the previous skill to continue the previously uncompleted task. When the robot start a task, the Solver [15] reads the Order graph [14] of the task and also tries to get a command from Interaction which is a module that tracks humans [17] and gets a command from a co-worker via gesture recognition [16]. The Solver requests a plan from Planner with the states of the robot and its environment, and executes a sequence of skills by following the plan. It continues until completing the task or terminated by the robot developer. when the robot stops, the developer repeats to set the state and to start the robot. The proposed algorithm is summarized in 1. In each task, the set O of objects to be manipulated, including their properties and place zones, is known in advance. The algorithm starts by building an Order Graph which represents the order of objects. The order is restricted by a direct acyclic graph (DAG), which represents a dependency graph between objects in terms of order of manipulation [14]. Leafs represent objects that need to be handled first. The dummy object λ is added to represent the graph root. To ensure that all object are eventually detected [28], a set of search poses S is estimated by the procedure buildSearchSpace with the insurances that all combined poses cover the whole working space. The set S is encoded as a circular list so that the search for poses never ends. Additionally, to improve the search [29], the vision system on the pan tilt unit is used to detect objects in the environment and the obtained poses are put in the head of S in the order defined by G . It may not detect any object, but, if it does, the system can gain in execution times due to good initial search poses. The algorithm then executes nested loops that, making the robot move around the search poses, finishing when only the root node ( λ ) remains in the Order Graph. Each search pose is explored to see if a leaf object is there. A plan is a tuple [19] consisting of a sequence of skills and their corresponding objects that allows to properly pick objects, move the end-effector of the manipulator and place the objects in the target position [30]. Those skills depend on a priori calculation of the pick and place pose. The specific plan depends on the task being solved. The Action Planner can estimate the state of task based on the input object. The plan could be related with several objects. For instance, in the assembly process several parts are added in sequence until the final assembly is produced. If the execution of the skill succeeds, the leaf corresponding to the processed object is removed from the graph. Because Order Graph and plan are separated from the agent processing algorithm, only three procedures are task dependent, buildOrderGraph, buildSearchSpace and makePlan. This formulation has two significant advantages. First, the agent can start execution at any task state, even if the agent meets a failure while execution, as it can continue the task after recovering from the failure. Second, to solve a task the developer only has to focus on the creation of a plan supported by a set of available skills. 3.2 Resource management scheme Fig. 9 shows an extension of the skill-based architecture for safe human–robot collaboration. The Human tracker keeps on tracking humans in the workspace by using laser scanners. The Human–Robot Interaction (HRI) module communicates with a human by recognizing gestures [24] and by providing information via multi-modal interfaces [16]. The Safety manager infers whether it is in a safe state or not based on system states and human tracking information. When the Safety manager decides to pause an executing task, it requests Solver to gaze at the nearest human operator, and to trigger HRI to interact with him. Then, HRI takes an order from the operator to resume or stop the paused task using gestures. To continuously monitor humans, the Human tracker and Safety manager need to be continuously active, while all other modules including skills and perceptions modules just run on request. That should cause conflicts over resources. For example, when the robot wants to recognize the pose of a blank magazine to feed a blank pile, a perception module tries to rotate the pan–tilt camera system to the blank magazine on the table. If, at the moment, a human operator approaches, the Safety manager also tries to rotate the same camera system to gaze the operator. Based on the skill-based agent architecture [14,15], a resource management scheme is added to the system architecture, as shown in Algorithm 2. When a robot starts, each module which needs to run continuously is launched and becomes a daemon. The Solver builds a resource map which lists all necessary resources for each daemon module. At every spin, which means a wake-up for all subscriptions, services, timers and so on in ROS (Robot Operating System), 3 3 the daemon checks the availability of its resources. If available, it runs normal procedures and release all resources at the end of the procedures. 4 Solving benchmarking tasks The objective of our team is to solve the tasks proposed for the EuRoC Benchmarking phase with high precision, accuracy and robustness, as fast as possible. Time is a key factor in solving the tasks at hand: not only it is an evaluation metric, but, for industrial applications, it a matter of productivity by reducing the time for development. In this section, we present our approach to solve two tasks of the Benchmarking phase -Production Logistics and Product Assembly- using the presented architecture. 4.1 Task 1: production logistics The goal of this task is to find all SLCs present in the room such as tables, shelves and workbenchs and place them in the designated target area in a workbench. Their approximate locations are known, on top of two tables and in a shelf, but their exact positions on those locations are unknown. To solve this task we start by designating several search poses that guarantees that eventually all SLCs are detected with the stereo camera mounted in the pan and tilt unit. Once an SLC is in sight, its pose should be detected, in order to pick it up. Then the SLC is placed somewhere else, in an intermediate or target area. This last step has several variations that affect the overall execution time because of the locations of SLCs. 4.1.1 SLC detection The detection of SLCs has two stages: first, color segmentation is used to define candidate regions in the image, that may contain at least an SLC; second, a 3D point cloud for each region is generated and matched against 3D template of an SLC to find its position and orientation, i.e. its pose. Color segmentation, in the HSV color space, is initially used to detect an SLC due to the SLC’s color homogeneity and good contrast with the environment. The output of the color segmentation is then used to generates blobs that represent SLC candidates. The resulting blobs must have a minimum size to be valid. The overlapping of SLCs in the image may generate a single blob for multiple SLCs, but that is not a concern as the disambiguation is deferred to the next stage. Once color segmentation is completed, the resulting blobs are used as masks to generate a point cloud for each candidate. While 3D point cloud generation and matching processes are heavy, the color segmentation is not. Thus, the SLC detection is time-optimized by reducing many candidates from the color segmentation. Let P be a point cloud and { p i } the set of points of P . The calculation of SLC’s pose relies on the processing of the point cloud P . To reduce the computational complexity of processing a point cloud with a high number of points, P is decimated by applying a voxelization filter. Then, to remove possible outliers in the point cloud a statistical outlier removal [31] is used. To address the possibility of SLCs overlap, the point cloud is divided into clusters using a euclidean cluster extractor [32], the cluster with the highest number of points being assigned to P and the remaining points being discarded – thanks to our agent architecture, discarded SLCs will be detected in the next cycle. The position of the SLC is approximately calculated from the centroid c of P , given by c = 1 n ∑ i = 1 n p i , while its orientation is initially provided by the Principal Component Analysis (PCA) of the projection of P in the X O Y plane [33]. However, this approach is not enough, as the view of the SLC may provide a partial point cloud that skews the centroid from the real center, and the orientation of the PCA has an ambiguity of π radians. The final pose of the SLC is calculated by matching P against a 3D template of the SLC that has its centroid in the origin and its bearing defined by the X axis. Before matching the point cloud, P is transformed to its origin, i.e. the inverse pose of P is applied to itself, then, the transformation that results from the matching between the template and P is the correction of the initial pose calculation. Note that because the orientation given by PCA is ambiguous, we do the matching with the initial orientation and with another rotated by π radians. To correct the pose, we use the matching transformation that provided the best matching. The algorithm used for matching is the adaptation of the scan matching algorithm proposed by Pedrosa et al. [34] to three dimensions. An example of SLC detection is shown in Fig. 10. 4.1.2 Manipulation and planning strategy To solve this task three manipulation skills were used. The pick_object and place_object are based on the skills trained in a simulation environment [14] with some minors adaptations. The pick_object_shelf skill is also derived from the pick_object skill but taking in account the space between the shelves of the shelf. So in this skill instead of approaching the object using a vertical movement it is approached at an angle of 45 degrees. This allows the arm to reach the objects on the shelf without hitting the upper level of the self. Our initial approach was to pick an SLC, hold it and deliver it to the goal area. With this approach the robot has to move across the room 4 times, 2 for the SLCs on the pickup table and 2 for the SLCs in the shelf. It takes around 15 min to complete the job, being most of this time spent on navigation between the goal table and the pickup table and shelf. In order to optimize this process a second approach was developed. Because a considerable amount of time was being spent on navigation, we manage to transport the SLCs on top of the robot platform. This way, navigation was reduced to one trip to each side: first, the two SLCs in the table are picked up and placed in the top of the robot; then, the robot moves to the shelf, pick up another SLC and also put it in its top surface; finally, the fourth SLC is picked up and held in the gripper, while the robot navigates to the target table. On the target table, the four SLCs are put in the target area, after which the fifth SLC, the one in the target table, is detected, picked and placed. With this improvement the time dropped to around 10 min. After this pick and place strategy was implemented, some improvements were accomplished, by parallelizing some steps. For example, after picking an SLC, while placing it on the top of the robot, movement to the next observation and picking position can be performed. Task time was now reduced to around 8 min. A significant amount of time was still being spent in picking the SLCs from the top of the robot and placing them on the goal area (3 SLCs from the top of the robot plus the fourth that was transported on the gripper). So our final solution was to rearrange the SLCs on top of the robot so that the manipulator can pick two at the same time. This way one of the picking from the robot’s body was eliminated. Also, by placing the fourth SLC on top of the robot aligned with the third and by picking both at once, the number of places in the target area was reduced to 3 – 2 places holding two SLCs and one holding only one SLC. The 4th SLC is placed on top of the robot while it is navigating to the target table. Also, during navigation the arm could pick the 3rd and 4th SLCs so that when the robot reaches the target table the SLCs are already grasped. These improvements dropped the time to 5 min. Furthermore, speed increasing was previously prepared through parameters in a configuration file. During the evaluation, 6 out of 7 attempts were successful and with decreasing times, which lead to the final task time of 3 min and 4 s just by increasing the speed of the movements. 4 4 4.2 Task 2: product assembly The goal of this task is to pre-assemble a set of bolts, nuts and washers using a single manipulator. Since the single arm manipulation is not able to assemble two parts, two fixtures are provided to help in the assembly: one contains the washers in an approximate upright position to facilitate picking; the other has a well with the shape of the bolt head shallow enough to hold the bolt in place when a torque is applied, i.e. it secures the bolt when screwing the nut. The specifications of the task includes the approximate locations of the assembly pieces and fixtures, but not their exact positions. To solve the task we start by defining an observation point for the camera that is mounted in the arm, that provides a complete view of all necessary elements for the task and allows the manipulation of all parts without changing the position of the platform. This is important as, if the platform does not move, the relative positions of all objects are maintained with high precision after the first detection (see Fig. 3). The robot has to detect the bolt, pick it and place it in the bolt fixture, then it has to detect the washer, pick it and place it in the bolt, and finally it has to detect a nut, pick it and screw it in the bolt. Positions are calculated using the pinhole model instead of the point cloud provided by the stereo rig. this strategy can be pursued because the dimensions of all elements in the task and a precise distance from the camera to the working table, that is inferred from the pose of the arm are known in advance. This is done to speed up detection, because the generation of depth information is computationally expensive. 4.2.1 Fixture detection The detection of the fixtures, although executed only once, is an important step. The robot does not start from the working area but has to navigate there. Thus, location errors are inevitable. The assembly area is well defined, therefore, the fixtures are used as reference points to the rest of the elements. The detection of the fixtures is done using HSV color segmentation. We start by detecting both fixtures from the observation point. Once the resulting blobs are obtained, for each blob the rotated rectangle that best encloses it is calculated. The detection from the observation point is not very precise, therefore using the information from the rotated rectangle, the camera is approximated to each fixture and the detection is repeated individually. The information about the fixture that contains the washers is used in the detection of the washers, as their relative position to the fixture is known and so the search space in the image can be reduced. The center of the rotated rectangle that derives from the bolt’s fixture coincides with screwing place. 4.2.2 Bolt, nut and washer detection The detection algorithm for the bolts and nuts is the same. We explore their shape similarity when viewed from the top, i.e. when the object is located at the image center. The detection of a bolt/nut starts by performing color segmentation, then blobs are created from the resulting segmentation. Only the blob closer to the image center and in the vicinity of the bolts virtual line is considered, the rest being discarded. We perform a shape analysis to find the vertices of its convex shape and to find afterwards two consecutive edges that resemble the bolt/nut hexagonal top in length and angle (Fig. 11). Those edges are then used to calculate the center of the bolt/nut, and its orientation. The orientation is required for the nut so that it can be picked up by its edges. The described approach assumes that the object to be detected is as much as possible in the center of the image. This is achieved by generating a hint list for bolts and nuts that gives a rough approximation of their positions. The list is populated by running the color segmentation once for the bolts and nuts from the observation position. The resulting blobs are then used as hints. When it is time to detect a bolt/nut the hint is used to approximate the camera to the object in focus. The detection of the washers uses a different strategy. Instead of color segmentation, we do an intensity filtering that keeps the pixels with higher intensity (Fig. 12). Then, from the resulting segmentation we extract several blobs validated by their size. The centers of these blobs are then used to calculate the positions of the washers. 4.3 Manipulation and planning strategy To place the bolt in the screwing fixture, the place_bolt skill takes advantage of the compliant movement of the arm. To insert the bolt head into the fixture, after aligning the bolt with the center of the fixture, the bolt is pushed against the fixture while rotating it. As soon as a drop in the bolt’s height is detected, the action finishes, as it means the bolt’s head entered the fixture. For the place_nut skill the strategy is similar. While using compliant movement of the arm, the robot starts rotating the nut while at the same time pushes it against the bolt tip. Based on how much the height of the nut dropped during the first rotation, the number of rotations is adjusted in order to be fully screwed on the bolt. In the pick_washer skill, since they are in an upright position slightly tilted, the gripper approaches the washers just like in a normal pick but with the fingers adjusted for the washer diameter. Then the gripper moves down slowly in order to push the adjacent washer and create space for the picking. Because they are tilted the robot pushes them in the opposite direction of the tilt in order to became upright and aligned with the fingers of the gripper. To place the washers on the bolt, the place_washer skill aligns the inner bottom edge of the washer with the top of the bolt, just touching it on the side. Then the washer is rotated by 60 degrees while pushing it against the bolt. This tilts the bolt a little bit making it push the washer to the correct position when it is released. The planning strategy for this task is straightforward. Not considering the perception parts, it corresponds to the following sequence of actions: first, a bolt is picked up and placed in the fixture; then, a washer is picked up and placed in the bolt; next, a nut is picked up and screwed in the bolt; finally, the assembly is picked up and placed in a target region. The same procedure applies to the other bolts, washers and nuts. The speed of the movements and the movements connecting the different skills were parameterized and optimized during evaluation, starting with safer speeds and proceeding to faster ones after the task had been completed with success. In 7 attempts to solve the task, only one of them failed to complete all the objectives. With this strategy the best achieved task time was 6 min and 15 s. 5 5 5 Solving showcase tasks 5.1 Manipulation of stacked non rigid objects Solving the showcase tasks introduced a number of technological issues. The blank pile is not a unique rigid solid object, as shown in Fig. 13. It is a stack of cardboards, that can bend under its own weight and can also be disrupted, since some blanks can break free from the pile, due to low friction between them. To prevent the breakdown of a pile, any manipulation procedure has to be aware of this fact. Blanks are provided in untied piles, piled up on pallets close to each other, which can cause erroneous detections. Blank piles have to be placed in a feeding mechanism avoiding hard collisions with blanks that can already be there and with the four blank guiding rods that prevent blanks from slipping out of the inclined magazine surface. This feeding task requires a high level of precision for a proper feeding, while preventing collisions between the blank magazine and the manipulator. The manipulation has to be performed using a single arm. Since the gripper provided by the host is not appropriate, a solution has to be revised, taking into account the aforementioned issues. Aside from the gripper design, a proper sequence of actions has to be planned to accomplish the showcase tasks. 5.2 Manipulator for packaging Regarding the gripper design, the TIMAIRIS team decided to used the gripper provided with the robotic arm and adapt it to the required manipulations. Two fingers were designed, able to grasp a pile of blanks with a maximum height of 80 mm. The closing force of 80N (or at least 50N) should be enough at least for manipulating the smaller piles. In order to grasp a pile, it should be partially dragged out of the table, as shown in Fig. 13. To do so, two thin shafts were attached to the fingers, as shown in Fig. 14(a) and Fig. 15(a). These thin shafts can slide along their own axes thanks to the presence of a spring, ensuring the existence of contact between the shafts and the interlayer and thus preventing the loss of any blank during the dragging of the pile. Warehouse or blank magazine is composed of a plate inclined by 55 ∘ and four aluminum legs that sustain the plate. The plate is ad hoc built for the industrial partner’s blanks or cardboards. On the plate, four thin rods are mounted that guide the blanks once the robot delivers the whole stack, as shown in Fig. 14(b) and Fig. 15(b). Moreover, a proximity sensor is added and connected to a led yellow light. The proximity sensor checks if the number of cardboards is below a given threshold, in which case the light is turned on, as shown in Fig. 15(b). 5.3 Showcase perception To accomplish the showcase tasks a number of perception activities must be implemented. The piles of blanks are put over two pallets, thus these pallets must be detected and located relative to the robot. The poses of the piles themselves must be precisely estimated, so the picking up could be well performed. Finally, the blank magazine must be detected and located in order to perform the feeding procedure. The detection of the pallets is done by processing the stereo images captured using the pan–tilt camera. It unfolds into three steps: first, voxel grid filtering [35] based on the height of the pallets is used to remove irrelevant points from the point cloud [36]; second, the filtered points are projected on a horizontal plane and clustering is applied to define candidate regions; finally, these regions are matched against a 3D template to find the poses of the pallets. The same approach is applied for a first rough estimation of the poses of the piles in the pallets, by using the average height of the piles and an appropriate template. Fig. 16 illustrates the detection of both pallets and piles. However, to reliably pick a blank pile up from a pallet, a robust pose estimation of piles is necessary. On the one hand, in real industry scenarios, the piles on a pallet are tightly-aligned and put close to each other. On the other hand, the patterns printed on the blanks, even for the same blank shape, are variable and can change with end users’ demands. Therefore, detection and pose estimation of blanks cannot rely on conventional approaches such as color segmentation or local feature matching such as SIFT [37]. The approximate piles’ poses estimated so far can be used to position the TCP camera, in order to obtain more reliable ones. The camera is positioned over a pile and an image is captured, as shown in Fig. 17(a). Then, a Canny edge detector is applied to that image, as shown in Fig. 17(b). The detected edges come from the blanks’ outline but also from the printed patterns on the top blank. A drawing pin filter which classifies each point with various number of neighbors is applied to detect the outline of a blank pile [26]. The kernel is defined as K D P = [ x i ] = p + h n , if x i is in the center h n , otherwise p > h × | [ x ] | , n = ∑ x i , where p and h are the values of pin and head, respectively. The p is larger than the sum of heads and n is the normalization factor of the kernel. In this work, a drawing pin kernel of size 5 × 5 with p = 50 and h = 1 is used, as shown in Fig. 18. The basic assumption is that the edges of outlines are straight lines and their points have few neighbors except those in the line, while the points in printed patterns have many neighbors. In the filtering algorithm, points with more than the kernel size are discarded, as shown in Fig. 17(c). Finally, to find the precise pose of the pile, it is matched against a template, starting from the roughly estimated pose in a spiral direction. Fig. 17(d) shows the result of the match. 5.4 Motion planing After grasping the blank pile, the arm is put in a transport pose. This pose is defined considering two requirements. In one side, the arm should be completely inside the robot footprint. This way, navigation to the blank magazine table will be much safer. In the other side, the arm pose should minimize the necessary motions to place the pile in the magazine. All of these manipulations have to be done while maintaining the blank pile in a pose that prevents it from breaking apart. In this challenge, motions have been generated in the simulator in advance and then the results are applied to the real robot. In order to achieve the best results specific filters had to be used to enhance and complete the trajectories that were derived from existing motion planners. Several different motion planners have also been tested and benchmarked for tasks of different complexities [38]. 5.5 Task planning The manipulation of the blank pile, aside from the gripper, also raises planning issues. The first relates to the order by which blank piles must be manipulated. Due to their dispositions in the pallet, certain blank piles are blocked by others and cannot be dragged before these are removed. Therefore, the order by which blank piles are manipulated has to be planned. The plan considers the blank piles available in all the pallets and gives preference to the pallet with the lowest number of blank piles, since an empty pallet can be replaced with a fully packed one. Fig. 19 shows a task plan with the sequence and dragging directions to pick up all blank piles on two pallets. The dragging itself is also a challenge. The gripper and the arm have to maintain pressure against the pallet while dragging the blank pile. Too much pressure and the pallet could move, not enough pressure and the pile can be disrupted. Therefore, the robotic arm has to be used in compliant mode and the pressure should be properly calculated. 5.6 Safe human–robot collaboration For small batch production, changing or adding new features, such as continuously changing printed patterns of blanks, can be a burden on both human operators and autonomous robots. Since industrial environments are noisy, where machines produce a continuous whirring sound, verbal communication is difficult for humans and impractical for robots. Thus, gestures have been considered as a practical alternative way of communication. Until now, gesture recognition systems in HRI have focused on small number of implicit interactions such as pointing and handing over. With respect to pointing, the target object must be in the field of view of both human and robot. Fig. 20 shows an example of human tracking and human–robot interaction during the EuRoC evaluation. When the robot detects an operator entering a region for safety handling, it stops the executing task and points the pan–tilt to the operator. To ask to fetch objects in a cluttered and unstructured environment, HRI systems need to have a rich vocabulary to designate an object [16]. Fig. 21 shows an interaction tree for the showcase task. That represents commands by sequentially encoding 8 gestures, which consist of 6 numbers 0 to 5 and thumb up/down. Gesture recognition module recognizes a one-hand gesture provided by the operator. Then HRI module tries to build a command with a sequence of gestures. Following the command, the robot continues or stops the paused task. 6 Challenge evaluation 6.1 Benchmark evaluation During the benchmark phase of the Stages II, all the Challenge 2 participants have been evaluated by developing same two tasks under the same conditions: the robot platform, EuRoC software architecture and working time. As the benchmark task 1, the robot has to pick up and place 5 SLCs into the target area to show the logistics capabilities with different payload from different location to a fixed place. The task has two metrics: a number of delivered SLCs regardless of whether parts are lost (metric 1) and a number of delivered SLCs without losing parts (metric 2). Table 1 shows the results, which are their best results out of three trials. The bonus is calculated as inverse proportion to the time difference from the best on that between the best and worst. As the benchmark task 2, the robot is required to screw nuts on 5 bolts placed in a fixed area on a table using a fixture. The task also has two metrics: a number of washers successfully put onto bolts (metric 1) and a number of bolts with a successfully screwed on nut (metric 2) Table 2 shows the results of the benchmark task 2. The bonus is calculated as same as that of the task 1 among the records of teams, who finish the assembly task. TIMAIRIS has completed the both tasks without failures in the shortest times. 6.2 Showcase evaluation TIMARIS’ showcase addresses all of these issues (and others) in the form of three challenges and two extra demos, with quantifiable metrics. The objectives and metrics are organized so that the highlights described above can be evaluated in a comprehensive and robust way. The first objective (O1) is focused on perception and includes 4 metrics: detecting the pose of blank piles, pallets and blank magazine (O1M1); recognizing the need for blank feeding (O1M2); identifying the number of piles in each pallet (O1M3); identifying the presence of humans in the vicinity of the robot (O1M4). The second objective is focused on manipulation and navigation and includes 4 metrics: correctly picking a blank pile (O2M1); transporting the piles to the blank magazine (O2M2); placing the blank piles in the blank magazine (O2M3); stopping manipulation and navigation if a human is close to the robot (O2M4). The third objective evaluates the planning capabilities and includes 2 metrics: providing a plan to pick the blank piles (O3M1); adapting navigation paths (O3M2). The last objective evaluates human robot interaction and includes 2 metrics: recognizing gesture commands provided by the human (O4M1); tracking a human for interaction (O4M2). The achieved metrics are presented in Table 3. TIMAIRIS completed the showcase with every objective and metric being accomplished as can be seen from Table 3 where targets is the number of trials in predefined task scenarios and events is the number of successes during the showcase evaluation. The metrics of O1M1 are composed of three metrics for detecting the pose of blank piles, pallets and blank magazine. In what regards Perception, Manipulation/Navigation and Planning, i.e. Objectives 1, 2 and 3 previously specified, all metrics have been achieved during the execution of the first part of the showcase evaluation that consisted of three challenges. Tracking humans with the pan–tilt camera, Metric 2 of Objective 4, was also achieved during this first part of the showcase evaluation. The gesture recognition was demonstrated during the first part of the showcase evaluation, where gesture commands have been used to start challenge execution. Safety has been demonstrated in manipulation and navigation several times. During the showcase, the gesture recognition, which includes automatic correction methods, has been presented independently and the results showed that it is very robust and adequate for this kind of interaction (see the linked video 6 6 ). The results obtained in the showcase phase provide an excellent base for the development of the pilot experiment. The pilot experiment environment is a real industrial setting but, as already referred, all the developments of showcase are directly applicable in this final environment. Some new features will have to be addressed that also depend on the speedup of the final prototype, such as considering several packaging machines and different types/shapes of blanks, enhanced safety and more challenging navigation issues. Still, the showcase results are a complete and very solid basis for the work that needs to be done in the pilot experiments. 7 Conclusion To enable the paradigm shift in the packaging industry, many developed technologies must be considered as the integration cannot be performed and only the complete set allows the execution of the task. The developed system has gradually evolved from the qualification stage in a limited time. During the Stage 2 of the EuRoC project, the proposed architecture has demonstrated the feasibility of practical use of for Shop Floor Logistics and Manipulation. It is believed that SAAA is efficient not only in autonomous execution for autonomous packaging tasks but also in its use of development during the competitive challenges and that the simple architecture and distributed skills make the system efficient. The results of benchmarking tasks in which TIMAIRIS took first place among 5 Stage 2 challenger teams was possible that our team just focused on improving individual skills to complete all tasks and to reduce running time. One of important development during the showcase is showing that autonomous blank feeding is possible in a realistic industrial environment. That is a pending task of the industry partner IMA S.p.A which is a world leading company in the design and manufacture of automatic machines for the processing and packaging. As the result of the Stage II evaluations, TIMAIRIS has been selected to advance to the final stage of the EuRoC project. Some new features will have to be addressed that also depend on the speedup of the final prototype to complete the pilot experiments. Still, the results of the Stage II are a complete and very solid basis for the work that needs to be done in the final stage of the EuRoC project. Declaration of Competing Interest The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper. Acknowledgments This work was supported by the EuRoC Project under Grant no. 608849 and by National Funds through the FCT - Foundation for Science and Technology , in the context of the project UID/CEC/00127/2013. References [1] Pratt G. Manzo J. The DARPA robotics challenge [competitions] IEEE Robot. Autom. Mag. 20 2 2013 10 12 G. Pratt, J. Manzo, The DARPA robotics challenge [competitions], IEEE Robotics & Automation Magazine 20 (2) (2013) 10–12 [2] Kitano H. Asada M. Kuniyoshi Y. Noda I. Osawa E. Robocup: the robot world cup initiative Proceedings of the First International Conference on Autonomous Agents 1997 ACM 340 347 H. Kitano, M. Asada, Y. Kuniyoshi, I. Noda, E. Osawa, Robocup: The robot world cup initiative, in: Proceedings of the first international conference on Autonomous agents, ACM, 1997, pp. 340–347 [3] Siciliano B. Caccavale F. Zwicker E. Achtelik M. Mansard N. Borst C. Achtelik M. Jepsen N.O. Awad R. Bischoff R. EuRoC-The challenge initiative for european robotics ISR/Robotik 2014; 41st International Symposium on Robotics; Proceedings of 2014 VDE 1 7 B. Siciliano, F. Caccavale, E. Zwicker, M. Achtelik, N. Mansard, C. Borst, M. Achtelik, N. O. Jepsen, R. Awad, R. Bischoff, EuRoC-the challenge initiative for european robotics, in: ISR/Robotik 2014 41st International Symposium on Robotics; Proceedings of, VDE, 2014, pp. 1–7 [4] Bischoff R. Guhl T. The strategic research agenda for robotics in europe [industrial activities] IEEE Robot. Autom. Mag. 1 17 2010 15 16 R. Bischoff, T. Guhl, The strategic research agenda for robotics in europe [industrial activities], IEEE Robotics & Automation Magazine 1 (17) (2010) 15–16 [5] Cully A. Clune J. Tarapore D. Mouret J.-B. Robots that can adapt like animals Nature 521 7553 2015 503 A. Cully, J. Clune, D. Tarapore, J.-B. Mouret, Robots that can adapt like animals, Nature 521 (7553) (2015) 503 [6] Hildebrandt A.-C. Schuetz C. Wahrmann D. Wittmann R. Rixen D. A flexible robotic framework for autonomous manufacturing processes: report from the european robotics challenge stage 1 Autonomous Robot Systems and Competitions (ICARSC), 2016 International Conference on 2016 IEEE 21 27 A.-C. Hildebrandt, C. Schuetz, D. Wahrmann, R. Wittmann, D. Rixen, A flexible robotic framework for autonomous manufacturing processes: Report from the European Robotics Challenge Stage 1, in: Autonomous Robot Systems and Competitions (ICARSC), 2016 International Conference on, IEEE, 2016, pp. 21–27 [7] Zadeh S.M. Powers D.M. Sammut K. An autonomous reactive architecture for efficient AUV mission time management in realistic dynamic ocean environment Robot. Auton. Syst. 87 2017 81 103 S. M. Zadeh, D. M. Powers, K. Sammut, An autonomous reactive architecture for efficient auv mission time management in realistic dynamic ocean environment, Robotics and Autonomous Systems 87 (2017) 81–103 [8] Baklouti E. Amor N.B. Jallouli M. Reactive control architecture for mobile robot autonomous navigation Robot. Auton. Syst. 89 2017 9 14 E. Baklouti, N. B. Amor, M. Jallouli, Reactive control architecture for mobile robot autonomous navigation, Robotics and Autonomous Systems 89 (2017) 9–14 [9] Nilsson K. Johansson R. Integrated architecture for industrial robot programming and control Robot. Auton. Syst. 29 4 1999 205 226 K. Nilsson, R. Johansson, Integrated architecture for industrial robot programming and control, Robotics and Autonomous Systems 29 (4) (1999) 205–226 [10] Chatzilygeroudis K. Vassiliades V. Mouret J.-B. Reset-free trial-and-error learning for robot damage recovery Robot. Auton. Syst. 100 2018 236 250 K. Chatzilygeroudis, V. Vassiliades, J.-B. Mouret, Reset-free trial-and-error learning for robot damage recovery, Robotics and Autonomous Systems 100 (2018) 236–250 [11] Insaurralde C.C. Petillot Y.R. Capability-oriented robot architecture for maritime autonomy Robot. Auton. Syst. 67 2015 87 104 C. C. Insaurralde, Y. R. Petillot, Capability-oriented robot architecture for maritime autonomy, Robotics and Autonomous Systems 67 (2015) 87–104 [12] Dean T.L. Boddy M.S. An analysis of time-dependent planning. AAAI, vol. 88 1988 49 54 T. L. Dean, M. S. Boddy, An analysis of time-dependent planning., in: AAAI, Vol. 88, 1988, pp. 49–54 [13] Grefenstette J.J. Ramsey C.L. An approach to anytime learning Machine Learning Proceedings 1992 1992 Elsevier 189 195 J. J. Grefenstette, C. L. Ramsey, An approach to anytime learning, in: Machine Learning Proceedings 1992, Elsevier, 1992, pp. 189–195 [14] Pedrosa E. Lau N. Pereira A. Cunha B. A skill-based architecture for pick and place manipulation tasks Progress in Artificial Intelligence: 17th Portuguese Conference on Artificial Intelligence, EPIA 2015 2015 Springer 457 468 E. Pedrosa, N. Lau, A. Pereira, B. Cunha, A skill-based architecture for pick and place manipulation tasks, in: Progress in Artificial Intelligence: 17th Portuguese Conference on Artificial Intelligence, EPIA 2015, Springer, 2015, pp. 457–468 [15] Amaral F. Pedrosa E. Lim G.H. Shafii N. Pereira A. Azevedo J.L. Cunha B. Reis L.P. Badini S. Lau N. Skill-based anytime agent architecture for logistics and manipulation tasks: EuRoC challenge 2, stage II-realistic labs: benchmarking Autonomous Robot Systems and Competitions (ICARSC), 2017 IEEE International Conference on 2017 IEEE 198 203 F. Amaral, E. Pedrosa, G. H. Lim, N. Shafii, A. Pereira, J. L. Azevedo, B. Cunha, L. P. Reis, S. Badini, N. Lau, Skill-based anytime agent architecture for logistics and manipulation tasks: EuRoC Challenge 2, Stage II-Realistic Labs: Benchmarking, in: Autonomous Robot Systems and Competitions (ICARSC), 2017 IEEE International Conference on, IEEE, 2017, pp. 198–203 [16] Lim G.H. Pedrosa E. Amaral F. Lau N. Pereira A. Dias P. Azevedo J.L. Cunha B. Reis L.P. Rich and robust human-robot interaction on gesture recognition for assembly tasks Autonomous Robot Systems and Competitions (ICARSC), 2017 IEEE International Conference on 2017 IEEE 159 164 G. H. Lim, E. Pedrosa, F. Amaral, N. Lau, A. Pereira, P. Dias, J. L. Azevedo, B. Cunha, L. P. Reis, Rich and robust human-robot interaction on gesture recognition for assembly tasks, in: Autonomous Robot Systems and Competitions (ICARSC), 2017 IEEE International Conference on, IEEE, 2017, pp. 159–164 [17] Lim G.H. Pedrosa E. Amaral F. Dias R. Pereira A. Lau N. Azevedo J.L. Cunha B. Reis L.P. Human-robot collaboration and safety management for logistics and manipulation tasks Iberian Robotics Conference 2017 Springer 15 27 G. H. Lim, E. Pedrosa, F. Amaral, R. Dias, A. Pereira, N. Lau, J. L. Azevedo, B. Cunha, L. P. Reis, Human-robot collaboration and safety management for logistics and manipulation tasks, in: Iberian Robotics conference, Springer, 2017, pp. 15–27 [18] Mokhtari V. Lim G.H. Lopes L.S. Pinho A.J. Gathering and conceptualizing plan-based robot activity experiences Intelligent Autonomous Systems 13 2016 Springer 993 1005 V. Mokhtari, G. H. Lim, L. S. Lopes, A. J. Pinho, Gathering and conceptualizing plan-based robot activity experiences, in: Intelligent Autonomous Systems 13, Springer, 2016, pp. 993–1005 [19] Lim G.H. Shared representations of actions for alternative suggestion with incomplete information Robot. Auton. Syst. 2019 G. H. Lim, Shared representations of actions for alternative suggestion with incomplete information, Robotics and Autonomous Systems. [20] Balogh R. I am a robot–competitor: a survey of robotic competitions Int. J. Adv. Robot. Syst. 2 2005 17 R. Balogh, I am a robot–competitor: A survey of robotic competitions, International Journal of Advanced Robotic Systems 2 (2005) 17 [21] Thrun S. Montemerlo M. Dahlkamp H. Stavens D. Aron A. Diebel J. Fong P. Gale J. Halpenny M. Hoffmann G. Stanley: the robot that won the DARPA grand challenge J. Field Robot. 23 9 2006 661 692 S. Thrun, M. Montemerlo, H. Dahlkamp, D. Stavens, A. Aron, J. Diebel, P. Fong, J. Gale, M. Halpenny, G. Hoffmann, et al., Stanley: The robot that won the darpa grand challenge, Journal of field Robotics 23 (9) (2006) 661–692 [22] Buehler M. Iagnemma K. Singh S. The DARPA Urban Challenge: Autonomous Vehicles in City Traffic, vol. 56 2009 Springer M. Buehler, K. Iagnemma, S. Singh, The DARPA urban challenge: autonomous vehicles in city traffic, Vol. 56, springer, 2009 [23] A. Dömel, S. Kriegel, M. Brucker, M. Suppa, Autonomous pick and place operations in industrial production, in: Ubiquitous Robots and Ambient Intelligence (URAI), 2015 12th International Conference on, 2015, pp. 356–356, [24] Lim G.H. Pedrosa E. Amaral F. Lau N. Pereira A. Azevedo J.L. Cunha B. Neural regularization jointly involving neurons and connections for robust image classification 2017 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems (MFI) 2017 IEEE 336 341 G. H. Lim, E. Pedrosa, F. Amaral, N. Lau, A. Pereira, J. L. Azevedo, B. Cunha, Neural regularization jointly involving neurons and connections for robust image classification, in: 2017 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems (MFI), IEEE, 2017, pp. 336–341 [25] Russell S. Norvig P. Artificial Intelligence: A Modern Approach third ed. 2010 Prentice Hall S. Russell, P. Norvig, Artificial Intelligence: A Modern Approach, 3rd Edition, Prentice Hall, 2010 [26] Lim G.H. Pedrosa E. Amaral F. Lau N. Pereira A. Azevedo J.L. Cunha B. Badini S. Mobile manipulation for autonomous packaging in realistic environments: euroc challenge 2, stage ii, showcase 2018 IEEE International Conference on Autonomous Robot Systems and Competitions (ICARSC) 2018 IEEE 231 236 G. H. Lim, E. Pedrosa, F. Amaral, N. Lau, A. Pereira, J. L. Azevedo, B. Cunha, S. Badini, Mobile manipulation for autonomous packaging in realistic environments: Euroc challenge 2, stage ii, showcase, in: 2018 IEEE International Conference on Autonomous Robot Systems and Competitions (ICARSC), IEEE, 2018, pp. 231–236 [27] Lim G.H. Lau N. Pedrosa E. Amaral F. Pereira A. Luís Azevedo J. Cunha B. Precise and efficient pose estimation of stacked objects for mobile manipulation in industrial robotics challenges Adv. Robot. 2019 1 11 G. H. Lim, N. Lau, E. Pedrosa, F. Amaral, A. Pereira, J. Luís Azevedo, B. Cunha, Precise and efficient pose estimation of stacked objects for mobile manipulation in industrial robotics challenges, Advanced Robotics (2019) 1–11 [28] Lim G.H. Yi C. Suh I.H. Ko D.W. Hong S.W. Ontology representation and instantiation for semantic map building by a mobile robot Intelligent Autonomous Systems, vol. 12 2013 Springer 387 395 G. H. Lim, C. Yi, I. H. Suh, D. W. Ko, S. W. Hong, Ontology representation and instantiation for semantic map building by a mobile robot, in: Intelligent Autonomous Systems 12, Springer, 2013, pp. 387–395 [29] G.H. Lim, M. Oliveira, S.H. Kasaei, L.S. Lopes, Hierarchical nearest neighbor graphs for building perceptual hierarchies, in: 22nd International Conference on Neural Information Processing, ICONIP2015, 2015. [30] Lim G.H. Suh I.H. Suh H. Ontology-based unified robot knowledge for service robots in indoor environments IEEE Trans. Syst., Man, Cybern. A 41 3 2011 492 509 10.1109/TSMCA.2010.2076404 G. H. Lim, I. H. Suh, H. Suh, Ontology-based unified robot knowledge for service robots in indoor environments, Systems, Man and Cybernetics, Part A: Systems and Humans, IEEE Transactions on 41 (3) (2011) 492 –509 doi:101109/TSMCA.20102076404 [31] Rusu R. Marton Z. Blodow N. Dolha M. Towards 3D point cloud based object maps for household environments Robot. Auton. Syst. 56 11 2008 927 941 R. B. Rusu, Z. C. Marton, N. Blodow, M. Dolha, Towards 3D point cloud based object maps for household environments, Robotics and Autonomous Systems 56 (11) (2008) 927–941 [32] Rusu R.B. Semantic 3D object maps for everyday manipulation in human living environments (Ph.D. thesis) 2009 Computer Science department, Technische Universitaet Muenchen, Germany R. B. Rusu, Semantic 3D Object Maps for Everyday Manipulation in Human Living Environments, Ph.D. thesis, Computer Science department, Technische Universitaet Muenchen, Germany (October 2009) [33] Oliveira M. Lopes L.S. Lim G.H. Kasaei S.H. Tomé A.M. Chauhan A. 3D object perception and perceptual learning in the RACE project Robot. Auton. Syst. 75 2016 614 626 M. Oliveira, L. S. Lopes, G. H. Lim, S. H. Kasaei, A. M. Tomé, A. Chauhan, 3d object perception and perceptual learning in the race project, Robotics and Autonomous Systems 75 (2016) 614–626 [34] Pedrosa E. Pereira A. Lau N. A scan matching approach to slam with a dynamic likelihood field 2016 International Conference on Autonomous Robot Systems and Competitions, ICARSC 2016 IEEE Portugal, Bragança 35 40 10.1109/ICARSC.2016.23 E. Pedrosa, A. Pereira, N. Lau, A Scan Matching Approach to SLAM with a Dynamic Likelihood Field, in: 2016 International Conference on Autonomous Robot Systems and Competitions (ICARSC), IEEE, Portugal, Bragança, 2016, pp. 35–40 doi:101109/ICARSC.201623 [35] Cohen-Or D. Kaufman A. Fundamentals of surface voxelization Graph. Models Image Process. 57 6 1995 453 461 D. Cohen-Or, A. Kaufman, Fundamentals of surface voxelization, Graphical models and image processing 57 (6) (1995) 453–461 [36] Rusu R.B. Cousins S. 3D is here: point cloud library (PCL) Robotics and Automation (ICRA), 2011 IEEE International Conference on 2011 IEEE 1 4 R. B. Rusu, S. Cousins, 3D is here: Point cloud library (PCL), in: Robotics and Automation (ICRA), 2011 IEEE International Conference on, IEEE, 2011, pp. 1–4 [37] Lowe D.G. Object recognition from local scale-invariant features Computer Vision, 1999. The Proceedings of the Seventh IEEE International Conference on, vol. 2 1999 Ieee 1150 1157 D. G. Lowe, Object recognition from local scale-invariant features, in: Computer vision, 1999 The proceedings of the seventh IEEE international conference on, Vol. 2, Ieee, 1999, pp. 1150–1157 [38] Tudico A. Lau N. Pedrosa E. Amaral F. Mazzotti C. Carricato M. Improving and benchmarking motion planning for a mobile manipulator operating in unstructured environments Portuguese Conference on Artificial Intelligence 2017 Springer 498 509 A. Tudico, N. Lau, E. Pedrosa, F. Amaral, C. Mazzotti, M. Carricato, Improving and benchmarking motion planning for a mobile manipulator operating in unstructured environments, in: Portuguese Conference on Artificial Intelligence, Springer, 2017, pp. 498–509 Dr. Gi Hyun Lim received the B.S. degree in metallurgical engineering and the M.S. and Ph.D. degrees in electronics and computer engineering from Hanyang University, Seoul, Korea, in 1997, 2007 and 2010, respectively. He is currently a Marie Curie individual fellow in the School of Computer Science at University of Manchester, UK. His research interests lie in the area of artificial intelligence and machine learning for autonomous robots, including perception, semantics, cognition and spatiotemporal representations on neuromorphic architectures. Eurico Pedrosa is a Post-Doc Researcher at the Institute of Electronics and Informatics Engineering of Aveiro (IEETA) integrated in Intelligent Robotics and Systems group (IRIS). He got his Informatics Engineering degree from University of Aveiro in 2010 and a Computer Science Ph.D. degree from Aveiro University in 2018. His research interest are focused on intelligent robotics, robotic navigation including localization and mapping (SLAM), space representation using volumetric grids and most recently the application of radar sensors in indoor robotics. Filipe Amaral is a Research Fellow at the Institute of Electronics and Informatics Engineering of Aveiro (IEETA) integrated in Intelligent Robotics and Systems group (IRIS). He got his MSc degree in Computer and Telematics Engineering from University of Aveiro in 2014. His current research interests are in the area of autonomous mobile robotics. Prof. Dr. Artur Pereira was born in Vila Nova de Famalicão, Portugal, in April 1960. He received the Ph.D. degree in Electrical Engineering from the University of Aveiro, Portugal, in 2003. He is currently an Assistant Professor at the Department of Electronics, Telecommunications and Informatics of the University of Aveiro and a researcher at the Intelligent Robotics and Systems group (IRIS Lab) of the Instituto de Engenharia Electrónica e Informática de Aveiro. The main focus of his research is robotics at the architectural and software levels, with emphasis on simulation, navigation, localization, mapping, and machine learning. Nuno Lau is Assistant Professor at Aveiro University, Portugal and Researcher at the Institute of Electronics and Informatics Engineering of Aveiro (IEETA), where he leads the Intelligent Robotics and Systems group (IRIS). He got is Electrical Engineering Degree from Oporto University in 1993, a DEA degree in Biomedical Engineering from Claude Bernard University, France, in 1994 and the Ph.D. from Aveiro University in 2003. His research interests are focused on Intelligent Robotics, Artificial Intelligence, Multi-Agent Systems and Simulation. Nuno Lau participated in more than 15 international and national research projects, having the tasks of general or local coordinator in about half of them. Nuno Lau won more than 50 scientific awards in robotic competitions, conferences (best papers) and education. He has lectured courses at Phd and MSc levels on Intelligent Robotics, Distributed Artificial Intelligence, Computer Architecture, Programming, etc. Nuno Lau is the author of more than 150 publications in international conferences and journals. He was President of the Portuguese Robotics Society from 2015 to 2017, and is currently the Vice-President of this Society. Prof. Dr. José Luís Azevedo is currently Assistant Professor at the Department of Electronics, Telecommunications and Informatics of the University of Aveiro and a researcher at the Intelligent Robotics and Systems group (IRIS Lab) of the Institute of Electronics and Informatics Engineering of Aveiro (IEETA). He received the Ph.D. degree in Electrical Engineering from the University of Aveiro, Portugal, in 1998. His current research interests are in the area of cooperative autonomous mobile robotics. Prof. Dr. Bernardo Cunha was born in 1959 in Porto, Portugal. He earned his doctoral degree in electrical engineering at the University of Aveiro, Portugal, in 1999. He is a full time teacher at Universidade de Aveiro in the computer architecture area and an investigator at the Instituto de Engenharia Electrónica e Informática de Aveiro. Current research interests are centered in the area of cooperative autonomous mobile robotics. Simone Badini is a Mechanical Designer in the Research and Development department of IMA Spa since 2013. IMA Spa is a world leader company in the design and manufacture of automatic machines for the processing and packaging of pharmaceuticals, cosmetics, food, tea and coffee and tobacco. He got is M.Sc. degree in Mechanical Engineering from University of Bologna, Italy in 2012. He is currently project manager for the integration of cobot and autonomous mobile robot in the production lines for the IMA group. "
    },
    {
        "doc_title": "Precise and efficient pose estimation of stacked objects for mobile manipulation in industrial robotics challenges",
        "doc_scopus_id": "85066896804",
        "doc_doi": "10.1080/01691864.2019.1617780",
        "doc_eid": "2-s2.0-85066896804",
        "doc_date": "2019-07-03",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Control and Systems Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2207"
            },
            {
                "area_name": "Software",
                "area_abbreviation": "COMP",
                "area_code": "1712"
            },
            {
                "area_name": "Human-Computer Interaction",
                "area_abbreviation": "COMP",
                "area_code": "1709"
            },
            {
                "area_name": "Hardware and Architecture",
                "area_abbreviation": "COMP",
                "area_code": "1708"
            },
            {
                "area_name": "Computer Science Applications",
                "area_abbreviation": "COMP",
                "area_code": "1706"
            }
        ],
        "doc_keywords": [
            "Industrial environments",
            "Industrial robotics",
            "Mobile manipulation",
            "Mobile manipulator",
            "Object manipulation",
            "Perception systems",
            "Pose estimation",
            "stacked objects"
        ],
        "doc_abstract": "© 2019, © 2019 Informa UK Limited, trading as Taylor & Francis Group and The Robotics Society of Japan.Object manipulation tasks such as picking up, carrying and placing should be executed based on the information of objects which are provided by the perception system. A precise and efficient pose estimation system has been developed to address the requirements and to achieve the objectives for autonomous packaging, specifically picking up of stacked non-rigid objects. For fine pose estimation, a drawing pin shaped kernel and pinhole filtering methods are used on the roughly estimated pose of objects. The system has been applied in a realistic industrial environment as a challenging scenario for the Challenge 2–Shop Floor Logistics and Manipulation on a mobile manipulator in the context of the European Robotics Challenges (EuRoC) project.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "A Model-Based Biped Walking Controller Based on Divergent Component of Motion",
        "doc_scopus_id": "85068445147",
        "doc_doi": "10.1109/ICARSC.2019.8733608",
        "doc_eid": "2-s2.0-85068445147",
        "doc_date": "2019-04-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Mechanical Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2210"
            },
            {
                "area_name": "Control and Optimization",
                "area_abbreviation": "MATH",
                "area_code": "2606"
            },
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            }
        ],
        "doc_keywords": [
            "Humanoid walking",
            "Inverted pendulum",
            "Optimal controller",
            "Optimal controls",
            "Push recoveries",
            "Reference trajectories",
            "Robotic community",
            "Unstable dynamics"
        ],
        "doc_abstract": "© 2019 IEEE.Biped robots have high degrees of freedom and they are naturally unstable, hence design and develop a reliable walking controller is a complex subject which is one of the interesting topics in the robotic community. In this paper, we proposed a model-based walking controller which is able to negate the effect of external impacts not only by applying compensating torques but also by adjusting the landing location of swing leg. This controller is composed of two levels of control which takes into account the stable and unstable dynamics parts of center of mass (COM). In the proposed controller, the overall dynamics of a humanoid robot is approximated using an enhanced version of Linear Inverted Pendulum Plus Flywheel Model (ELIPPFM) and, according to this dynamics model, an optimal controller is designed to track the reference trajectories. Moreover, Divergent Component of Motion (DCM) is used to define when and where a robot should take a step to prevent falling. The proposed controller has been successfully tested by performing several simulations using MATLAB. The results showed that the proposed controller is capable of controlling the balance of a simulated robot in presence of severe disturbances.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "A Non-Linear Least Squares Approach to SLAM using a Dynamic Likelihood Field",
        "doc_scopus_id": "85039043621",
        "doc_doi": "10.1007/s10846-017-0763-7",
        "doc_eid": "2-s2.0-85039043621",
        "doc_date": "2019-03-15",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Software",
                "area_abbreviation": "COMP",
                "area_code": "1712"
            },
            {
                "area_name": "Control and Systems Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2207"
            },
            {
                "area_name": "Mechanical Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2210"
            },
            {
                "area_name": "Industrial and Manufacturing Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2209"
            },
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            },
            {
                "area_name": "Electrical and Electronic Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2208"
            }
        ],
        "doc_keywords": [
            "Least-squares optimization",
            "Levenberg- Marquardt methods",
            "Likelihood field",
            "Low computational complexity",
            "Non-linear least squares",
            "Nonlinear least squares problems",
            "Scan matching",
            "SLAM"
        ],
        "doc_abstract": "© 2017, Springer Science+Business Media B.V., part of Springer Nature.This paper presents a fast scan matching approach to online SLAM supported by a dynamic likelihood field. The dynamic likelihood field plays a central role in the approach: it avoids the necessity to establish direct correspondences; it is the connection link between scan matching and the online SLAM; and it has a low computational complexity. Scan matching is formulated as a non-linear least squares problem that allows us to solve it using Gauss-Newton or Levenberg-Marquardt methods. Furthermore, to reduce the influence of outliers during optimization, a loss function is introduced. The proposed solution was evaluated using an objective benchmark designed to compare different SLAM solutions. Additionally, the execution times of our proposal were also analyzed. The obtained results show that the proposed approach provides a fast and accurate online SLAM, suitable for real-time operation.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "A Fast and Stable Omnidirectional Walking Engine for the Nao Humanoid Robot",
        "doc_scopus_id": "85076917465",
        "doc_doi": "10.1007/978-3-030-35699-6_8",
        "doc_eid": "2-s2.0-85076917465",
        "doc_date": "2019-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Desired trajectories",
            "Humanoid robot",
            "Inverted pendulum model",
            "Linear quadratic Gaussian",
            "Linear Quadratic Gaussian controllers",
            "Low-level controllers",
            "Omni-directional walkings",
            "Optimization algorithms"
        ],
        "doc_abstract": "© 2019, Springer Nature Switzerland AG.This paper proposes a framework designed to generate a closed-loop walking engine for a humanoid robot. In particular, the core of this framework is an abstract dynamics model which is composed of two masses that represent the lower and the upper body of a humanoid robot. Moreover, according to the proposed dynamics model, the low-level controller is formulated as a Linear-Quadratic-Gaussian (LQG) controller that is able to robustly track the desired trajectories. Besides, this framework is fully parametric which allows using an optimization algorithm to find the optimum parameters. To examine the performance of the proposed framework, a set of simulation using a simulated Nao robot in the RoboCup 3D simulation environment has been carried out. Simulation results show that the proposed framework is capable of providing fast and reliable omnidirectional walking. After optimizing the parameters using genetic algorithm (GA), the maximum forward walking velocity that we have achieved was 80.5 cm/s.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Self-adaptive Team of Aquatic Drones with a Communication Network for Aquaculture",
        "doc_scopus_id": "85072860307",
        "doc_doi": "10.1007/978-3-030-30244-3_47",
        "doc_eid": "2-s2.0-85072860307",
        "doc_date": "2019-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Cooperative navigations",
            "Cooperative perception",
            "Land platforms",
            "Low costs",
            "Network qualities",
            "Real time",
            "Target allocations"
        ],
        "doc_abstract": "© 2019, Springer Nature Switzerland AG.The use of Unmanned Surface Vehicle (USV) teams, more commonly known as drones, has become increasingly common for aquaculture scenarios due to their availability and low cost. For monitoring to be feasible and in real time, it is necessary for the drones to be in constant communication so that they can organize themselves and send data to a land platform. This paper presents a cooperative navigation behavior in constant communication with the network layer to achieve a better overall performance in the coverage of a space and a better network quality between heterogeneous USVs. In conclusion, increasing the amount of USVs is beneficial as long as an Avoid or Assist does not impact the overall time.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Multi-Robot Fast-Paced Coordination with Leader Election",
        "doc_scopus_id": "85070697946",
        "doc_doi": "10.1007/978-3-030-27544-0_2",
        "doc_eid": "2-s2.0-85070697946",
        "doc_date": "2019-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Global objective",
            "Leader election",
            "Multi-agent coordinations",
            "Multi-robot systems",
            "Real time constraints",
            "Soccer-playing robots",
            "Stochastic environment",
            "Task assignment"
        ],
        "doc_abstract": "© Springer Nature Switzerland AG 2019.Coordination in Multi-Robot Systems is an active research line in Artificial Intelligence applied to Robotics. Through coordination, a team of robots can efficiently achieve their pre-defined global objective. From a wide range of multi-agent coordination sub-topics, one of the current open issues is task assignment and role selection in fast-paced environments. In homogeneous teams, where robots have the ability to dynamically change roles, working in highly dynamic and stochastic environments, it is important that any solution is able to perform and achieve results while complying with realtime constraints. In this paper, we balance the advantages and disadvantages of completely decentralised solutions and centralised ones, and then present our solution for leader election among a team, which is based on the Raft algorithm and tackles two of its limitations. The proposed solution was implemented in a real team of soccer-playing robots and the experimental results are thoroughly presented and discussed.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "An aquatic mobile sensing usv swarm with a link quality-based delay tolerant network",
        "doc_scopus_id": "85054892317",
        "doc_doi": "10.3390/s18103440",
        "doc_eid": "2-s2.0-85054892317",
        "doc_date": "2018-10-13",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Analytical Chemistry",
                "area_abbreviation": "CHEM",
                "area_code": "1602"
            },
            {
                "area_name": "Information Systems",
                "area_abbreviation": "COMP",
                "area_code": "1710"
            },
            {
                "area_name": "Atomic and Molecular Physics, and Optics",
                "area_abbreviation": "PHYS",
                "area_code": "3107"
            },
            {
                "area_name": "Biochemistry",
                "area_abbreviation": "BIOC",
                "area_code": "1303"
            },
            {
                "area_name": "Instrumentation",
                "area_abbreviation": "PHYS",
                "area_code": "3105"
            },
            {
                "area_name": "Electrical and Electronic Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2208"
            }
        ],
        "doc_keywords": [
            "Forwarding strategies",
            "Link quality",
            "Low-cost systems",
            "Mobile sensing platforms",
            "Simulation and real experimentation",
            "Unmanned surface vessels"
        ],
        "doc_abstract": "© 2018 by the authors. Licensee MDPI, Basel, Switzerland.The Smart City concept is starting to extend into maritime environments alongside with the increase of Unmanned Surface Vehicles (USV) models on the market. Consequently, by joining both Smart City and USV technologies, a set of platforms and applications for aquatic environments are emerging. This work proposes a low-cost aquatic mobile sensing platform for data gathering with a swarm of USVs communicating through a Delay-Tolerant Network (DTN). A set of DTN link quality-based routing strategies select the best quality path in a dynamic approach so the sensed information is able to reach the mobile gateway in a reliable way. A Link Quality Estimation (LQE) approach is proposed and its accuracy is evaluated through real experimentation. An aquatic simulation environment, considering both navigation and communication layers, was also proposed and used to evaluate the performance of the proposed routing strategies, and complement real environment performance studies.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Mobile manipulation for autonomous packaging in realistic environments: EuRoC challenge 2, stage II, showcase",
        "doc_scopus_id": "85048892736",
        "doc_doi": "10.1109/ICARSC.2018.8374188",
        "doc_eid": "2-s2.0-85048892736",
        "doc_date": "2018-06-06",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            },
            {
                "area_name": "Mechanical Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2210"
            },
            {
                "area_name": "Control and Optimization",
                "area_abbreviation": "MATH",
                "area_code": "2606"
            }
        ],
        "doc_keywords": [],
        "doc_abstract": "© 2018 IEEE.European Robotics Challenges (EuRoC) project has been launched to find competitive solutions by exploiting synergies across research institutes to industrial end-users. This paper reports the research conducted by the TIMAIRIS team to fulfill EuRoC C2 Stage II tasks. TIMAIRIS is one of the 6 EuRoC finalists (Stage III) from an initial group of 102 teams. The packaging industry is very interested in recent advances in robotics but is still quite conservative in the way it uses automation, since shapes and printed patterns of blanks vary a lot to comply with end users' demands. The use of programmable logic controllers (PLCs) is widely common but the use of more sophisticated decision mechanisms is not so common. A shop floor logistics and manipulation system has been developed and demonstrated in a realistic environment for autonomous packaging.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "An optimal closed-loop framework to develop stable walking for humanoid robot",
        "doc_scopus_id": "85048881269",
        "doc_doi": "10.1109/ICARSC.2018.8374156",
        "doc_eid": "2-s2.0-85048881269",
        "doc_date": "2018-06-06",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            },
            {
                "area_name": "Mechanical Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2210"
            },
            {
                "area_name": "Control and Optimization",
                "area_abbreviation": "MATH",
                "area_code": "2606"
            }
        ],
        "doc_keywords": [],
        "doc_abstract": "© 2018 IEEE.Bipedal robots are essentially unstable because of their complex kinematics as well as high dimensional state space dynamics, hence control and generation of stable walking is a complex subject that is still one of the active topics in the robotic community. This paper proposes a closed-loop model-based walk engine which takes into account push recovery strategies. In this paper, Linear Inverted Pendulum Plus Flywheel Model (LIPPFM) is extended and used to approximate the overall dynamics of a humanoid robot. We extended this model by releasing the height constraint of the center of mass (COM) as well as by considering the mass of pendulum to increase the accuracy of the model. In this framework, a step is composed of a double support phase in addition to a single support phase. Moreover, ZMP and reference trajectory generators are formulated based on the input parameters and tracking problem are formulated as a finite-time horizon linear quadratic regulator (LQR) problem. The proposed framework has been successfully tested by performing several simulations using MATLAB. The simulation results show this framework is capable to provide stable walking on an uneven terrain.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "A sparse-dense approach for efficient grid mapping",
        "doc_scopus_id": "85048861103",
        "doc_doi": "10.1109/ICARSC.2018.8374173",
        "doc_eid": "2-s2.0-85048861103",
        "doc_date": "2018-06-06",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            },
            {
                "area_name": "Mechanical Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2210"
            },
            {
                "area_name": "Control and Optimization",
                "area_abbreviation": "MATH",
                "area_code": "2606"
            }
        ],
        "doc_keywords": [],
        "doc_abstract": "© 2018 IEEE.The regular volumetric grid is a popular method used in mapping to represent the environment, however for large three-dimensional environments it requires a large amount of memory that may not even be available. In this paper we present a sparse-dense data structure to manage the space of a volumetric grid that provides improvements over the octree data structure, a data structure popularized by the OctoMap mapping framework. Furthermore, we propose an online data compression scheme supported by a cache mechanism that further improves the space efficiency of our approach without compromising time efficiency. The approach is evaluated using public available datasets that show an increase in space and memory efficiency over OctoMap without compromising accuracy.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "A reliable hierarchical omnidirectional walking engine for a bipedal robot by using the enhanced lip plus flywheel",
        "doc_scopus_id": "85048897160",
        "doc_doi": "10.1142/9789813231047_0049",
        "doc_eid": "2-s2.0-85048897160",
        "doc_date": "2018-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Human-Computer Interaction",
                "area_abbreviation": "COMP",
                "area_code": "1709"
            },
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            }
        ],
        "doc_keywords": [
            "Center of mass",
            "Humanoid robot",
            "Inverted pendulum",
            "Kinematics and dynamics",
            "Natural motions",
            "Omni-directional walkings",
            "Reference trajectories",
            "Vertical CoM motion"
        ],
        "doc_abstract": "© 2018 by World Scientific Publishing Co. Pte. Ltd.According to the similarity in kinematic architecture, bipedal robots are the most appropriate type of robot to operate in humanoid environments. Most of the humanoid robots have more than 20 degrees of freedom (DoF), therefore they have complex kinematics and dynamics. Due to these complexities, developing a stable walking engine is a difficult subject which is still one of the main challenges. In this paper, a hierarchical walking engine is presented which tries to fade the complexities and increases the flexibility and portability. To generate the reference trajectories of walking, Linear Inverted Pendulum Plus Flywheel Model is used. We enhanced this model to release the height constraint of the Center of Mass (CoM). This enhancement not only provides more natural motion but also it provides larger stride. The reliability of the proposed structure is verified through real experiments for an 110cm bipedal robot. The experimental results show the performance of this controller to keep robot’s stability during walking. The average speed of walking that we have achieved was 20cm/sec.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "A Hybrid ZMP-CPG Based Walk Engine for Biped Robots",
        "doc_scopus_id": "85042234860",
        "doc_doi": "10.1007/978-3-319-70836-2_61",
        "doc_eid": "2-s2.0-85042234860",
        "doc_date": "2018-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Control and Systems Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2207"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Central pattern generator",
            "CREPS-CMA",
            "Hierarchical structures",
            "Humanoid robot",
            "Omni-directional walkings",
            "Soccer simulation"
        ],
        "doc_abstract": "© Springer International Publishing AG 2018.Developing an optimized omnidirectional walking for biped robots is a challenging task due to their complex dynamics and kinematics. This paper proposes a hierarchical walk engine structure to generate fast and stable walking. In particular, this structure provides a closed-loop CPG-based omnidirectional walking that takes into account two human-inspired push recovery strategies. In addition, this structure is fully parametric and allows using a policy search algorithm to find the optimum parameters for the walking. To show the performance of the proposed structure, a set of experiments on a simulated NAO robot has been carried out. Experimental results demonstrate that the proposed structure is able to generate fast and stable omnidirectional walking. The maximum speed of forward walking that we have achieved was 59 cm/s.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Human-Robot Collaboration and Safety Management for Logistics and Manipulation Tasks",
        "doc_scopus_id": "85042220407",
        "doc_doi": "10.1007/978-3-319-70836-2_2",
        "doc_eid": "2-s2.0-85042220407",
        "doc_date": "2018-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Control and Systems Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2207"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Human-robot collaboration",
            "Industrial context",
            "Manipulation task",
            "Mobile manipulator",
            "Reasoning methods",
            "Region-based filtering",
            "Safety concerns",
            "Safety management"
        ],
        "doc_abstract": "© Springer International Publishing AG 2018.To realize human-robot collaboration in manufacturing, industrial robots need to share an environment with humans and to work hand in hand. This introduces safety concerns but also provides the opportunity to take advantage of human-robot interactions to control the robot. The main objective of this work is to provide HRI without compromising safety issues in a realistic industrial context. In the paper, a region-based filtering and reasoning method for safety has been developed and integrated into a human-robot collaboration system. The proposed method has been successfully demonstrated keeping safety during the showcase evaluation of the European robotics challenges with a real mobile manipulator.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Neural regularization jointly involving neurons and connections for robust image classification",
        "doc_scopus_id": "85042368378",
        "doc_doi": "10.1109/MFI.2017.8170451",
        "doc_eid": "2-s2.0-85042368378",
        "doc_date": "2017-12-07",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Control and Systems Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2207"
            },
            {
                "area_name": "Software",
                "area_abbreviation": "COMP",
                "area_code": "1712"
            },
            {
                "area_name": "Computer Science Applications",
                "area_abbreviation": "COMP",
                "area_code": "1706"
            }
        ],
        "doc_keywords": [
            "Classification performance",
            "Classification results",
            "Experimental analysis",
            "Fully connected neural network",
            "Fully-connected layers",
            "Prediction performance",
            "Regularization methods",
            "Regularization technique"
        ],
        "doc_abstract": "© 2017 IEEE.This paper presents an integrated neural regularization method in fully-connected neural networks that jointly combines the cutting edge of regularization techniques; Dropout [1] and DropConnect [2]. With a small number of data set, trained feed-forward networks tend to show poor prediction performance on test data which has never been introduced while training. In order to reduce the overfitting, regularization methods commonly use only a sparse subset of their inputs. While a fully-connected layer with Dropout takes account of a randomly selected subset of hidden neurons with some probability, a layer with DropConnect only keeps a randomly selected subset of connections between neurons. It has been reported that their performances are dependent on domains. Image classification results show that the integrated method provides more degrees of freedom to achieve robust image recognition in the test phase. The experimental analyses on CIFAR-10 and one-hand gesture dataset show that the method provides the opportunity to improve classification performance.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "A reliable model-based walking engine with push recovery capability",
        "doc_scopus_id": "85026890170",
        "doc_doi": "10.1109/ICARSC.2017.7964063",
        "doc_eid": "2-s2.0-85026890170",
        "doc_date": "2017-06-29",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Biomedical Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2204"
            },
            {
                "area_name": "Control and Optimization",
                "area_abbreviation": "MATH",
                "area_code": "2606"
            },
            {
                "area_name": "Mechanical Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2210"
            },
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            }
        ],
        "doc_keywords": [
            "Hierarchical structures",
            "Human environment",
            "Human-like motion",
            "Humanoid robot",
            "Humanoid soccer robots",
            "Inverted pendulum",
            "Omni-directional walkings",
            "Push recoveries"
        ],
        "doc_abstract": "© 2017 IEEE.Bipedal humanoid robots have complex dynamics and they are intrinsically unstable. Although, bipedal robots have a similar kinematic architecture to a human and they are the most appropriate type of robots to operate in human environments, developing a humanoid robot that has robust is a difficult task. This paper proposes an omnidirectional walking engine that takes into account the push recovery strategies. The walking engine has a hierarchical structure and tries to fade the complexities of the dynamic walking. In addition, it can adapt to another platform with few changes. We enhanced the Linear Inverted Pendulum Plus Flywheel Model to release the height constraint of the center of mass. This enhancement allows a more human-like motion and provides more stable walking. The proposed walking engine has been successfully tested on a real humanoid soccer robot. The experimental results show the performance of this controller to generate stable walking. The average speed of walking that we have achieved was 20cm/sec.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Skill-based anytime agent architecture for logistics and manipulation tasks: EuRoC Challenge 2, Stage II - Realistic Labs: Benchmarking",
        "doc_scopus_id": "85026869156",
        "doc_doi": "10.1109/ICARSC.2017.7964075",
        "doc_eid": "2-s2.0-85026869156",
        "doc_date": "2017-06-29",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Biomedical Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2204"
            },
            {
                "area_name": "Control and Optimization",
                "area_abbreviation": "MATH",
                "area_code": "2606"
            },
            {
                "area_name": "Mechanical Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2210"
            },
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            }
        ],
        "doc_keywords": [
            "Agent architectures",
            "Continuous development",
            "Effective solution",
            "Manipulation task",
            "Planning strategies",
            "Production quality",
            "Robotic technologies",
            "Scientific competition"
        ],
        "doc_abstract": "© 2017 IEEE.Nowadays, the increase of robotic technology application to industry scenarios is notorious. Proposals for new effective solutions are in continuous development once industry needs a constantly improvement in time as well as in production quality and efficiency. The EuRoC research project proposes a scientific competition in which research and industry manufacturers joint teams are encouraged to develop and test solutions that can solve several issues as well as be useful in manufacturing improvement. This paper presents the TIMAIRIS architecture and approach used in the Challenge 2 - Stage II - Benchmarking phase, namely regarding the perception, manipulation and planning strategy that was applied to achieve the tasks objectives. The used approach proved to be quite robust and efficient, which allowed us to rank first in the Benchmarking phase.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Efficient localization based on scan matching with a continuous likelihood field",
        "doc_scopus_id": "85026864903",
        "doc_doi": "10.1109/ICARSC.2017.7964053",
        "doc_eid": "2-s2.0-85026864903",
        "doc_date": "2017-06-29",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Biomedical Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2204"
            },
            {
                "area_name": "Control and Optimization",
                "area_abbreviation": "MATH",
                "area_code": "2606"
            },
            {
                "area_name": "Mechanical Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2210"
            },
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            }
        ],
        "doc_keywords": [
            "Gauss Newton",
            "Levenberg-Marquardt method",
            "Localization algorithm",
            "Loss functions",
            "Mobile robot localization",
            "Nonlinear least squares problems",
            "Scan matching",
            "State of the art"
        ],
        "doc_abstract": "© 2017 IEEE.This paper presents a fast scan matching approach to mobile robot localization supported by a continuous likelihood field. The likelihood field plays a central role in the approach, as it avoids the necessity to establish direct correspondences; it is the connection link between scan matching and robotic localization, and it provides a reduced computational complexity. Scan matching is formulated as a non-linear least squares problem and solved by the Gauss-Newton and Levenberg-Marquardt methods. Furthermore, to reduce the influences of outliers during optimization, a loss function is introduced. The proposed solution was evaluated using a publicly available dataset and compared with AMCL, a state-of-the-art localization algorithm. Our proposal shows to be a fast and accurate localization algorithm suitable for any type of operation.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Rich and robust human-robot interaction on gesture recognition for assembly tasks",
        "doc_scopus_id": "85026864168",
        "doc_doi": "10.1109/ICARSC.2017.7964069",
        "doc_eid": "2-s2.0-85026864168",
        "doc_date": "2017-06-29",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Biomedical Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2204"
            },
            {
                "area_name": "Control and Optimization",
                "area_abbreviation": "MATH",
                "area_code": "2606"
            },
            {
                "area_name": "Mechanical Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2210"
            },
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            }
        ],
        "doc_keywords": [
            "Assembly tasks",
            "Human robot Interaction (HRI)",
            "Manufacturing enterprise",
            "Mobile manipulator",
            "Multiple feature fusion",
            "Puzzle games",
            "Robotics technology",
            "Small and medium sized enterprise"
        ],
        "doc_abstract": "© 2017 IEEE.The adoption of robotics technology has the potential to advance quality, efficiency and safety for manufacturing enterprises, in particular small and medium-sized enterprises. This paper presents a human-robot interaction (HRI) system that enables a robot to receive commands, provide information to a human teammate and ask them a favor. In order to build a robust HRI system based on gesture recognition, three key issues are addressed: richness, multiple feature fusion and failure verification. The developed system has been tested and validated in a realistic lab with a real mobile manipulator and a human teammate to solve a puzzle game.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Erratum to: Processing Time Reduction: an Application in Living Human High-Resolution Diffusion Magnetic Resonance Imaging Data (Journal of Medical Systems, (2016), 40, 11, (243), 10.1007/s10916-016-0594-2)",
        "doc_scopus_id": "85010876668",
        "doc_doi": "10.1007/s10916-016-0683-2",
        "doc_eid": "2-s2.0-85010876668",
        "doc_date": "2017-03-01",
        "doc_type": "Erratum",
        "doc_areas": [
            {
                "area_name": "Medicine (miscellaneous)",
                "area_abbreviation": "MEDI",
                "area_code": "2701"
            },
            {
                "area_name": "Information Systems",
                "area_abbreviation": "COMP",
                "area_code": "1710"
            },
            {
                "area_name": "Health Informatics",
                "area_abbreviation": "MEDI",
                "area_code": "2718"
            },
            {
                "area_name": "Health Information Management",
                "area_abbreviation": "HEAL",
                "area_code": "3605"
            }
        ],
        "doc_keywords": [],
        "doc_abstract": "© 2015, Springer Science+Business Media New York.The original version of this article unfortunately contained an error. The correct spelling of Augustin Ibañez should be Agustin Ibañez.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "A Scan Matching Approach to SLAM with a Dynamic Likelihood Field",
        "doc_scopus_id": "85010460599",
        "doc_doi": "10.1109/ICARSC.2016.23",
        "doc_eid": "2-s2.0-85010460599",
        "doc_date": "2016-12-12",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Human-Computer Interaction",
                "area_abbreviation": "COMP",
                "area_code": "1709"
            },
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            },
            {
                "area_name": "Computer Science Applications",
                "area_abbreviation": "COMP",
                "area_code": "1706"
            }
        ],
        "doc_keywords": [
            "Gauss-Newton methods",
            "Loss functions",
            "Low computational complexity",
            "Nonlinear least squares problems",
            "Real-time operation",
            "Scan matching",
            "SLAM",
            "SLAM approach"
        ],
        "doc_abstract": "© 2016 IEEE.This paper presents a fast scan matching approach to online SLAM supported by a dynamic likelihood field. The dynamic likelihood field plays a central role in the approach, as it avoids the necessity to establish direct correspondences, it is the connection link between scan matching and the online SLAM and it has a low computational complexity. Scan matching is formulated as a non-linear least squares problem and solved by the Gauss-Newton method. Furthermore, to reduce the influences of outliers during optimization, a loss function is introduced. The proposed solution was evaluated using an objective benchmark designed to compare SLAM solutions and its execution times were also analyzed. It shows to be a fast and accurate online SLAM approach, suitable for real-time operation.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "How to Select a Suitable Action against Strong Pushes in Adult-Size Humanoid Robot: Learning from Past Experiences",
        "doc_scopus_id": "85010447569",
        "doc_doi": "10.1109/ICARSC.2016.43",
        "doc_eid": "2-s2.0-85010447569",
        "doc_date": "2016-12-12",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Human-Computer Interaction",
                "area_abbreviation": "COMP",
                "area_code": "1709"
            },
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            },
            {
                "area_name": "Computer Science Applications",
                "area_abbreviation": "COMP",
                "area_code": "1706"
            }
        ],
        "doc_keywords": [
            "Empirical experiments",
            "External disturbances",
            "Humanoid robot",
            "Joint angle",
            "Nonlinear force",
            "Out-of-control",
            "Real environments",
            "Strong collisions"
        ],
        "doc_abstract": "© 2016 IEEE.Avoiding a fall after strong collisions between two players is an important capability for an adult-size humanoid robot. Particularly in the RoboCup competitions, matches are really competitive and collisions between players are occurred frequently. In the adult-size humanoid league, robots are tall and heavy. Whenever robots contact each other during moving, several unpredicted non-linear forces are entered to the robots. As a consequence, the stability of robots goes out of control and they fall down. In order to maintain and recover balance of an adult-size humanoid robot against external disturbances, a Neural Network is used for learning from past experiments to reduce the effect of disturbances forces by providing proper step sizes and joint angles to the robot. In our approach, the robot's controller is learned using several empirical experiments and tested on a real adult-size humanoid robot namely Ariana from BehRobot humanoid team. Experiments demonstrate after receiving strong pushes during walking, Ariana can efficiently recover its stability in the real environment.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "A Validation Framework for Visible Light Positioning in Mobile Robotics",
        "doc_scopus_id": "85010402359",
        "doc_doi": "10.1109/ICARSC.2016.25",
        "doc_eid": "2-s2.0-85010402359",
        "doc_date": "2016-12-12",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Human-Computer Interaction",
                "area_abbreviation": "COMP",
                "area_code": "1709"
            },
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            },
            {
                "area_name": "Computer Science Applications",
                "area_abbreviation": "COMP",
                "area_code": "1706"
            }
        ],
        "doc_keywords": [
            "Indoor localization",
            "ITS applications",
            "LED illumination",
            "Mobile robot localization",
            "Mobile robot systems",
            "Regular patterns",
            "Simulation and validation",
            "Visible light"
        ],
        "doc_abstract": "© 2016 IEEE.Visible Light Positioning (VLP) is emerging as a solution for indoor localization. Interest on VLP has risen, amongst other reasons, as a result of the dissemination of LED illumination. This paper proposes a VLP system based on photo-diode receivers arranged in a regular pattern over a hemispherical dome to detect the position of a light source. Additionally, it proposes a 3D test environment, based on Gazebo, allowing the simulation and validation of our system and its application to mobile robot systems. The results show that the proposed system is capable of estimating the location of a mobile robot with an error of a few centimetres in a 3D space of 20×20×5m.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Processing Time Reduction: an Application in Living Human High-Resolution Diffusion Magnetic Resonance Imaging Data",
        "doc_scopus_id": "84989926299",
        "doc_doi": "10.1007/s10916-016-0594-2",
        "doc_eid": "2-s2.0-84989926299",
        "doc_date": "2016-11-01",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Medicine (miscellaneous)",
                "area_abbreviation": "MEDI",
                "area_code": "2701"
            },
            {
                "area_name": "Information Systems",
                "area_abbreviation": "COMP",
                "area_code": "1710"
            },
            {
                "area_name": "Health Informatics",
                "area_abbreviation": "MEDI",
                "area_code": "2718"
            },
            {
                "area_name": "Health Information Management",
                "area_abbreviation": "HEAL",
                "area_code": "3605"
            }
        ],
        "doc_keywords": [
            "Brain",
            "Diffusion Magnetic Resonance Imaging",
            "Humans",
            "Image Processing, Computer-Assisted",
            "Monte Carlo Method"
        ],
        "doc_abstract": "© 2016, Springer Science+Business Media New York.High Angular Resolution Diffusion Imaging (HARDI) is a type of brain imaging that collects a very large amount of data, and if many subjects are considered then it amounts to a big data framework (e.g., the human connectome project has 20 Terabytes of data). HARDI is also becoming increasingly relevant for clinical settings (e.g., detecting early cerebral ischemic changes in acute stroke, and in pre-clinical assessment of white matter-WM anatomy using tractography). Thus, this method is becoming a routine assessment in clinical settings. In such settings, the computation time is critical, and finding forms of reducing the processing time in high computation processes such as Diffusion Spectrum Imaging (DSI), a form of HARDI data, is very relevant to increase data-processing speed. Here we analyze a method for reducing the computation time of the dMRI-based axonal orientation distribution function h by using Monte Carlo sampling-based methods for voxel selection. Results evidenced a robust reduction in required data sampling of about 50 % without losing signal’s quality. Moreover, we show that the convergence to the correct value in this type of Monte Carlo HARDI/DSI data-processing has a linear improvement in data-processing speed of the ODF determination. Although further improvements are needed, our results represent a promissory step for future processing time reduction in big data.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Reducing computation time by Monte Carlo method: An application in determining axonal orientation distribution function",
        "doc_scopus_id": "84961665228",
        "doc_doi": "10.1007/978-3-319-31307-8_10",
        "doc_eid": "2-s2.0-84961665228",
        "doc_date": "2016-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Control and Systems Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2207"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Axonal ODF",
            "Computation process",
            "Diffusion mris",
            "Diffusion spectrum imaging",
            "Monte Carlo approach",
            "Monte Carlo sampling",
            "Orientation distribution function",
            "White matter"
        ],
        "doc_abstract": "© Springer International Publishing Switzerland 2016.Diffusion MRI (dMRI) is highly sensitive in detecting early cerebral ischemic changes in acute stroke, and in pre-clinical assessment of white matter (WM) anatomy using tractography, thus being an important component of health informatics. In clinical settings, the computation time is critical, and so finding forms of reducing the processing time in high computation processes such as Diffusion Spectrum Imaging (DSI) dMRI data processing is extremely relevant. We analyse here a method for reducing the computation of the dMRI-based axonal orientation distribution function h by using a Monte Carlo sampling-based methods for voxel selection, and so obtained a reduction in required data sampling of about 20%. In this work we show that the convergence to the correct value in this type of dMRI data-processing is linear and not exponential, implying that the Monte Carlo approach in this type of dMRI data processing improves its speed, but further improvements are needed.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "A coordinated team of agents to solve mazes",
        "doc_scopus_id": "84952361953",
        "doc_doi": "10.1007/978-3-319-27149-1_30",
        "doc_eid": "2-s2.0-84952361953",
        "doc_date": "2016-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Control and Systems Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2207"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Ciber mouse",
            "Collision-free",
            "Coordinated teams",
            "Degree of complexity",
            "Distributed teams",
            "Intelligent robotics",
            "Maze problems",
            "Virtual agent"
        ],
        "doc_abstract": "© Springer International Publishing Switzerland 2016.Mazes have been famously chosen as a great challenge for robots, either real or virtual, to solve, where agents have to explore the maze and fulfil goals. Mazes can be explored with greater speed by using a group of agents, as opposed to a single-agent system. There is, however, a greater degree of complexity in the implementation of a distributed team of agents that can coordinate to complete their tasks faster and more efficiently. This paper explores theCiberMouse competition problem,where a team of virtual agents need to complete tasks within an unknown maze, with as much efficiency as possible. Their solution has shown great results in the challenge and has won the CiberMouse 2015 competition. The team can solve many complex mazes, in a smart and mostly collision-free manner. Our agents struggle with very tight paths, but compensate by having flexible high-level behaviours which allow them an efficient maze exploration.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "DISim: Ontology-driven simulation of biomedical data integration tasks",
        "doc_scopus_id": "84943338784",
        "doc_doi": "10.1109/CISTI.2015.7170405",
        "doc_eid": "2-s2.0-84943338784",
        "doc_date": "2015-07-28",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Computer Networks and Communications",
                "area_abbreviation": "COMP",
                "area_code": "1705"
            },
            {
                "area_name": "Hardware and Architecture",
                "area_abbreviation": "COMP",
                "area_code": "1708"
            },
            {
                "area_name": "Education",
                "area_abbreviation": "SOCI",
                "area_code": "3304"
            },
            {
                "area_name": "Human-Computer Interaction",
                "area_abbreviation": "COMP",
                "area_code": "1709"
            },
            {
                "area_name": "Computer Science Applications",
                "area_abbreviation": "COMP",
                "area_code": "1706"
            },
            {
                "area_name": "Information Systems",
                "area_abbreviation": "COMP",
                "area_code": "1710"
            }
        ],
        "doc_keywords": [
            "Acquisition time",
            "Biomedical data",
            "Biomedical data integration",
            "Heterogeneous data integrations",
            "Heterogeneous data sources",
            "Integration simulation",
            "Modelling and simulations",
            "Task completion time"
        ],
        "doc_abstract": "© 2015 AISTI.The continuous growth in quantity and diversity of life sciences data is triggering several bioinformatics challenges to be able to integrate and select desired information for later study. The majority of these data are scattered through independent systems disregarding interoperability features, which makes data integration processes not a trivial task. Consequently, several ETL (Extract-Transform-and-Load) frameworks have been developed to make data integrations tasks suitable for later exploration studies, providing better solutions for data heterogeneity, diversity and distribution. However, current advanced data integration tasks depend on large and heterogeneous data sources that must be modelled according to the source specifications and network conditions. Furthermore, these automated tasks are significantly dependent of sequential processes that dramatically increase the global request and processing time. Without estimation of the task completion time, the whole research workflow becomes even more challenging. This paper presents DISim, an ontology for data integration simulation, to estimate large and heterogeneous data integration jobs, in order to provide valuable outputs to enhance decision-making scenarios.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "A skill-based architecture for pick and place manipulation tasks",
        "doc_scopus_id": "84945908825",
        "doc_doi": "10.1007/978-3-319-23485-4_45",
        "doc_eid": "2-s2.0-84945908825",
        "doc_date": "2015-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Manipulation task",
            "Pick and place",
            "Product customization",
            "Specific tasks",
            "Unstructured environments"
        ],
        "doc_abstract": "© Springer International Publishing Switzerland 2015.Robots can play a significant role in product customization but they should leave a repetitive, low intelligence paradigm and be able to operate in unstructured environments and take decisions during the execution of the task. The EuRoC research project addresses this issue by posing as a competition to motivate researchers to present their solution to the problem. The first stage is a simulation competition where Pick & Place type of tasks are the goal and planning, perception and manipulation are the problems. This paper presents a skill-based architecture that enables a simulated moving manipulator to solve these tasks. The heuristics that were used to solve specific tasks are also presented. Using computer vision methods and the definition of a set of manipulation skills, an intelligent agent is able to solve them autonomously. The work developed in this project was used in the simulation competition of EuRoC project by team IRIS and enabled them to reach the 5th rank.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Online SLAM based on a fast scan-matching algorithm",
        "doc_scopus_id": "84884726130",
        "doc_doi": "10.1007/978-3-642-40669-0_26",
        "doc_eid": "2-s2.0-84884726130",
        "doc_date": "2013-10-03",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "localization",
            "real-time",
            "Real-time operation",
            "Scan-matching",
            "Simultaneous localization and mapping",
            "SLAM approach"
        ],
        "doc_abstract": "This paper presents a scan-matching approach for online simultaneous localization and mapping. This approach combines a fast and efficient scan-matching algorithm for localization with dynamic and approximate likelihood fields to incrementally build a map. The achievable results of the approach are evaluated using an objective benchmark designed to compare SLAM solutions that use different methods. The result is a fast online SLAM approach suitable for real-time operations. © 2013 Springer-Verlag.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "From an autonomous soccer robot to a robotic platform for elderly care",
        "doc_scopus_id": "84861984252",
        "doc_doi": null,
        "doc_eid": "2-s2.0-84861984252",
        "doc_date": "2012-06-13",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Biomedical Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2204"
            }
        ],
        "doc_keywords": [
            "Developed countries",
            "Elderly care",
            "Hardware and software",
            "Home care",
            "Independent living",
            "Innovative solutions",
            "Number of peoples",
            "Nursing homes",
            "Robotic platforms",
            "Robotic soccer",
            "Soccer robot"
        ],
        "doc_abstract": "Current societies in developed countries face a serious problem of aged population. The growing number of people with reduced health and capabilities, allied with the fact that elders are reluctant to leave their own homes to move to nursing homes, requires innovative solutions since continuous home care can be very expensive and dedicated 24/7 care can only be accomplished by more than one care-giver. This paper presents the proposal of a robotic platform for elderly care integrated in the Living Usability Lab for Next Generation Networks. The project aims at developing technologies and services tailored to enable the active aging and independent living of the elderly population. The proposed robotic platform is based on the CAMBADA robotic soccer platform, with the necessary modifications, both at hardware and software levels, while simultaneously applying the experiences achieved in the robotic soccer environment.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "A mobile robotic platform for elderly care",
        "doc_scopus_id": "79960496492",
        "doc_doi": null,
        "doc_eid": "2-s2.0-79960496492",
        "doc_date": "2011-07-25",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Computational Theory and Mathematics",
                "area_abbreviation": "COMP",
                "area_code": "1703"
            },
            {
                "area_name": "Applied Mathematics",
                "area_abbreviation": "MATH",
                "area_code": "2604"
            }
        ],
        "doc_keywords": [
            "Elderly care",
            "Hardware and software",
            "Independent living",
            "Mobile robotic",
            "Next generation network",
            "Robotic platforms",
            "Robotic soccer"
        ],
        "doc_abstract": "This paper presents the proposal of a robotic platform for elderly care integrated in the Living Usability Lab for Next Generation Networks. The project aims at developing technologies and services tailored to enable the active aging and independent living of the elderly population. The proposed robotic platform is based on the CAMBADA robotic soccer platform, with the necessary modifications, both at hardware and software levels, while simultaneously applying the experiences achieved in the robotic soccer environment.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Control and monitoring of a robotic soccer team: The base station application",
        "doc_scopus_id": "71049158832",
        "doc_doi": "10.1007/978-3-642-04686-5_25",
        "doc_eid": "2-s2.0-71049158832",
        "doc_date": "2009-11-16",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Autonomous robot",
            "Base station applications",
            "Control and monitoring",
            "Efficient architecture",
            "Human interference",
            "Robotic soccer",
            "Robotic soccer team",
            "Software applications"
        ],
        "doc_abstract": "In robotic soccer, teams of autonomous robots play soccer according to rules similar to the official FIFA rules. The game is refereed by a human and his orders are communicated to the teams using an application called \"Referee Box\". No human interference is allowed during the games except for removing malfunctioning robots and re-entering robots in the game. The base station, a software application as described in this paper, has a determinant role during the development of a robotic soccer team and also during a game. This application must control the agents interpreting and sending high level instructions, like Start or Stop, and monitor information of the robots, for example the position and velocity, allowing easily to attest the feasibility of the robots behavior. This paper discusses the importance of the control and monitoring of a robotic soccer team, presenting the main challenges and the approaches that were used by the CAMBADA team in the conception of the base station application. As far as we know, no previous work has been published about the study of these important problems and the discussion of an efficient architecture to a base station application. The results obtained by the team confirms the good performance of this software, both during the games and in the development of the team. © 2009 Springer Berlin Heidelberg.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Multi-agent debugging and monitoring framework",
        "doc_scopus_id": "80051506774",
        "doc_doi": "10.3182/20061002-2-br-4906.00020",
        "doc_eid": "2-s2.0-80051506774",
        "doc_date": "2006-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Control and Systems Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2207"
            }
        ],
        "doc_keywords": [
            "Debug",
            "Hard task",
            "Middle sized league",
            "Monitoring frameworks",
            "Multi agent",
            "Multi systems",
            "Multi-Processes",
            "Robotic soccer team"
        ],
        "doc_abstract": "In this paper we present a framework developed for the CAMBADA Middle-sized league robotic team, which allows human developers to better understand the robots actions during a game. Robotic soccer teams are in their nature dynamic multi-process and multi-agent systems, and knowing what is happening in all processes running on the agents at the same time is a hard task. To accomplish this task we developed a framework to create log files, one per process, and to interlace them later. The logs represent robot's knowledge. The framework allows the synchronization and visualization of logs and videos. Videos give the actual real behaviors. This will allow us to understand the robot's reasoning. A GUI utility to navigate and search inside log files was also developed.",
        "available": true,
        "clean_text": "serial JL 314898 291210 291718 291882 291883 31 IFAC Proceedings Volumes IFACPROCEEDINGSVOLUMES 2016-04-23 2016-04-23 2016-04-23 2016-04-23 2016-04-23T09:02:33 S1474-6670(15)31196-4 S1474667015311964 10.3182/20061002-2-BR-4906.00020 S350 S350.1 HEAD-AND-TAIL 2022-05-20T10:40:22.839963Z 0 0 20060101 20061231 2006 2016-04-23T09:20:26.364478Z rawtext articleinfo articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid hubeid indexeddate isbn isbns isbnnorm isbnsnorm issfirst issn issnnorm issuelist itemstage itemtransactionid itemweight openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sortorder srctitle srctitlenorm srctype ssids alllist content subj tomb vol volfirst volissue volumelist yearnav affil articletitle auth authfirstini authfull authkeywords authlast primabst ref 1474-6670 14746670 978-3-902661-20-3 9783902661203 false 39 39 20 20 Volume 39, Issue 20 21 114 120 114 120 2006 2006 2006-01-01 2006-12-31 2006 1st IFAC Workshop on Multivehicle Systems article fla Copyright © 2006 IFAC. Published by Elsevier Ltd. All rights reserved. MULTIAGENTDEBUGGINGMONITORINGFRAMEWORK FIGUEIREDO J KITANO 1997 340 347 H PROCEEDINGSFIRSTINTERNATIONALCONFERENCEAUTONOMOUSAGENTSAGENTS97 ROBOCUPROBOTWORLDCUPINITIATIVE REIS 2000 29 40 L FCPORTUGALTEAMDESCRIPTIONROBOCUP2000SIMULATIONLEAGUECHAMPIONVOL2019 SILVA 2005 781 788 V TROLLTECH FIGUEIREDOX2006X114 FIGUEIREDOX2006X114X120 FIGUEIREDOX2006X114XJ FIGUEIREDOX2006X114X120XJ item S1474-6670(15)31196-4 S1474667015311964 10.3182/20061002-2-BR-4906.00020 314898 2016-04-23T04:20:26.364478-04:00 2006-01-01 2006-12-31 true 1453745 MAIN 7 49132 849 656 IMAGE-WEB-PDF 1 First IFAC Workshop on Multivehicle Systems MULTI-AGENT DEBUGGING AND MONITORING FRAMEWORK Jo~o Figueiredo, Nuno Lau, Artur Pereira a IEETA/DETI, Universidade de Aveiro joao.figueiredo@ieeta.pt, lau@det.ua.pt, artur@det.ua.pt Abstract: In this paper we present a framework developed for the CAMBADA Middle-sized league robotic team, which allows human developers to better understand the robots actions during a game. Robotic soccer teams are in their nature dynamic multi-process and multi-agent systems, and knowing what is happening in all processes running on the agents at the same time is a hard task. To accomplish this task we developed a framework to create log files, one per process, and to interlace them later. The logs represent robot's knowledge. The framework allows the synchronization and visualization of logs and videos. Videos give the actual real behaviors. This will allow us to understand the robot's reasoning. A GUI utility to navigate and search inside log files was also developed. Keywords: monitoring, debug, multi-agent, multi-systems, robotics, MSL, Middle-Sized League 1. INTRODUCTION RoboCup (Kitano et al., 1997) is an international joint project to promote AI, robotics, and related fields. It is an attempt to foster AI and intelligent robotics research by providing a standard problem where wide range of technologies can be integrated and examined. RoboCup chose to use soccer as a central topic of research, aiming at innovations developed for soccer playing robots to be applied later for socially significant problems and industries. CAMBADA (Almeida et al., 2004b) is the MiddleSized League soccer team from the University of Aveiro, and is composed of three field players and a goal-keeper. By itself the team is a dynamic multi-agent system with all players sharing their perception of the game field. Each robot is an autonomous unit, capable of making decisions in real-time based on its own sensorial data and from data received from its team mates. The software each robot runs is composed of several programs, all running simultaneously, taking large amounts of decisions in a very short period of time and performing complex tasks, which makes it very difficult to understand its reasoning while it's playing. Following the robot's reasoning based only on external observation is also difficult because it all happens very fast from the human point of view and most of the robots internal state is hidden. And we also need to consider that their decisions are based not only on information received from its own sensors but from the other team mates as well. This difficulty turns the process of tuning and debugging the decision mechanisms quite hard. To solve this problem a framework which uses the concept of layered disclosure (Stone et al., 1999) and extends its functionalities was developed. It allows each process to log its data to a separate file and later join them to analyze the information saved as if it was on a continuous time-line. This process can be performed for each robot. A GUI program that allows navigating the files, searching for specific events and synchronize 114 First IFAC Workshop on Multivehicle Systems video from the robots and other external sources was also developed. This paper is organized as follows. This introduction is followed by section 2 with the main specifications that led to the development of the framework. Sections 3 and 4 discuss log creation and log navigation, respectively. Section 5 presents the GUI application developed for navigating the logs, synchronizing videos and searching for specific events. Section 6 introduces another tool for automatically determining the robots position in the field and help on the development of a self localization technique. Section 7 presents some results and finally on section 8 the conclusion of this paper. knowledge and its real behavior. It is composed of a back end and a front end. The former is a library of functions and allows for the production of log files including video data. The latter is library of objects and a GUI application that allows the user to interact with single and multi-file logs from one or multiple agents. The tool allows for the synchronized visualization of the robot's reasoning through the contents of the log files, and of its external behavior, by displaying synchronously recorded video of the robot acting in the field. 2.1 Main Requirements To create the framework to support the manipulation of log files several key points were defined. First of all it should support generic text with information pertinent to the program. Second, it should be possible to organize the information by category, eg. vision, decision, etc and by level of detail so that when reading the log files, the user may have the ability to analyze specific parts of it. CAMBADA robots run several processes at the same time so it's easier to create the framework so that it allows each program to write its own log file. Some form of synchronization is required to later be able to open them and read the information synchronously. This allows for the production of log files in different processes in the same machine, or even in different machines, and for overall analysis of the collected information. When applied to a soccer team this allows for: · analyze together log data from different processes of a soccer player; · analyze together log data from processes on different players; · compare log data from a soccer player with data obtained with some monitoring system; · analyze the robot's reasoning; · analyze the real data on which robot's reasoning was generated. Navigating log files and searching for specific information is another aspect to include in the specification. This means that some form of bookmarking is required for fast searching. Recording video images is also required to be able to see what the robot sees at a given time and understand its decisions with the textual information. Finally and probably the most important feature of the back end is the easiness of use so that other people will rapidly adapt to its interface and use it in their software. 2. SPECIFICATION CAMBADA soccer team is composed of four players, three field players and a goal-keeper. Each robot operates autonomously processing the information obtained from the cameras, the base micro-controllers and also from the other team mates. Fig. 1. CAMBADA Soccer Player World information is shared between the robots using the RtDB TDMA protocol (Almeida et al., 2004a). The purpose of the RtDB (Santos et al., 2004) is to serve as both local and shared area for communication among processes within the same robot and communication among different robots and also to create a channel to communicate with the micro-controllers using FTT-CAN (Silva et al., 2005). The RtDB is implemented using RTAI, a real-time layer for the Linux kernel. Understanding what a particular robot is doing and why it is doing that is not easy, since it is a complex system, its world changes dynamically and it takes a lot of decisions per second. To help in this task we propose a debugging and monitoring system that simultaneously shows robot's 115 First IFAC Workshop on Multivehicle Systems 2.2 Log structure Since we will be logging multiple forms of information (text, image, bookmarking), we need to create different record types to record that information in the log files and to help navigating in them. So far we identified 4 types of records: · Text to record formatted text messages; · Video to save one image for example from the vision or from an external camera; · Bookmark to place a bookmark for a specific category and later allow seeking on the information; · Registration to register a new category of the tree to file; The information contained in the logs may be overwhelming. On the other hand it should be as easy to visualize as possible. This has led to the use of classified information: vertically by level of detail; and horizontally by subject using a tree of categories. To organize information by level of detail we use some points derived from the concept of Layered Disclosure as proposed by (Stone et al., 1999), where the relevant information is organized in layers. Layers give us the depth of the information, that is, layers with smaller numbers indicate highlevel reasoning of the robot and layers with higher numbers add more and more detail to the lower ones. We extended the concept of layered disclosure with the inclusion of a tree of categories. This concept of tree was implemented on another library for logging system events (log4cpp (Bakker et al., 2005)). The tree of categories is important to better organize the information, not only by its importance but by its type. Figure 2 shows an example of a tree of categories where it is possible to see the detailed structure of run (the agent of the robot) and vision which controls the front camera. The tree also gives the possibility to stop/start sending information of a given category to the log file in runtime or allow the person reading the files to hide categories that are not relevant for the analysis of the problem. To be able to analyze multiple log files from one robot or from multiple robots, a common time line is required in all files. This can be done including a time-stamp in each record. Time-stamps can be obtained from the computer clock or from the RtDB/RTAI (Santos et al., 2004). If we want to log data on multiple robots playing at the same time and later read it simultaneously, we need to synchronize their clocks. Synchronization can be done with NTP servers when using the computer clock as the source of time-stamps or from the RTAI layer in the Linux kernel. Fig. 2. An example of a tree of categories with two programs running 2.3 Visualization of logs Reading the log files and understanding the sequence in which the programs are executed is simple but it is highly time-consuming to do it by hand. This led us to create a second library to read log files simultaneously, interlacing them and give the person using it the impression that only one log file for each robot exists, the front end. This is done on-the-fly with all the selected log files and gives the user the exact order on which the programs ran. A GUI application was also developed in conjunction with the front end to allow navigation in the log and searching information by specific text, bookmarks, time, etc. The framework includes the set of both developed libraries and the application to interactively analyze the log. 3. LOG PRODUCTION CAMBADA robots run several processes in realtime simultaneously which makes impossible to use prints on the screen for debugging. By using the monitoring framework's back end, every running program creates its own log file. The default file type is \"Formatted Text \" where every record is encoded in plain readable text, but other formats can be developed as well.\"XML\" 1 or even a \"binary\" format are possible. Every file is composed of records. There are four types of records created so far: Registration, Text, Video, Bookmark. The type of information each record contains is described in section 2.2. Every record is composed, of: · · · · 1 a time-stamp; a type; a category; specific data. Language web site: Extensible Markup 116 First IFAC Workshop on Multivehicle Systems Here's an example of a registration and a text records: 35203551142 REGC /run/ctrlloop/decision/defender/ 35203839343 TEXT /run/ctrlloop/integration/ball/ 2 CORRIGIDA ws->ball is 1.86, 0.29 The first record has no specific data. It indicates that the program has just registered category /run/ctrlloop/decision/defender. The category being registered is defender but its full path along the tree of categories is written to the log file. The specific data of the second record is composed of a level of detail (2) and free text. It shows that the ball was seen at position (1.86, 0.29) relative to the robot's position and orientation. To write these records to file and manage the tree of categories, several functions are available to the user and they are described in section 3.1. · logRegisterSubModule - registers a new category under any other existing category and returns an handle · logEnableOutput - given the handle, enables logging of this category; it can also enable logging of all the subtree below this category · logDisableOutput - given the handle, disables logging of this category; it can also disable logging of all the subtree below this category Categories can be created and enabled/disabled on the fly when a program is running and can depend on conditions or program options, avoiding the need for recompiling. Figure 3 shows a simplified view of its components. 3.1 System Architecture When creating the back end library to write log files, one of the key aspects was to keep it as simple as possible to the user. So we decided the best is to present it as a library of functions in C. Here is a small set of the most important functions available: · logInitialize - given the file name initializes the tree of categories with the root category · logTerminate - terminates all the logging facilities of the library, closes all files and releases all memory allocated · logText - saves a text record · logBookmark - saves a bookmark · logYuv - saves a video image Using categories is optional. An user may use only the root category which is created automatically by the library. Liblog is the main block. It implements the initialization of the library and the logging functions available to the user. Names implements the functions to manage the tree of categories. Error is a common block which makes available a set of functions to analyze errors of the library. Error is used by Liblog and by Names to manage errors internally and can also be used be the user to print or analyze them. All functions provided by these blocks are developed using dynamic buffers to prevent suspending the process execution and maintain the impact on the performance to a minimum. Also, all functions have a small number of parameters and some of them are similar to system functions, making them very easy to use. Fig. 3. User interface block diagram Using long strings, like the ones shown in the records example of section 3, to identify catThe remaining blocks: crecord, cwriter and ccategories can be cumbersome and they are also egory are support classes for the objects used prone to typing errors. To overcome this, an handle/descriptor number is created for each category internally by the library: different record types, and returned to the user by the logRegisterNewModule formatted text output and each category in the tree, respectively. This means that the core of the and logRegisterSubModule functions when new framework is built in C++ because it is simple to categories are registered. The handle may be used write code that closely represents the conceptual in subsequent calls to logging functions to identify categories. model of the project using an Object Oriented programming language. The back end interface These are the most important functions to manis a wrapper to these objects in C so it will be age the tree of categories simple to use. To add new functionalities to the framework like new types of records or new log · logRegisterNewModule - registers a new category under the root of the tree and refile formats it's as easy as creating new derived turns an handle classes of these. 117 First IFAC Workshop on Multivehicle Systems 4. LOG NAVIGATION 4.1 Synchronization To read data from different log files and retrieve joined information a kind of synchronization is required. This synchronization is based on timestamps included in each record, on every file. Rebuilding the original sequence on which the records were saved to the log files is possible just by implementing an algorithm to seek the record with the closest time-stamp to the current one. Several classes that represent the front end of the framework are implemented as seen in figure 4, using C++ and the STL library to maintain the portability between multiple platforms. They implement gradually several forms of navigating the information: · CFile - Implements basic file I/O, open, read and seek functionalities; · CParser - Implements file interpretation, creates records from a file and allows sequential navigation on them and has some caching built-in; · CTimeNavigator - Extends the CParser functionalities by adding the ability to navigate using time-stamps (seek to time-stamp) besides the already existing sequential navigation; · CCursor - Uses all the functionalities of the classes above and a look ahead technique to allow sequential navigation and by timestamp on multiples files at the same time; them to the current time-stamp. Current timestamp can be interpreted as the current position of the cursor. CCursor makes available to the user, the timestamp limits for the set of files and the ability to seek to a specific position and navigate from there, forward or backwards. The tree of categories can be created by the user from the log files managed by CCursor by means of CCategory objects and CCategoryIterator iterators which implement depth-first search algoritm. Based on CCursor, it was possible to develop the GUI application (section 5) that receives the records already \"organized\" so they can be filtered and displayed according to their nature, either text or video. 5. LOGREADERQT APPLICATION To make practical use the log files in CAMBADA to debug the robot's software a GUI application was developed using the Qt framework (Trolltech, 2005). An image of the main window is shown in figure 5. So far this application has two modes of displaying information, one textual and one with video. Fig. 5. Logreader main window When LogreaderQt starts it creates a CCursor object and an empty tree of categories. The CCursor object will maintain and manage the set of log files provided by the user and it will also allow navigating the records to extract information to display and to create the tree of categories. Log files can be added and removed from the set whenever it is required. Navigation in the set of files is entirely done by CCursor object. Figure 5 shows the tree of categories, inside each window, that is created when CCursor opens files. It is possible to create empty categories on the tree and to \"mount\" log files in them, using the same analogy of a file Fig. 4. User interface block diagram 4.2 Multiple log file navigation CCursor is the top level class for this front end library of the framework. Its name comes from the analogy of a sliding cursor used to navigate all the records on multiple files. It can manipulate multiple log files at the same time and synchronize 118 First IFAC Workshop on Multivehicle Systems system. This allows to separate logs from different agents and applications if required. Filtering details and/or hiding data is possible using context menus either for categories of data or for level of detail of information. This way an user can hide everything that is not important and read only what matters most for a particular analysis. LogreaderQt gives the user several ways of searching for what he's looking for in the log. It is possible to search information using: · records - seek a number of records at a time and showing them; · time - seek some time forward or backwards in the log. The time units for the files and navigation are user selectable; · bookmarks - seek inside the log to the next or previous bookmark of the selected category; this way it's possible to jump from one control cycle to the next for example; · video - seek to the next or previous image of the selected category; · play - play mode to keep advancing the records and video until the user instructs the program to stop; · regular expressions - in the future; Finally video and text are synchronized, which means when a text record is selected the video jumps to the nearest previous image. This simplifies the process of analyzing information by the user as it allows the direct comparison of robots internal state and reality as seen by the camera. camera has its own software, figure 6, to identify the field limits, the robotic agents in the field and log their position (text and video) to a file, using the framework. Comparing this log and the robots' logs should give us the ability to identify current problems and evaluate new solutions. 7. RESULTS To demonstrate a typical application of the framework, log files were created on two robots that exhibited a strange behavior while playing soccer. The setup for the experience consisted on leaving the robots side by side and placing the ball at a distance were the problem was visible. It was clear that if they seen the ball simultaneously and if their distance to the ball was similar at that time, robot number 3 was always the one to change to striker. After opening the log files with the application it became clear were the problem was coming from. Figure 7 shows one of the images recorded by the robot's log. Figure 8 shows an excerpt of textual information from the log files. There we can see that robot number 3 detects the ball at a distance of 4 meters and robot 1 at 6 meters. Clearly robot 3 thinks it is the closest to the ball and changes its behavior to striker. The source of the problem is in the neural network that translates pixels from the image to distances in the field not being properly calibrated. After analyzing the rest of the log we also discovered that the vision of robot 3 was not returning any distances greater than 5 meters. 6. REAL POSITION MONITORING One of the problems we faced while developing the soccer team is the fact that the robot's absolute position on the field is not trustable. Moving along the field while playing, when the robot's absolute position is updated only by odometry it tends to accumulate errors after travelling a few dozen meters. Fig. 7. Log image from the vision Fig. 6. Top viewer detecting a robot top marker Facing this problem we devised a solution to help quantify the error of the current solution and test new solutions as they are implemented. Like the Robocup's Small-Sized League, we incorporated a video camera on the top of the game field. This Fig. 8. Excerpt from the textual information Like this problem, that was quickly discovered, many others can be easily spotted with the ability to cross information from multiple processes and multiple agents simultaneously if we use these tools. 119 First IFAC Workshop on Multivehicle Systems 8. CONCLUSION In this paper we presented a framework developed for debugging a robotic soccer team which proved to be useful for a human user to understand the reasoning of an agent. Although it has been developed for soccer, its implementation has been carefully done to allow it to be easily adaptable to other projects where off-line debugging of multiple autonomous robots with different categories of information is required. It's main capabilities were easiness of use on single and multi-agent systems, multiple log files per agent (reading and writing), information organization in categories and level of detail, synchronization with video and different methods of searching information in the log. Silva, Valter, Ricardo Marau, Lu´ Almeida, is J. Ferreira, M. Calha, P. Pedreiras and J. Fonseca (2005). Implementing a distributed sensing and actuation system: The CAMBADA robots case study. In: Proceedings of the 10th IEEE International Conference on Emerging Technologies and Factory Automation. Vol. 2. pp. 781­788. Stone, Peter, Patrick Riley and Manuela Veloso (1999). Layered Extrospection: Why is the agent doing what it's doing?. Fourth International Conference on Autonomous Agents (Agents-2000). Trolltech (2005). Trolltech - Cross-platform C++ GUI development Online Reference Documentation. In: REFERENCES Almeida, Lu´ is, Frederico Santos, Tullio Facchinetti, Paulo Pedreiras, Valter Silva and Lu´ Seabra Lopes (2004a). Coordinating disis tributed autonomous agents with a real-time database: The cambada project.. In: ISCIS. pp. 876­886. Almeida, Luis, Luis Seabra Lopes, P. Bartolomeu, E. Brito, M. B. Cunha, J. P. Figueiredo, P. Fonseca, C. Lima, R. Marau, N. Lau, P. Pedreiras, A. Pereira, A. Pinho, F. Santos, L. Seabra Lopes and J. Vieira (2004b). CAMBADA: Team Description Paper. In: CD of the Robocup Symposium / TDP. Bakker, Bastiaan, Cedric Le Goater, Marc Welz, Lynn Owen andSteve Ostlind, Marcel Harkema, Uwe Jger, Walter Stroebel, Glen Scott, Tony Cheung, Alex Tapaccos, Brendan B. Boerner, Paulo Pizarro, David Resnick, Aaron Ingram, Alan Anderson and Emiliano Martin (2005). Log for C++ Project Website. 0.3.5rc3 ed. Kitano, Hiroaki, Minoru Asada, Yasuo Kuniyoshi, Itsuki Noda and Eiichi Osawa (1997). RoboCup: The Robot World Cup Initiative. In: Proceedings of the First International Conference on Autonomous Agents (Agents'97) (W. Lewis Johnson and Barbara Hayes-Roth, Eds.). ACM Press. New York. pp. 340­347. Reis, Lu´ Paulo and Nuno Lau (2000). FC Portuis gal Team Description: RoboCup 2000 Simulation League Champion. pp. 29­40. Vol. 2019. Springer-Verlag. Santos, Frederico, Luis Almeida, Paulo Pedreiras, Luis S Lopes and Tullio Facchinetti (2004). An Adaptive TDMA Protocol for Soft Real-Time Wireless Communication among Mobile Autonomous Agents. WACERTS'04 RTSS'04. 120 anslates pixels from the image to distances in the field not being properly calibrated. After analyzing the rest of the log we also discovered that the vision of robot 3 was not returning any distances greater than 5 meters. 6. REAL POSITION MONITORING One of the problems we faced while developing the soccer team is the fact that the robot's absolute position on the field is not trustable. Moving along the field while playing, when the robot's absolute position is updated only by odometry it tends to accumulate errors after travelling a few dozen meters. Fig. 7. Log image from the vision Fig. 6. Top viewer detecting a robot top marker Facing this problem we devised a solution to help quantify the error of the current solution and test new solutions as they are implemented. Like the Robocup's Small-Sized League, we incorporated a video camera on the top of the game field. This Fig. 8. Excerpt from the textual information Like this problem, that was quickly discovered, many others can be easily spotted with the ability to cross information from multiple processes and multiple agents simultaneously if we use these tools. 119 First IFAC Workshop on Multivehicle Systems 8. CONCLUSION In this paper we presented a framework developed for debugging a robotic soccer team which proved to be useful for a human user to understand the reasoning of an agent. Although it has been developed for soccer, its implementation has been carefully done to allow it to be easily adaptable to other projects where off-line debugging of multiple autonomous robots with different categories of information is required. It's main capabilities were easiness of use on single and multi-agent systems, multiple log files per agent (reading and writing), information organization in categories and level of detail, synchronization with video and different methods of searching information in the log. Silva, Valter, Ricardo Marau, Lu´ Almeida, is J. Ferreira, M. Calha, P. Pedreiras and J. Fonseca (2005). Implementing a distributed sensing and actuation system: The CAMBADA robots case study. In: Proceedings of the 10th IEEE International Conference on Emerging Technologies and Factory Automation. Vol. 2. pp. 781­788. Stone, Peter, Patrick Riley and Manuela Veloso (1999). Layered Extrospection: Why is the agent doing what it's doing?. Fourth International Conference on Autonomous Agents (Agents-2000). Trolltech (2005). Trolltech - Cross-platform C++ GUI development Online Reference Documentation. In: REFERENCES Almeida, Lu´ is, Frederico Santos, Tullio Facchinetti, Paulo Pedreiras, Valter Silva and Lu´ Seabra Lopes (2004a). Coordinating disis tributed autonomous agents with a real-time database: The cambada project.. In: ISCIS. IPV 31196 S1474-6670(15)31196-4 10.3182/20061002-2-BR-4906.00020 IFAC MULTI-AGENT DEBUGGING AND MONITORING FRAMEWORK João Figueiredo Nuno Lau Artur Pereira IEETA/DETI, Universidade de Aveiro IEETA/DETI Universidade de Aveiro In this paper we present a framework developed for the CAMBADA Middle-sized league robotic team, which allows human developers to better understand the robots actions during a game. Robotic soccer teams are in their nature dynamic multi-process and multi-agent systems, and knowing what is happening in all processes running on the agents at the same time is a hard task. To accomplish this task we developed a framework to create log files, one per process, and to interlace them later. The logs represent robot's knowledge. The framework allows the synchronization and visualization of logs and videos. Videos give the actual real behaviors. This will allow us to understand the robot's reasoning. A GUI utility to navigate and search inside log files was also developed. Keywords monitoring debug multi-agent multi-systems robotics MSL Middle-Sized League References Almeida et al., 2004 Almeida, Luís, Frederico Santos, Tullio Facchinetti, Paulo Pedreiras, Valter Silva and Luís Seabra Lopes (2004a). Coordinating distributed autonomous agents with a real-time database: The cambada project. In: ISCIS. pp. 876-886. Almeida et al., 2004 Almeida, Luis, Luis Seabra Lopes, P. Bartolomeu, E. Brito, M. B. Cunha, J. P. Figueiredo, P. Fonseca, C. Lima, R. Marau, N. Lau, P. Pedreiras, A. Pereira, A. Pinho, F. Santos, L. Seabra Lopes and J. Vieira (2004b). CAMBADA: Team Description Paper. In: CD of the Robocup Symposium/TDP. Bakker et al., 2005 Bakker, Bastiaan, Cedric Le Goater, Marc Welz, Lynn Owen and Steve Ostlind, Marcel Harkema, Uwe Jger, Walter Stroebel, Glen Scott, Tony Cheung, Alex Tapaccos, Brendan B. Boerner, Paulo Pizarro, David Resnick, Aaron Ingram, Alan Anderson and Emiliano Martin (2005). Log for C++ Project Website. 0.3.5rc3 ed. Kitano et al., 1997 Hiroaki Kitano Asada Minoru Yasuo Kuniyoshi Itsuki Noda Eiichi Osawa RoboCup: The Robot World Cup Initiative W. Lewis Johnson Barbara Hayes-Roth Proceedings of the First International Conference on Autonomous Agents (Agents'97) 1997 ACM Press New York 340 347 Reis and Lau, 2000 Luís Paulo Reis Nuno Lau FC Portugal Team Description: RoboCup 2000 Simulation League Champion. Vol. 2019 2000 Springer-Verlag 29 40 Santos et al., 2004 Santos, Frederico, Luis Almeida, Paulo Pedreiras, Luis S Lopes and Tullio Facchinetti (2004). An Adaptive TDMA Protocol for Soft Real-Time Wireless Communication among Mobile Autonomous Agents. WACERTS'04 RTSS'04. Silva et al., 2005 Valter Silva Ricardo Marau Luís Almeida J. Ferreira M. Calha P. Pedreiras J. Fonseca Implementing a distributed sensing and actuation system: The CAMBADA robots case study Proceedings of the 10th IEEE International Conference on Emerging Technologies and Factory Automation 2 2005 781 788 Stone et al., 1999 Stone, Peter, Patrick Riley and Manuela Veloso (1999). Layered Extrospection: Why is the agent doing what it's doing?. Fourth International Conference on Autonomous Agents (Agents-2000). Trolltech, 2005 Trolltech Trolltech - Cross-platform C++ GUI development Online Reference Documentation. In: 2005 "
    },
    {
        "doc_title": "Exclusion relation of k out of n and the synthesis of speed-independent circuits [asynchronous circuits]",
        "doc_scopus_id": "84945334322",
        "doc_doi": "10.1109/SBCCI.2003.1232822",
        "doc_eid": "2-s2.0-84945334322",
        "doc_date": "2003-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Engineering (all)",
                "area_abbreviation": "ENGI",
                "area_code": "2200"
            }
        ],
        "doc_keywords": [
            "Access protocols",
            "Asynchronous circuit design",
            "Asynchronous circuits",
            "Bipartite graphs",
            "Circuit construction",
            "Circuit synthesis",
            "Signal synthesis",
            "Speed-independent circuits"
        ],
        "doc_abstract": "© 2003 IEEE.The mutual exclusion element (mutex) is a well-known hardware device used to fairly implement a mutual exclusion relation between concurrent entities, for instance in asynchronous circuit design. In this paper we generalize this notion introducing the exclusion relation of k out of n. We then propose a circuit construction, built up from mutex elements, of a hardware component implementing this exclusion relation. Finally, we present an example, in the field of speed independent asynchronous circuits, where this component is used.",
        "available": false,
        "clean_text": ""
    }
]