[
    {
        "doc_title": "Robust biped locomotion using deep reinforcement learning on top of an analytical control approach",
        "doc_scopus_id": "85117070684",
        "doc_doi": "10.1016/j.robot.2021.103900",
        "doc_eid": "2-s2.0-85117070684",
        "doc_date": "2021-12-01",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Software",
                "area_abbreviation": "COMP",
                "area_code": "1712"
            },
            {
                "area_name": "Control and Systems Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2207"
            },
            {
                "area_name": "Mathematics (all)",
                "area_abbreviation": "MATH",
                "area_code": "2600"
            },
            {
                "area_name": "Computer Science Applications",
                "area_abbreviation": "COMP",
                "area_code": "1706"
            }
        ],
        "doc_keywords": [
            "Deep reinforcement learning",
            "Dynamics models",
            "Genetic algorithm",
            "Humanoid robot",
            "Linear quadratic Gaussian",
            "Linear–quadratic–gaussian",
            "Modular walk engine",
            "Modulars",
            "Policy optimization",
            "Proximal policy optimization"
        ],
        "doc_abstract": "© 2021 Elsevier B.V.This paper proposes a modular framework to generate robust biped locomotion using a tight coupling between an analytical walking approach and deep reinforcement learning. This framework is composed of six main modules which are hierarchically connected to reduce the overall complexity and increase its flexibility. The core of this framework is a specific dynamics model which abstracts a humanoid's dynamics model into two masses for modeling upper and lower body. This dynamics model is used to design an adaptive reference trajectories planner and an optimal controller which are fully parametric. Furthermore, a learning framework is developed based on Genetic Algorithm (GA) and Proximal Policy Optimization (PPO) to find the optimum parameters and to learn how to improve the stability of the robot by moving the arms and changing its center of mass height. A set of simulations are performed to validate the performance of the framework using the official RoboCup 3D League simulation environment. The results validate the performance of the framework, not only in creating a fast and stable gait but also in learning to improve the upper body efficiency.",
        "available": true,
        "clean_text": "serial JL 271599 291210 291866 291870 291882 291883 31 Robotics and Autonomous Systems ROBOTICSAUTONOMOUSSYSTEMS 2021-10-01 2021-10-01 2021-10-14 2021-10-14 2021-11-01T10:55:17 S0921-8890(21)00185-8 S0921889021001858 10.1016/j.robot.2021.103900 S300 S300.1 FULL-TEXT 2022-02-09T11:58:40.089314Z 0 0 20211201 20211231 2021 2021-10-01T04:54:03.279527Z articleinfo articlenumber articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid hubeid indexeddate issn issnnorm itemstage itemtransactionid itemweight openaccess openarchive pg pgfirst pii piinorm pubdateend pubdatestart pubdatetxt pubyr sortorder srctitle srctitlenorm srctype ssids alllist content subj subheadings suppl tomb volfirst volissue volumelist yearnav figure table body mmlmath acknowledge affil articletitle auth authfirstini authfull authkeywords authlast footnotes grantnumber grantsponsor grantsponsorid highlightsabst orcid primabst ref vitae 0921-8890 09218890 true 146 146 C Volume 146 15 103900 103900 103900 202112 December 2021 2021-12-01 2021-12-31 2021 article fla © 2021 Elsevier B.V. All rights reserved. ROBUSTBIPEDLOCOMOTIONUSINGDEEPREINFORCEMENTLEARNINGTOPANALYTICALCONTROLAPPROACH KASAEI M 1 Introduction 2 Related work 2.1 Combination of model-based walking and ML algorithms 2.2 Combination of CPG-based Walking and ML algorithms 2.3 Combination of CPG-ZMP based walking and ML algorithms 2.4 Learning to walk from scratch 3 Dynamics model and stability criteria 3.1 Zero momentum point 3.2 Dynamics model 4 Controller 4.1 State estimator 4.2 Optimal gain 5 Reference trajectories planner 6 Learning framework 7 Overall structure 8 Simulations 8.1 Omnidirectional walk 8.2 Optimizing the walking parameters 8.3 Learning to improve the upper body efficiency 8.3.1 Original scenario results 8.3.2 Straightforward path results 9 Discussion 9.1 Features 9.2 Limitations 10 Conclusion Acknowledgment References KAJITA 1991 1405 1411 S ROBOTICSAUTOMATION1991PROCEEDINGS1991IEEEINTERNATIONALCONFERENCE STUDYDYNAMICBIPEDLOCOMOTIONRUGGEDTERRAINDERIVATIONAPPLICATIONLINEARINVERTEDPENDULUMMODE KAJITA 2003 1620 1626 S ROBOTICSAUTOMATION2003PROCEEDINGSICRA03IEEEINTERNATIONALCONFERENCEVOL2 BIPEDWALKINGPATTERNGENERATIONBYUSINGPREVIEWCONTROLZEROMOMENTPOINT KAJITA 2010 4489 4496 S INTELLIGENTROBOTSSYSTEMSIROS2010IEEERSJINTERNATIONALCONFERENCE BIPEDWALKINGSTABILIZATIONBASEDLINEARINVERTEDPENDULUMTRACKING SHIMMYO 2013 5137 5147 S FARAJI 2017 436 455 S GRIFFIN 2017 667 673 R 2017IEEERSJINTERNATIONALCONFERENCEINTELLIGENTROBOTSSYSTEMSIROS WALKINGSTABILIZATIONUSINGSTEPTIMINGLOCATIONADJUSTMENTHUMANOIDROBOTATLAS KASAEI 2019 1429 1434 M 2019IEEERSJINTERNATIONALCONFERENCEINTELLIGENTROBOTSSYSTEMS AROBUSTBIPEDLOCOMOTIONBASEDLINEARQUADRATICGAUSSIANCONTROLLERDIVERGENTCOMPONENTMOTION KASAEI 2019 1 6 M 2019IEEEINTERNATIONALCONFERENCEAUTONOMOUSROBOTSYSTEMSCOMPETITIONSICARSC AMODELBASEDBIPEDWALKINGCONTROLLERBASEDDIVERGENTCOMPONENTMOTION YAMAGUCHI 1999 368 374 J PROCEEDINGS1999IEEEINTERNATIONALCONFERENCEROBOTICSAUTOMATIONCATNO99CH36288CVOL1 DEVELOPMENTABIPEDALHUMANOIDROBOTCONTROLMETHODWHOLEBODYCOOPERATIVEDYNAMICBIPEDWALKING KHATIB 2008 303 312 O EUROPEANROBOTICSSYMPOSIUM2008 AUNIFIEDFRAMEWORKFORWHOLEBODYHUMANOIDROBOTCONTROLMULTIPLECONSTRAINTSCONTACTS ISHIHARA 2019 119 126 K SHAN 2000 1930 1935 J PROCEEDINGS2000IEEERSJINTERNATIONALCONFERENCEINTELLIGENTROBOTSSYSTEMSIROS2000CATNO00CH37113VOL3 DESIGNCENTRALPATTERNGENERATORFORHUMANOIDROBOTWALKINGBASEDMULTIOBJECTIVEGA LEE 2013 360 365 J LIU 2013 1206 1215 C YU 2013 441 456 J GUERTIN 2009 45 56 P ZHONG 2012 4735 4759 G MENELAOU 2019 1 12 E KASAEI 2019 99 111 M ROBOCUP2019ROBOTWORLDCUPXXIII AFASTSTABLEOMNIDIRECTIONALWALKINGENGINEFORNAOHUMANOIDROBOT ENDO 2008 213 228 G ABREU 2019 3 15 M ROBOTWORLDCUP LEARNINGRUNFASTERINAHUMANOIDROBOTSOCCERENVIRONMENTTHROUGHREINFORCEMENTLEARNING MACALPINE 2012 P TWENTYSIXTHAAAICONFERENCEARTIFICIALINTELLIGENCE DESIGNOPTIMIZATIONOMNIDIRECTIONALHUMANOIDWALKAWINNINGAPPROACHROBOCUP20113DSIMULATIONCOMPETITION OR 2010 452 460 J HE 2014 160 B KASAEI 2017 743 755 S IBERIANROBOTICSCONFERENCE AHYBRIDZMPCPGBASEDWALKENGINEFORBIPEDROBOTS CARPENTIER 2016 3555 3561 J 2016IEEEINTERNATIONALCONFERENCEROBOTICSAUTOMATIONICRA AVERSATILEEFFICIENTPATTERNGENERATORFORGENERALIZEDLEGGEDLOCOMOTION KORYAKOVSKIY 2018 2471 2477 I SONG 2014 5109 5114 K 2014IEEEINTERNATIONALCONFERENCEROBOTICSAUTOMATIONICRA CPGBASEDCONTROLDESIGNFORBIPEDALWALKINGUNKNOWNSLOPESURFACES MISSURA 2015 387 392 M 2015IEEERSJINTERNATIONALCONFERENCEINTELLIGENTROBOTSSYSTEMSIROS GRADIENTDRIVENONLINELEARNINGBIPEDALPUSHRECOVERY MASSAH 2013 3473 3486 A LIU 2016 39 54 J ABDOLMALEKI 2016 94 99 A 2016INTERNATIONALCONFERENCEAUTONOMOUSROBOTSYSTEMSCOMPETITIONSICARSC CONTEXTUALRELATIVEENTROPYPOLICYSEARCHCOVARIANCEMATRIXADAPTATION DHARIWAL 2017 P OPENAIBASELINES VUKOBRATOVIC 1970 25 36 M WINTER 1990 534 541 D MULTIPLEMUSCLESYSTEMS CONTROLBALANCEUPPERBODYDURINGGAIT KAJITA 2019 17 24 S 2019IEEERAS19THINTERNATIONALCONFERENCEHUMANOIDROBOTSHUMANOIDS POSITIONBASEDLATERALBALANCECONTROLFORKNEESTRETCHEDBIPEDROBOT CARVALHOMELO 2019 37 42 L 2019LATINAMERICANROBOTICSSYMPOSIUMLARS2019BRAZILIANSYMPOSIUMROBOTICSSBR2019WORKSHOPROBOTICSINEDUCATIONWRE LEARNINGHUMANOIDROBOTRUNNINGSKILLSTHROUGHPROXIMALPOLICYOPTIMIZATION TEIXEIRA 2020 34 39 H 2020IEEEINTERNATIONALCONFERENCEAUTONOMOUSROBOTSYSTEMSCOMPETITIONSICARSC HUMANOIDROBOTKICKINMOTIONABILITYFORPLAYINGROBOTICSOCCER MELO 2020 240 245 D 2020LATINAMERICANROBOTICSSYMPOSIUMLARS2020BRAZILIANSYMPOSIUMROBOTICSSBR2020WORKSHOPROBOTICSINEDUCATIONWRE PUSHRECOVERYSTRATEGIESTHROUGHDEEPREINFORCEMENTLEARNING ABREU 2019 1 8 M 2019IEEEINTERNATIONALCONFERENCEAUTONOMOUSROBOTSYSTEMSCOMPETITIONSICARSC LEARNINGLOWLEVELSKILLSSCRATCHFORHUMANOIDROBOTSOCCERUSINGDEEPREINFORCEMENTLEARNING MUZIO 2020 246 251 A 2020LATINAMERICANROBOTICSSYMPOSIUMLARS2020BRAZILIANSYMPOSIUMROBOTICSSBR2020WORKSHOPROBOTICSINEDUCATIONWRE DEEPREINFORCEMENTLEARNINGFORHUMANOIDROBOTDRIBBLING PICADO 2009 805 812 H BIOINSPIREDSYSTEMSCOMPUTATIONALAMBIENTINTELLIGENCE AUTOMATICGENERATIONBIPEDWALKBEHAVIORUSINGGENETICALGORITHMS SHAFII 2010 324 335 N ROBOCUP2010ROBOTSOCCERWORLDCUPXIV BIPEDWALKINGUSINGCORONALSAGITTALMOVEMENTSBASEDTRUNCATEDFOURIERSERIES DIEDAM 2008 1121 1126 H 2008IEEERSJINTERNATIONALCONFERENCEINTELLIGENTROBOTSSYSTEMS ONLINEWALKINGGAITGENERATIONADAPTIVEFOOTPOSITIONINGTHROUGHLINEARMODELPREDICTIVECONTROL HERDT 2010 719 737 A GRIFFIN 2016 1763 1768 R 2016IEEEINTERNATIONALCONFERENCEROBOTICSAUTOMATIONICRA MODELPREDICTIVECONTROLFORDYNAMICFOOTSTEPADJUSTMENTUSINGDIVERGENTCOMPONENTMOTION ASTA 2011 434 443 S EUROPEANCONFERENCEAPPLICATIONSEVOLUTIONARYCOMPUTATION NATUREINSPIREDOPTIMIZATIONFORBIPEDROBOTLOCOMOTIONGAITPLANNING MACALPINE 2017 473 485 P ROBOTWORLDCUP UTAUSTINVILLAROBOCUP20173DSIMULATIONLEAGUECOMPETITIONTECHNICALCHALLENGESCHAMPIONS KASAEI 2020 257 262 M 2020IEEEINTERNATIONALCONFERENCEAUTONOMOUSROBOTSYSTEMSCOMPETITIONSICARSC AROBUSTMODELBASEDBIPEDLOCOMOTIONFRAMEWORKBASEDTHREEMASSMODELPLANNINGCONTROL HAARNOJA 2018 1861 1870 T INTERNATIONALCONFERENCEMACHINELEARNING SOFTACTORCRITICOFFPOLICYMAXIMUMENTROPYDEEPREINFORCEMENTLEARNINGASTOCHASTICACTOR KASAEIX2021X103900 KASAEIX2021X103900XM 2023-10-14T00:00:00.000Z 2023-10-14T00:00:00.000Z © 2021 Elsevier B.V. All rights reserved. 2021-10-19T23:08:26.218Z FCT, Portugal Foundation for Science and Technology SFRH/BD/118438/2016 SFRH/BD/139926/2018 FCT Fundação para a Ciência e a Tecnologia This research is supported by Portuguese National Funds through Foundation for Science and Technology (FCT), Portugal through FCT scholarship SFRH/BD/118438/2016 . The second author is supported by FCT, Portugal under grant SFRH/BD/139926/2018 . 0 item S0921-8890(21)00185-8 S0921889021001858 10.1016/j.robot.2021.103900 271599 2022-02-09T11:58:40.089314Z 2021-12-01 2021-12-31 true 2788065 MAIN 13 67688 849 656 IMAGE-WEB-PDF 1 gr11 16780 145 328 fx1 5642 132 113 gr6 92251 361 659 fx3 5678 132 113 fx5 5798 132 113 gr5 55395 177 678 gr3 16573 147 386 fx2 8721 132 113 gr2 23530 199 464 gr10 29071 212 378 gr7 31450 192 379 gr9 29007 201 376 gr1 33011 192 614 gr4 50638 177 678 fx4 6185 132 113 gr12 15103 143 376 gr13 41919 210 535 gr8 26304 217 386 gr11 5236 97 219 fx1 13070 163 140 gr6 15478 120 219 fx3 17502 163 140 fx5 14995 163 140 gr5 5673 57 219 gr3 5129 83 219 fx2 21018 163 140 gr2 7615 94 219 gr10 18017 123 219 gr7 16760 111 219 gr9 17729 117 219 gr1 4578 68 219 gr4 5361 57 219 fx4 19141 163 140 gr12 3154 83 219 gr13 5909 86 219 gr8 4181 123 219 gr11 125477 643 1455 fx1 53948 583 500 gr6 731261 1596 2916 fx3 56853 583 500 fx5 55103 583 500 gr5 547646 785 3000 gr3 123084 651 1711 fx2 84459 583 500 gr2 196575 881 2055 gr10 357260 938 1673 gr7 371628 851 1677 gr9 373975 893 1667 gr1 247182 849 2720 gr4 510980 784 3000 fx4 57994 583 500 gr12 106692 634 1668 gr13 344359 928 2369 gr8 185114 960 1708 si19 20470 si187 2514 si103 23911 si23 3114 si70 1677 si1 2457 si11 3084 si141 3594 si131 4271 si174 2953 si121 23654 si71 18003 si182 9289 si136 3913 si56 6790 si83 7347 si189 11578 si132 4013 si102 8190 si175 2891 si94 9318 si185 1662 si173 4536 si95 4115 si73 1896 si155 12175 si179 5756 si57 7511 si9 6294 si84 6799 si139 4025 si142 3809 si61 6055 si129 1606 si190 749 si10 3680 si143 3896 si193 999 si138 4663 si112 7658 si170 5998 si99 3853 si67 2997 si47 18918 si2 6289 si105 2324 si144 2004 si145 2446 si125 5573 si28 40521 si79 4410 si100 1323 si186 6820 si184 2372 si62 4442 si167 2014 si81 1522 si117 2107 si113 1644 si158 3131 si78 8374 si72 8432 si25 3561 si127 4082 si5 3500 si128 1867 si171 4907 si12 23572 si7 6847 si106 2641 si166 2577 si134 3567 si135 5103 si16 8582 si181 1991 si24 3769 si119 1726 si192 14315 si96 4096 si86 2771 si68 3367 si15 1576 si118 1593 si188 3647 si60 1666 si22 1208 si101 6548 si80 1153 si69 3440 si165 5326 si97 3756 si20 3739 si77 12950 si59 9443 si133 7212 si26 2906 si164 2445 si162 2736 si180 2333 si13 2992 si169 1582 si58 12427 si168 1670 si114 1371 si108 3487 si116 16322 si122 2740 si107 3170 si126 1474 si21 2935 si3 21809 si172 3605 si6 6791 si8 12141 si18 19583 si124 5363 si74 1593 si82 7278 si63 10818 si4 1781 si157 3389 si85 2430 si64 10250 si111 6592 si176 916 si104 24765 si87 32014 si161 3772 si120 23929 am 2037839 ROBOT 103900 103900 S0921-8890(21)00185-8 10.1016/j.robot.2021.103900 Elsevier B.V. Fig. 1 An abstract overview of the proposed framework. The highlighted boxes represent functional modules and the white boxes correspond to exchange data among them. Fig. 2 Schematics of the dynamics models: (a) LIPM; (b) LIPM with vertical motion of COM; (c) Proposed model. Fig. 3 Overall architecture of the proposed controller. Fig. 4 Simulation results of examining the state estimator performance. In this simulation, the measurements are affected by a Gaussian noise N ( 0, 6.25e−4 ) to simulate uncertainties. In these plots, light-blue and light-red lines represent the measurements, solid-blue and solid-red lines are the estimated values, dashed black lines represent the references. (For interpretation of the references to color in this figure legend, the reader is referred to the web version of this article.) Fig. 5 Simulation results of examining the controller performance in presence of noises. In this simulation, the controller should track a references trajectories in presence of the noise N ( 0, 6.25e−4 ) . Fig. 6 Overall architecture of the proposed framework. The highlighted boxes represent the main modules and the exchanged information among them is represented by the white boxes. Fig. 7 Omnidirectional walk scenario. In this scenario, the simulated robot should follow the commands that are generated by an operator: dashed arrows show a set of commands that has been generated for this simulation, including forward walk, side walk, diagonal walk and turning while performing diagonal walking. Fig. 8 Evolution of the fitness. Fig. 9 The optimization scenario and the results of an exemplary test after optimizing the parameters. In this test, the simulated robot has been placed at a specific point which is 10 m far from the center of the field and it should walk towards the center as fast as possible. The results showed that the robot touched the midline at t = 11 . 52 s. Fig. 10 Stability optimization scenario. The robot exploits the most common walking patterns — forward walking and turning — to keep itself within a predefined squared area of side length 2 m. When inside that area, the robot walks forward as fast as possible. Otherwise, it turns at a random rate until it is directed towards the area. Fig. 11 Learning curves considering only the arms (blue) and considering arms and COM height (red). (For interpretation of the references to color in this figure legend, the reader is referred to the web version of this article.) Fig. 12 Mean speed comparison between the baseline (on the left) with the best optimization using the Arms & COM Height controller (on the right). These values were averaged for 500 successful episodes, where the robot runs for 12 m in a straight line. Fig. 13 Angular displacement performed by all arms joints (sum) during an episode, averaged for 500 successful episodes (on the left). The linear path described by the robot was divided into sections of 1 m, which are represented by each bar. The baseline is represented by the dotted red bars while the optimized version is represented by the solid blue bars. The same sort of analysis for all joints is depicted on the right. (For interpretation of the references to color in this figure legend, the reader is referred to the web version of this article.) Table 1 The best parameters. Parameter Symbol Value Step duration T s s 0.1274 s Step length x 0.09059 m Step width y 0.010086 m Step angle α − 0 . 2899 deg Height of swing z s w 0.038 m Torso inclination T I t o 5 . 601 deg Amplitude of height of COM A z −0.004 Amplitude of torso movement A t o −1.9195 Table 2 Summary of the results in the maximum speed scenario. Dynamics model Maximum speed LIPM 0.590 m/s LIPM + vertical motion of COM 0.630 m/s LIPM + vertical motion of COM + Torso 0.866 m/s Table 3 State space for the stability optimization. Parameter Data size (×32b) α 1 Gyroscope 3 Accelerometer 3 Joints position 20 Joints speed 20 Controller actions 20 Table 4 Original scenario results — average duration and speed ± SD, and success rate (30 s). Parameter Ep. length mean (s) Reach 30 s (%) Speed mean (m/s) Baseline 5.1 ± 2.9 0 0.602 ± 0.027 Arms 51.6 ± 31.8 68.8 0.710 ± 0.037 Arms & COM height 148.2 ± 153.0 87.6 0.956 ± 0.060 Table 5 Comparison results. Maximum speed Ability of changing direction Proposed framework 0.956 m/s Yes [19] 0.805 m/s Yes [46] 0.770 m/s Yes [25] 0.590 m/s Yes [38] 3.910 m/s No [21] 2.500 m/s No [51] 1.188 m/s No [41] 1.340 m/s No [50] 0.550 m/s No [45] 0.510 m/s No Table 6 Summary of the results in the maximum speed scenario. Dynamics model ML algorithm Maximum speed LIPM GA 0.590 m/s LIPM + vertical motion of COM GA 0.630 m/s LIPM + vertical motion of COM + Torso GA 0.866 m/s LIPM GA + PPO 0.710 m/s LIPM + vertical motion of COM GA + PPO 0.741 m/s LIPM + vertical motion of COM + Torso GA + PPO 0.956 m/s Robust biped locomotion using deep reinforcement learning on top of an analytical control approach Mohammadreza Kasaei a ⁎ Miguel Abreu b Nuno Lau a Artur Pereira a Luis Paulo Reis b a IEETA/DETI University of Aveiro, 3810-193 Aveiro, Portugal IEETA/DETI University of Aveiro Aveiro 3810-193 Portugal IEETA / DETI University of Aveiro 3810-193 Aveiro, Portugal b University of Porto, LIACC/FEUP, Artificial Intelligence and Computer Science Lab, Faculty of Engineering of the University of Porto, Portugal University of Porto, LIACC/FEUP, Artificial Intelligence and Computer Science Lab, Faculty of Engineering of the University of Porto Portugal bUniversity of Porto, LIACC/FEUP, Artificial Intelligence and Computer Science Lab, Faculty of Engineering of the University of Porto, Portugal ⁎ Corresponding author. This paper proposes a modular framework to generate robust biped locomotion using a tight coupling between an analytical walking approach and deep reinforcement learning. This framework is composed of six main modules which are hierarchically connected to reduce the overall complexity and increase its flexibility. The core of this framework is a specific dynamics model which abstracts a humanoid’s dynamics model into two masses for modeling upper and lower body. This dynamics model is used to design an adaptive reference trajectories planner and an optimal controller which are fully parametric. Furthermore, a learning framework is developed based on Genetic Algorithm (GA) and Proximal Policy Optimization (PPO) to find the optimum parameters and to learn how to improve the stability of the robot by moving the arms and changing its center of mass height. A set of simulations are performed to validate the performance of the framework using the official RoboCup 3D League simulation environment. The results validate the performance of the framework, not only in creating a fast and stable gait but also in learning to improve the upper body efficiency. Keywords Humanoid robots Modular walk engine Linear–Quadratic–Gaussian (LQG) Genetic Algorithm (GA) Proximal Policy Optimization (PPO) Deep Reinforcement Learning (DRL) 1 Introduction Developing a robust locomotion for bipedal robots is a challenging problem which has been investigated for decades. Although several walking approaches have been proposed and walking performance has considerably improved, it still falls short of expectations in certain domains, such as speed and stability. The question is how is it that humans can constantly change their direction when running, while keeping their stability, but humanoids cannot? To find a good answer for this question, we start by reviewing recently proposed walking frameworks, consequently identifying four points of view related with the development of a fast and stable gait. In the first point of view, the fundamental framework’s core is a dynamics model of the robot, based on which the walking planner and controller are designed. In this type of framework, to reduce the complexity of developing a whole body dynamics model, some constraints are considered. Based on these constraints, an abstract model is designed instead of a real whole body dynamics model [1–8]. It should be mentioned that several studies exist where a whole body dynamics model is developed [9–11]. In the second point of view, the core of the framework is a set of signal generators which are coupled together to generate endogenously rhythmic signals [12–15]. This type of framework is called Central Pattern Generator (CPG)-based framework and is inspired by the neurophysiological studies on invertebrate and vertebrate animals [16–18]. These studies showed that rhythmic locomotion like walking, running and swimming are generated by CPGs at the spinal cord that are connected together in a particular arrangement. In this type of framework, oscillators are assigned to each limb, typically to generate the setpoints (position, torque, etc.). Most humanoid robots have more than 20 Degrees of Freedom (DOF), therefore, adjusting the parameters of the oscillators is not only difficult but also trial-intensive [19]. Moreover, there is not a straight way to adapt sensory information to the oscillators. In the third point of view, the generation of walking trajectories is based on reinforcement learning (RL) or a heuristic algorithm [12,20,21]. In this type of framework, the walking trajectories will be generated after a training period which needs many samples and takes a considerable amount of time. During training, the framework tries to learn how to generate the walking trajectories, subject to an objective function. In the fourth point of view, the framework is designed by combining the aforementioned approaches [19,22–25]. This type of framework is generally known as a hybrid walking framework. It tries to leverage the different capabilities of each approach to improve the final performance. After studying all types of humanoid walking frameworks, to find the answer for the question raised in the beginning of this section, let us look at how a baby starts to walk. It starts by learning to stand for a few seconds. It then improves the stability after many experiments, takes a few steps, learns how to maintain equilibrium while moving; until finally, after a long process of trial and error, a robust walking behavior emerges. This process shows how a human learns from previous experiences to improve its walking performance. Based on these explanations, we believe that the ability to learn from past experiences is the most important difference between human walking and robot walking. Particularly, a robot should be able to learn how to generate efficient locomotion according to different situations (e.g., learning to recover its balance from postural perturbations). In the first two types of framework, the knowledge of robots is static, generally, and does not evolve from past experiences. Therefore, they need to at least re-tune the parameters to be able to adapt to new environments. In the third type of framework, the learning process typically does not consider any dynamics model and is designed based on learning from scratch, which is trial intensive and not applicable to a real robot directly. Several research groups have been exploring how to learn from previous experiences to improve stability and robustness. We believe the fourth type is the best approach to develop a robust biped locomotion framework. In this paper, we propose a tight coupling between analytical control approaches and machine learning (ML) algorithms to develop a robust walking framework. Particularly, our contribution is a biped locomotion framework composed of two major components — an analytical planner and controller; and a fully connected neural network. The former is responsible for optimally controlling the overall state of the robot based on an abstract dynamics model. It is also responsible for generating reference trajectories using dynamic planners with genetically optimized parameters and overcome uncertainties up to a certain degree. The latter component – a fully connected network – is optimized with reinforcement learning to control the arms residuals and the COM height of the robot, thus improving the upper body efficiency, which impacts the overall stability and speed of the robot. The remainder of this paper is structured as follows: Section 2 provides an overview of related work. In Section 3, the concept of ZMP will be used to define a specific dynamics model which is composed of two masses. Afterwards, in Section 4, this dynamics model will be used to design an optimal controller which is able to track the walking reference trajectories, even in the presence of uncertainties. Section 5 explains how the problem of generating walking reference trajectories can be decomposed into five distinct planners. In Section 6, we will describe our learning approach and explain its structure. The overall architecture of the proposed framework will be presented in Section 7. In Section 8, three simulations scenarios will be designed to validate the performance of the proposed framework. According to the simulation results, its discussion and comparison with related work will be provided in Section 9. Finally, conclusions and future research are presented in Section 10. 2 Related work Several of the proposed walking frameworks are based on learning approaches to generate a stable locomotion for biped and multi-legged robots. Using ML algorithms for biped locomotion has made remarkable progress recently. These studies showed that using these algorithms on top of analytical approaches can improve robustness and performance significantly [19,22]. In the remainder of this section, some recent proposed walking frameworks will be categorized and reviewed, focusing on those that use ML algorithms to improve their performance. 2.1 Combination of model-based walking and ML algorithms MacAlpine et al. [22] designed and implemented a learning architecture to enable a humanoid soccer agent to perform omnidirectional walk. In their architecture, the overall dynamics of a humanoid robot is abstracted by a double inverted pendulum model which is parameterized to be able to learn a set of parameters for different tasks. The performance of their framework has been validated using a set of simulations that have been designed using SimSpark, 1 1 a generic physical multiagent system simulator. The simulations results showed that their framework is able to learn multiple parameter sets according to the specified tasks. Kasaei et al. [19] proposed a closed-loop model-based walking framework. Their dynamics model is composed of two masses that takes into account the lower and upper body dynamics of the robot. Based on this dynamics model, they generate walking reference trajectories and also designed an optimal controller to track these references. They showed the performance of their framework by performing a set of simulations using a simulated NAO robot in SimSpark. Moreover, they optimized the parameters using a genetic algorithm (GA) and showed that the maximum forward walking speed of the simulated robot reached 80.5 cm/s. Carpentier et al. [26] proposed a generic and efficient walking pattern generator which is able to generate dynamically consistent motions. They argued that their approach is fast enough to generate the trajectory of COM along with the angular momentum according to the given configuration of contacts while the previous step is executing. Their method has been implemented on a real HRP-2 robot to demonstrate its interest. The experiment results showed that their method is able to generate long-step walking and climbing a staircase with handrail support. Koryakovskiy et al. [27] proposed two approaches for combining a Nonlinear Model Predictive Control (NMPC) with reinforcement learning to compensate model-mismatch. The first approach deals with learning a policy to compensate control actions to minimize the same performance measure as their NMPC. The second approach was focused on learning a policy based on the difference of a transition predicted by NMPC and the actual transition. They performed a set of simulations to show the feasibility of both approaches and to compare their performances. The simulation results showed that the second approach was better than the first one. Moreover, They deployed the second approach on a real humanoid robot named Robot Leo to perform squat motion to validate the performance of their approach. 2.2 Combination of CPG-based Walking and ML algorithms Song et al. [28] designed CPG-Based Control walking framework which is able to generate stable walking, even on unknown sloped surfaces. In their framework, the walking patterns are generated based on CPG theory and a PI controller is designed according to gyroscope and accelerometer information, allowing the adjustment of the upper body’s tilt angle to keep the robot’s stability. They performed some experiments using a real NAO humanoid robot and the results showed that the robot is able to walk successfully on unknown slopes. Missura et al. [29] proposed a walking framework which bootstraps a learning algorithm with a CPG-based walk engine. Their framework is composed of a feed-forward walking pattern generator, a state estimator and a balance controller. In their framework, while the robot is walking, the balance controller adjusts the step size based on the estimated error and also learns how to improve the walking performance by adjusting the swing leg parameters. The performance of their framework has been validated using a set of experiments on a real humanoid robot. The results showed that their framework is able to keep the robot’s stability even after applying a severe push. 2.3 Combination of CPG-ZMP based walking and ML algorithms Massah et al. [30] developed a hybrid CPG-ZMP controller to generate stable locomotion for humanoid robots. In their approach, a set of non-linear oscillators were used to generate walking trajectories and two controllers were developed to handle small and large disturbances. They optimized the walking parameters using the differential evolution (DE) algorithm. The performance of their approach was demonstrated in the Webots robot simulator using the NAO humanoid robot. Liu et al. [31] proposed a CPG-ZMP based walking framework which is inspired by biomechanical studies on human walking. In their framework, walking reference trajectories are generated offline according to a point mass model. They used a PD controller to modify the reference walking patterns to keep the robot’s stability. Moreover, their framework takes the vertical motion of the upper body into account to generate almost stretched knees. The performance of their framework has been validated using a set of experiments on a real NAO humanoid robot. The results proved the improvement of walking stability and energy efficiency. Kasaei et al. [25] developed a hybrid CPG-ZMP based walk engine for biped robots. Their walk engine has a hierarchical structure and it is fully parametric. They argued that this structure allows using a policy search algorithm to find the optimum walking parameters. To show this ability, they used an optimization technique based on Contextual Relative Entropy Policy Search with Covariance Matrix Adaptation (CREPS-CMA) [32] to tune the walking parameters. The performance of their walk engine has been validated by showing a fast and stable omnidirectional walk using a simulated Nao robot in Simspark ( 59 cm/s). 2.4 Learning to walk from scratch Abreu et al. [21] applied a reinforcement learning algorithm to develop a fast and stable running behavior from scratch. In their approach, the environment has been represented by 80 states and the action space is composed of 20 actions which were all the joints of a simulated humanoid robot. They used the Proximal Policy Optimization (PPO) based on the implementation provided by OpenAI [33]. The performance of their approach was shown by learning sprinting and stopping behaviors. The results demonstrated that both behaviors are stable and the sprinting speed stabilizes around 2 . 5 m/s which was a considerable improvement. Most of the aforementioned works combine a simplified model-based or a model-free approach with ML approaches to improve the performance of their walking. In the rest of this paper, we develop an optimal closed-loop walking pattern generator based on a more complex dynamics model which takes into account the vertical motion of the COM and the torso’s dynamics. Besides, we use the PPO algorithm which is one of the most successful deep reinforcement learning methods, on top of our walking pattern generator to improve its robustness and efficiency and also to provide more human-like walking. An abstract overview of the proposed framework is depicted in Fig. 1. 3 Dynamics model and stability criteria When designing a model-based walking, two general perspectives exist: (i) considering an abstract dynamics model which takes into account a trade-off between accuracy and simplicity; (ii) considering a whole-body dynamics model which is more accurate but, not only is it platform dependent but also resource-intensive due to its non-linear nature. In the rest of this section, the concept of Zero Momentum Point (ZMP) will be reviewed and then used to define an abstract dynamics model of a humanoid robot. 3.1 Zero momentum point ZMP has been proposed in [34] and is currently one of the most successful metrics in the walking literature. Particularly, it is a point on the ground where the ground reaction force (GRF) acts to cancel the gravity and the inertia. Normal human walking is a periodic motion which can be decomposed into two main phases: (i) Single Support (SS) and (ii) Double Support (DS) [35]. During SS phase, only one foot is in contact with the ground and the other foot swings towards the next planned foot position. In this paper, we used the ZMP as our main criterion for analyzing the stability of the robot while performing walking and it can be defined using the following equation: (1) p x = ∑ k = 1 n m k x k ( z ̈ k + g ) − ∑ k = 1 n m k z k x ̈ k ∑ k = 1 n m k ( z ̈ k + g ) , where n represents the number of parts that are considered in the dynamics model, m k is the mass of each part, ( x k , x ̇ k ) , are the horizontal position and acceleration, and ( z k , z ̈ k ) are the vertical position and acceleration of each mass, respectively. 3.2 Dynamics model Although considering a full body dynamics model is not impossible, it generally needs powerful computational resources. Therefore, it is not affordable for real-time implementation. To reduce the complexity of the model and its computation cost, the overall dynamics is approximated by an abstract model. Kajita and Tani [1] proposed an abstract model named Linear Inverted Pendulum Model (LIPM) which is a well-known abstract model in the community. LIPM is popular because it provides a simple, fast and efficient solution for walking dynamics that is suitable for real-time implementation. In this model, the overall dynamics of the robot is abstracted to a single mass that is connected to ground via a massless rod. Additionally, this model assumes that the vertical motion of the mass is restricted by a horizontally defined plane. According to these assumptions and using a set of predefined footsteps, the trajectory of Center of Mass (COM) can be obtained from a straightforward analytical solution which guarantees long-term stability. It should be mentioned that based on these assumptions, the equations in sagittal and frontal planes are equivalent and independent, therefore we just derive the equation in the sagittal plane. The schematic of this model is depicted in Fig. 2(a). Using (1) and considering the LIPM’s assumptions, the COM’s motion equation can be obtained as follows: (2) x ̈ c = ω 2 ( x c − p x ) , where ω = g z is the natural frequency of the pendulum, p x and x c represent the positions of ZMP and COM, respectively. As aforementioned, LIPM tries to keep the COM’s vertical position at a predefined position which causes the knee joints to be always bent. Indeed, walking with bent knees consumes more energy and does not resemble human walking [36]. To release this constraint and generate more energy efficient and human-like walking, a sinusoidal motion is assigned to the vertical motion of the COM: (3) z c = z 0 + A z cos ( 2 π S t e p T i m e t + ϕ ) , where z 0 denotes the COM’s initial height, A z is the amplitude, and ϕ represents the phase shift of the COM’s vertical sinusoidal motion. The initial value of these parameters are determined by an expert. Additionally, a controller can be designed to adjust these parameters based on sensory feedback. Although the current version of the dynamics model is able to provide fast and stable walking, it is not good enough to generate a very fast walking. In fact, in some situations like when a push is applied, the COM accelerates forward, and, as a consequence, the ZMP goes behind the Center of Gravity (COG). In this situation, the robot tries to decelerate the COM by applying a compensating torque at its ankles, keeping the ZMP inside the support polygon. The compensating torque will be saturated once the ZMP is at the support polygon’s boundary and, consequently, the robot is going to be unstable. In such situations, a human moves its torso to keep the ZMP inside the support polygon and prevent falling. To consider the effect of the torso’s motion in the dynamics model, another mass should be added to the dynamic model. This modification changes the dynamics model to be non-linear. Therefore, it does not have an analytical solution and it should be solved numerically. Biomechanical analysis of human walking showed that the torso motion can be represented by a sinusoidal function whose motion parameters are dependent on the current robot state, and terrain conditions. The interesting point is that if the torso is considered as a mass with a small sinusoidal movement relative to the hip ( sin ( θ t o ) = θ t o ), the dynamics model can keep its linearity. The schematic of this model is depicted in Fig. 2(c) and it can be represented by the following equation: (4) x ̈ c = μ ( x c + α l 1 + α θ t o − p x ) − α β l 1 + α β θ ̈ t o , α = m t o m c , β = z t o z c , μ = 1 + α 1 + α β ω 2 , x t o = x c + l θ t o , where x t o denotes the position of torso, θ t o , l are the angle of torso and length of torso, m c , m t o represent the masses of lower body and torso, z t o , z c are the torso and COM height, respectively. 4 Controller In this section, an optimal controller will be designed for tracking the reference trajectories to minimize the tracking error. To do that, Eq. (4) will be represented as a linear state space system. Then, this system will be discretized to be used in a discrete-time implementation. Afterwards, we will explain how this system can be used to design an optimal controller. The process of designing the controller starts by defining a linear state space system based on Eq. (4): (5) d d t x c x ̇ c θ t o θ ̇ t o ︸ X = 0 1 0 0 μ 0 μ α l 1 + α 0 0 0 0 1 0 0 0 0 ︸ A x c x ̇ c θ t o θ ̇ t o ︸ X + 0 0 − μ − α β l 1 + α β 0 0 0 1 ︸ B p x θ ̈ t o ︸ u , y = 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 ︸ C x c x ̇ c θ t o θ ̇ t o ︸ X . The presented system is a continuous system and should be discretized for implementation in discrete time. To discretize this system, we assume that x ̇ c , θ ̇ t o are linear. Therefore p x , θ ̈ t o are constant within a control cycle. Thus, the discretized system can be represented as follows: X ( k + 1 ) = A d X ( k ) + B d u ( k ) , (6) y ( k ) = C d X ( k ) , where k represents the current sampling instance, A d , B d , C d are the discretized versions of the A , B , C matrices in (5), respectively. According to this discretized dynamics model, an optimal closed-loop controller can be designed to track the reference trajectories. This controller is a Linear–Quadratic–Gaussian (LQG) which is composed of two main modules: a state estimator and an optimal controller gain. The overall architecture of this controller is depicted in Fig. 3. In the remaining of this section, each module will be explained and the overall performance of the controller will be validated. 4.1 State estimator An LQG controller is able to track the reference trajectories even in the presence of measurement noise. This controller uses a state estimator to cancel the effect of uncertainties which can be raised because of many aspects like errors in modeling the system, sensor noise, backlash of the gears, etc. In particular, this controller uses a state estimator to estimate the current state of the system according to the control inputs and the observations. In our target framework, we considered that the position of the joints is available through measurements and the torso orientation can be obtained based on an Inertial Measurement Unit (IMU) information which is mounted on the torso. Based on the joint information and using a Forward Kinematic (FK) model of the robot, the current configuration of the robot can be estimated. In this estimation, the support foot is considered to be in flat contact with the ground, which is not always true. Therefore, the whole body orientation with respect to the ground should be added to this estimation. To do so, the IMU information is used to rotate the current configuration. Based on this configuration, the COM position can be estimated at each control cycle and its velocity can be obtained from its position’s derivative, followed by a first-order lag filter. To validate the performance of this module, a simulation has been designed. In this simulation, the observations are modeled as a stochastic process by applying additive Gaussian noise to the measured states. The simulation results are shown in Fig. 4. According to the simulation results, the state estimator is able to estimate the states perfectly. 4.2 Optimal gain As shown in Fig. 3, the optimal control law is obtained using the following formulation: (7) u = − K x ̃ − x r x i , where x ̃ , x r denote the estimated states and the reference states, respectively. x i is the integration of error which is used to eliminate the steady-state error, K represents the optimal gain of the controller that should be designed to minimize the following cost function: (8) J ( u ) = ∫ 0 ∞ { z ⊺ Q z + u ⊺ R u } d t , where z = [ x ̃ x i ] ⊺ , R and Q are positive-semidefinite and positive-definite matrices which are determined by an expert. In fact, these matrices determine a trade-off between cost of control effort and tracking performance. Therefore, the performance of the controller is sensitive to these matrices. It should be noted that there is a straightforward solution to determine K based on solving a differential equation named Riccati Differential Equation (RDE). To check the performance of the proposed controller, a simulation has been performed. In this simulation, a set of reference trajectories has been generated and the controller should track this reference in presence of measurement noise. The simulation results are shown in Fig. 5. The results showed that the controller is able to track the references even when the measurements are affected by noise. In the next section, we explain how the reference trajectories are generated. 5 Reference trajectories planner Our walking reference trajectories planner is composed of five sub planners which are connected together hierarchically. The first level of this hierarchy is a footstep planner which generates a set of foot positions based on given step information and some predefined constraints (e.g., maximum and minimum step length, step width, distance between feet, etc.). To do so, we consider a state variable to represent the current state of the robot’s feet: (9) s = ( x l , y l , θ l , ϕ l , x r , y r , θ r , ϕ r ) , where x l , y l , θ l , x r , y r , θ r are the position and orientation of the left and right foots, respectively. ϕ l , ϕ r represent the current state of feet which is 1 if the foot is the swing foot and − 1 otherwise. Walking is a period motion which is generated by moving the right and the left legs alternating. Therefore, we parametrize a step action by a length and an angle from the swing foot position at the beginning of steps a = ( R , σ ) . According to the input parameters and the current state of the feet, an action should be taken and the state transits to a new state, s ′ = t ( s , a ) . Afterwards, the current footstep will be saved ( f i i ∈ N ) and ϕ l and ϕ r will be toggled. The second planner is the ZMP planner that uses the planned footstep information to generate ZMP reference trajectories. In our target framework, the ZMP reference planner is formulated as follows: (10) r z m p = f i , x f i , y 0 ≤ t < T s s f i , x + L s x × ( t − T s s ) T d s f i , y + L s y × ( t − T s s ) T d s T s s ≤ t < T s s + T d s , where f i = [ f i , x f i , y ] are the planned footsteps on a 2D surface ( i ∈ N ), L s x and L s y represent the step length and width, T s s , T d s are the single support and double support durations, respectively, and t is the time which will be reset at the end of each step ( t ≥ T s s + T d s ). The third planner is the swing leg planner which generates the swing leg trajectory using a cubic spline function. This planner uses three control points that are the position of the swing leg at the beginning of the step, the next footstep position and a point between them with a predefined height ( Z s w i n g ). The fourth planner is the global sinusoidal planner which generates three sinusoidal trajectories for the COM height, the torso angles and the arm positions. The fifth planner is the hip planner which uses the generated ZMP and torso trajectories to generate hip trajectory. Indeed, these trajectories are used to determine the positions of the hip at the begging and the end of step. Using these positions, Eq. (4) can be solved as a boundary value problem as follows: (11) x ( t ) = g x + ( g x − x f ) sinh ( μ ( t − t 0 ) ) + ( x 0 − g x ) sinh ( μ ( t − t f ) ) sinh ( μ ( t 0 − t f ) ) , where g x = r z m p x − α l 1 + α θ t o + α β l μ ( 1 + α β ) θ ̈ t o , and t 0 , t f , x 0 , x f are the times and corresponding positions of the hip at the beginning and end of a step, respectively. In this work, T d s is considered to be zero, which means ZMP transits to the next step at the end of each step instantaneously. Moreover, x f is assumed to be in the middle of current support foot and next support foot ( f i + f i + 1 2 ). 6 Learning framework The learning framework optimizes problems that are formalized as a Markov Decision Process (MDP) — a 4-tuple S , A , p , R — where S denotes the set of states, A the set of actions, and R the set of numerical rewards. The dynamics of the MDP is given by the state-transition probability function p ( s ′ | s , a ) : S × S × A ( s ) → [ 0 , 1 ] , which gives the probability of ending in state s ′ given the current state s and action a . The framework employs the Proximal Policy Optimization (PPO) algorithm, introduced by Schulman et al. [37], which was chosen due to its success in optimizing low-level skills concerning the NAO robot [21,38–41], and high-level skills [42], where it outperformed other algorithms such as TRPO or DDPG. The chosen implementation uses the clipped surrogate objective: L ( θ ) = E ˆ t m i n r t ( θ ) A ˆ t , c l i p ( r t ( θ ) , 1 − ε , 1 + ε ) A ˆ t , (12) with r t ( θ ) = π θ ( a t | s t ) π θ o l d ( a t | s t ) , where A ˆ t is an estimator of the advantage function at timestep t . The clip function clips the probability ratio r t ( θ ) in the interval given by [ 1 − ε , 1 + ε ] . This implementation alternates between sampling data from multiple parallel sources, and performing several epochs of stochastic gradient ascent on the sampled data, to optimize the objective function. The clipping parameter ε was set to 0.2, as suggested by Schulman et al. [37]. Also, as in the implementations published by OpenAI for the 3D humanoid environment [33], the entropy bonus was not used, and the number of optimization epochs and batches was set to 10 and 64, respectively. Some other hyperparameters were tuned using grid search: step size (2.5 × 10−4); batch size ( 4096 ); and the Adaptive Moment Estimation (Adam) [43] optimizer was set to use a constant scheduler. Finally, the Generalized Advantage Estimation (GAE) [44] algorithm’s parameters — gamma and lambda — were set to 0.99 and 0.95, respectively, accordingly to the ranges established by the GAE’s authors as best-performing for 3D biped locomotion. The policy is represented by a multilayer perceptron with two hidden layers of 64 neurons. The number of inputs, outputs, and the maximum number of time steps for the optimization are dependent on the scenario and will be described in Section 8.3. The training session was parallelized to improve the optimization duration. 7 Overall structure In this section, the previously introduced planner and controller will be coupled together to generate stable locomotion. To do that, we designed a modular framework composed of six main modules. Two modules are concerned with optimization algorithms — GA and PPO. The former optimizes the planners’ parameters based on a reward function that can be defined for specific purposes (e.g. maximum walking speed). On top of the resulting model, the PPO algorithm is used to adjust the COM height and optimize joint residuals. The optimization setup for both algorithms is described in Section 8. The overall architecture of this framework is depicted in Fig. 6. As shown in this figure, the walking process is controlled by a state machine which abstracts the process into four distinct states: Idle, Initialize, Single Support and Double Support. In this state machine, the transitions are triggered by a timer that is associated to each state. Additionally, it can be triggered by an emergency signal generated according to the controller’s state in key moments, such as when a swift move is necessary to regain equilibrium after a strong external perturbation. The Idle state is the initial state in which the robot is standing in place and waiting to receive a walking signal, which can be generated by an operator or a path planning algorithm. That signal triggers the Initialize state, in which the walking parameters and configurations are loaded from a data base. Afterwards, the robot is ready to walk by shifting its COM towards the first support foot. The next state is triggered after a predefined time. During Single Support State and Double Support State, the dynamics planner generates the walking reference trajectories according to the generated walking signal and the controller tries to track these references. At the same time, the neural network receives a set of observations, including data from inertial sensors, joints’ position and speed, target joint positions generated by the LGQ controller, and the target turning rate. The network outputs residuals which are added to the target joint positions before being fed to the simulator, which runs the next simulation step. The neural network also adjusts the height of the COM, which is then used by the dynamic planners in the following iteration. In the next section, a set of simulations will be carried out to verify the framework’s performance. Moreover, we will show how the planners parameters are optimized using a genetic learning approach, and what is the impact of the policy gradient algorithm on the performance of the framework. 8 Simulations In this section, we introduce a set of simulation scenarios to validate the performance of the proposed framework. The simulation scenarios have been designed using the official RoboCup 3D simulation environment which is based on SimSpark, a multi-agent simulator. This simulator relies on the Open Dynamics Engine (ODE) to simulate rigid body dynamics. The physics engine is updated every 0.02 s. The simulator can also be configured to update the physics engine just after receiving commands from all agents. This greatly improves simulation speed and provides a better environment for learning approaches. 8.1 Omnidirectional walk This scenario is designed to demonstrate the performance of the framework in providing an omnidirectional walk. The simulated robot starts from an idle state and follows a command comprising length ( X ), width ( Y ) and angle ( α ) of the step, which is determined by an operator. Note that the step time is constant and set to 0.2 s. To avoid discontinuity in the input command, a first-order lag filter is used, yielding a smooth transition. At the beginning of this scenario, the robot is walking in place and all the setpoints are zero ( X = 0 . 0 m, Y = 0 . 0 m, α = 0 . 0 deg /s). At t = 10 s, the operator sets the step length ( X = 0 . 05 m) to generate forward walking; at t = 20 s, the operator resets the step length ( X = 0 . 0 m) and sets the step width ( Y = 0 . 04 m) to generate side walking; at t = 30 s, while the robot is performing side walking, the operator sets the step length ( X = 0 . 05 m) to generate diagonal walking; at t = 40 s, while the robot is performing diagonal walking, the robot is commanded to turn right simultaneously, by setting the step angle ( α = 10 deg); and finally, at t = 60 s, all the set points are reset and the robot starts walking in place. A set of snapshots of this simulation is depicted in Fig. 7. The simulation results showed that the framework was able to generate omnidirectional walking according to the input commands. A video of this simulation is available online at: 8.2 Optimizing the walking parameters This scenario is focused on optimizing the walking parameters to generate the fastest stable forward walk. This process is executed before applying the reinforcement learning algorithm, which means that all the residual arm target joints are set to zero, and the height of the COM is computed by the dynamic planners. In this scenario, the robot is placed 10 m away from the halfway line and it should walk straight forward towards that line as fast as possible. Initially, the best parameters were hand-tuned and, after several attempts, the maximum walking speed did not exceed 53 cm/s. Afterwards, based on the parametric nature of the proposed planner, a GA is used to optimize the parameters to improve the walking speed. To do that, 8 parameters of the framework have been selected to be optimized. These parameters are the step length ( x ), step width ( y ), step angle ( α ), height of the swing leg ( z s w ), duration of a step ( T s s ), torso inclination T I t o , amplitude of the COM ( A z ) and amplitude of the torso movement ( A t o ). In our optimization scenario, the simulated robot should walk forward for 10 seconds and its performance will be evaluated based on the following cost function: (13) f ( ϕ ) = − | δ x | + | δ y | + ε , where ϕ represents the selected parameters, δ X , δ Y are the distance covered in X-axis and Y -axis, respectively, ε is used to penalize the robot when it falls during walking ( ε = 100 ) otherwise it is zero. According to this cost function, the simulated robot is rewarded for straight forward walk and it is penalized for deviation and falling. A slow and stable forward walking (0.11 m/s) is used as an initial solution to start the optimization process. It should be noted that, each iteration has been repeated three times and the average of the finesses was used to be sure about the walking performance. The fitness values have been recorded for each iteration and the average fitness values can be visualized in Fig. 8. The average fitness value starts at around 85 and after about 2000 iterations, it drops under 10 , which is much better than the first solution. The optimization has been executed for 6000 iterations. After optimizing the parameters, the walking velocity reaches 0.866 m/s, which is 61 % faster than the best hand-tuned solution. The best parameters found by the GA are shown in Table 1. The optimization scenario and a set of snapshots of a test are shown in Fig. 9. A video of this simulated scenario is available online at: To compare the effectiveness of the dynamics model, this scenario has been repeated for the dynamics models (a) and (b) presented in Fig. 2. To do so, the planner and the controller have been adjusted according to the dynamics models and then their parameters have been refined manually. Finally, this simulation scenario has been repeated to find the maximum forward speed of each model. The simulation results are summarized in Table 2. The simulation results validated that the sinusoidal motion of the height of COM improves the stability and allows the robot to move faster in comparison with fixed COM. 8.3 Learning to improve the upper body efficiency This scenario was designed to improve the efficiency of the walking gait in terms of speed and stability during the most common walking patterns — forward walking and turning. To mitigate the effects of the learning process on the maneuverability and predictability of the walking trajectory, only the arms actuators and COM height were optimized. The robot is initially placed in an arbitrary position within a squared area of side length 2 m, as depicted in Fig. 10. It then starts walking forward with the best parameters found in Section 8.2. When the robot steps out of the predefined area, it starts to turn in either direction at a random rate | α | ∈ [ 30 deg/s, 60 deg/s], until it is facing the square again. This process is repeated continuously until the episode ends with the robot falling (detected when its z coordinate drops below 0.3 m). The fact that the robot runs at full speed when changing direction, and that it needs to constantly adapt to different turning rates makes this a very challenging scenario. The interaction between agent and environment is performed at discrete time steps ( t = { 0 , 0 . 02 , 0 . 04 , … } ). The robot’s behavior was optimized by the PPO algorithm, using 67 observed variables, as listed in Table 3. The first parameter indicates the current turning rate. The inertial sensors (gyroscope and accelerometer) are both composed of 1 variable per axis in a three-dimensional space. The position and speed of all joints (excluding the head) is important to obtain a correct state representation, even though the action space only controls a limited number of these joints. Finally, the joint positions computed by the analytical controller are fed to the algorithm, and later added as residuals to the output values. These positions can be used by the network to predict the next analytical state, so that the produced residuals can be adjusted accordingly. In preliminary tests, removing this information from the state space results in a loss of performance between 5 % and 20 %, depending on possible action space combinations. The action space encompasses four angle variables per arm (shoulder roll, shoulder pitch, elbow yaw, elbow roll) and one variable to define the setpoint of the COM height at each step. The arm joints angles are computed by summing the analytical controller’s output to the neural network’s corresponding output. This forms a controller which uses the planner’s arms control signals both as state data and action bias. The objective of this scenario is to improve forward speed and stability at all times (i.e., when moving forward or turning). The former requirement is met by rewarding the agent for stepping forward and not sideways, which can be numerically translated into the scalar projection of its velocity vector v → in the direction of its orientation unit vector o → . Let v → = P t − P t − 1 , where P t and P t − 1 are the current and previous positions of the robot, respectively. The partial reward to motivate forward speed is then max ( v → ⋅ o → , 0 ) , where ⋅ denotes the dot product. The minimum reward value is limited to zero because walking backward or sideways is not worse than falling. The second requirement — stability — is motivated by a constant k , set empirically to 0.01, that rewards the agent for staying alive. More precisely, it favors stability at the cost of lowering the speed. The complete immediate reward can then be formulated as: (14) r = max ( v → ⋅ o → , 0 ) + k . The learning algorithm was first applied to the arms actuators and later extended to the COM height. Fig. 11 shows the average return evolution when learning only the arms (blue line) and after adding the COM height (red line). The former optimization plateaued at around 20 million time steps, and the latter at around 26 million time steps. It is important to note that the return obtained during the optimization was based on a stochastic policy whereas in the following tests, we used the corresponding deterministic policy. The results were divided into two sections: Original scenario — the robot is tested in the same scenario used for learning (see Fig. 10) and the analysis delves into the same metrics used to define the reward function; Straightforward path — the robot’s direction is constantly corrected to describe a linear path and the resulting behavior is analyzed in terms of efficiency. 8.3.1 Original scenario results The robot was evaluated with regard to stability and speed in the same scenario where the learning algorithm was applied. Stability was measured by the episode length, since it terminates once the robot falls to the ground. No time limitation was imposed per episode. Speed was measured at every iteration and averaged at the end of the episode. Table 4 lists the average speed and duration results for 500 episodes, as well as the success rate in reaching the 30 s mark without falling. The first line corresponds to the walk optimized in Section 8.2, which is used as a baseline. The robot walks on average for 5.1 s, with a standard deviation (SD) of 2.9 s before falling, generally on the first or second sharp change of direction, never being able to reach 30 s. The mean speed, from a stand-still position to the end of each episode, was 0.602 m/s with a SD of 0.027 m/s. After learning how to control the arms, the episode duration increased tenfold, on average, and the mean speed rose to 0.710 m/s. Most falls occur at an advanced stage or during the initial sharp turns, hence the larger standard deviation. Adding the COM height to the group of controlled variables increased the episode length to almost 15 times the initial value. When compared to the version without the COM height adaptation, this metric improved approximately 3 times, and the percentage of episodes in which the robot walked for at least 30 s went from 68.8 % to 87.6 %. The mean speed rose to 0.956 m/s, a gain of almost 60 % in relation to the baseline. In every episode the robot eventually falls. As aforementioned, when the robot steps out of the predefined area, it starts to turn with a random turning rate between 30 and 60 deg/s, in either direction. Most falls occur when approximating the upper limit or when the rotation direction is inverted after the robot enters and exits the predefined area in a short time (e.g. when stepping over a corner of that area). A video comparing the baseline with the Arms & COM height optimization is available online at: 8.3.2 Straightforward path results To evaluate the gait efficiency without taking stability into account, the displacement of certain joints as well as the average speed were analyzed, as discussed later in this section. Due to the challenging nature of the learning scenario, and to provide a fair comparison with the baseline algorithm, a simplified setup was developed. The objective is to compare the baseline and best optimization algorithms while the robot tries to describe a straight path of 12 m length. The turning parameter is computed at every iteration to maximize the path’s linearity using a reactive proportional controller. After 12 m, if the robot has not fallen, the episode is considered successful. Fig. 12 compares the baseline’s mean speed for the entire path with its improved version using the Arms & COM height controller. In both cases, the speed values were averaged for 500 successful episodes. In comparison with Table 4, the baseline algorithm improved its mean speed from 0.602 m/s to 0.704 m/s. The Arms & COM height optimization went from 0.956 m/s to 0.958 m/s, indicating that the robot has a virtually constant speed, whether turning or not. The improvement of the optimized version in relation to the baseline is about 36 %. The total angular displacement performed by certain groups of joints during a successful episode was analyzed, as this metric provides a reasonable indicator of energy consumption, considering that the actuators load is not disclosed by the server. Fig. 13 compares the displacement sum of the arms joints with the displacement sum of all robot joints (except for the head). This analysis was performed for different stages of the linear path described by the robot. In the first meter, as expected, the robot spends more energy while gaining momentum, and then it stabilizes. Considering only the arms joints (shoulder roll, shoulder pitch, elbow yaw, elbow roll), the average angular displacement for the entire episode rose 49 %. Despite this result, the same analysis performed for all joints yields an increment of only 10 %. Therefore, without considering stability gains, the ratio of relative speed improvement to relative displacement increment in successful episodes is 3.6. In essence, the robot became much more energy efficient, as a small raise in energy consumption led to a considerably faster gait. 9 Discussion Simulation results showed that the framework is able to generate a fast and stable omnidirectional walk and improve its performance by learning how to control the arms and the height of the COM. Indeed, the results showed that providing a tight coupling between analytical approaches and ML improves the performance considerably. In the remaining of this section, we point out the features and limitations of the proposed framework and provide comparisons with the results of previous works. 9.1 Features • Architecture: the modular architecture of the proposed framework provides some important properties such as reducing the complexity and increasing the flexibility. In comparison with approaches that are based on heuristic methods [12–15,45,46] or based on learning from scratch [12,20,21], our framework is expected to be able to migrate to different humanoid platforms with small changes to the control module. • Computational efficiency: unlike the approaches presented in [6,27,47–49] which are based on online optimization (e.g., MPC), our controller was designed on top of an offline optimization algorithm. Therefore, it does not need powerful computational resources and it can be deployed on any platform easily. • Considering the upper body dynamics: most of the presented approaches in the literature used LIPM as their dynamics model, mainly due to its linearity and simplicity. Unlike LIPM-based approaches, we take into account the robot’s upper body dynamics and we showed how this consideration helps to enhance the stability and speed of the robot, while improving the energy efficiency as a ratio of mean speed to total angular displacement. • Release the height of COM constraint: LIPM-based approaches assume a fixed vertical position for the COM. According to this assumption, the knee joints have to be bent while the robot is walking, which is harmful for the knee joints and causes additional energy consumption. Additionally, walking with bent knees is not very human-like. We released this constraint by assuming a sinusoidal movement for the vertical position of the COM. We showed that this assumption not only cancels the explained limitations but it also improves the stability. • Performance: to have an entirely fair comparison, the performance of our framework should be compared with other frameworks in the same scenario and simulator. To do so, we took into consideration the maximum forward speed, and our proposed framework provides a faster walk than the agents in [19,25,45,46,50] and slower than [21,38,41,51]. However, the faster examples are solely focused on sprinting forward, without the basic ability of changing direction. The comparison results are summarized in Table 5. • Learning flexibility: we believe that a humanoid robot should be able to learn from experience, not only to create a new behavior but also to improve its skills. Additionally, it should be able to reuse its knowledge in different scenarios. Learning how to control the arms and the COM height had a positive effect under different conditions in which the robot was not explicitly trained. The robot preserved its stability and speed when subjected to constant orientation adjustments to move in a straight line. Furthermore, we kept the learning module on top of the others to allow situations where generalization is not a conceivable solution. This is an improvement over learning from scratch approaches, as it builds upon a logical and reliable initial solution. This analytical layer is less prone to modeling errors than the learning layer, which is critical when transferring the knowledge to a real robot. After tuning the control module to new conditions, the neural network can be partially retrained by leveraging existing knowledge of similar tasks. This architecture allows for a plethora of modular optimizations aimed at stability, speed, energy efficiency, path optimization, context awareness problems (including prevention and recovery), etc. • Controller and robustness: some approaches [22,25] used a dynamics model just to generate a feed-forward walk and did not consider any controller to track the references. Other approaches that are based on learning from scratch [12,20,21] do not take into account any controller explicitly. Instead, they use a learning algorithm to develop a controller implicitly. Unlike these approaches, we believe that a robust controller is an essential module of a walking framework due to the unstable nature of a humanoid robot. More specifically, when deploying the framework on a real robot, using a closed-loop walking is the best approach because it provides a better stability guarantee. Moreover, as we showed, the ML algorithms can be used on top of this controller to improve its performance. The summary of the results in the maximum speed scenario are presented in the Table 6. 9.2 Limitations • Swing leg dynamics: the legs of a humanoid robot are generally composed of six joints and have non-negligible masses. In our dynamics models, the swing leg is considered to be massless, which affects the controller performance. Taking into account the inertia and mass of the swing leg can minimize tracking errors and improve the controller’s performance [5,52]. • Reality gap: the disparity between reality and simulation is a matter of concern when employing offline ML techniques. Learning to improve the upper body efficiency took between 20 and 26 million time steps. Other works have shown the optimization of robotic tasks, such as squatting [27], using RL combined with an analytical controller, in under 10 million time steps. Haarnoja et al. also demonstrated that learning humanoid tasks from scratch can also be performed in about the same period of time [53]. However, it must be noted that these approaches employed distinct environments with different robots, directly influencing the complexity of the task. Learning to run using the NAO robot in SimSpark can take close to 200 million time steps [21,38]. Nevertheless, 20–26 million time steps can still be characterized as poor sample efficiency, as it takes a considerable amount of time and must be performed in a simulated environment. The gap between both worlds largely affects the transferability of knowledge to the real robot. Despite the scientific community’s considerable effort to reduce this gap, it remains an issue when dealing with intricate robot models. Additionally, it is not possible to learn directly on the real robot due to the high potential of mechanical damage. 10 Conclusion In this paper, we have tackled the problem of developing a robust biped locomotion framework by proposing a tight coupling between an analytical control approach and a reinforcement learning approach. The overall architecture of the framework was composed of six distinct modules which were hierarchically structured. We abstracted the overall dynamics of a humanoid robot into two masses. Then, we used the ZMP concept and some assumptions to represent this dynamics model as a linear state space system. The system was composed of four states and we explained how it can be used to plan and control the walking reference trajectories. Particularly, the planner was composed of five sub-planners and the controller was formulated as an LQG controller, which is not only robust against uncertainties but also provides a promising solution using an offline optimization. We analyzed the performance of the controller in the presence of uncertainties using simulations and the results validated its performance. Moreover, we illustrated how the parametric nature of the framework allows us to use the PPO algorithm on top of an analytical control approach to improve the performance of the framework. Finally, the performance of the proposed framework was validated in several simulated scenarios. The first two scenarios were focused on examining the ability of the framework in generating an omnidirectional walk and finding the maximum velocity of the forward walk. The third scenario was designed to assess the capability of the learning module in improving the framework’s performance. The robot learned how to move its arms and COM height in order to improve the stability, speed and energy efficiency. This limited action space enabled the robot to learn how to walk without falling for much longer periods (almost 15 times longer), while also improving the speed by 60 % when walking forward or turning. As future work, we would like to design a more accurate dynamics model by considering the mass of the swing leg to improve the framework’s performance, and test it on a more realistic simulator. Additionally, we would like to extend our framework by adding another module that learns a set of specific actions to handle emergency conditions . Declaration of Competing Interest The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper. Acknowledgment This research is supported by Portuguese National Funds through Foundation for Science and Technology (FCT), Portugal through FCT scholarship SFRH/BD/118438/2016. The second author is supported by FCT, Portugal under grant SFRH/BD/139926/2018. References [1] Kajita S. Tani K. Study of dynamic biped locomotion on rugged terrain-derivation and application of the linear inverted pendulum mode Robotics and Automation, 1991. Proceedings., 1991 IEEE International Conference on 1991 IEEE 1405 1411 S. Kajita, K. Tani, Study of dynamic biped locomotion on rugged terrain-derivation and application of the linear inverted pendulum mode, in: Robotics and Automation, 1991. Proceedings., 1991 IEEE International Conference on, IEEE, 1991, 1405–1411. [2] Kajita S. Kanehiro F. Kaneko K. Fujiwara K. Harada K. Yokoi K. Hirukawa H. Biped walking pattern generation by using preview control of zero-moment point : Robotics and Automation, 2003. Proceedings. ICRA’03. IEEE International Conference on, Vol. 2 2003 IEEE 1620 1626 S. Kajita, F. Kanehiro, K. Kaneko, K. Fujiwara, K. Harada, K. Yokoi, H. Hirukawa, Biped walking pattern generation by using preview control of zero-moment point, in: Robotics and Automation, 2003. Proceedings. ICRA’03. IEEE International Conference on, 2, IEEE, 2003, 1620–1626. [3] Kajita S. Morisawa M. Miura K. Nakaoka S. Harada K. Kaneko K. Kanehiro F. Yokoi K. Biped walking stabilization based on linear inverted pendulum tracking Intelligent Robots and Systems (IROS), 2010 IEEE/RSJ International Conference on 2010 IEEE 4489 4496 S. Kajita, M. Morisawa, K. Miura, S. Nakaoka, K. Harada, K. Kaneko, F. Kanehiro, K. Yokoi, Biped walking stabilization based on linear inverted pendulum tracking, in: Intelligent Robots and Systems (IROS), 2010 IEEE/RSJ International Conference on, IEEE, 2010, 4489–4496. [4] Shimmyo S. Sato T. Ohnishi K. Biped walking pattern generation by using preview control based on three-mass model IEEE Trans. Ind. Electron. 60 11 2013 5137 5147 S. Shimmyo, T. Sato, K. Ohnishi, Biped walking pattern generation by using preview control based on three-mass model, Industrial Electronics, IEEE Transactions on 60 (11) (2013) 5137–5147. [5] Faraji S. Ijspeert A.J. 3LP: A linear 3D-walking model including torso and swing dynamics Int. J. Robot. Res. 36 4 2017 436 455 S. Faraji, A. J. Ijspeert, 3LP: A linear 3D-walking model including torso and swing dynamics, the international journal of robotics research 36 (4) (2017) 436–455. [6] Griffin R.J. Wiedebach G. Bertrand S. Leonessa A. Pratt J. Walking stabilization using step timing and location adjustment on the humanoid robot, atlas 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) 2017 IEEE 667 673 R. J. Griffin, G. Wiedebach, S. Bertrand, A. Leonessa, J. Pratt, Walking stabilization using step timing and location adjustment on the humanoid robot, atlas, in: 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), IEEE, 2017, 667–673. [7] Kasaei M. Lau N. Pereira A. A robust biped locomotion based on linear-quadratic-gaussian controller and divergent component of motion 2019 IEEE/RSJ International Conference on Intelligent Robots and Systems 2019 IEEE 1429 1434 M. Kasaei, N. Lau, A. Pereira, A robust biped locomotion based on linear-quadratic-gaussian controller and divergent component of motion, in: 2019 IEEE/RSJ International Conference on Intelligent Robots and Systems, IEEE, 2019, 1429–1434. [8] Kasaei M.M. Lau N. Pereira A. A model-based biped walking controller based on divergent component of motion 2019 IEEE International Conference on Autonomous Robot Systems and Competitions (ICARSC) 2019 IEEE 1 6 M. M. Kasaei, N. Lau, A. Pereira, A model-based biped walking controller based on divergent component of motion, in: 2019 IEEE International Conference on Autonomous Robot Systems and Competitions (ICARSC), IEEE, 2019, 1–6. [9] Yamaguchi J. Soga E. Inoue S. Takanishi A. Development of a bipedal humanoid robot-control method of whole body cooperative dynamic biped walking Proceedings 1999 IEEE International Conference on Robotics and Automation (Cat. No. 99CH36288C), Vol. 1 1999 IEEE 368 374 J. Yamaguchi, E. Soga, S. Inoue, A. Takanishi, Development of a bipedal humanoid robot-control method of whole body cooperative dynamic biped walking, in: Proceedings 1999 IEEE International Conference on Robotics and Automation (Cat. No. 99CH36288C), 1, IEEE, 1999, 368–374. [10] Khatib O. Sentis L. Park J.-H. A unified framework for whole-body humanoid robot control with multiple constraints and contacts European Robotics Symposium 2008 2008 Springer 303 312 O. Khatib, L. Sentis, J.-H. Park, A unified framework for whole-body humanoid robot control with multiple constraints and contacts, in: European Robotics Symposium 2008, Springer, 2008, 303–312. [11] Ishihara K. Itoh T.D. Morimoto J. Full-body optimal control toward versatile and agile behaviors in a humanoid robot IEEE Robot. Autom. Lett. 5 1 2019 119 126 K. Ishihara, T. D. Itoh, J. Morimoto, Full-body optimal control toward versatile and agile behaviors in a humanoid robot, IEEE Robotics and Automation Letters 5 (1) (2019) 119–126. [12] Shan J. Junshi C. Jiapin C. Design of central pattern generator for humanoid robot walking based on multi-objective ga Proceedings. 2000 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2000)(Cat. No. 00CH37113), Vol. 3 2000 IEEE 1930 1935 J. Shan, C. Junshi, C. Jiapin, Design of central pattern generator for humanoid robot walking based on multi-objective ga, in: Proceedings. 2000 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2000)(Cat. No. 00CH37113), 3, IEEE, 2000, 1930–1935. [13] Lee J. Seo K. Generation of walking trajectory of humanoid robot using cpg J. Korean Inst. Intell. Syst. 23 4 2013 360 365 J. Lee, K. Seo, Generation of walking trajectory of humanoid robot using cpg, Journal of Korean Institute of Intelligent Systems 23 (4) (2013) 360–365. [14] Liu C. Wang D. Chen Q. Central pattern generator inspired control for adaptive walking of biped robots IEEE Trans. Syst. Man Cybern.: Syst. 43 5 2013 1206 1215 C. Liu, D. Wang, Q. Chen, Central pattern generator inspired control for adaptive walking of biped robots, IEEE Transactions on Systems, Man, and Cybernetics: Systems 43 (5) (2013) 1206–1215. [15] Yu J. Tan M. Chen J. Zhang J. A survey on cpg-inspired control models and system implementation IEEE Trans. Neural Netw. Learn. Syst. 25 3 2013 441 456 J. Yu, M. Tan, J. Chen, J. Zhang, A survey on cpg-inspired control models and system implementation, IEEE transactions on neural networks and learning systems 25 (3) (2013) 441–456. [16] Guertin P.A. The mammalian central pattern generator for locomotion Brain Res. Rev. 62 1 2009 45 56 P. A. Guertin, The mammalian central pattern generator for locomotion, Brain research reviews 62 (1) (2009) 45–56. [17] Zhong G. Shevtsova N.A. Rybak I.A. Harris-Warrick R.M. Neuronal activity in the isolated mouse spinal cord during spontaneous deletions in fictive locomotion: insights into locomotor central pattern generator organization J. Physiol. 590 19 2012 4735 4759 G. Zhong, N. A. Shevtsova, I. A. Rybak, R. M. Harris-Warrick, Neuronal activity in the isolated mouse spinal cord during spontaneous deletions in fictive locomotion: insights into locomotor central pattern generator organization, The Journal of physiology 590 (19) (2012) 4735–4759. [18] Menelaou E. McLean D.L. Hierarchical control of locomotion by distinct types of spinal v2a interneurons in zebrafish Nature Commun. 10 1 2019 1 12 E. Menelaou, D. L. McLean, Hierarchical control of locomotion by distinct types of spinal v2a interneurons in zebrafish, Nature communications 10 (1) (2019) 1–12. [19] Kasaei M. Lau N. Pereira A. A fast and stable omnidirectional walking engine for the nao humanoid robot Chalup S. Niemueller T. Suthakorn J. Williams M.-A. RoboCup 2019: Robot World Cup XXIII 2019 Springer International Publishing Cham 99 111 M. Kasaei, N. Lau, A. Pereira, A fast and stable omnidirectional walking engine for the nao humanoid robot, in: S. Chalup, T. Niemueller, J. Suthakorn, M.-A. Williams (Eds.), RoboCup 2019: Robot World Cup XXIII, Springer International Publishing, Cham, 2019, 99–111. [20] Endo G. Morimoto J. Matsubara T. Nakanishi J. Cheng G. Learning cpg-based biped locomotion with a policy gradient method: Application to a humanoid robot Int. J. Robot. Res. 27 2 2008 213 228 G. Endo, J. Morimoto, T. Matsubara, J. Nakanishi, G. Cheng, Learning cpg-based biped locomotion with a policy gradient method: Application to a humanoid robot, The International Journal of Robotics Research 27 (2) (2008) 213–228. [21] Abreu M. Reis L.P. Lau N. Learning to run faster in a humanoid robot soccer environment through reinforcement learning Robot World Cup 2019 Springer 3 15 M. Abreu, L. P. Reis, N. Lau, Learning to run faster in a humanoid robot soccer environment through reinforcement learning, in: Robot World Cup, Springer, 2019, 3–15. [22] MacAlpine P. Barrett S. Urieli D. Vu V. Stone P. Design and optimization of an omnidirectional humanoid walk: A winning approach at the robocup 2011 3d simulation competition Twenty-Sixth AAAI Conference on Artificial Intelligence 2012 P. MacAlpine, S. Barrett, D. Urieli, V. Vu, P. Stone, Design and optimization of an omnidirectional humanoid walk: A winning approach at the robocup 2011 3d simulation competition, in: Twenty-Sixth AAAI Conference on Artificial Intelligence, 2012. [23] Or J. A hybrid cpg–zmp control system for stable walking of a simulated flexible spine humanoid robot Neural Netw. 23 3 2010 452 460 J. Or, A hybrid cpg–zmp control system for stable walking of a simulated flexible spine humanoid robot, Neural Networks 23 (3) (2010) 452–460. [24] He B. Wang Z. Shen R. Hu S. Real-time walking pattern generation for a biped robot with hybrid cpg-zmp algorithm Int. J. Adv. Robot. Syst. 11 10 2014 160 B. He, Z. Wang, R. Shen, S. Hu, Real-time walking pattern generation for a biped robot with hybrid cpg-zmp algorithm, International Journal of Advanced Robotic Systems 11 (10) (2014) 160. [25] Kasaei S.M. Simões D. Lau N. Pereira A. A hybrid zmp-cpg based walk engine for biped robots Iberian Robotics Conference 2017 Springer 743 755 S. M. Kasaei, D. Simões, N. Lau, A. Pereira, A hybrid zmp-cpg based walk engine for biped robots, in: Iberian Robotics conference, Springer, 2017, pp. 743–755. [26] Carpentier J. Tonneau S. Naveau M. Stasse O. Mansard N. A versatile and efficient pattern generator for generalized legged locomotion 2016 IEEE International Conference on Robotics and Automation (ICRA) 2016 IEEE 3555 3561 J. Carpentier, S. Tonneau, M. Naveau, O. Stasse, N. Mansard, A versatile and efficient pattern generator for generalized legged locomotion, in: 2016 IEEE International Conference on Robotics and Automation (ICRA), IEEE, 2016, pp. 3555–3561. [27] Koryakovskiy I. Kudruss M. Vallery H. Babuška R. Caarls W. Model-plant mismatch compensation using reinforcement learning IEEE Robot. Autom. Lett. 3 3 2018 2471 2477 I. Koryakovskiy, M. Kudruss, H. Vallery, R. Babuška, W. Caarls, Model-plant mismatch compensation using reinforcement learning, IEEE Robotics and Automation Letters 3 (3) (2018) 2471–2477. [28] Song K.-T. Hsieh C.-H. Cpg-based control design for bipedal walking on unknown slope surfaces 2014 IEEE International Conference on Robotics and Automation (ICRA) 2014 IEEE 5109 5114 K.-T. Song, C.-H. Hsieh, Cpg-based control design for bipedal walking on unknown slope surfaces, in: 2014 IEEE International Conference on Robotics and Automation (ICRA), IEEE, 2014, 5109–5114. [29] Missura M. Behnke S. Gradient-driven online learning of bipedal push recovery 2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) 2015 IEEE 387 392 M. Missura, S. Behnke, Gradient-driven online learning of bipedal push recovery, in: 2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), IEEE, 2015, 387–392. [30] Massah A. Zamani A. Salehinia Y. Sh M.A. Teshnehlab M. A hybrid controller based on cpg and zmp for biped locomotion J. Mech. Sci. Technol. 27 11 2013 3473 3486 A. Massah, A. Zamani, Y. Salehinia, M. A. Sh, M. Teshnehlab, A hybrid controller based on cpg and zmp for biped locomotion, Journal of Mechanical science and technology 27 (11) (2013) 3473–3486. [31] Liu J. Urbann O. Bipedal walking with dynamic balance that involves three-dimensional upper body motion Robot. Auton. Syst. 77 2016 39 54 J. Liu, O. Urbann, Bipedal walking with dynamic balance that involves three-dimensional upper body motion, Robotics and Autonomous Systems 77 (2016) 39–54. [32] Abdolmaleki A. Simoes D. Lau N. Reis L.P. Neumann G. Contextual relative entropy policy search with covariance matrix adaptation 2016 International Conference on Autonomous Robot Systems and Competitions (ICARSC) 2016 IEEE 94 99 A. Abdolmaleki, D. Simoes, N. Lau, L. P. Reis, G. Neumann, Contextual relative entropy policy search with covariance matrix adaptation, in: 2016 International Conference on Autonomous Robot Systems and Competitions (ICARSC), IEEE, 2016, 94–99. [33] Dhariwal P. Hesse C. Klimov O. Nichol A. Plappert M. Radford A. Schulman J. Sidor S. Wu Y. Zhokhov P. Openai baselines 2017 P. Dhariwal, C. Hesse, O. Klimov, A. Nichol, M. Plappert, A. Radford, J. Schulman, S. Sidor, Y. Wu, P. Zhokhov, Openai baselines, (2017). [34] Vukobratovic M. Frank A. Juricic D. On the stability of biped locomotion IEEE Trans. Biomed. Eng. BME-17 1 1970 25 36 M. Vukobratovic, A. Frank, D. Juricic, On the stability of biped locomotion, IEEE Transactions on Biomedical Engineering BME-17 (1) (1970) 25–36. [35] Winter D.A. Ruder G.K. MacKinnon C.D. Control of balance of upper body during gait Multiple Muscle Systems 1990 Springer 534 541 D. A. Winter, G. K. Ruder, C. D. MacKinnon, Control of balance of upper body during gait, in: Multiple muscle systems, Springer, 1990, 534–541. [36] Kajita S. Benallegue M. Cisneros R. Sakaguchi T. Morisawa M. Kaminaga H. Kumagai I. Kaneko K. Kanehiro F. Position-based lateral balance control for knee-stretched biped robot 2019 IEEE-RAS 19th International Conference on Humanoid Robots (Humanoids) 2019 IEEE 17 24 S. Kajita, M. Benallegue, R. Cisneros, T. Sakaguchi, M. Morisawa, H. Kaminaga, I. Kumagai, K. Kaneko, F. Kanehiro, Position-based lateral balance control for knee-stretched biped robot, in: 2019 IEEE-RAS 19th International Conference on Humanoid Robots (Humanoids), IEEE, 2019, 17–24. [37] J. Schulman, F. Wolski, P. Dhariwal, A. Radford, O. Klimov, Proximal policy optimization algorithms, CoRR 1707.06347. [38] Carvalho Melo L. Omena Albuquerque Máximo M.R. Learning humanoid robot running skills through proximal policy optimization 2019 Latin American Robotics Symposium (LARS), 2019 Brazilian Symposium on Robotics (SBR) and 2019 Workshop on Robotics in Education (WRE) 2019 37 42 L. Carvalho Melo, M. R. Omena Albuquerque Máximo, Learning humanoid robot running skills through proximal policy optimization, in: 2019 Latin American Robotics Symposium (LARS), 2019 Brazilian Symposium on Robotics (SBR) and 2019 Workshop on Robotics in Education (WRE), 2019, 37–42. [39] Teixeira H. Silva T. Abreu M. Reis L.P. Humanoid robot kick in motion ability for playing robotic soccer 2020 IEEE International Conference on Autonomous Robot Systems and Competitions (ICARSC) 2020 IEEE 34 39 H. Teixeira, T. Silva, M. Abreu, L. P. Reis, Humanoid robot kick in motion ability for playing robotic soccer, in: 2020 IEEE International Conference on Autonomous Robot Systems and Competitions (ICARSC), IEEE, 2020, 34–39. [40] Melo D.C. Máximo M.R.O.A da Cunha A.M. Push recovery strategies through deep reinforcement learning 2020 Latin American Robotics Symposium (LARS), 2020 Brazilian Symposium on Robotics (SBR) and 2020 Workshop on Robotics in Education (WRE) 2020 IEEE 240 245 D. C. Melo, M. R. O. A. Máximo, A. M. da Cunha, Push recovery strategies through deep reinforcement learning, in: 2020 Latin American Robotics Symposium (LARS), 2020 Brazilian Symposium on Robotics (SBR) and 2020 Workshop on Robotics in Education (WRE), IEEE, 2020, 240–245. [41] Abreu M. Lau N. Sousa A. Reis L.P. Learning low level skills from scratch for humanoid robot soccer using deep reinforcement learning 2019 IEEE International Conference on Autonomous Robot Systems and Competitions (ICARSC) 2019 IEEE 1 8 M. Abreu, N. Lau, A. Sousa, L. P. Reis, Learning low level skills from scratch for humanoid robot soccer using deep reinforcement learning, in: 2019 IEEE International Conference on Autonomous Robot Systems and Competitions (ICARSC), IEEE, 2019, 1–8. [42] Muzio A.F.V. Maximo M.R.O.A Yoneyama T. Deep reinforcement learning for humanoid robot dribbling 2020 Latin American Robotics Symposium (LARS), 2020 Brazilian Symposium on Robotics (SBR) and 2020 Workshop on Robotics in Education (WRE) 2020 IEEE 246 251 A. F. V. Muzio, M. R. O. A. Maximo, T. Yoneyama, Deep reinforcement learning for humanoid robot dribbling, in: 2020 Latin American Robotics Symposium (LARS), 2020 Brazilian Symposium on Robotics (SBR) and 2020 Workshop on Robotics in Education (WRE), IEEE, 2020, 246–251. [43] D.P. Kingma, J. Ba, Adam: A method for stochastic optimization, CoRR 1412.6980. [44] J. Schulman, P. Moritz, S. Levine, M. Jordan, P. Abbeel, High-dimensional continuous control using generalized advantage estimation, CoRR 1506.02438. [45] Picado H. Gestal M. Lau N. Reis L. Tomé A. Automatic generation of biped walk behavior using genetic algorithms Bio-Inspired Systems: Computational and Ambient Intelligence 2009 805 812 H. Picado, M. Gestal, N. Lau, L. Reis, A. Tomé, Automatic generation of biped walk behavior using genetic algorithms, Bio-inspired systems: Computational and ambient intelligence (2009) 805–812. [46] Shafii N. Reis L.P. Lau N. Biped walking using coronal and sagittal movements based on truncated fourier series Ruiz-del Solar J. Chown E. Plöger P.G. RoboCup 2010: Robot Soccer World Cup XIV 2010 Springer Berlin Heidelberg Berlin, Heidelberg 324 335 N. Shafii, L. P. Reis, N. Lau, Biped walking using coronal and sagittal movements based on truncated fourier series, in: J. Ruiz-del Solar, E. Chown, P. G. Plöger (Eds.), RoboCup 2010: Robot Soccer World Cup XIV, Springer Berlin Heidelberg, Berlin, Heidelberg, 2011, 324–335. [47] Diedam H. Dimitrov D. Wieber P.-B. Mombaur K. Diehl M. Online walking gait generation with adaptive foot positioning through linear model predictive control 2008 IEEE/RSJ International Conference on Intelligent Robots and Systems 2008 IEEE 1121 1126 H. Diedam, D. Dimitrov, P.-B. Wieber, K. Mombaur, M. Diehl, Online walking gait generation with adaptive foot positioning through linear model predictive control, in: 2008 IEEE/RSJ International Conference on Intelligent Robots and Systems, IEEE, 2008, 1121–1126. [48] Herdt A. Diedam H. Wieber P.-B. Dimitrov D. Mombaur K. Diehl M. Online walking motion generation with automatic footstep placement Adv. Robot. 24 5–6 2010 719 737 A. Herdt, H. Diedam, P.-B. Wieber, D. Dimitrov, K. Mombaur, M. Diehl, Online walking motion generation with automatic footstep placement, Advanced Robotics 24 (5-6) (2010) 719–737. [49] Griffin R.J. Leonessa A. Model predictive control for dynamic footstep adjustment using the divergent component of motion 2016 IEEE International Conference on Robotics and Automation (ICRA) 2016 IEEE 1763 1768 R. J. Griffin, A. Leonessa, Model predictive control for dynamic footstep adjustment using the divergent component of motion, in: 2016 IEEE International Conference on Robotics and Automation (ICRA), IEEE, 2016, pp. 1763–1768. [50] Asta S. Sariel-Talay S. Nature-inspired optimization for biped robot locomotion and gait planning European Conference on the Applications of Evolutionary Computation 2011 Springer 434 443 S. Asta, S. Sariel-Talay, Nature-inspired optimization for biped robot locomotion and gait planning, in: European Conference on the Applications of Evolutionary Computation, Springer, 2011, 434–443. [51] MacAlpine P. Stone P. UT Austin Villa: RoboCup 2017 3D simulation league competition and technical challenges champions Robot World Cup 2017 Springer 473 485 P. MacAlpine, P. Stone, UT Austin Villa: RoboCup 2017 3D simulation league competition and technical challenges champions, in: Robot World Cup, Springer, 2017, 473–485. [52] Kasaei M. Ahmadi A. Lau N. Pereira A. A robust model-based biped locomotion framework based on three-mass model: From planning to control 2020 IEEE International Conference on Autonomous Robot Systems and Competitions (ICARSC) 2020 IEEE 257 262 M. Kasaei, A. Ahmadi, N. Lau, A. Pereira, A robust model-based biped locomotion framework based on three-mass model: From planning to control, in: 2020 IEEE International Conference on Autonomous Robot Systems and Competitions (ICARSC), IEEE, 2020, 257–262. [53] Haarnoja T. Zhou A. Abbeel P. Levine S. Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor International Conference on Machine Learning 2018 PMLR 1861 1870 T. Haarnoja, A. Zhou, P. Abbeel, S. Levine, Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor, in: International Conference on Machine Learning, PMLR, 2018, 1861–1870. Mohammadreza Kasaei joined the Department of Electronics, Telecommunications and Informatics (IEETA) of the University of Aveiro in 2016 as a Ph.D. student. His Ph.D. aims to propose a hybrid walking framework by coupling a model-based walk engine with DRL algorithms to combine the potential of both approaches. This hybrid framework aims at generating robust, versatile, and agile omnidirectional walking gaits by exploring the full potential of the robot, taking advantage of the analytical solution’s consistency and the flexibility of residual learning. Miguel Abreu is currently a Ph.D. student at the Faculty of Engineering of the University of Porto (FEUP), Portugal. He received his M.Sc. degree in Electronics and Computers Engineering from the University of Minho, in 2017. His interests include applied mathematics, reinforcement learning, bioinspired artificial intelligence, and autonomous systems in the field of robotics. He is currently focused on improving reinforcement learning algorithms applied to symmetrical models. Nuno Lau is associate professor at Aveiro University, Portugal, and Researcher at the Institute of Electrical and Informatics Engineering of Aveiro (IEETA), where he leads the Intelligent Robotics and Systems group (IRIS). His research interests are focused on Intelligent Robotics, Artificial Intelligence, Multi-Agent Systems and Simulation. Nuno Lau participated in more than 15 international and national research projects, having the tasks of general or local coordinator in about half of them. Nuno Lau won more than 50 scientific awards in robotic competitions, conferences (best papers) and education. Nuno Lau is the author of more than one 150 publications in international conferences and journals. Artur Pereira was born in Vila Nova de Famalicão, Portugal, in April 1960. He received the Ph.D. degree in Electrical Engineering from the University of Aveiro, Portugal, in 2003. He is currently an Assistant Professor at the Department of Electronics, Telecommunications and Informatics of the University of Aveiro and a researcher at the Intelligent Robotics and Systems group (IRIS Lab) of the Institute of Electronics and Informatics Engineering of Aveiro (IEETA). The main focus of his research is robotics at the architectural and software levels, with emphasis on simulation, navigation, localization, mapping, and machine learning. Luis Paulo Reis is Associate Professor and Director of LIACC - Artificial Intelligence and Computer Science Laboratory at the University of Porto in Portugal. He is an IEEE Senior Member and President of APPIA - Portuguese Association for Artificial Intelligence. His research interests are on Artificial Intelligence, Intelligent Robotics, Multi-Agent Systems, Intelligent Simulation and Machine Learning. He was the principal investigator of more than 10 research projects and supervised 21 Ph.D. and 120 M.Sc. theses to completion. He organized more than 50 international scientific events and belonged to the Program Committee of more than 250 scientific events. He is the author of more than 400 publications in international conferences and journals. "
    },
    {
        "doc_title": "Editorial of the topical collection “state of the art on autonomous robot systems and competitions”",
        "doc_scopus_id": "85116284216",
        "doc_doi": "10.1007/s42452-021-04819-7",
        "doc_eid": "2-s2.0-85116284216",
        "doc_date": "2021-11-01",
        "doc_type": "Editorial",
        "doc_areas": [
            {
                "area_name": "Engineering (all)",
                "area_abbreviation": "ENGI",
                "area_code": "2200"
            },
            {
                "area_name": "Environmental Science (all)",
                "area_abbreviation": "ENVI",
                "area_code": "2300"
            },
            {
                "area_name": "Materials Science (all)",
                "area_abbreviation": "MATE",
                "area_code": "2500"
            },
            {
                "area_name": "Physics and Astronomy (all)",
                "area_abbreviation": "PHYS",
                "area_code": "3100"
            },
            {
                "area_name": "Chemical Engineering (all)",
                "area_abbreviation": "CENG",
                "area_code": "1500"
            },
            {
                "area_name": "Earth and Planetary Sciences (all)",
                "area_abbreviation": "EART",
                "area_code": "1900"
            }
        ],
        "doc_keywords": [],
        "doc_abstract": null,
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "A general approach to hand-eye calibration through the optimization of atomic transformations",
        "doc_scopus_id": "85103787190",
        "doc_doi": "10.1109/TRO.2021.3062306",
        "doc_eid": "2-s2.0-85103787190",
        "doc_date": "2021-10-01",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Control and Systems Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2207"
            },
            {
                "area_name": "Computer Science Applications",
                "area_abbreviation": "COMP",
                "area_code": "1706"
            },
            {
                "area_name": "Electrical and Electronic Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2208"
            }
        ],
        "doc_keywords": [
            "Atomic transformation",
            "Calibration algorithm",
            "Calibration problems",
            "Calibration procedure",
            "Initial configuration",
            "Nonlinear least squares methods",
            "Optimization procedures",
            "Robot operating system"
        ],
        "doc_abstract": "© 2021 IEEE.This article proposes a general approach to solve the hand-eye calibration problem. The system is general since it is able to calibrate any number of cameras and, moreover, is able to simultaneously perform the calibration of several instances of the two common hand-eye calibration use cases: eye-on-hand and eye-to-base. The calibration is solved with a nonlinear least squares method, and the reprojection error is used as a metric to guide the optimization procedure. Our approach is seamlessly integrated with the robot operating system framework and allows for the interactive positioning of sensors and labeling of data, facilitating both the data acquisition and labeling and the calibration procedures. Results show that the proposed approach is able to handle any calibration use case with a minimal initial configuration. The approach is compared with several other state-of-the-art hand-eye calibration algorithms. Results show that the proposed approach produces very accurate calibrations when compared to the state of the art.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "A modular framework to generate robust biped locomotion: from planning to control",
        "doc_scopus_id": "85112248611",
        "doc_doi": "10.1007/s42452-021-04752-9",
        "doc_eid": "2-s2.0-85112248611",
        "doc_date": "2021-09-01",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Engineering (all)",
                "area_abbreviation": "ENGI",
                "area_code": "2200"
            },
            {
                "area_name": "Environmental Science (all)",
                "area_abbreviation": "ENVI",
                "area_code": "2300"
            },
            {
                "area_name": "Materials Science (all)",
                "area_abbreviation": "MATE",
                "area_code": "2500"
            },
            {
                "area_name": "Physics and Astronomy (all)",
                "area_abbreviation": "PHYS",
                "area_code": "3100"
            },
            {
                "area_name": "Chemical Engineering (all)",
                "area_abbreviation": "CENG",
                "area_code": "1500"
            },
            {
                "area_name": "Earth and Planetary Sciences (all)",
                "area_abbreviation": "EART",
                "area_code": "1900"
            }
        ],
        "doc_keywords": [
            "Biped Robot",
            "Dynamics modeling",
            "Input-output",
            "Model-based OPC",
            "Modular framework",
            "Reference trajectories",
            "Research efforts",
            "Tracking problem"
        ],
        "doc_abstract": "© 2021, The Author(s).Biped robots are inherently unstable because of their complex kinematics as well as dynamics. Despite many research efforts in developing biped locomotion, the performance of biped locomotion is still far from the expectations. This paper proposes a model-based framework to generate stable biped locomotion. The core of this framework is an abstract dynamics model which is composed of three masses to consider the dynamics of stance leg, torso, and swing leg for minimizing the tracking problems. According to this dynamics model, we propose a modular walking reference trajectories planner which takes into account obstacles to plan all the references. Moreover, this dynamics model is used to formulate the controller as a Model Predictive Control (MPC) scheme which can consider some constraints in the states of the system, inputs, outputs, and also mixed input-output. The performance and the robustness of the proposed framework are validated by performing several numerical simulations using MATLAB. Moreover, the framework is deployed on a simulated torque-controlled humanoid to verify its performance and robustness. The simulation results show that the proposed framework is capable of generating biped locomotion robustly.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "6D Localization and Kicking for Humanoid Robotic Soccer",
        "doc_scopus_id": "85105728593",
        "doc_doi": "10.1007/s10846-021-01385-3",
        "doc_eid": "2-s2.0-85105728593",
        "doc_date": "2021-06-01",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Software",
                "area_abbreviation": "COMP",
                "area_code": "1712"
            },
            {
                "area_name": "Control and Systems Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2207"
            },
            {
                "area_name": "Mechanical Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2210"
            },
            {
                "area_name": "Industrial and Manufacturing Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2209"
            },
            {
                "area_name": "Electrical and Electronic Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2208"
            },
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            }
        ],
        "doc_keywords": [
            "Actor critic",
            "Average errors",
            "Complex problems",
            "Humanoid robotics",
            "Localization technique",
            "Policy optimization",
            "Robotic soccer",
            "State-of-the-art algorithms"
        ],
        "doc_abstract": "© 2021, The Author(s), under exclusive licence to Springer Nature B.V.Robotic soccer simulation is a challenging area, where the development of new techniques is paramount to remain competitive. Robotic skill evolution has accelerated with recent developments in deep learning algorithms, leading to improvements in behavior number and complexity. Shooting a ball towards a defined target is one of the most basic yet indispensable skills in soccer. However, fast and accurate kicks pose several challenges. In order to reach that target, the skill is highly dependent on the ability of the agent to self-locate and self-orient, in order to better position itself before the kick. To tackle these issues, a 6D localization technique was devised. To optimize the kick behavior, two scenarios were proposed. In the first, the robot walks to the ball, stops, and then kicks. In the second, it kicks the ball while moving. We used state-of-the-art algorithms — Proximal Policy Optimization and Soft Actor Critic — to solve these complex problems and show their applicability in the context of RoboCup. Obtained results have shown very significant improvements over previously used behaviors by FC Portugal 3D team. The new kick in motion executes 5 times faster than the previous kick, and the new 6D pose estimator has an average error of just 6.3mm, a reduction of more than 97%.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Segmentation and Manipulation of Cork Strips in Bulk",
        "doc_scopus_id": "85107151302",
        "doc_doi": "10.1109/ICARSC52212.2021.9429769",
        "doc_eid": "2-s2.0-85107151302",
        "doc_date": "2021-04-28",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            },
            {
                "area_name": "Computer Vision and Pattern Recognition",
                "area_abbreviation": "COMP",
                "area_code": "1707"
            },
            {
                "area_name": "Human-Computer Interaction",
                "area_abbreviation": "COMP",
                "area_code": "1709"
            },
            {
                "area_name": "Mechanical Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2210"
            },
            {
                "area_name": "Control and Optimization",
                "area_abbreviation": "MATH",
                "area_code": "2606"
            }
        ],
        "doc_keywords": [
            "Computer vision techniques",
            "Conveyor belts",
            "Cork stoppers",
            "Industry sectors",
            "Motion planners",
            "Natural cork",
            "Punching machine",
            "Rgb-d cameras"
        ],
        "doc_abstract": "© 2021 IEEE.The production of cork stoppers is the largest application of natural cork, which is an ever-growing industry sector. Many attempts have been made to increase the automation of this process, such as the use of automated cork punching machines, but not all steps of this process are fully efficient such as the manipulation of cork strips prior to perforation, which is still a hand labor. This paper presents a system based on an RGBD camera and a 6 DoF robotic arm that manipulates cork strips which are disposed in bulk, either in a container or in a conveyor belt. It uses computer vision techniques to segment a single cork strip from the bunch and motion planners to control the robotic arm in order to grab the selected cork strip. On the experiments made, the system was able to correctly grab a cork strip with 92% success rate and with a frequency of 6 strips per minute.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Welcome Message",
        "doc_scopus_id": "85107138391",
        "doc_doi": "10.1109/ICARSC52212.2021.9429802",
        "doc_eid": "2-s2.0-85107138391",
        "doc_date": "2021-04-28",
        "doc_type": "Editorial",
        "doc_areas": [
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            },
            {
                "area_name": "Computer Vision and Pattern Recognition",
                "area_abbreviation": "COMP",
                "area_code": "1707"
            },
            {
                "area_name": "Human-Computer Interaction",
                "area_abbreviation": "COMP",
                "area_code": "1709"
            },
            {
                "area_name": "Mechanical Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2210"
            },
            {
                "area_name": "Control and Optimization",
                "area_abbreviation": "MATH",
                "area_code": "2606"
            }
        ],
        "doc_keywords": [],
        "doc_abstract": null,
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Game Adaptation by Using Reinforcement Learning Over Meta Games",
        "doc_scopus_id": "85078048588",
        "doc_doi": "10.1007/s10726-020-09652-8",
        "doc_eid": "2-s2.0-85078048588",
        "doc_date": "2021-04-01",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Decision Sciences (all)",
                "area_abbreviation": "DECI",
                "area_code": "1800"
            },
            {
                "area_name": "Arts and Humanities (miscellaneous)",
                "area_abbreviation": "ARTS",
                "area_code": "1201"
            },
            {
                "area_name": "Social Sciences (all)",
                "area_abbreviation": "SOCI",
                "area_code": "3300"
            },
            {
                "area_name": "Strategy and Management",
                "area_abbreviation": "BUSI",
                "area_code": "1408"
            },
            {
                "area_name": "Management of Technology and Innovation",
                "area_abbreviation": "BUSI",
                "area_code": "1405"
            }
        ],
        "doc_keywords": [],
        "doc_abstract": "© 2020, Springer Nature B.V.In this work, we propose a Dynamic Difficulty Adjustment methodology to achieve automatic video game balance. The balance task is modeled as a meta game, a game where actions change the rules of another base game. Based on the model of Reinforcement Learning (RL), an agent assumes the role of a game master and learns its optimal policy by playing the meta game. In this new methodology we extend traditional RL by adding the existence of a meta environment whose state transition depends on the evolution of a base environment. In addition, we propose a Multi Agent System training model for the game master agent, where it plays against multiple agent opponents, each with a distinct behavior and proficiency level while playing the base game. Our experiment is conducted on an adaptive grid-world environment in singleplayer and multiplayer scenarios. Our results are expressed in twofold: (i) the resulting decision making by the game master through gameplay, which must comply in accordance to an established balance objective by the game designer; (ii) the initial conception of a framework for automatic game balance, where the balance task design is reduced to the modulation of a reward function (balance reward), an action space (balance strategies) and the definition of a balance space state.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "VGC AI Competition - A New Model of Meta-Game Balance AI Competition",
        "doc_scopus_id": "85122960103",
        "doc_doi": "10.1109/CoG52621.2021.9618985",
        "doc_eid": "2-s2.0-85122960103",
        "doc_date": "2021-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            },
            {
                "area_name": "Computer Graphics and Computer-Aided Design",
                "area_abbreviation": "COMP",
                "area_code": "1704"
            },
            {
                "area_name": "Computer Vision and Pattern Recognition",
                "area_abbreviation": "COMP",
                "area_code": "1707"
            },
            {
                "area_name": "Human-Computer Interaction",
                "area_abbreviation": "COMP",
                "area_code": "1709"
            },
            {
                "area_name": "Software",
                "area_abbreviation": "COMP",
                "area_code": "1712"
            }
        ],
        "doc_keywords": [
            "AI competition",
            "Automatic game design",
            "Competitive games",
            "Game balances",
            "Game design",
            "Games designers",
            "Multitask learning",
            "Set of rules"
        ],
        "doc_abstract": "© 2021 IEEE.This work presents a framework for a new type of meta-game balance AI Competition based on Pokémon, Pokémon battles can be viewed as adversarial games played by AIs. Around these games, there is also a meta-game: which Pokémon to include in a team for battles, which moves to pick for every Pokémon in the team, etc. This meta-game is itself a game with a set of rules that govern which Pokémon and which moves are available in the roster that can be selected from, or which attributes (health points, damage, etc.) a Pokémon or moves should have. The aim of the framework is to facilitate competitions in creating the most balanced meta-game possible; one where there is a large variety of Pokémon and moves to choose from, and many possible combinations that are effective. AI agents could assist human designers in achieving strategically expressive meta-games, and this type of benchmark could incentivize game designers and researchers alike to advance knowledge on this type of domain.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Preface",
        "doc_scopus_id": "85115613714",
        "doc_doi": null,
        "doc_eid": "2-s2.0-85115613714",
        "doc_date": "2021-01-01",
        "doc_type": "Editorial",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [],
        "doc_abstract": null,
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Neural Network Classifier and Robotic Manipulation for an Autonomous Industrial Cork Feeder",
        "doc_scopus_id": "85115444254",
        "doc_doi": "10.1007/978-3-030-86230-5_34",
        "doc_eid": "2-s2.0-85115444254",
        "doc_date": "2021-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Convolutional neural network",
            "Cork",
            "Deep learning",
            "High quality",
            "Image processing technique",
            "Network robotics",
            "Neural networks classifiers",
            "Robotic manipulation",
            "Specific orientation",
            "Universal robot"
        ],
        "doc_abstract": "© 2021, Springer Nature Switzerland AG.This paper presents a solution for an autonomous cork puncher feeder with a robotic arm using image processing techniques and a convolutional neural network. Due to the need for cork strips to be inserted into the puncher with a specific orientation, to produce high quality cork stoppers, the identification of the orientation of each cork strip on the conveyor belt is a necessity. In response to this problem a convolutional neural network is used to analyse images processed with subtracted background, to create a robust solution for cork strips classification. In the tests carried out, a classification accuracy of 100% was obtained in a test data set with 12 different cork strips.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "A survey of planning and learning in games",
        "doc_scopus_id": "85087795422",
        "doc_doi": "10.3390/app10134529",
        "doc_eid": "2-s2.0-85087795422",
        "doc_date": "2020-07-01",
        "doc_type": "Review",
        "doc_areas": [
            {
                "area_name": "Materials Science (all)",
                "area_abbreviation": "MATE",
                "area_code": "2500"
            },
            {
                "area_name": "Instrumentation",
                "area_abbreviation": "PHYS",
                "area_code": "3105"
            },
            {
                "area_name": "Engineering (all)",
                "area_abbreviation": "ENGI",
                "area_code": "2200"
            },
            {
                "area_name": "Process Chemistry and Technology",
                "area_abbreviation": "CENG",
                "area_code": "1508"
            },
            {
                "area_name": "Computer Science Applications",
                "area_abbreviation": "COMP",
                "area_code": "1706"
            },
            {
                "area_name": "Fluid Flow and Transfer Processes",
                "area_abbreviation": "CENG",
                "area_code": "1507"
            }
        ],
        "doc_keywords": [],
        "doc_abstract": "© 2020 by the authors. Licensee MDPI, Basel, Switzerland.In general, games pose interesting and complex problems for the implementation of intelligent agents and are a popular domain in the study of artificial intelligence. In fact, games have been at the center of some of the most well-known achievements in artificial intelligence. From classical board games such as chess, checkers, backgammon and Go, to video games such as Dota 2 and StarCraft II, artificial intelligence research has devised computer programs that can play at the level of a human master and even at a human world champion level. Planning and learning, two well-known and successful paradigms of artificial intelligence, have greatly contributed to these achievements. Although representing distinct approaches, planning and learning try to solve similar problems and share some similarities. They can even complement each other. This has led to research on methodologies to combine the strengths of both approaches to derive better solutions. This paper presents a survey of the multiple methodologies that have been proposed to integrate planning and learning in the context of games. In order to provide a richer contextualization, the paper also presents learning and planning techniques commonly used in games, both in terms of their theoretical foundations and applications.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Multi Agent Deep Learning with Cooperative Communication",
        "doc_scopus_id": "85086234837",
        "doc_doi": "10.2478/jaiscr-2020-0013",
        "doc_eid": "2-s2.0-85086234837",
        "doc_date": "2020-07-01",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Information Systems",
                "area_abbreviation": "COMP",
                "area_code": "1710"
            },
            {
                "area_name": "Modeling and Simulation",
                "area_abbreviation": "MATH",
                "area_code": "2611"
            },
            {
                "area_name": "Hardware and Architecture",
                "area_abbreviation": "COMP",
                "area_code": "1708"
            },
            {
                "area_name": "Computer Vision and Pattern Recognition",
                "area_abbreviation": "COMP",
                "area_code": "1707"
            },
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            }
        ],
        "doc_keywords": [],
        "doc_abstract": "© 2020 David Simões et al., published by Sciendo.We consider the problem of multi agents cooperating in a partially-observable environment. Agents must learn to coordinate and share relevant information to solve the tasks successfully. This article describes Asynchronous Advantage Actor-Critic with Communication (A3C2), an end-to-end differentiable approach where agents learn policies and communication protocols simultaneously. A3C2 uses a centralized learning, distributed execution paradigm, supports independent agents, dynamic team sizes, partially-observable environments, and noisy communications. We compare and show that A3C2 outperforms other state-of-the-art proposals in multiple environments.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Multi-agent actor centralized-critic with communication",
        "doc_scopus_id": "85078851559",
        "doc_doi": "10.1016/j.neucom.2020.01.079",
        "doc_eid": "2-s2.0-85078851559",
        "doc_date": "2020-05-21",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Computer Science Applications",
                "area_abbreviation": "COMP",
                "area_code": "1706"
            },
            {
                "area_name": "Cognitive Neuroscience",
                "area_abbreviation": "NEUR",
                "area_code": "2805"
            },
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            }
        ],
        "doc_keywords": [
            "Actor-critic algorithm",
            "Centralized controllers",
            "Credit assignment problems",
            "Curse of dimensionality",
            "Decentralized communications",
            "Multi-agent algorithms",
            "Multi-agent environment",
            "Partial observability"
        ],
        "doc_abstract": "© 2020 Elsevier B.V.Multiple real-world problems are naturally modeled as cooperative multi-agent systems, ranging from satellite formation to traffic monitoring. These systems require algorithms that can learn successful policies with independent agents that rely solely on local partial-observations of the environment. However, multi-agent environments are more complex, due to their partial-observability and non-stationarity from an agent's perspective, as well as the structural credit assignment problem and the curse of dimensionality, and achieving coordination in such systems remains a complex challenge. To this end, we propose a multi-agent actor-critic algorithm called Asynchronous Advantage Actor Centralized-Critic with Communication (A3C3). A3C3 uses a centralized critic to estimate a value function, decentralized actors to approximate each agent's policy function, and decentralized communication networks for each agent to share relevant information with its team. The critic can incorporate additional information, like the environment's global state, when available, and optimizes the actor networks. The actor networks of an agent's teammates optimize that agent's communication network, such that each agent learns to output information that is relevant to the policies of others. A3C3 supports a dynamic amount of agents, noisy communication mediums, and can be horizontally scaled to shorten its learning phase. We evaluate A3C3 in two partially-observable multi-agent suites where agents benefit from communicating local information to each other. A3C3 outperforms state-of-the-art multi-agent algorithms, independent approaches, and centralized controllers with access to all agents’ observations.",
        "available": true,
        "clean_text": "serial JL 271597 291210 291735 291866 31 Neurocomputing NEUROCOMPUTING 2020-01-23 2020-01-23 2020-05-04 2020-05-04 2020-05-04T10:57:12 S0925-2312(20)30131-4 S0925231220301314 10.1016/j.neucom.2020.01.079 S300 S300.1 FULL-TEXT 2020-07-03T23:17:03.812289Z 0 0 20200521 2020 2020-01-23T01:55:43.644586Z articleinfo articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid hubeid indexeddate issn issnnorm itemstage itemtransactionid itemweight openaccess openarchive pg pgfirst pglast pii piinorm pubdatestart pubdatetxt pubyr sortorder srctitle srctitlenorm srctype ssids alllist content subj subheadings suppl tomb volfirst volissue volumelist yearnav figure table e-component body mmlmath acknowledge affil appendices articletitle auth authfirstini authfull authkeywords authlast grantnumber grantsponsor grantsponsorid misctext orcid primabst ref vitae 0925-2312 09252312 true 390 390 C Volume 390 5 40 56 40 56 20200521 21 May 2020 2020-05-21 2020 article fla © 2020 Elsevier B.V. All rights reserved. MULTIAGENTACTORCENTRALIZEDCRITICCOMMUNICATION SIMOES D 1 Introduction 2 Related work 2.1 Reinforcement learning 2.2 Multi-agent deep learning 2.3 Multi-agent deep learning with communication 2.4 Others 3 Problem statement 4 Asynchronous Advantage Actor Centralized-Critic with communication 4.1 Actor network 4.2 Centralized Critic network 4.3 Communication network 5 Results 5.1 Test Environments 5.1.1 Partially Observable with Communication suite 5.1.2 Multi-agent Particle Environment suite 5.2 State-of-the-art comparison 5.3 Effects of communication 5.4 Communication noise 5.5 Advantage estimators 5.6 Architecture variance 6 Conclusion CRediT authorship contribution statement Acknowledgements Appendix A Supplementary materials References DUCATELLE 2014 1 33 F GEBHARDT 2018 7688 7695 G PROCEEDINGS2018IEEEINTERNATIONALCONFERENCEROBOTICSAUTOMATIONICRA LEARNINGROBUSTPOLICIESFOROBJECTMANIPULATIONROBOTSWARMS MANNION 2016 47 66 P AUTONOMICROADTRANSPORTSUPPORTSYSTEMS EXPERIMENTALREVIEWREINFORCEMENTLEARNINGALGORITHMSFORADAPTIVETRAFFICSIGNALCONTROL SKOBELEV 2016 287 P FIROIU 2017 V BEATINGWORLDSBESTSUPERSMASHBROSDEEPREINFORCEMENTLEARNING ALBRECHT 2018 66 95 S FOERSTER 2016 J LEARNINGCOMMUNICATEDEEPMULTIAGENTREINFORCEMENTLEARNING FOERSTER 2017 J COUNTERFACTUALMULTIAGENTPOLICYGRADIENTS BOUTILIER 1996 195 210 C PROCEEDINGSSIXTHCONFERENCETHEORETICALASPECTSRATIONALITYKNOWLEDGE PLANNINGLEARNINGCOORDINATIONINMULTIAGENTDECISIONPROCESSES SUKHBAATAR 2016 S LEARNINGMULTIAGENTCOMMUNICATIONBACKPROPAGATION DAMBROSIO 2012 603 614 D PROCEEDINGSINTERNATIONALCONFERENCEINTELLIGENTROBOTICSAPPLICATIONS MULTIROBOTBEHAVIORSYNCHRONIZATIONTHROUGHDIRECTNEURALNETWORKCOMMUNICATION DAS 2017 A LEARNINGCOOPERATIVEVISUALDIALOGAGENTSDEEPREINFORCEMENTLEARNING MORDATCH 2017 I EMERGENCEGROUNDEDCOMPOSITIONALLANGUAGEINMULTIAGENTPOPULATIONS MNIH 2016 1928 1937 V PROCEEDINGSINTERNATIONALCONFERENCEMACHINELEARNING ASYNCHRONOUSMETHODSFORDEEPREINFORCEMENTLEARNING KAPOOR 2018 S MULTIAGENTREINFORCEMENTLEARNINGAREPORTCHALLENGESAPPROACHES SUTTON 1998 R INTRODUCTIONREINFORCEMENTLEARNING YANG 2005 292 299 E PROCEEDINGSIEEE2005SYMPOSIUMCOMPUTATIONALINTELLIGENCEGAMESCIG05 ASURVEYMULTIAGENTREINFORCEMENTLEARNINGTOWARDSMULTIROBOTSYSTEMS MATIGNON 2012 1 31 L BOWLING 2001 1021 1026 M PROCEEDINGSSEVENTEENTHINTERNATIONALJOINTCONFERENCEARTIFICIALINTELLIGENCEVOLUME2 RATIONALCONVERGENTLEARNINGINSTOCHASTICGAMES BUSONIU 2008 156 172 L ABEDALGUNI 2014 B COOPERATIVEREINFORCEMENTLEARNINGFORINDEPENDENTLEARNERS ABEDALGUNI 2015 213 226 B MNIH 2015 529 533 V CLAUS 1998 746 752 C PROCEEDINGSFIFTEENTHNATIONALTENTHCONFERENCEARTIFICIALINTELLIGENCEINNOVATIVEAPPLICATIONSARTIFICIALINTELLIGENCE DYNAMICSREINFORCEMENTLEARNINGINCOOPERATIVEMULTIAGENTSYSTEMS SUNEHAG 2018 2085 2087 P PROCEEDINGSSEVENTEENTHINTERNATIONALCONFERENCEAUTONOMOUSAGENTSMULTIAGENTSYSTEMS VALUEDECOMPOSITIONNETWORKSFORCOOPERATIVEMULTIAGENTLEARNINGBASEDTEAMREWARD RASHID 2018 T QMIXMONOTONICVALUEFUNCTIONFACTORISATIONFORDEEPMULTIAGENTREINFORCEMENTLEARNING PENG 2017 P MULTIAGENTBIDIRECTIONALLYCOORDINATEDNETSFORLEARNINGPLAYSTARCRAFTCOMBATGAMES LITTMAN 1994 157 163 M PROCEEDINGSELEVENTHINTERNATIONALCONFERENCEINTERNATIONALCONFERENCEMACHINELEARNING MARKOVGAMESAFRAMEWORKFORMULTIAGENTREINFORCEMENTLEARNING RUMELHART 1986 533 D PASCANU 2012 R UNDERSTANDINGEXPLODINGGRADIENTPROBLEM LOWE 2017 R MULTIAGENTACTORCRITICFORMIXEDCOOPERATIVECOMPETITIVEENVIRONMENTS BELLEMARE 2013 253 279 M WILLIAMS 1992 229 256 R LAZARIDOU 2016 A MULTIAGENTCOOPERATIONEMERGENCENATURALLANGUAGE LEWIS 2017 M DEALNODEALENDTOENDLEARNINGFORNEGOTIATIONDIALOGUES LI 2017 Q LEARNINGCOORDINATIONPOLICIESFORROBOTICSWARMS MNIH 2016 V ASYNCHRONOUSMETHODSFORDEEPREINFORCEMENTLEARNING SIMOES 2018 129 140 D PROCEEDINGSROBOT2017THIRDIBERIANROBOTICSCONFERENCE MIXEDPOLICYASYNCHRONOUSDEEPQLEARNING SIMOES 2018 375 381 D PROCEEDINGSIJCNN18INTERNATIONALJOINTCONFERENCENEURALNETWORKS GUIDEDDEEPREINFORCEMENTLEARNINGINGEOFRIENDS2ENVIRONMENT SCHULMAN 2015 J HIGHDIMENSIONALCONTINUOUSCONTROLUSINGGENERALIZEDADVANTAGEESTIMATION WILLIAMS 1991 241 268 R GLOROT 2010 249 256 X PROCEEDINGSTHIRTEENTHINTERNATIONALCONFERENCEARTIFICIALINTELLIGENCESTATISTICS UNDERSTANDINGDIFFICULTYTRAININGDEEPFEEDFORWARDNEURALNETWORKS KINGMA 2014 D ADAMAMETHODFORSTOCHASTICOPTIMIZATION HENDERSON 2018 P PROCEEDINGSTHIRTYSECONDAAAICONFERENCEARTIFICIALINTELLIGENCE DEEPREINFORCEMENTLEARNINGMATTERS SIMOES 2019 D PROCEEDINGS2019INTERNATIONALJOINTCONFERENCENEURALNETWORKSIJCNN MULTIAGENTDEEPREINFORCEMENTLEARNINGEMERGENTCOMMUNICATION SIMOESX2020X40 SIMOESX2020X40X56 SIMOESX2020X40XD SIMOESX2020X40X56XD 2022-05-04T00:00:00.000Z 2022-05-04T00:00:00.000Z © 2020 Elsevier B.V. All rights reserved. 2020-01-24T17:13:40.667Z FCT Foundation for Science and Technology item S0925-2312(20)30131-4 S0925231220301314 10.1016/j.neucom.2020.01.079 271597 2020-07-03T23:17:03.812289Z 2020-05-21 true 5893288 MAIN 17 55131 849 656 IMAGE-WEB-PDF 1 gr1 13842 154 323 gr10 54916 629 565 gr11 29357 622 565 gr12 213442 697 809 gr13 99646 346 809 gr14 178491 685 809 gr15 31677 282 393 gr16 96299 359 809 gr17 34141 229 507 gr18 9746 200 277 gr2 10419 181 215 gr3 9774 169 226 gr4 15487 93 393 gr5 17939 216 282 gr6 12257 112 367 gr7 17137 187 339 gr8 15181 156 393 gr9 40391 209 489 fx1 6709 151 113 fx2 5268 151 113 fx3 6748 151 113 gr1 5745 105 219 gr10 8121 164 147 gr11 4458 164 149 gr12 15086 164 190 gr13 9350 94 219 gr14 13322 164 193 gr15 8473 157 219 gr16 8236 97 219 gr17 6828 99 219 gr18 4348 158 219 gr2 6992 164 195 gr3 6912 163 219 gr4 5082 52 219 gr5 9444 164 214 gr6 4651 67 219 gr7 6711 121 219 gr8 5414 87 219 gr9 10255 94 219 fx1 16688 164 123 fx2 15746 164 123 fx3 15156 164 123 gr1 136109 821 1719 gr10 601241 3342 3000 gr11 327689 3304 3000 gr12 2318252 3704 4300 gr13 1163486 1837 4300 gr14 2007625 3643 4300 gr15 240476 1503 2092 gr16 987838 1908 4300 gr17 300068 1218 2694 gr18 123225 886 1230 gr2 101713 964 1146 gr3 90582 895 1200 gr4 167617 494 2090 gr5 177392 1151 1500 gr6 118820 597 1950 gr7 161592 992 1800 gr8 151657 830 2090 gr9 455740 1111 2600 fx1 79695 667 500 fx2 43338 667 500 fx3 58024 667 500 mmc1 mmc1.xml xml 1143 APPLICATION si87 2748 si23 13921 si24 2780 si44 2154 si45 3759 si59 6410 si83 22320 si12 4412 si1 3208 si13 2555 si14 6305 si15 3561 si19 1704 si17 4485 si2 3559 si16 3228 si22 1674 si21 6195 si85 3036 si25 3225 si26 2944 si40 9533 si27 2693 si28 12023 si3 3376 si29 4346 si31 3434 si32 2665 si33 1713 si34 4320 si35 8067 si36 2219 si37 1268 si38 3873 si39 8614 si4 6966 si41 9070 si42 4149 si43 2709 si46 3318 si47 3782 si48 1807 si49 2069 si5 3098 si51 3683 si52 9125 si53 3946 si54 13645 si55 1953 si56 11964 si57 10704 si58 2855 si6 2670 si60 3796 si61 6839 si62 2725 si63 6996 si64 4298 si65 3918 si66 4054 si67 4338 si68 2815 si69 4312 si7 3573 si71 1874 si72 2104 si73 1571 si74 2116 si75 1968 si76 7507 si77 11757 si78 14063 si79 8112 si8 3672 si80 3765 si81 13887 si82 20364 si84 4965 si86 3079 si9 2651 si10 2761 si11 4879 si18 7577 si20 2715 si30 1420 si50 3018 si70 5440 am 2037608 NEUCOM 21836 S0925-2312(20)30131-4 10.1016/j.neucom.2020.01.079 Elsevier B.V. Fig. 1 The RL cycle for MAS [18], with J agents. At time-step t, each agent j executes action a t j upon the environment, composing the joint-action At . After this, each agent j obtains reward r t + 1 j and observation O t + 1 j . This process is repeated until the environment reaches a terminal state. Fig. 1 Fig. 2 The framework for Asynchronous Advantage Actor-Critic [16], with n workers. Each worker keeps a local copy of the on-line network, and interacts with its own environment. Updates are asynchronously performed on the global on-line and target networks. Fig. 2 Fig. 3 A3C architecture, using n separate workers. Each worker interacts with its own environment. As samples are collected in mini-batches, workers asynchronously update the global networks, and copy those weights into their local networks. Fig. 3 Fig. 4 The architecture of an agent j at time-step i, using three separate networks: a policy (or actor) network, which outputs an action probability π ( o i j ; r c i j ) (from which a i j is sampled) based on a given local observation o i j and received messages r c i j from other agents; a communication network, which outputs an outgoing message s c i j based on a given local observation o i j ; and a value (or critic) network, which outputs a value estimation based on a given centralized observation O i j . Fig. 4 Fig. 5 A3C3 architecture, using n separate workers. Each worker interacts with its own environment and its separate set of j agents. As samples are collected in mini-batches, workers asynchronously update the global networks, and copy those weights into their local networks. Fig. 5 Fig. 6 An exemplary architecture of agent j’s actor network. In this case, the actor aggregates the observation and the broadcast message of all other agents as its input. The network’s output layer then outputs a probability distribution for agent j’s movement in four possible directions. The output layer is directly based on the environment’s action space. Fig. 6 Fig. 7 An exemplary architecture of agent j’s centralized critic. In this case, the centralized observation O t j concatenates all agent observations as well as some additional information from the environment, when available. If the environment provides access to its underlying state, the centralized observation O t j simply becomes the complete environment state st . Fig. 7 Fig. 8 An exemplary architecture of agent j’s communication network. In this case, the network’s output layer uses a binary activation function and has 8 nodes, generating single-byte messages. Other output architectures are supported, including continuous valued messages. For example, a 10-node layer with tanh activations outputs a vector with elements x i , i = 1 , … , 10 , where each element x i → [ − 1 , 1 ] . Fig. 8 Fig. 9 Diagram of how broadcast communication with three agents is performed across two time-steps (arrow direction), and of how gradients for the communication network are propagated backwards (emphasized lines). This architecture can be extended to an arbitrary amount of agents. If messages are not broadcast, gradients are pushed only to the corresponding message senders, based on the built communication map. Fig. 9 Fig. 10 The POC suite [49], consisting of four environments: Hidden Reward, Traffic Intersection, Pursuit, and Navigation. All are partially-observable multi-agent environments, where agents benefit from sharing information and coordinating as a team. (a) Agents (black) only know their own position and explore the map until the reward zone (red) is found. (b) Agents (colored) must cross intersections without colliding. They know their desired direction, sense other vehicles around them, and are penalized if they collide (red marker). (c) Predators (squared) see only a small local area, and must chase, surround and capture the prey (green circles), which are hard-coded to run from the closest predator. (d) Agents (black) know the beacons' coordinates, but not each others' positions. They must cover all the beacons (red), and are rewarded by how close any agent is to each beacon. Fig. 10 Fig. 11 Some environments from the MPE suite [34], consisting on Cooperative Reference, Cooperative Communication, Cooperative Navigation, and Tag Challenge. (a) Agents (light colored) know their positions and their ally's target landmark (heavy colored). They must share that information and converge on their corresponding targets. (b) The gray agent cannot move and knows its ally's (light blue) target (dark blue). The grey agent must share that information for the light blue agent to converge on it. (c) Agents (blue) must cover all landmarks (black), by deciding which agent should cover which landmark. (d) Agents (red) try and touch the prey (green) as many times as possible, while dodging the black obstacles and remaining within map boundaries. Fig. 11 Fig. 12 Results of A3C, PPO, and A3C3 for the POC suite. The plots represent the average reward and standard deviation (over N workers) obtained by PPO, A3C, and A3C3 (with and without communication or a centralized critic), over training episodes. A dashed baseline is shown, obtained with a hard-coded joint-action output by a central entity with access to all agents’ observations. (a) Cooperative Reference. Agents (light colored) know their positions and their ally's target landmark (heavy colored). They must share that information and converge on their corresponding targets. (b) Cooperative Communication. The gray agent cannot move and knows its ally's (light blue) target (dark blue). The grey agent must share that information for the light blue agent to converge on it. (c) Cooperative Navigation. Agents (blue) must cover all landmarks (black), by deciding which agent should cover which landmark. (d) Tag Challenge. Agents (red) try and touch the prey (green) as many times as possible, while dodging the black obstacles and remaining within map boundaries. Fig. 12 Fig. 13 Results of A3C, A3C3, and MADDPG for the tested environments. The colored plots represent the average reward and standard deviation (over N workers) obtained by A3C and A3C3 agents, and the dashed plot represent MADDPG agents’ average reward, over training episodes. Fig. 13 Fig. 14 Results of A3C3 with different CC for the tested environments. The plots represent the average reward and standard deviation (over N workers) obtained by A3C3 with 0 to 20 CC, over training episodes. Fig. 14 Fig. 15 Results of the effects of noise for multiple environments. The plots represent the average reward and standard deviation obtained by agents at the end of the training phase, normalized between the average reward with no noise (dashed) and the average reward with no communication (dash-dotted). Fig. 15 Fig. 16 Results of multiple advantage estimators. ADV A3C3 uses a critic with a single output node, approximating V ( O t , θ v j ) . ADV A3C3’ , ADV COMA , and ADV A3C3’+COMA use a critic architecture with multiple outputs, which estimates V ( a t j | O t , θ v j ) for each action a t j . The plots represent the average reward and standard deviation (over N workers) obtained by A3C3 with each advantage estimator, over training episodes. Fig. 16 Fig. 17 The grid parameter search for adequate network architectures. Rows represent hidden layer configurations (e.g., bottom row represents a network with three hidden layers), whose sizes are multiplied by a network layer size multiplier x in each column (e.g., far right column represents multiplying hidden layer sizes by a factor of six). Each cell in the top table shows the average normalized reward r ∈ [0, 1] obtained by agents at the end of 150k training episodes, and each cell in the bottom table the thousands of time-steps t ∈ [0, 150] required to find the optimal strategy (if ever). Fig. 17 Algorithm 1 Pseudo-code for A3C3’s worker thread. Workers locally copy global parameters, sample the observations and rewards for all agents, and output corresponding actions and messages. Steps are taken until a mini-batch has been gathered, or a terminal state is reached. Workers compute the loss locally, apply gradients globally, and repeat this process until convergence has been achieved. Algorithm 1 Table 1 The hyper-parameters used for the tests conducted in this article, for all environments. This table lists the amount of agents J, the amount of workers N, the future reward discount γ, the learning rate η, the amount of communication channels (CC), and the layer size modifier x. Critic and actor networks used two fully connected hidden layers of 20x and 10x nodes activated with a ReLU function. The communication network used a single hidden layer with 10x nodes activated with a ReLU function, and an output layer of CC nodes, activated with a hyperbolic tangent function. The non-received message rc initial default value is all zeros. Table 1 Environment J N γ η CC x POC Hidden Reward 4 3 0.95 10 − 4 20 2 POC Traffic Simulator 40 3 0.1 10 − 4 1 2 POC Pursuit 3 12 0.95 5 × 10 − 5 10 6 POC Navigation 2 3 0.95 10 − 4 20 4 MPE Coop Navigation 3 3 0.001 10 − 4 10 8 MPE Coop Communication 2 3 0.001 10 − 4 10 8 MPE Coop Reference 2 3 0.001 10 − 4 10 8 MPE Tag 3 12 0.95 10 − 4 10 8 Table 2 Results of algorithms for cooperative navigation and cooperative communication environments. Table 2 Cooperative navigation Cooperative communication Average Distance # Collisions Average Distance Target Reached A3C3 0.162 1.245 0.006 99.9% MADDPG 1.767 0.209 0.133 84.0% DDPG 1.858 0.375 0.456 32.0% Table 3 The average score of predators in the Tag environment when pitting teams trained with different algorithms against a team trained with MADDPG. Algorithms try to maximize their score when acting as the Predator team, and minimize their score when acting as Prey. Table 3 A3C A3C3 Predator Prey Predator Prey MADDPG 144.66 141.37 123.27 108.06 Score difference 3 15 Multi-agent actor centralized-critic with communication Multi-agent actor centralized-critic with communication David Simões Conceptualization Methodology Software Writing - original draft Validation Investigation ⁎ a b Nuno Lau Supervision Writing - review & editing a Luís Paulo Reis Supervision Writing - review & editing b a DETI/IEETA, Institute of Electronics and Informatics Engineering of Aveiro, University of Aveiro, Portugal DETI/IEETA, Institute of Electronics and Informatics Engineering of Aveiro University of Aveiro Portugal DETI/IEETA, Institute of Electronics and Informatics Engineering of Aveiro, University of Aveiro, Portugal b Faculty of Engineering, LIACC/FEUP, Artificial Intelligence and Computer Science Lab., University of Porto, Portugal Faculty of Engineering, LIACC/FEUP, Artificial Intelligence and Computer Science Lab. University of Porto Portugal Faculty of Engineering, LIACC/FEUP, Artificial Intelligence and Computer Science Lab., University of Porto, Portugal ⁎ Corresponding author at: DETI/IEETA, Institute of Electronics and Informatics Engineering of Aveiro, University of Aveiro, Portugal. DETI/IEETA, Institute of Electronics and Informatics Engineering of Aveiro University of Aveiro Portugal Communicated by Dr. Tie-Yan Liu Multiple real-world problems are naturally modeled as cooperative multi-agent systems, ranging from satellite formation to traffic monitoring. These systems require algorithms that can learn successful policies with independent agents that rely solely on local partial-observations of the environment. However, multi-agent environments are more complex, due to their partial-observability and non-stationarity from an agent’s perspective, as well as the structural credit assignment problem and the curse of dimensionality, and achieving coordination in such systems remains a complex challenge. To this end, we propose a multi-agent actor-critic algorithm called Asynchronous Advantage Actor Centralized-Critic with Communication (A3C3). A3C3 uses a centralized critic to estimate a value function, decentralized actors to approximate each agent’s policy function, and decentralized communication networks for each agent to share relevant information with its team. The critic can incorporate additional information, like the environment’s global state, when available, and optimizes the actor networks. The actor networks of an agent’s teammates optimize that agent’s communication network, such that each agent learns to output information that is relevant to the policies of others. A3C3 supports a dynamic amount of agents, noisy communication mediums, and can be horizontally scaled to shorten its learning phase. We evaluate A3C3 in two partially-observable multi-agent suites where agents benefit from communicating local information to each other. A3C3 outperforms state-of-the-art multi-agent algorithms, independent approaches, and centralized controllers with access to all agents’ observations. Keywords Multi-agent systems Neural networks Emergent communication Reinforcement learning Distributed deep learning 1 Introduction Many complex reinforcement learning problems can be modeled as cooperative multi-agent systems (MAS), including robotic navigation [1,2], traffic monitoring [3], and satellite formation [4]. The recent popularity of deep reinforcement learning has achieved great results in highly complex single-agent environments [5], through the use of neural networks to approximate policies. However, single-agent algorithms typically underperform in multi-agent environments, as the joint action-space of the agents grows exponentially with the team size. It becomes a necessity for policies to be executed in an independent and decentralized manner, where an agent only has access to its own local observation of the environment, its action-observation history, and communicated information sent by other team members. Various research efforts [7,6,8] have shown that achieving coordination among agents under such conditions remains a complex challenge with open questions. Hence, there is a great need for new reinforcement learning methods that can efficiently learn decentralized policies. In many cases, learning can take place in a simulator or a laboratory in which extra state information is available and agents can communicate freely, a paradigm known as centralized learning, distributed execution [9]. However, how best to exploit this paradigm remains an open issue [10]. An additional challenge is how to transmit relevant information to other agents of the team. Communication is a general and flexible approach, that allow agents to share both low- and high-level information [11], despite being possibly constrained by environment restraints, such as distance. Recent research has shown that agents can learn communication protocols tabula rasa [12,13] or derive them from symbol alphabets [14,15]. Determining how agents learn their communication protocols also remains an open question. In this work, we propose Asynchronous Advantage Actor Centralized-Critic with Communication (A3C3), a deep multi-agent reinforcement learning algorithm based on actor-critic methods. A3C3 agents train an actor, i.e., the policy, by following a gradient estimated by a centralized critic, while also training an additional communication network, which follows a gradient given by the actors of their own team-mates. A3C3 is based on three core ideas. Firstly, it is based on Asynchronous Advantage Actor-Critic (A3C) [16], a deep learning single-agent actor-critic method. A3C use advantages to train its actors, representing how better an action’s actual returns were when compared with the value expectation given by the critic. A larger advantage implies the action had a better outcome than expected, and it should be taken more often. A3C can also be horizontally scaled through multiple workers, requiring no specialized hardware. Secondly, A3C3 uses a centralized critic. The critic, only used during learning, incorporates all agents’ observations and any additional information provided by the environment. During execution, agents do not require a critic, and can act based solely on their local observations. The centralized critic speeds up and stabilizes the learning process. Its function is to estimate the expected reward for a given state when agents follow their current policies. It is simpler than approaches which output value estimations for all actions in a given state, and, by extension, is trained faster. Thirdly, A3C3 uses a communication network. This network, like the actor, takes as input only local information available to each agent (such as local observations or incoming messages sent by other agents). It outputs messages, modeled as vectors of continuous values, which are sent to other agents following environment restraints (limitations, noise, among others). The protocol learned by each population is unique, and stimulates coordination among agents, by improving the policies of an agent’s team-mates. The remainder of this paper is structured as follows. Section 2 lists related work, from actor-critic based algorithm with centralized critics, to reinforcement learning algorithms that simultaneously learn communication protocols and action policies. Section 3 states our problem, and Section 4 introduces and formally describes A3C3, as well as its architecture, modules, limitations, and methodology. Section 5 shows the results of our proposal obtained in complex environments, on two multi-agent environment suites, used by other state-of-the-art algorithms. Finally, Section 6 draws conclusions and lists future work directions. 2 Related work Multi-Agent Reinforcement Learning (MARL) is the discipline that focuses on models where agents dynamically learn policies through interaction with the environment. An agent’s goal is to maximize its local reward, a numerical-representation of a long-term objective [17]. In a MAS, multiple agents behaves as learners, selecting and performing actions on the environment, which then reaches a new state. Agents sample observations from the environment’s current state, and obtain a reward associated with each state-transition, as shown in Fig. 1 . There are many open issues and challenges in MARL [19,20]. Theoretical guarantees common in most single-agent RL algorithms are lost, since the optimal policy for an agent may change as other agents change their own behavior [21]. Algorithms must also handle the structural credit assignment problem, related to how players that have not contributed equally to the task completion should be rewarded. In environments with homogeneous rewards (the entire team receives the same rewards), agents who did not contribute may get rewarded for an objective. In environments with heterogeneous rewards (each agent receives its own local reward), agents who contributed to complete an objective may receive no feedback about it. If communication is available to agents, there is yet no consensus about what and when to communicate, and how that protocol should be learned. Finally, the fundamental issue of MARL is the coordination problem or, in other words, how should multiple agents coordinate to form an optimal joint-behavior, and how this joint-behavior can be learned. Common properties of MAS include requiring agents to be executed in a distributed and independent manner, with some environments even varying the amount of agents active in the environment during run-time. Agents are also expected to rely solely on their own local and possibly incomplete or incorrect observations of the environment. The structural credit assignment problem should be handled in a way that prevents agents from converging to sub-optimal policies. Finally, when inter-agent communication is used, often there are constraints regarding reliability, message sizes, and message delays for agents. An environment where all messages can be broadcast perfectly without delays, errors, and range-limit is unrealistic. 2.1 Reinforcement learning Although MARL has been applied in a variety of settings [22], it has often been restricted to tabular methods and simple environments [10]. To scale to high dimensional input and action spaces, algorithms require specific techniques. Hierarchical learning solutions, for example, decompose the problem model to reduce the complexity of its state-space [23]. QA-Learning [24] demonstrates how hierarchically decomposing the problem model can reduce the complexity of its state-space in cooperative multi-agent environments. The algorithm classifies agents as workers, tutors and consultants, and assigns sub-problems to consultants, who delegate them to tutors and workers. It has been shown to outperform other hierarchical decomposition reinforcement learning algorithms, but the decomposition process is currently implemented by hand. Other approaches rely on deep learning to simplify state-space, such as the Deep Q-Networks (DQN) algorithm [25], which uses a deep neural network with weights θ, known as the on-line network, as a function approximator, where Q(s, a, θ) ≈ Q*(s, a). The agent’s experience at each time-step ( s t , a t , r t , s t + 1 ) is stored in a data-set D , known as an experience replay. Random batches of uncorrelated samples are uniformly drawn from the replay memory, and used to optimize weights θ, where the loss L(θ) is given by the mean squared error between the network and a target y t = r t + γ max a Q ( s t + 1 , a , θ − ) . Mnih et al. [16] have shown that asynchronous methods running on multi-core CPUs not only require less specialized hardware than their GPU counterparts, but they also achieve greater results in a shorter amount of time. Asynchronous methods essentially keep a global network which all worker threads asynchronously update and whose weights are periodically copied by each worker into its own network. There is no experience replay from which to draw samples, and each thread provides its own samples, in order to break the correlations between mini-batches. These algorithms can be horizontally scaled by increasing the amount of workers, which increases the amount of samples and updates per unit of time, and speeds up the learning process. Asynchronous Advantage Actor-Critic (A3C) [16] is an asynchronous algorithm based on actor-critic methods. Actor-Critic methods decouple the value and policy functions into two separate networks. The Critic network with weights θv approximates a value function V(st, θv ) and estimates the expected return at a given state st . The Actor network with weights θa maintains a policy π(at |st, θa ) from which action at is sampled for state st . Workers keep local copies of both these networks, but asynchronously update their global versions, as shown in Fig. 2 . Proximal Policy Optimization (PPO) [26] is a policy search-based method largely inspired on A3C. The policy network uses a new update function which clips policy updates to prevent very large update steps. It has been shown to achieve state-of-the-art results in multiple single-agent environments, with less hyper-parameters and a simpler implementation. Both DQN, A3C, and PPO are single-agent deep reinforcement-learning algorithms. They can be adapted to the multi-agent paradigm through the Independent Learners approach [27], where each agent assumes its environment as a single-agent stationary one. However, such efforts do not enforce coordination among agents, do not take advantage of the distributed nature of the environment, and do not share information among agents to speed up the task’s completion. 2.2 Multi-agent deep learning Some recent deep-learning contributions for multi-agent environments focus on centralized-learning to enforce coordination among agents. Foerster et al. propose Counterfactual Multi-Agent Policy Gradients (COMA) [10], as an extension to actor-critic algorithms. COMA requires centralized learning to augment the critic network with additional information, while the actor network only requires local information. This allows agents to run in a distributed manner, where the team is composed of decentralized and independent agents, which act based solely on their own set of local observations of the environment. COMA’s centralized critic optimizes a stationary value function, even as policies change, and is used as a solution to the credit-assignment problem, by comparing how each agent’s action effectively contributes to the overall reward. However, COMA’s critic includes agent actions as input, and its complexity is proportional to the amount of agents in the environment. Agents also share this critic network, so COMA does not support heterogeneous reward functions. Sunehag et al. present the value-decomposition network (VDN) [28], where agents learn a factorized joint-action value function based on their independent observations, and the sum of each agent’s estimation approximates the centralized joint-action function. Agents can communicate by concatenating the output of their layers at some points, thus assuming noiseless communication without constraints once more. VDN disregards any additional information available from the environment, and limits the complexity of the centralized joint-action function to a simple sum. Rashid et al. present QMIX [29], a VDN-extension, where each agent’s value function is no longer summed to approximate the centralized joint-action function. Instead, an additional mixing network is used to combine each individual value function in a more complex manner, which is also able to incorporate additional environment information. Since COMA, VDN, and QMIX do not use communication between agents, agents may not compensate for partially-observable environments by sharing relevant information. 2.3 Multi-agent deep learning with communication Deep learning algorithms that focus on learning communication protocols do in fact compensate for local partial-observability, but authors do not often adhere to expected assumptions, such as agent independence or imperfect communication channels. Peng et al. propose Multi-Agent Bidirectionally Coordinated Network (BiCNet) [30], an actor-critic extension on Minimax Q-Learning [31]. Actor and critic networks output the agents’ actions and Q-value, respectively, by using a shared observation from all agents. Agents are ordered hierarchically and given a memory through Recursive Neural Network (RNN) [32] layers. They communicate by sharing the RNN’s internal states with their hierarchical neighbors, which is not a fully decentralized approach. BiCNet also requires RNN layers, which are notoriously harder to train [33]. Lowe et al. propose Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments (MADDPG) [34], another actor-critic extension. Similarly to COMA, the critic network is augmented with additional information, but MADDPG learns a centralized critic for each agent, and thus supports heterogeneous reward functions. The critic is augmented with the shared observations of all agents, and its complexity is again proportional to the amount of agents in the environment. MADDPG introduces a communication mechanism to handle partially-observable environments, by formulating message passing as an additional discrete action-space. Sukhbaatar et al. propose CommNet [12], which focuses on learning continuous communication protocols between agents simultaneously with agent policies. At each time-step, agents communicate multiple times through differentiable communication channels, and agents receive a jumbled sum of all messages sent by other agents. The amount of transmitted messages is an arbitrary value chosen a priori, and CommNet outputs a joint-action. Foerster et al. propose Differentiable Inter-Agent Learning (DIAL) [9], also focused on learning continuous communication protocols. While learning a policy based on Q-learning, discrete messages are learned simultaneously to handle the partial-observability of the environment. The authors assume perfect communication between agents, and test their proposal in a limited set of short-horizon environments. The applicability of DIAL to complex environments is not described, but DIAL disables the experience replay feature, which was shown to be an essential component of DQN [25] to achieve successful policies in complex environments like the Atari 2600 test-bed [35]. Some proposals use a pre-determined vocabulary to communicate between agents. Mordatch et al. [15] propose learning communication from a set of discrete symbols, based on a Gumbel distribution and a joint-reward function. The authors use RNN modules, in order to maintain a meaningful conversation between agents, assume perfect perfect communication, and their algorithm requires fully cooperative environments. Das et al. [14] use Hierarchical Recurrent Encoder-Decoder networks applied on REINFORCE [36] to learn action and communication policies. Agents use a pre-determined vocabulary consisting of natural-language symbols, and learn to complete the tasks using human readable communication. Lazaridou et al. [37] propose a multi-agent reinforcement learning algorithm in which the action space is replaced by the communication alphabet. Agents learn to communicate and complete cooperative tasks in which images must be identified. Since BiCNet requires a joint-observation and CommNet outputs a joint-action, neither can be run in a decentralized manner, and both have limited scalability. MADDPG, the Mordatch algorithm, the Das algorithm, and the Lazaridou algorithm all require a communication alphabet to be defined a priori, and do not allow the vocabulary to grow or otherwise change without repeating the learning phase. All of the shown algorithms also assume perfect communication conditions, without noise, message loss, or message constraints. 2.4 Others Some proposals also deviate from pure deep reinforcement-learning approaches, and instead mix reinforcement with supervised learning techniques. Lewis et al. [38] intersperse training with supervised learning so that agents learn natural language protocols. The models use dialogue rollouts to plan ahead in bargaining tasks or fake interests in adversarial tasks. Li et al. propose Multi-Step, Multi-Agent Neural Network (MSMANN) [39], where supervised learning is used for decentralized agents to learn to imitate a centralized strategy. Communication and action policies are both learned simultaneously, despite requiring a JAL strategy to be learned a priori. Techniques that rely on supervised learning require researchers to provide a pre-determined solution for agents to imitate. This may introduce human bias in the provided solutions, or it might simply not be possible in complex environments. Our proposal is a fully reinforcement learning approach, end-to-end differentiable. A3C3 focuses on centralized learning along with continuous communication protocols, based on generic message passing. It supports distributed execution, a dynamic amount of agents, and noisy communications. While A3C3 does not require any additional information from the environment, it can incorporate such information and benefit from it. To the best of our knowledge, it is the first algorithm that is shown to achieve successful policies under all of these constraints. 3 Problem statement We focus on multi-agent cooperative environments with J agents, in which each agent j has local partial observations o t j of the environment at each discrete time-step t. An observation o t j is a (usually incomplete) representation of the environment’s state st , and can be noisy, discrete or continuous. Orthogonally, observations may also be local or global. Global observations represent the state without any agent specific information or perspective (e.g., a bird’s eye view over a soccer field), while local observations are based on the agent’s identity and pose (e.g., the positions of players in a soccer field relative to the agent’s location and orientation). Agent j acts independently upon the environment, through a discrete set of actions A j , and obtains reward r t j based on a reward function R j determined by the environment. The environment is modeled as a Decentralized Partially-Observable Markov Decision Process (Dec-POMDP), a multi-agent generalization of a Markov Decision Process. Formally, it is defined by the tuple E = ( S , { A J } , F , { O J } , O , { R J } ) , where J is the number of agents and S ∈ N d is a finite set of possible d-dimensional states of the environment E . For simplicity, assume j = 1 , … , J throughout the remainder of this paper. A j is a set of possible actions for agent j and A is the joint-action set A = A 1 × ⋯ × A J , whereas F : S * A * S → [ 0 , 1 ] is a state transition probability function F(s′|s, a) for transitioning to state s′ after taking joint-action a in state s. O j is the set of observations for agent j and O is the joint-observation set O = O 1 × ⋯ × O J , while O : S * A * O → [ 0 , 1 ] is a state observation probability function O(o|s, a) for observing o after taking joint-action a in state s. Finally, R j : S * A * S → R is the reward function of agent j. A joint policy π is gathered from the policies π j : O j * A j → [ 0 , 1 ] , which represent probability distributions over possible actions for each observation. At time-step t, agent j samples observation o t j ∈ O j from the environment, acts based on its policy πj , and obtains reward r t j when the environment transitions to the next state s t + 1 . If agents obtain global observations of the environment, the environment is instead modeled by a POMDP and agents instead observe o ∈ O . In fully-observable environments, agents directly obtain the environment’s underlying state s. Agents have homogeneous reward functions when R j = R i for any agents j and i, and heterogeneous reward functions otherwise. This article focuses both on environment with homogeneous joint-rewards, where agents receive points as a team, and in cooperative environments with heterogeneous rewards, where agents receive individual rewards but benefit from cooperating with one another. Agents must be executed in a distributed and independent manner, based solely on their own local observations. However, during the learning phase, algorithms can take advantage of centralized architectures, and incorporate additional information from the environment or from the agents into their policies. This includes concatenating agent observations, or accessing the underlying state s, for a better estimation of the value function. This additional information is no longer available during the execution phase. The amount of agents J can vary throughout each episode, depending on the environment (e.g., a race can initially have three vehicle agents, but only two remain active after one finishes the track). Agents can also share information between them through message passing. Messages may have limited range, where agents can only communicate with geographically close team members. Messages can also be size-limited, and agents may not be able to transmit large sets of continuous values, but instead only a single byte of information. Finally, messages may also have target constraints, and cannot be broadcast to the entire team, but instead directly sent to a specific target. Not only that, but communication channels are imperfect, and suffer from noise. Messages can be delayed or, in the worst case, lost. They can also suffer external interference (e.g., random noise over the message’s values) or suffer from internal jumbling (e.g., an agent receives the average of two messages, instead of receiving each message separately and distinctly). 4 Asynchronous Advantage Actor Centralized-Critic with communication Single-agent distributed algorithms like Asynchronous Advantage Actor-Critic (A3C) [40] run multiple parallel workers in multi-core CPU and have been shown to outperform single-threaded GPU-based algorithms. They keep global networks which are updated by multiple workers asynchronously, as shown in Fig. 3 . Because they are based on Actor-Critic, they keep an actor network, outputting the probability π(at |ot; θa ) of taking action at at time-step t, based on the current observation ot and the actor’s weights θa . They also keep a critic network V(ot; θv ), outputting a value estimation based on the current observation ot and the critic’s weights θv , which are updated with mini-batches from each worker. We propose Asynchronous Advantage Actor Centralized-Critic with Communication (A3C3), a multi-agent deep reinforcement learning algorithm. Each agent is represented by an actor, a centralized critic, and an additional communication network, as shown in Fig. 4 . The centralized critic outputs a value estimation based on a centralized observation O t j , which can be an aggregate of all agents’ local observations, or directly provided by the environment when possible. The central critic acts as an implicit information sharing mechanism, which makes gradient updates much more robust. The actor network remains decentralized, and outputs each agent j’s action probability distribution based on its current observation o t j . The communication network is also decentralized, and outputs a message s c t j sent by each agent j, which is then received by its team members at time-step t + 1 . The communication networks are optimized in order to help agents improve their policies, in order to handle partially-observable domains in a cooperative setting. Both the central critic and the communication network techniques have the goal of improving the coordination level of the team. Multiple workers asynchronously update all networks for each agent, by periodically making local copies of the networks, using them to calculate gradients, and applying the gradients on the global networks, as shown in Fig. 5 . A3C3 is a more general version of A3C, since if the number of agents J = 1 , there is no communication, and the centralized critic uses the agent’s local observation, the algorithm becomes A3C. We describe the behavior of a worker thread in Algorithm 1. A3C3 can be horizontally scaled by increasing the amount of workers, which increases the amount of samples and updates per unit of time, and speeds up the learning process. Computations may also be sped up if networks with the same input (actor and communication networks) use intra-agent parameter sharing for all layers but the last one [40–42]. This technique consists on having a single network with two output layers, instead of two separate networks. The error of both outputs is summed to optimize the shared network. If agents are homogeneous (also known as agent invariance [29]), A3C3 can also use inter-agent parameter sharing, to further speed up the learning process. This allows the same actor, critic, or communication network to be learned by all agents simultaneously. Since agents have different perspectives and batches of experience, when using inter-agent parameter sharing, each agent’s mini-batch of samples will break correlations in the network updates, in the same way multiple workers do so in A3C’s single-agent learning. In other words, with homogeneous agents and inter-agent parameter sharing, A3C3 can optimize agent policies with a single worker. Multiple workers speed-up the learning process, but this may be useful in contexts with hardware limitations, such as when multiple GPUs are necessary but unavailable, or when using older commodity hardware. In the limit, if agents are homogeneous, A3C3 can optimize only two networks, a decentralized network (with a policy and a communication output layer) and a centralized critic, for all agents. However, this computational performance increase comes at the cost of a more complex network being necessary to approximate both the policy and communication functions simultaneously. 4.1 Actor network The actor networks with weights θ a j for each agent j aggregate observations o t j and received messages r c t j as input, and output policy π ( a t j | o t j , r c t j , θ a j ) through a softmax function. For scalability, agents can average the received messages, instead of aggregating them, reducing the complexity of the network at the cost of losing information from messages. An exemplary actor network is shown in Fig. 6 , where an agent will move north with 70% chance, and move south otherwise. Workers optimize the actor loss L a t j based on an advantage estimator, the logarithm of the policy, and an entropy factor. The advantages ADV A3C3 are given by the Generalized Advantage Estimator (GAE) [43], where ADV A3C3 = ( r t j + γ V ( O t + 1 , θ v j ) − V ( O t , θ v j ) ) with γ = 1 . The advantages are then multiplied by the logarithm of the policy log π ( a t j | o t j , r c t j , ϑ a j ) to represent how an action obtained rewards higher than expected. An entropy factor β determines the weight of the policy’s entropy loss H ( π ( a t j | o t j , r c t j , ϑ a j ) ) and discourages premature convergence [44]. Agents with homogeneous action spaces and reward functions can use inter-agent parameter sharing in the actor networks. 4.2 Centralized Critic network The centralized critic networks with weights θ v j for each agent j use centralized observations O t j as input, and output expected value estimations V ( O t j , θ v j ) , as shown in Fig. 7 . This centralized observation is environment dependent, and can be: • Sampled as a fully-observable environment state, common to all agents. This may not be possible in some environments; • Derived as a fully-observable environment observation, from the concatenation of each agent’s partial local observation. This requires that the concatenation of all agents’ partial observations oj can create a fully-observable observation; • Derived as a partial observation of the environment, from the computation of each agent’s partial local observation. This is the least restrictive option, as it makes no assumptions on the observability of the environment. The properties of the centralized observation O t j depend on the depth of information provided by the environment to agents. For example, the centralized observation of a chess game is readily available as the underlying fully-observable game-state (both agents can see the entire board and there are no hidden pieces). The centralized observation for a game of cards, on the other hand, is a partial-observation encompassing the cards each player holds in hand, but without knowing cards hidden in the deck. If the hidden cards information can be accessed by A3C3 (for example, by directly requesting the simulator for additional debug information) and is concatenated with the agents’ observations, the centralized observation becomes a fully-observable state. Workers optimize the critic loss L v t j based on the squared difference between the actual returns R and the value estimation V ( S t j , θ v j ) . The critic estimation bootstraps the next state’s expected value at the end of a mini-batch, if a terminal state has not been reached. Agents with homogeneous reward functions can use inter-agent parameter sharing in the critic networks. A3C3 supports using the same centralized critic for all agents (following the approach of COMA), or the more general case of a centralized critic for each agent (following the approach of MADDPG). 4.3 Communication network The communication networks with weights θ c j for each agent j use observations o t j as input, and output messages M ( o t j , ϑ c j ) . The output layer of this network defines the size and type of the generated messages. In other words, n-channel messages are generated by a network with an output layer of n nodes, and its activation function defines the value range of each channel. For example, an 8-node output layer using binary activations computes single-byte messages, as shown in Fig. 8 . Communication constraints are environment-dependent, and can be classified based on reliability, connectivity, parallelism, or others. Messages can be broadcast to all other agents or sent to specific recipients, depending on the environment. Received messages can be averaged to maintain a simpler network architecture, at the cost of losing some information. Broadcasting messages to all other agents may lead to scalability issues with large teams. If agents expect to send or receive a specific amount of messages based on the team size, then the networks may not handle varying numbers of agents during execution. These communication properties are captured within a communication map, built by each worker thread, which describes what agents sent which messages to which agents in the current batch of samples. An undelivered messaged takes a value rc initial for the network input layer. If agents send messages to themselves, they create a memory channel through which information from previous states can still be accessed. A sent message s c t j is received by other agents in the next time-step as r c t + 1 j . Gradients are first computed on the actor network with respect to the received messages, and is modeled as the error of received messages L r c i + 1 . Those are then applied to the sent messages (through the communication map) as message loss L s c t , which is then minimized by optimizing the communication network. The loss can be summed or averaged, if a sent message is received by multiple agents, which can lead to large network updates, or steady slow ones, respectively. Fig. 9 shows an example where three agents broadcast messages to others. The actor error for agents 1 and 2 is propagated into the message sent by agent 0 on the previous time-step, and used to optimize the communication network. This makes agents optimize the messages they send such that other agents improve their policies, thus causing agents to send relevant information and enforcing coordination. Because gradients of a received message r c t + 1 j are propagated across the last time-step’s communication network of agent j to optimize message s c t j , the agent learns to transmit as much relevant information as possible from its observations o t j . Information is considered relevant when it improves the policies of team members, since the environments are cooperative. 5 Results The A3C3 algorithm is tested in the POC and MPE environment suites. A3C3 is compared against state-of-the-art single-agent algorithms, A3C, DDPG, and PPO. It is then compared against multi-agent MADDPG, and the effects of its centralized critic and communication networks are independently tested. After this, the effects of noise in the communication medium are tested against baselines with no noise or no communication. Finally, multiple advantage estimation formulae are evaluated. Some of the tests with three workers were conducted in a medium-range laptop without a GPU, demonstrating how the proposed algorithm can be deployed in commodity hardware and still achieve complex reinforcement learning policies within a reasonable amount of time. The performance of algorithms is based on the average episodic reward obtained by the team, where better policies imply higher rewards. Accordingly, the plots shown represent the average reward obtained by the team. Learned policies have been published at For these tests, the actor, critic, and central critic networks had two fully connected hidden layers of 40x and 20x nodes activated with a ReLU function, where x represents a problem-dependent width modifier. The communication network had a single fully connected hidden layer of 20x nodes activated with a hyperbolic tangent function, with a non-received message rc initial equal to zeros. The adequate architecture for each environment was found with a grid parameter search, as described in Section 5.6. We used the simplest architectures that consistently converged to proper policies in a set of five independent runs. All A3C3 plots show the results of a randomly chosen run from that set. Networks used the Glorot initializer [45] with default parameters to compute their initial weights, the Adam optimizer [46] with default parameters to optimize them, and an entropy weight β = 0.01 to discourage premature convergence. For each environment, we chose the highest learning rate η that still allowed convergence, and a future reward discount factor γ dependent on the horizon of each scenario and its importance of future rewards. A list of the final hyper-parameters for our tests is shown in Table 1 . Following reproducibility guidelines [47], our tests and parameters have also been published along with our source-code at 5.1 Test Environments A3C3 is tested in eight MARL environments, compliant with the Gym de facto standard API [48]. These environments can be represented as Dec-POMDP, and contain partially-observable state-spaces, where agents can only sample incomplete, noisy, or incorrect observations of the underlying state. All are cooperative or mixed environments, where coordination is vital for the team to complete the task. 5.1.1 Partially Observable with Communication suite In the Partially Observable with Communication (POC) Suite [49], communication is crucial to overcome the partial observability of the environments. The following sections describe a Hidden Reward challenge, a Traffic Intersection simulator, a Pursuit game, and a Navigation task, as shown in Fig. 10 . The Hidden Reward game focuses on classic exploration, and agents need to learn how to efficiently explore the environment and alert team members when the target is found. The Traffic Intersection is a close-horizon game, with large amounts of agents, where agents need to learn to adhere to rules and overcome multiple indistinguishable intersections. The Pursuit game is a classical benchmark where agents need to explore and coordinate in order to capture the prey, and the Navigation task focuses on goal assignment, and agents learn how best to distribute themselves in order to complete the task. While agents receive observations about the environment, it is possible to access the environment’s underlying state directly. This allows algorithms with the centralized learning, distributed execution method to augment their learning phase with additional information in an efficient manner. The scenarios, some of which are shown in Fig. 10, include: • Hidden Reward – J agents, one target area. Each agent observes its own coordinates and whether it is in the target or not. There is a global time limit since the challenge starts, and a smaller one since any agent finds the reward zone. Agents receive individual rewards each cycle, 0 points if not on the reward zone, and n points if on the reward zone, where n is the total amount of agents there. • Traffic Intersection – Up to J agents, and six by six road intersections. Each agent observes its desired direction and nearby vehicles. Agents get small penalties for stalling traffic, big penalties if they crash, and even larger penalties if they crashed without having priority. The communication range of agents is geographically limited to close vehicles. • Pursuit – J predators, and up to J prey. The prey team is hard-coded, has global vision, and runs from the closest predator. Predators observer a small local area (less than 10% of the total map) and their own global coordinates. The team gets small penalties as time passes, and agents get penalized and randomly placed if they collide. • Navigation – J agents and J landmarks. Each agent observers its own position and the landmark positions. The episode ends when all beacons are covered, or when the episode length reached a time-limit. The team gets points at the end of each time-limited episode, based on how close an agent was to each beacon. The POC suite requires agents to share information regarding their observations in order to complete the tasks of each environment. Environments are cooperative and agents must coordinate to complete them successfully within their time-limits. 5.1.2 Multi-agent Particle Environment suite The Multi-agent Particle Environment (MPE) suite [34] is a set of local continuous observation- and discrete action-space scenarios with simulated physics, which may incorporate communication. The action-space for an agent consists on increasing or decreasing its velocity in one of two axes, both of which decay over time. An agent’s observation space usually consists on the relative positions of all entities on the map, as well as the velocities of all allied agents. In environments with agent-specific targets, observations also comprise the relevant information (possibly of a different agent’s target, thus requiring communication to complete the task). The scenarios, some of which are shown in Fig. 11 , include: • Cooperative Reference – two agents, three landmarks. Agents know the target landmark of their ally, and not their own, which they are rewarded for being close to. • Cooperative Communication – the same as Cooperative Coverage, but only one agent can move, while the other knows its target. • Cooperative Navigation – J agents and landmarks. Agents are rewarded by being close to each landmark. • Tag Challenge – one adversary, J agents and landmarks. Agents try to touch as many times as possible the faster adversary. In order to successfully complete these tasks, mechanisms to handle partial-observability are required. These may range from memory of previous states to communication protocols. In addition, tasks also require strong coordination skills, and Cooperative Reference and Cooperative Communication both require relevant information sharing to successfully be completed. 5.2 State-of-the-art comparison This section focuses on evaluation the performance of learned policies in multiple environments. Teams are evaluated based on their average episodic reward, and algorithms are given similar training parameters for a fair evaluation. A3C3 is now compared against A3C, DDPG, MADDPG, and PPO. A3C3 can be directly compared with its variants (A3C3 without communication, or A3C3 without a centralized critic), and with A3C, due to their similarities. The same hyper-parameters can be used across these tests, and learning curves are directly comparable. In contrast, DDPG, MADDPG, and PPO cannot use the exact same hyper-parameters, as they do not implement communication in the same manner, and have different network structures. Because MPE was used to evaluate the performance of DDPG and MADDPG, we use the hyper-parameters proposed by Lowe et al. [34] to evaluate those algorithms in MPE, and the average performance of the best policies is used as a baseline against A3C3. For PPO, the hyper-parameters proposed by Schulman et al. [26] are used, along with a learning rate η = 3 × 10 − 4 . Tests are initially conducted on A3C3, PPO, and A3C, in the POC suite. A variant of A3C3 without communication is considered, where implicit coordination is learned but no information is shared, as well as a variant without the centralized critic, where value estimations are fully independent for each agent. In this architecture, each agent’s critic takes as input solely its own local partial observation to approximate the value function. As a comparison baseline, we implemented a centralized controller that has access to all agents’ observations and is able to efficiently complete the task. The results, shown in Fig. 12 , demonstrate that A3C3 outperforms all other options. The algorithm achieves stronger policies within less time-steps and with less variance than other algorithms. Without communication, both A3C, PPO, and A3C3 fail to complete tasks successfully. Without the centralized critic, A3C3’s learning process takes longer to converge, and policies have a higher variance. This demonstrates how both these components of the algorithm contribute to its success. A3C3 is also able to either match or outperform our centralized control baseline. In the Hidden Reward and Pursuit environments, A3C3 agents converged to a more optimized coordinated exploration policy and completed the task more efficiently. Tests are now conducted on the MPE suite with A3C, A3C3, DDPG, and MADDPG. The results for MPE’s Cooperative Navigation and Cooperative Communication are shown in Table 2 . In Cooperative Communication, A3C3 can learn policies that are more frequently successful and also achieve shorter distances to the target positions than DDPG and MADDPG. In the Cooperative Navigation environment, A3C3 achieves smaller distances, but more collisions. Rewards are structured such that the reward r of each agent is given by r = ∑ l L − d l − C , where L is the total amount of landmarks, da is the minimum distance of each landmark l to any agent, and C is the amount of collisions on the environment. Therefore, achieving smaller distances at the cost of a higher number of collisions maximizes the rewards obtained by agents, and A3C3 outperforms MADDPG and DDPG. Algorithms are now evaluated in MPE’s Cooperative Reference and Tag tasks, and evaluated based on their average obtained reward. The results, shown in Fig. 13 , demonstrate the evolution of policies learned by A3C and A3C3 against MADDPG baselines, trained under the same conditions until convergence was achieved. A3C3 agents completed both the proposed tasks and greatly outperformed MADDPG, while A3C was unable to do so in Cooperative Reference, which required communication. Finally, A3C3, A3C and MADDPG teams are also evaluated after learning policies through self-play. In this case, the Tag task is used as a competitive environment, and each algorithm trains both teams until policies stabilize. The actual average reward obtained by the predatorial team for each algorithm has no meaning, since its performance depends on its opponent’s strategy. Weak predators may obtain higher rewards against weak prey than optimal predators against strong prey. Table 3 shows an analysis of policies learned by A3C3 and A3C against those learned by MADDPG. Surprisingly, A3C has the best predators against MADDPG, while A3C3 has the best prey. We conclude that this is due to two main factors: A3C3 learned overfit policies, which made A3C3 predators less flexible to different opponents; MPE Tag provides fairly complete observations for predators, which lessens their need to communicate. A more intuitive way of analyzing each algorithm’s performance is to compare the scores of each algorithm when the teams are reversed. Predators try to maximize their own score, catching the prey as often as possible yields points. Prey try to minimize the predators’ score, by not getting caught, awarding no points to predators. An algorithm that achieved perfect policies would earn maximum points when playing as Predators, and zero points when playing as Prey. Calculating the difference of points by the Predator team shows that A3C3 achieves the highest difference, 15 points, and therefore outperforms A3C. 5.3 Effects of communication Fig. 14 shows the policy evolution of A3C3 across training episodes of the team, applied to the proposed suite of environments. Different amounts of communication channels (CC) are tested, demonstrating how explicitly sharing information with learned protocols can also improve the agent policies. The CC represent the width of the communication network’s output layer and the length of sent messages. The communication network’s output layer is activated with a hyperbolic tangent function, such that each CC outputs a continuous value [ − 1 , 1 ] . For the Hidden Reward challenge, shown in Fig. 14(a), without communication, the average reward stagnates around 30, since agents cannot share the reward zone’s position, and thus resort to random exploration to find it. However, with a single CC, a better policy can immediately be found. This continuous channel helps reduce the area of exploration, and allows the policy to greatly improve. With multiple channels, agents obtain an average reward of 85, and as we increase the amount of channels up to twenty, the speed at which the policy is found also increases. Agents learn to coordinately explore, and to alert team-mates when the reward has been found, which lets the team converge on it. In Fig. 14(b), communication is crucial to achieve a decent policy in the Traffic Simulator, where traffic flows easily and without collisions. We estimate the quality of traffic flow by the amount of intersection collisions, where two vehicles intend to follow the same path try to cross the intersection simultaneously, and the amount of intersections stops, where a vehicle at the intersection does not move (possibly to avoid a collision). With no communication, the total average reward for all agents is − 60 , since agents cannot communicate whether they have to turn or not, which leads to large traffic jams, and agents randomly colliding, with an average of 4 collisions and 95 stops per episode. A single CC is sufficient to achieve a policy where vehicles adhere to traffic rules and agree on who should advance at intersections, achieving a total average reward of − 17 , an average of 0.5 collisions, and 15 stops per episode. Interestingly, agent populations learn different communication protocols, signaling either their intent to turn or to move forward, depending on the randomly initialized weights. Regarding the Pursuit game, Fig. 14(c) shows how the lack of communication leads to underperforming and unstable policies, which obtain an average reward of − 35 . Analysis of the policy’s behavior and of the average time taken to complete an episode shows the majority of time-steps are wasted while a single predator chases a prey, until another predator randomly crosses its path. With at least one CC, predators can now signal that a prey has been spotted, and they can converge on it. Through communication, A3C3 predators coordinate to obtain an average reward of − 20 , and converge to more stable policies. In the Navigation task, Fig. 14(d) shows that, without communication, no suitable policy is found, since agents cannot share their position, resort to pure chance to cover all the beacons, and obtain an average reward of 1.25. Agents try to cover both beacons simultaneously and end up failing the task. However, communication allows agents to coordinate with one another, and while a single CC does not allow enough information to be conveyed, multiple channels lead to optimal policies with an average reward of 2 (the maximum possible reward obtainable). Agents learn to assign tasks to one another, and distribute themselves accordingly. For all the POC Suite environments, A3C3’s communication techniques allow a team of agents to complete them. Policies and communication protocols are learned simultaneously, tabula rasa, and demonstrate that information sharing is an adequate tool to compensate for partial-observability. As more information is transmitted (by increasing the amount of communication channels), the team’s performance increases until the transmitted information is sufficient to achieve optimal policies. The learned communication protocols are not easily translated into human-readable protocols. The simpler ones can be easily deduced (like transmitting whether the vehicle intends to turn or not), but with over five channels, most protocols require a non-trivial analysis. 5.4 Communication noise Noise is applied to communicated messages, and its effects are evaluated against a noiseless communication channel, and a policy with no communication at all. Three major types of noise are considered: • Loss – covering messages that are lost, sent messages have a chance P loss of not being delivered. This also covers delays in messages, where a delayed message is considered to be lost. • Noise – covering external interference in received messages, as these are continuous-valued vectors. Gaussian noise N ( 0 , V noise ) is added to these values. • Jumble – covering internal interference in messages, received messages have a chance P jumble of having been mixed with others. Instead of receiving the original message, that message is instead a sum of all received messages, and there is no indication to the agent whether the message has been jumbled or not. Each effect is tested individually, as well as all three simultaneously (shown as “All”). Fig. 15 shows the effects of disturbing the communication channels of the teams. For all environments, communication can be robust to both noisy interference and jumbled messages, as they allow some non-negligible form of coordination. Message loss has the greatest impact on the performance of the team, as it necessarily approximates the team’s performance to one without communication. In the Traffic Simulator, for example, losing messages at intersections forces agents to wait for that turn even if they have priority. In general, noise makes policies slower to learn, and decreases their overall performance. However, even with all noise types enabled, cooperation is still achieved in all environments, and results are better than policies with no communication at all. 5.5 Advantage estimators We research whether an advantage estimator targeted at handling the structural credit assignment problem can improve A3C3 policies. In A3C3, the advantage estimation is a simple difference ADV A3C3 = R − V ( S t j , θ v j ) that represents how better an action’s returns has been in comparison with the value expectation for the current state given the current policy. This is a specific case of the generalized advantage estimator G A E ( γ , 0 ) = ( r t j + γ V ( O i + 1 , θ v j ) − V ( O t , θ v j ) ) , which has been shown to lead to low variance updates given the adequate parameters [43]. If a critic were to output the value expectation V ( a t j | S t j , θ v j ) for each action a t j , like COMA’s value network, the advantage estimation would be given by ADV A3C3’ = R − V ( a t j | S t j , θ v j ) . COMA instead uses a credit assignment baseline method, and an action’s advantage is its expected return against the expected return of following the policy without that action, ADV COMA = V ( a t j | S t j , θ v j ) − ∑ − a t j ( π ( − a t j | o t j , r c t j , ϑ a j ) V ( − a t j | S t j , θ v j ) ) . This essentially estimates how an agent contributed to the reward obtained by the team with his own action, and authors claim it helps with the structural credit assignment problem. It requires the value network to output a value expectation per action. We also test an advantage estimation that combines A3C’s advantage estimation, which depends on how better actions fare against their expectation, and COMA’s advantage estimation, which depends on how the agent’s action contributes to the team reward, and obtain ADV A3C3’+COMA = R − ∑ − a t j ( π ( − a t j | o t j , r c t j , ϑ a j ) V ( − a t j | S t j , θ v j ) ) . An action a t j receives a higher advantage when the actual returns it led to were higher than expected and when it actually contributed to the team’s joint-action. We now compare ADV A3C3 with the three advantage estimators ADV A3C3’ , ADV COMA , and ADV A3C3’+COMA , using the new critic architecture. Instead of outputting a value estimation V ( O t , θ v j ) for following the current policy with centralized observation Ot , the centralized critic now outputs V ( a t j | O t , θ v j ) for all actions a t j that agent j can take at the given time-step t. A single output node corresponding to the taken action is optimized at every time-step. The additional network complexity is detrimental in two ways: network passes are computationally more expensive, since the output layer now scales with the agent’s action-spaces; and the critic takes more passes to update, since only a single node of the output layer is optimized at a time. The POC Navigation and POC Pursuit environments provide agents with team rewards, and thus are ideal to showcase whether new advantage estimators can improve A3C3’s credit assignment methods. Fig. 16 shows the evolution of policies for both environments using ADV A3C3 , ADV A3C3’ , ADV COMA , and ADV A3C3’+COMA . In the POC Navigation environment, both ADV A3C3’ and ADV COMA fail to converge to adequate policies. Their combination, however, allows the team to successfully complete the task, faster than the original estimator. In the POC Pursuit environment, using ADV A3C3’+COMA once again yielded the best results, and was the only new estimator in which teams managed to complete the task. However, it still did not outperform using the simpler critic structure with ADV A3C3 , which achieves a stronger policy within less episodes. While COMA’s advantage estimator, theoretically, addresses the structural credit assignment problem found in MAS, a comparison with other advantage estimators shows that it may be insufficient to simply compare the benefits of one action against others, without taking into account how that action’s returns matched the centralized critic’s expectation. By combining both estimation methods, results improved, and outperformed the original estimator in the Navigation environment. Contrarily, in the Pursuit Game, they were outperformed by the original A3C3’s simpler centralized critic, which outputs a single value expectation V ( O t , θ v j ) for the current policy. Given the increased unreliability of ADV A3C3’+COMA , off-set by a slight speed-up in the convergence speed of policies, we recommend the use of ADV A3C3 as a simpler and more robust advantage estimator. 5.6 Architecture variance To test the robustness of A3C3 with respect to its network architecture, a grid parameter search was conducted, and the performance and learning time for multiple configurations was evaluated. Configurations included one to three fully connected hidden layers, whose width ranged from 10 to 20 nodes. These layer sizes were then multiplied by a network layer size multipliers x, ranging from one to six. This choice of configurations was based on previous experience with deep reinforcement learning [42], but many other configurations of depth and width can be adequate. The tested configurations included a single hidden layer with 10x nodes, two hidden layers with 20x and 10x nodes, and three hidden layers with 20x, 10x, and 10x nodes. On opposites of the spectrum, the simplest network had a single hidden layer of 10 nodes, and the most complex had three layers of 120, 60 and 60 nodes, respectively. Orthogonally, the ReLU, ELU and Sigmoid activation functions were also evaluated. These configurations were used in the actor and centralized critic networks, while the communication network had a single hidden layer with the same size as the smallest layer in each configuration. All hyper-parameters apart from the network architecture remained the same in these tests, and the results for the Navigation environment are shown in Fig. 17 . Results show that A3C3 is fairly robust to varied network architectures, from the moment where they are complex enough to successfully approximate the target functions. The simpler networks with a single hidden layer were unable to converge and successfully complete the task. Analogously, the most complex networks are successful and feature the fastest convergence to optimal policies. 6 Conclusion This article describes a multi-agent deep reinforcement learning algorithm, which we call Asynchronous Advantage Actor Centralized-Critic with Communication (A3C3), where distributed worker threads use Actor-Critic methods to asynchronously optimize value, policy and communication networks for agents. The algorithm features a centralized learning phase, distributed execution, and inter-agent communication. A3C3 supports partially observable domains, noisy communications, heterogeneous reward functions, distributed independent execution, and a variable amount of agents. It can be horizontally scaled, and supports inter- and intra-agent parameter sharing, techniques which increase the convergence speed of policies. A3C3 works by implicitly sharing information during a centralized learning stage, through a Centralized Critic network, which improves the convergence of other networks and increases the performance of learned strategies. A3C3 agents also explicitly share relevant information, through the Communication network, which is optimized based on the performance of other agents. In other words, the network is optimized such that other agents perform better, thus enforcing coordination between agents. Even with noise and partial observability, agents can learn successful policies and communication protocols tabula rasa. The shared information may not be human-readable, as it is represented by vectors of continuous-valued messages. However, agents use them to share local information, alert other, assign targets, and coordinate exploration. Logically, agents from different populations may not be able to communicate with each other, as different communication protocols will likely have been learned. A3C3 is formally described and its behavior is shown in two multi-agent suites. It is compared against independent single-agent implementations of A3C, DDPG, and PPO and against MADDPG, another multi-agent algorithm, exceeding its performance. The effects of communication noise and other advantage estimation techniques are also analyzed. A3C3 can be framed as a more general version of previous works, and its source-code is publicly available. Despite its generality, A3C3 carries multiple assumptions. Environments are expected to be cooperative, with a discrete action space, and each worker thread is expected to have access to all agents and communications. A major drawback of A3C3 is that actor-critic algorithms are on-policy and sample inefficient. While the algorithm scales horizontally to alleviate this problem, learning in real-world robotic tasks will likely require an initial simulated phase to achieve an adequate initial solution before deploying policies on robotic agents. A3C3 can be improved in several ways. While we limit our scope to cooperative environments, describing a loss function for communication networks would be necessary for non-cooperative environments. For example, in a fully competitive environment, agents would optimize their communication protocol such that they would minimize the opponent’s rewards, while maximizing their own. A3C3 uses a feedforward network as a centralized critic that aggregates agent observations and additional environment state information to output a value estimation. The QMIX algorithm instead uses a value-decomposition network to further improve the value function approximation, and further research is necessary to determine whether A3C3 would benefit from such a network. Finally, integrating A3C3 with recursive neural networks, like RNN or LSTM, may allow agents to further exploit partially-observable environments. With feedforward networks, agents can only react to and share current information, but recursive architectures would allow past observations to be exploited as well. CRediT authorship contribution statement David Simões: Conceptualization, Methodology, Software, Writing - original draft, Validation, Investigation. Nuno Lau: Supervision, Writing - review & editing. Luís Paulo Reis: Supervision, Writing - review & editing. Declaration of Competing Interest The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper. Acknowledgements The first author is supported by FCT (Portuguese Foundation for Science and Technology) under grant PD/BD/113963/2015. This research was partially supported by IEETA (UID/CEC/00127/2019) and LIACC (PEst-UID/CEC/00027/2019). Supplementary material Supplementary material associated with this article can be found, in the online version, at doi:10.1016/j.neucom.2020.01.079. Appendix A Supplementary materials Supplementary Data S1 Supplementary Raw Research Data. This is open data under the CC BY license Supplementary Data S1 References [1] F. Ducatelle G.A. Di Caro A. Förster M. Bonani M. Dorigo S. Magnenat F. Mondada R. O’Grady C. Pinciroli P. Rétornaz Cooperative navigation in robotic swarms Swarm Intell. 8 1 2014 1 33 F. Ducatelle, G. A. Di Caro, A. Förster, M. Bonani, M. Dorigo, S. Magnenat, F. Mondada, R. O’Grady, C. Pinciroli, P. Rétornaz, et al., Cooperative navigation in robotic swarms, Swarm Intelligence 8(1) (2014) 1–33. [2] G.H. Gebhardt K. Daun M. Schnaubelt G. Neumann Learning robust policies for object manipulation with robot swarms Proceedings of the 2018 IEEE International Conference on Robotics and Automation (ICRA) 2018 IEEE 7688 7695 G. H. Gebhardt, K. Daun, M. Schnaubelt, G. Neumann, Learning robust policies for object manipulation with robot swarms, in: 2018 IEEE International Conference on Robotics and Automation (ICRA), IEEE, 2018, pp. 7688–7695. [3] P. Mannion J. Duggan E. Howley An experimental review of reinforcement learning algorithms for adaptive traffic signal control Autonomic Road Transport Support Systems 2016 Springer 47 66 P. Mannion, J. Duggan, E. Howley, An experimental review of reinforcement learning algorithms for adaptive traffic signal control, in: Autonomic Road Transport Support Systems, Springer, 2016, pp. 47–66. [4] P. Skobelev E. Simonova A. Zhilyaev Using multi-agent technology for the distributed management of a cluster of remote sensing satellites Compl. Syst.: Fundam. Appl. 90 2016 287 P. Skobelev, E. Simonova, A. Zhilyaev, Using multi-agent technology for the distributed management of a cluster of remote sensing satellites, Complex Systems: Fundamentals & Applications 90 (2016) 287. [5] V. Firoiu W.F. Whitney J.B. Tenenbaum Beating the world’s best at super smash bros. with deep reinforcement learning 2017 V. Firoiu, W. F. Whitney, J. B. Tenenbaum, Beating the world’s best at super smash bros. with deep reinforcement learning, CoRR abs/1702.06230 (2017). URL arXiv:1702.06230. [6] P. Hernandez-Leal, M. Kaisers, T. Baarslag, E.M. de Cote, A survey of learning in multiagent environments: Dealing with non-stationarity, 2017. arXiv:1707.09183. [7] S.V. Albrecht P. Stone Autonomous agents modelling other agents: a comprehensive survey and open problems Artif. Intell. 258 2018 66 95 S. V. Albrecht, P. Stone, Autonomous agents modelling other agents: A comprehensive survey and open problems, Artificial Intelligence 258 (2018) 66–95. [8] P. Hernandez-Leal, B. Kartal, M.E. Taylor, Is multiagent deep reinforcement learning the answer or the question? a brief survey, 2018. arXiv:1810.05587. [9] J.N. Foerster Y.M. Assael N. de Freitas S. Whiteson Learning to communicate with deep multi-agent reinforcement learning 2016 J. N. Foerster, Y. M. Assael, N. de Freitas, S. Whiteson, Learning to communicate with deep multi-agent reinforcement learning, CoRR abs/1605.06676 (2016). URL arXiv:1605.06676. [10] J.N. Foerster G. Farquhar T. Afouras N. Nardelli S. Whiteson Counterfactual multi-agent policy gradients 2017 J. N. Foerster, G. Farquhar, T. Afouras, N. Nardelli, S. Whiteson, Counterfactual multi-agent policy gradients, CoRR abs/1705.08926 (2017). URL arXiv:1705.08926. [11] C. Boutilier Planning, learning and coordination in multiagent decision processes Proceedings of the Sixth conference on Theoretical Aspects of Rationality and Knowledge 1996 Morgan Kaufmann Publishers Inc. 195 210 C. Boutilier, Planning, learning and coordination in multiagent decision processes, in: Proceedings of the 6th conference on Theoretical aspects of rationality and knowledge, Morgan Kaufmann Publishers Inc., 1996, pp. 195–210. [12] S. Sukhbaatar A. Szlam R. Fergus Learning multiagent communication with backpropagation 2016 S. Sukhbaatar, A. Szlam, R. Fergus, Learning multiagent communication with backpropagation, CoRR abs/1605.07736 (2016). URL arXiv:1605.07736. [13] D.B. D’Ambrosio S. Goodell J. Lehman S. Risi K.O. Stanley Multirobot behavior synchronization through direct neural network communication Proceedings of the International Conference on Intelligent Robotics and Applications 2012 Springer 603 614 D. B. D’Ambrosio, S. Goodell, J. Lehman, S. Risi, K. O. Stanley, Multirobot behavior synchronization through direct neural network communication, in: International Conference on Intelligent Robotics and Applications, Springer, 2012, pp. 603–614. [14] A. Das S. Kottur J.M.F. Moura S. Lee D. Batra Learning cooperative visual dialog agents with deep reinforcement learning 2017 A. Das, S. Kottur, J. M. F. Moura, S. Lee, D. Batra, Learning cooperative visual dialog agents with deep reinforcement learning, CoRR abs/1703.06585 (2017). URL arXiv:1703.06585. [15] I. Mordatch P. Abbeel Emergence of grounded compositional language in multi-agent populations 2017 I. Mordatch, P. Abbeel, Emergence of grounded compositional language in multi-agent populations, CoRR abs/1703.04908 (2017). URL arXiv:1703.04908. [16] V. Mnih A.P. Badia M. Mirza A. Graves T. Lillicrap T. Harley D. Silver K. Kavukcuoglu Asynchronous methods for deep reinforcement learning Proceedings of the International Conference on Machine Learning 2016 1928 1937 V. Mnih, A. P. Badia, M. Mirza, A. Graves, T. Lillicrap, T. Harley, D. Silver, K. Kavukcuoglu, Asynchronous methods for deep reinforcement learning, in: International Conference on Machine Learning, 2016, pp. 1928–1937. [17] S. Kapoor Multi-agent reinforcement learning: a report on challenges and approaches 2018 S. Kapoor, Multi-agent reinforcement learning: A report on challenges and approaches, CoRR abs/1807.09427 (2018). URL arXiv:1807.09427. [18] R.S. Sutton A.G. Barto Introduction to Reinforcement Learning 135 1998 MIT Press Cambridge R. S. Sutton, A. G. Barto, et al., Introduction to reinforcement learning, volume 135, MIT press Cambridge, 1998. [19] Yang E. Gu D. A survey on multiagent reinforcement learning towards multi-robot systems. Proceedings of the IEEE 2005 Symposium on Computational Intelligence and Games, CIG’05 2005 IEEE 292 299 E. Yang, D. Gu, A survey on multiagent reinforcement learning towards multi-robot systems., in: IEEE 2005 Symposium on Computational Intelligence and Games, CIG’05, IEEE, 2005, pp. 292–299. [20] L. Matignon G.J. Laurent N. Le Fort-Piat Independent reinforcement learners in cooperative Markov games: a survey regarding coordination problems Knowl. Eng. Rev. 27 01 2012 1 31 L. Matignon, G. J. Laurent, N. Le Fort-Piat, Independent reinforcement learners in cooperative markov games: a survey regarding coordination problems, The Knowledge Engineering Review 27(01) (2012) 1–31. [21] M. Bowling M. Veloso Rational and convergent learning in stochastic games Proceedings of the Seventeenth International Joint Conference on Artificial Intelligence – Volume 2 IJCAI’01 2001 Morgan Kaufmann Publishers Inc. San Francisco, CA, USA 1021 1026 M. Bowling, M. Veloso, Rational and convergent learning in stochastic games, in: Proceedings of the 17th International Joint Conference on Artificial Intelligence - Volume 2, IJCAI’01, Morgan Kaufmann Publishers Inc., San Francisco, CA, USA, 2001, pp. 1021–1026. URL URL [22] L. Busoniu R. Babuska B. De Schutter A comprehensive survey of multiagent reinforcement learning Trans. Syst. Man Cyber C 38 2 2008 156 172 10.1109/TSMCC.2007.913919 L. Busoniu, R. Babuska, B. De Schutter, A comprehensive survey of multiagent reinforcement learning, Trans. Sys. Man Cyber Part C 38(2) (2008) 156–172. doi:10.1109/TSMCC.2007.913919 [23] B.H.K. Abed-Alguni Cooperative reinforcement learning for independent learners 2014 University of Newcastle Ph.D. thesis B. H. K. Abed-Alguni, Cooperative reinforcement learning for independent learners, Ph.D. thesis, University of Newcastle, 2014. [24] B.H. Abed-alguni S.K. Chalup F.A. Henskens D.J. Paul A multi-agent cooperative reinforcement learning model using a hierarchy of consultants, tutors and workers Vietnam J. Comput. Sci. 2 4 2015 213 226 B. H. Abed-alguni, S. K. Chalup, F. A. Henskens, D. J. Paul, A multi-agent cooperative reinforcement learning model using a hierarchy of consultants, tutors and workers, Vietnam Journal of Computer Science 2(4) (2015) 213–226. [25] V. Mnih K. Kavukcuoglu D. Silver A.A. Rusu J. Veness M.G. Bellemare A. Graves M. Riedmiller A.K. Fidjeland G. Ostrovski Human-level control through deep reinforcement learning Nature 518 7540 2015 529 533 V. Mnih, K. Kavukcuoglu, D. Silver, A. A. Rusu, J. Veness, M. G. Bellemare, A. Graves, M. Riedmiller, A. K. Fidjeland, G. Ostrovski, et al., Human-level control through deep reinforcement learning, Nature 518(7540) (2015) 529–533. [26] J. Schulman, F. Wolski, P. Dhariwal, A. Radford, O. Klimov, Proximal policy optimization algorithms, 2017. arXiv:1707.06347. [27] C. Claus C. Boutilier The dynamics of reinforcement learning in cooperative multiagent systems Proceedings of the Fifteenth National/Tenth Conference on Artificial Intelligence/Innovative Applications of Artificial Intelligence AAAI ’98/IAAI ’98 1998 American Association for Artificial Intelligence Menlo Park, CA, USA 746 752 C. Claus, C. Boutilier, The dynamics of reinforcement learning in cooperative multiagent systems, in: Proceedings of the Fifteenth National/Tenth Conference on Artificial Intelligence/Innovative Applications of Artificial Intelligence, AAAI ’98/IAAI ’98, American Association for Artificial Intelligence, Menlo Park, CA, USA, 1998, pp. 746–752. URL URL [28] P. Sunehag G. Lever A. Gruslys W.M. Czarnecki V. Zambaldi M. Jaderberg M. Lanctot N. Sonnerat J.Z. Leibo K. Tuyls T. Graepel Value-decomposition networks for cooperative multi-agent learning based on team reward Proceedings of the Seventeenth International Conference on Autonomous Agents and Multi-Agent Systems AAMAS ’18 2018 International Foundation for Autonomous Agents and Multiagent Systems Richland, SC 2085 2087 P. Sunehag, G. Lever, A. Gruslys, W. M. Czarnecki, V. Zambaldi, M. Jaderberg, M. Lanctot, N. Sonnerat, J. Z. Leibo, K. Tuyls, T. Graepel, Value-decomposition networks for cooperative multi-agent learning based on team reward, in: Proceedings of the 17th International Conference on Autonomous Agents and MultiAgent Systems, AAMAS ’18, International Foundation for Autonomous Agents and Multiagent Systems, Richland, SC, 2018, pp. 2085–2087. URL URL [29] T. Rashid M. Samvelyan C.S. de Witt G. Farquhar J.N. Foerster S. Whiteson QMIX: Monotonic value function factorisation for deep multi-agent reinforcement learning 2018 T. Rashid, M. Samvelyan, C. S. de Witt, G. Farquhar, J. N. Foerster, S. Whiteson, QMIX: monotonic value function factorisation for deep multi-agent reinforcement learning, CoRR abs/1803.11485 (2018). URL arXiv:1803.11485. [30] Peng P. Yuan Q. Wen Y. Yang Y. Tang Z. Long H. Wang J. Multiagent bidirectionally-coordinated nets for learning to play starcraft combat games 2017 P. Peng, Q. Yuan, Y. Wen, Y. Yang, Z. Tang, H. Long, J. Wang, Multiagent bidirectionally-coordinated nets for learning to play starcraft combat games, CoRR abs/1703.10069 (2017). URL arXiv:1703.10069. [31] M.L. Littman Markov games as a framework for multi-agent reinforcement learning Proceedings of the Eleventh International Conference on International Conference on Machine Learning ICML’94 1994 Morgan Kaufmann Publishers Inc. San Francisco, CA, USA 157 163 M. L. Littman, Markov games as a framework for multi-agent reinforcement learning, in: Proceedings of the Eleventh International Conference on International Conference on Machine Learning, ICML’94, Morgan Kaufmann Publishers Inc., San Francisco, CA, USA, 1994, pp. 157–163. URL URL [32] D.E. Rumelhart G.E. Hinton R.J. Williams Learning representations by back-propagating errors Nature 323 6088 1986 533 D. E. Rumelhart, G. E. Hinton, R. J. Williams, Learning representations by back-propagating errors, nature 323(6088) (1986) 533. [33] R. Pascanu T. Mikolov Y. Bengio Understanding the exploding gradient problem 2012 R. Pascanu, T. Mikolov, Y. Bengio, Understanding the exploding gradient problem, CoRR abs/1211.5063 (2012). URL arXiv:1211.5063. [34] R. Lowe Wu Y. A. Tamar J. Harb P. Abbeel I. Mordatch Multi-agent actor-critic for mixed cooperative-competitive environments 2017 R. Lowe, Y. Wu, A. Tamar, J. Harb, P. Abbeel, I. Mordatch, Multi-agent actor-critic for mixed cooperative-competitive environments, CoRR abs/1706.02275 (2017). URL arXiv:1706.02275. [35] M.G. Bellemare Y. Naddaf J. Veness M. Bowling The arcade learning environment: an evaluation platform for general agents J. Artif. Intell. Res. 47 2013 253 279 M. G. Bellemare, Y. Naddaf, J. Veness, M. Bowling, The arcade learning environment: An evaluation platform for general agents, Journal of Artificial Intelligence Research 47 (2013) 253–279. [36] R.J. Williams Simple statistical gradient-following algorithms for connectionist reinforcement learning Mach. Learn. 8 3 1992 229 256 10.1007/BF00992696 R. J. Williams, Simple statistical gradient-following algorithms for connectionist reinforcement learning, Machine Learning 8(3) (1992) 229–256. 10.1007/BF00992696 [37] A. Lazaridou A. Peysakhovich M. Baroni Multi-agent cooperation and the emergence of (natural) language 2016 A. Lazaridou, A. Peysakhovich, M. Baroni, Multi-agent cooperation and the emergence of (natural) language, CoRR abs/1612.07182 (2016). URL arXiv:1612.07182. [38] M. Lewis D. Yarats Y.N. Dauphin D. Parikh D. Batra Deal or no deal? end-to-end learning for negotiation dialogues 2017 M. Lewis, D. Yarats, Y. N. Dauphin, D. Parikh, D. Batra, Deal or no deal? end-to-end learning for negotiation dialogues, CoRR abs/1706.05125 (2017). URL arXiv:1706.05125. [39] Li Q. Du X. Huang Y. Q. Sykora A.P. Schoellig Learning of coordination policies for robotic swarms 2017 Q. Li, X. Du, Y. Huang, Q. Sykora, A. P. Schoellig, Learning of coordination policies for robotic swarms, CoRR abs/1709.06620 (2017). URL arXiv:1709.06620. [40] V. Mnih A.P. Badia M. Mirza A. Graves T.P. Lillicrap T. Harley D. Silver K. Kavukcuoglu Asynchronous methods for deep reinforcement learning 2016 V. Mnih, A. P. Badia, M. Mirza, A. Graves, T. P. Lillicrap, T. Harley, D. Silver, K. Kavukcuoglu, Asynchronous methods for deep reinforcement learning, CoRR abs/1602.01783 (2016). URL arXiv:1602.01783. [41] D. Simões Lau N. L.P. Reis Mixed-policy asynchronous deep q-learning A. Ollero A. Sanfeliu L. Montano N. Lau C. Cardeira Proceedings of the ROBOT 2017: Third Iberian Robotics Conference 2018 Springer International Publishing 129 140 D. Simões, N. Lau, L. P. Reis, Mixed-policy asynchronous deep q-learning, in: A. Ollero, A. Sanfeliu, L. Montano, N. Lau, C. Cardeira (Eds.), ROBOT 2017: Third Iberian Robotics Conference, Springer International Publishing, 2018a, pp. 129–140. [42] D. Simões N. Lau L.P. Reis Guided deep reinforcement learning in the geofriends2 environment Proceedings of the IJCNN 18: International Joint-Conference on Neural Networks 2018 375 381 D. Simões, N. Lau, L. P. Reis, Guided deep reinforcement learning in the geofriends2 environment, in: IJCNN 18: Internation Joint-Conference on Neural Networks, 2018b, pp. 375–381. [43] J. Schulman P. Moritz S. Levine M.I. Jordan P. Abbeel High-dimensional continuous control using generalized advantage estimation 2015 J. Schulman, P. Moritz, S. Levine, M. I. Jordan, P. Abbeel, High-dimensional continuous control using generalized advantage estimation, CoRR abs/1506.02438 (2015). URL arXiv:1506.02438. [44] R.J. Williams Peng J. Function optimization using connectionist reinforcement learning algorithms Comput. Sci. 3 3 1991 241 268 10.1080/09540099108946587 R. J. Williams, J. Peng, Function optimization using connectionist reinforcement learning algorithms, Connection Science 3(3) (1991) 241–268. doi:10.1080/09540099108946587 [45] X. Glorot Y. Bengio Understanding the difficulty of training deep feedforward neural networks Y.W. Teh M. Titterington Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics Proceedings of Machine Learning Research, PMLR, Chia Laguna Resort, Sardinia, Italy 9 2010 249 256 X. Glorot, Y. Bengio, Understanding the difficulty of training deep feedforward neural networks, in: Y. W. Teh, M. Titterington (Eds.), Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics, volume 9 of Proceedings of Machine Learning Research, PMLR, Chia Laguna Resort, Sardinia, Italy, 2010, pp. 249–256. URL URL [46] D.P. Kingma J. Ba Adam: a method for stochastic optimization 2014 D. P. Kingma, J. Ba, Adam: A method for stochastic optimization, CoRR abs/1412.6980 (2014). URL arXiv:1412.6980. [47] P. Henderson R. Islam P. Bachman J. Pineau D. Precup D. Meger Deep reinforcement learning that matters Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence 2018 P. Henderson, R. Islam, P. Bachman, J. Pineau, D. Precup, D. Meger, Deep reinforcement learning that matters, in: Thirty-Second AAAI Conference on Artificial Intelligence, 2018. [48] G. Brockman, V. Cheung, L. Pettersson, J. Schneider, J. Schulman, J. Tang, W. Zaremba, Openai gym, 2016. arXiv:1606.01540. [49] D. Simões Lau N. L.P. Reis Multi-agent deep reinforcement learning with emergent communication Proceedings of the 2019 International Joint Conference on Neural Networks (IJCNN) 2019 IEEE D. Simões, N. Lau, L. P. Reis, Multi-agent deep reinforcement learning with emergent communication, in: 2019 International Joint Conference on Neural Networks (IJCNN), IEEE, 2019. David Simões obtained a M.Sc. (2015) in Computer and Telematics Engineering from the University of Aveiro, Portugal, and is currently a Ph.D. student in a joint Ph.D. program at the Universities of Minho, Aveiro and Porto (Portugal). His thesis topic is on learning coordination in multi-agent systems. He has worked on simulated humanoid robots and achieved different ranks in Robocup competitions including 4 world championships, and has worked in robotic and simulated maze-solving competitions, winning several national Micro-Rato competitions. His main research interests include multi-agent systems, deep learning, and game theory. Nuno Lau is Assistant Profess or at Aveiro University, Portugal and Researcher at the Institute of Electronics and Informatics Engineering of Aveiro (IEETA), where he leads the Intelligent Robotics and Systems group (IRIS). He got his Electrical Engineering Degree from Oporto University in 1993, a DEA degree in Biomedical Engineering from Claude Bernard University, France, in 1994 and the Ph.D. from Aveiro University in 2003. His research interests are focused on Intelligent Robotics, Artificial Intelligence, Multi-Agent Systems and Simulation. Nuno Lau participated in more than 15 international and national research projects, having the tasks of general or local coordinator in about half of them. Nuno Lau won more than 50 scientific awards in robotic competitions, conferences (best papers) and education. He has lectured courses at Ph.D. and M.Sc. levels on Intelligent Robotics, Distributed Artificial Intelligence, Computer Architecture, Programming, etc. Nuno Lau is the author of more than 160 publications in international conferences and journals. He was President of the Portuguese Robotics Society from 2015 to 2017. Luís Paulo Reis is an Associate Professor at the Faculty of Engineering of the University of Porto in Portugal and Director of LIACC – Artificial Intelligence and Computer Science Laboratory at the same University. He is an IEEE Senior Member and he was president of the Portuguese Society for Robotics and is vice-president of the Portuguese Association for Artificial Intelligence. During the last 25 years, he has lectured courses on Artificial Intelligence, Intelligent Robotics, Multi-Agent Systems, Simulation and Modelling, Games and Interaction, Educational/Serious Games and Computer Programming. He was the principal investigator of more than 10 research projects in those areas. He won more than 50 scientific awards including wining more than 15 RoboCup international competitions and best papers at conferences such as ICEIS, Robotica, IEEE ICARSC and ICAART. He supervised 20 Ph.D. and 102 M.Sc. theses to completion and is supervising 8 Ph.D. theses. He organized more than 50 international scientific events and belonged to the Program Committee of more than 250 scientific events. He is the author of more than 300 publications in international conferences and journals (indexed at SCOPUS or ISI Web of Knowledge). "
    },
    {
        "doc_title": "Fast Grid SLAM based on particle filter with scan matching and multithreading",
        "doc_scopus_id": "85085940206",
        "doc_doi": "10.1109/ICARSC49921.2020.9096191",
        "doc_eid": "2-s2.0-85085940206",
        "doc_date": "2020-04-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            },
            {
                "area_name": "Mechanical Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2210"
            },
            {
                "area_name": "Control and Optimization",
                "area_abbreviation": "MATH",
                "area_code": "2606"
            }
        ],
        "doc_keywords": [
            "Fast scan",
            "Multi-threading",
            "Particle filter",
            "Pose refinement",
            "Rao-blackwellized particle filter",
            "Real-time operation",
            "Scan matching",
            "Space management"
        ],
        "doc_abstract": "© 2020 IEEE.This paper presents a SLAM solution based on Rao-Blackwellized particle filters supported by a fast scan matching algorithm for pose refinement and a flexible space management data structure. By taking advantage of independence between particles its computational efficiency is further improved through multithreading. We have evaluated the efficiency of the solution by using several publicly available datasets and compared the results with the popular solution GMapping. The obtained results show the proposed approach provides a fast and accurate particle filter SLAM suitable for real-time operations.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Welcome Message",
        "doc_scopus_id": "85085918545",
        "doc_doi": "10.1109/ICARSC49921.2020.9096118",
        "doc_eid": "2-s2.0-85085918545",
        "doc_date": "2020-04-01",
        "doc_type": "Editorial",
        "doc_areas": [
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            },
            {
                "area_name": "Mechanical Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2210"
            },
            {
                "area_name": "Control and Optimization",
                "area_abbreviation": "MATH",
                "area_code": "2606"
            }
        ],
        "doc_keywords": [],
        "doc_abstract": null,
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Competitive deep reinforcement learning over a pokémon battling simulator",
        "doc_scopus_id": "85085916831",
        "doc_doi": "10.1109/ICARSC49921.2020.9096092",
        "doc_eid": "2-s2.0-85085916831",
        "doc_date": "2020-04-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            },
            {
                "area_name": "Mechanical Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2210"
            },
            {
                "area_name": "Control and Optimization",
                "area_abbreviation": "MATH",
                "area_code": "2606"
            }
        ],
        "doc_keywords": [
            "Commodity hardware",
            "Continuous State Space",
            "De facto standard",
            "Delayed rewards",
            "Faster convergence",
            "High-dimensional",
            "Learning objectives",
            "Multi-agent environment"
        ],
        "doc_abstract": "© 2020 IEEE.Pokémon is one of the most popular video games in the world, and recent interest has appeared in Pokémon battling as a testbed for AI challenges. This is due to Pokémon battling showing interesting properties which contrast with current AI challenges over other video games. To this end, we implement a Pokémon Battle Environment, which preserves many of the core elements of Pokémon battling, and allows researchers to test isolated learning objectives. Our approach focuses on type advantage in Pokémon battles and on the advantages of delayed rewards through switching, which is considered core strategies for any Pokémon battle. As a competitive multi-agent environment, it has a partially-observable, high-dimensional, and continuous state-space, adheres to the Gym de facto standard reinforcement learning interface, and is performance-oriented, achieving thousands of interactions per second in commodity hardware. We determine whether deep competitive reinforcement learning algorithms, WPLθ and GIGAθ, can learn successful policies in this environment. Both converge to rational and effective strategies, and GIGAθ shows faster convergence, obtaining a 100% win-rate in a disadvantageous test scenario.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "A robust model-based biped locomotion framework based on three-mass model: From planning to control",
        "doc_scopus_id": "85085910734",
        "doc_doi": "10.1109/ICARSC49921.2020.9096150",
        "doc_eid": "2-s2.0-85085910734",
        "doc_date": "2020-04-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            },
            {
                "area_name": "Mechanical Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2210"
            },
            {
                "area_name": "Control and Optimization",
                "area_abbreviation": "MATH",
                "area_code": "2606"
            }
        ],
        "doc_keywords": [
            "Biped Robot",
            "Dynamics modeling",
            "Model-based OPC",
            "Reference trajectories",
            "Robust modeling",
            "Three-mass model",
            "Tracking problem"
        ],
        "doc_abstract": "© 2020 IEEE.Biped robots are inherently unstable because of their complex kinematics as well as dynamics. Despite types of research in developing biped locomotion, the performance of biped locomotion is still far from the expectations.This paper proposes a model-based framework to generate stable biped locomotion. The core of this framework is an abstract dynamics model which is composed of three masses to consider the dynamics of stance leg, torso and swing leg for minimizing the tracking problems. According to this dynamics model, we propose a modular walking reference trajectories planner which takes into account obstacles to plan all the references. Moreover, this dynamics model is used to formulate the controller as a Model Predictive Control (MPC) scheme which can consider some constraints in the states of the system, inputs, outputs and also mixed input-output.The performance and the robustness of the proposed framework are validated by performing several simulations using MATLAB. The simulation results show that the proposed framework is capable of generating the biped locomotion robustly.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Exploring communication protocols and centralized critics in multi-agent deep learning",
        "doc_scopus_id": "85092653201",
        "doc_doi": "10.3233/ICA-200631",
        "doc_eid": "2-s2.0-85092653201",
        "doc_date": "2020-01-01",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Software",
                "area_abbreviation": "COMP",
                "area_code": "1712"
            },
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science Applications",
                "area_abbreviation": "COMP",
                "area_code": "1706"
            },
            {
                "area_name": "Computational Theory and Mathematics",
                "area_abbreviation": "COMP",
                "area_code": "1703"
            },
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            }
        ],
        "doc_keywords": [
            "Human performance",
            "Learning phase",
            "Limited observations",
            "Multi-agent environment",
            "Non-trivial tasks",
            "Partial knowledge",
            "Soccer simulation",
            "Team members"
        ],
        "doc_abstract": "© 2020 - IOS Press and the authors. All rights reserved.Tackling multi-agent environments where each agent has a local limited observation of the global state is a non-trivial task that often requires hand-tuned solutions. A team of agents coordinating in such scenarios must handle the complex underlying environment, while each agent only has partial knowledge about the environment. Deep reinforcement learning has been shown to achieve super-human performance in single-agent environments, and has since been adapted to the multi-agent paradigm. This paper proposes A3C3, a multi-agent deep learning algorithm, where agents are evaluated by a centralized referee during the learning phase, but remain independent from each other in actual execution. This referee's neural network is augmented with a permutation invariance architecture to increase its scalability to large teams. A3C3 also allows agents to learn communication protocols with which agents share relevant information to their team members, allowing them to overcome their limited knowledge, and achieve coordination. A3C3 and its permutation invariant augmentation is evaluated in multiple multi-agent test-beds, which include partially-observable scenarios, swarm environments, and complex 3D soccer simulations.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "TIMAIRIS: Autonomous Blank Feeding for Packaging Machines",
        "doc_scopus_id": "85087543982",
        "doc_doi": "10.1007/978-3-030-34507-5_7",
        "doc_eid": "2-s2.0-85087543982",
        "doc_date": "2020-01-01",
        "doc_type": "Book Chapter",
        "doc_areas": [
            {
                "area_name": "Electrical and Electronic Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2208"
            },
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            }
        ],
        "doc_keywords": [
            "Alternative solutions",
            "Computer vision system",
            "Current packaging",
            "Different shapes",
            "Industrial environments",
            "Mobile manipulator",
            "Modes of operation",
            "Multi-Modal Interactions"
        ],
        "doc_abstract": "© 2020, Springer Nature Switzerland AG.Current packaging machine vendors do not provide any automated mechanism for blank feeding and the state of the art is to have a human operator dedicated to feed the blank piles to the packaging machine. This is a tedious, repetitive and tiring task. This also results in problems with unintentional errors, such as using the wrong pile of blanks. An alternative solution is the use of a fixed robotic arm surrounded by a protective cage. However, this solution is restricted to a single packaging machine, a unique type of blank shapes and does not cooperate with humans. TIMAIRIS is a joint effort between IMA S.p.A., Italy, (IMA) and the Universidade de Aveiro, Portugal, (UAVR), promoted by the European Robotics Challenges (EuRoC) project. Together, we propose a system based on a mobile manipulator for flexible, autonomous and collaborative blank feeding of packaging machines on industrial shop floor. The system provides a software architecture that allows a mobile robot to take high level decisions on how the task should be executed, which can depend on variables such as the number of packaging machines to feed and the rate of blank consumption at each one. Through a computer vision system, blanks of different shapes and sizes are correctly identified for adequate manipulation. The manipulation of the piles of blanks is performed using a single arm using compliant modes of operation to increase manipulation safety and robustness. Additionally, it has a safe navigation system that allows the robot to be integrated in an industrial environment where humans are present. Finally, it provides an enhanced multimodal interaction between human and robot that can be adapted to the environment and operator characteristics to make communication intuitive, redundant and safe.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Learning Low-Level Behaviors and High-Level Strategies in Humanoid Soccer",
        "doc_scopus_id": "85079101144",
        "doc_doi": "10.1007/978-3-030-36150-1_44",
        "doc_eid": "2-s2.0-85079101144",
        "doc_date": "2020-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Control and Systems Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2207"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Coordination strategy",
            "Distributed framework",
            "Evolution strategies",
            "Humanoid robot",
            "Pre-defined position",
            "Soccer team"
        ],
        "doc_abstract": "© 2020, Springer Nature Switzerland AG.This paper investigates the learning of both low-level behaviors for humanoid robot controllers and of high-level coordination strategies for teams of robots engaged in simulated soccer. Regarding controllers, current approaches typically hand-tune behaviors or optimize them without realistic constraints, for example allowing parts of the robot to intersect with others. This level of optimization often leads to low-performance behaviors. Regarding strategies, most are hand-tuned with arbitrary parameters (like agents moving to pre-defined positions on the field such that eventually they can score a goal) and the thorough analysis of learned strategies is often disregarded. This paper demonstrates how it is possible to use a distributed framework to learn both low-level behaviors, like sprinting and getting up, and high-level strategies, like a kick-off scenario, outperforming previous approaches in the FCPortugal3D Simulated Soccer team.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Benchmarking Deep and Non-deep Reinforcement Learning Algorithms for Discrete Environments",
        "doc_scopus_id": "85079092068",
        "doc_doi": "10.1007/978-3-030-36150-1_22",
        "doc_eid": "2-s2.0-85079092068",
        "doc_date": "2020-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Control and Systems Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2207"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Benchmark study",
            "Learning environments",
            "Network algorithms",
            "Neural Fitted Q-Iteration",
            "Policy gradient",
            "Q-learning",
            "Value iteration"
        ],
        "doc_abstract": "© 2020, Springer Nature Switzerland AG.Given the plethora of Reinforcement Learning algorithms available in the literature, it can prove challenging to decide on the most appropriate one to use in order to solve a given Reinforcement Learning task. This work presents a benchmark study on the performance of several Reinforcement Learning algorithms for discrete learning environments. The study includes several deep as well as non-deep learning algorithms, with special focus on the Deep Q-Network algorithm and its variants. Neural Fitted Q-Iteration, the predecessor of Deep Q-Network as well as Vanilla Policy Gradient and a planner were also included in this assessment in order to provide a wider range of comparison between different approaches and paradigms. Three learning environments were used in order to carry out the tests, including a 2D maze and two OpenAI Gym environments, namely a custom-built Foraging/Tagging environment and the CartPole environment.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "A Robust Biped Locomotion Based on Linear-Quadratic-Gaussian Controller and Divergent Component of Motion",
        "doc_scopus_id": "85081157666",
        "doc_doi": "10.1109/IROS40897.2019.8967778",
        "doc_eid": "2-s2.0-85081157666",
        "doc_date": "2019-11-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Control and Systems Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2207"
            },
            {
                "area_name": "Software",
                "area_abbreviation": "COMP",
                "area_code": "1712"
            },
            {
                "area_name": "Computer Vision and Pattern Recognition",
                "area_abbreviation": "COMP",
                "area_code": "1707"
            },
            {
                "area_name": "Computer Science Applications",
                "area_abbreviation": "COMP",
                "area_code": "1706"
            }
        ],
        "doc_keywords": [
            "Closed loop controllers",
            "Humanoid robot",
            "Inverted pendulum",
            "Inverted pendulum model",
            "Landing locations",
            "Linear quadratic Gaussian",
            "Linear Quadratic Gaussian controllers",
            "Number of degrees of freedom"
        ],
        "doc_abstract": "© 2019 IEEE.Generating robust locomotion for a humanoid robot in the presence of disturbances is difficult because of its high number of degrees of freedom and its unstable nature. In this paper, we used the concept of Divergent Component of Motion (DCM) and propose an optimal closed-loop controller based on Linear-Quadratic-Gaussian to generate a robust and stable walking for humanoid robots. The biped robot dynamics has been approximated using the Linear Inverted Pendulum Model (LIPM). Moreover, we propose a controller to adjust the landing location of the swing leg to increase the withstanding level of the robot against a severe external push. The performance and also the robustness of the proposed controller is analyzed and verified by performing a set of simulations using MATLAB. The simulation results showed that the proposed controller is capable of providing a robust walking even in the presence of disturbances and in challenging situations.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Contextual Direct Policy Search: With Regularized Covariance Matrix Estimation",
        "doc_scopus_id": "85059747674",
        "doc_doi": "10.1007/s10846-018-0968-4",
        "doc_eid": "2-s2.0-85059747674",
        "doc_date": "2019-11-01",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Software",
                "area_abbreviation": "COMP",
                "area_code": "1712"
            },
            {
                "area_name": "Control and Systems Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2207"
            },
            {
                "area_name": "Mechanical Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2210"
            },
            {
                "area_name": "Industrial and Manufacturing Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2209"
            },
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            },
            {
                "area_name": "Electrical and Electronic Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2208"
            }
        ],
        "doc_keywords": [
            "Contextual learning",
            "Covariance matrix adaptation",
            "Covariance matrix estimation",
            "Direct policy search",
            "Multitask learning",
            "Optimization problems",
            "Stochastic policy",
            "Stochastic search and optimization"
        ],
        "doc_abstract": "© 2019, Springer Nature B.V.Stochastic search and optimization techniques are used in a vast number of areas, ranging from refining the design of vehicles, determining the effectiveness of new drugs, developing efficient strategies in games, or learning proper behaviors in robotics. However, they specialize for the specific problem they are solving, and if the problem’s context slightly changes, they cannot adapt properly. In fact, they require complete re-leaning in order to perform correctly in new unseen scenarios, regardless of how similar they are to previous learned environments. Contextual algorithms have recently emerged as solutions to this problem. They learn the policy for a task that depends on a given context, such that widely different contexts belonging to the same task are learned simultaneously. That being said, the state-of-the-art proposals of this class of algorithms prematurely converge, and simply cannot compete with algorithms that learn a policy for a single context. We describe the Contextual Relative Entropy Policy Search (CREPS) algorithm, which belongs to the before-mentioned class of contextual algorithms. We extend it with a technique that allows the algorithm to severely increase its performance, and we call it Contextual Relative Entropy Policy Search with Covariance Matrix Adaptation (CREPS-CMA). We propose two variants, and demonstrate their behavior in a set of classic contextual optimization problems, and on complex simulator robot tasks.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Skill-based anytime agent architecture for European Robotics Challenges in realistic environments: EuRoC Challenge 2, Stage II — realistic labs",
        "doc_scopus_id": "85070213536",
        "doc_doi": "10.1016/j.robot.2019.06.006",
        "doc_eid": "2-s2.0-85070213536",
        "doc_date": "2019-10-01",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Software",
                "area_abbreviation": "COMP",
                "area_code": "1712"
            },
            {
                "area_name": "Control and Systems Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2207"
            },
            {
                "area_name": "Mathematics (all)",
                "area_abbreviation": "MATH",
                "area_code": "2600"
            },
            {
                "area_name": "Computer Science Applications",
                "area_abbreviation": "COMP",
                "area_code": "1706"
            }
        ],
        "doc_keywords": [
            "Agent architectures",
            "European robotics challenges (EuRoC)",
            "Manufacturing industries",
            "Mobile manipulation",
            "Realistic environments",
            "Robotics technology",
            "Scientific competition",
            "Skill-based"
        ],
        "doc_abstract": "© 2019As demands on pragmatic solutions of robotics technology increase in the manufacturing industry, deep affinities between research experts and industry users are required. The European Robotics Challenges (EuRoC) research project has proposed a scientific competition and matched up research labs with industrial end users to establish challenger teams to develop and test solutions that will be applied in the real context of the industrial end-users. The paper reports the result of TIMAIRIS who is one of 6 challenger teams to advance to the final stage out of 103 teams and technical details used in the Challenge 2 - Shop Floor Logistics and Manipulation. To address the requirements and achieve the objectives of the challenge, a skill-based anytime agent architecture has been developed and extended to make the team focus on the challenging research that addresses real issues in the user environments. Finally, shop floor logistics and manipulation scenarios have been developed and demonstrated in a realistic environment for autonomous packaging.",
        "available": true,
        "clean_text": "serial JL 271599 291210 291866 291870 291882 291883 31 Robotics and Autonomous Systems ROBOTICSAUTONOMOUSSYSTEMS 2019-08-02 2019-08-02 2019-08-08 2019-08-08 2019-09-13T06:57:28 S0921-8890(17)30794-7 S0921889017307947 10.1016/j.robot.2019.06.006 S300 S300.1 FULL-TEXT 2020-01-13T11:13:04.440713Z 0 0 20191001 20191031 2019 2019-08-02T15:14:58.064687Z articleinfo articlenumber articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid hubeid indexeddate issn issnnorm itemstage itemtransactionid itemweight openaccess openarchive pg pgfirst pii piinorm pubdateend pubdatestart pubdatetxt pubyr sortorder srctitle srctitlenorm srctype ssids alllist content subj subheadings suppl tomb volfirst volissue volumelist yearnav figure table body mmlmath acknowledge affil articletitle auth authfirstini authfull authkeywords authlast footnotes grantnumber grantsponsor grantsponsorid highlightsabst orcid primabst ref vitae 0921-8890 09218890 true 120 120 C Volume 120 9 103227 103227 103227 201910 October 2019 2019-10-01 2019-10-31 2019 article fla © 2019 Published by Elsevier B.V. SKILLBASEDANYTIMEAGENTARCHITECTUREFOREUROPEANROBOTICSCHALLENGESINREALISTICENVIRONMENTSEUROCCHALLENGE2STAGEIIREALISTICLABS LIM G 1 Introduction 1.1 Motivation 1.2 Related work 2 European robotics challenges (EuRoC) 2.1 Challenge 2: shop floor logistics and manipulation 2.1.1 Benchmarking 2.1.2 Showcase: autonomous packaging 2.2 EuRoC platform 2.3 TIMAIRIS software architecture 3 Agent architecture 3.1 Skill-based anytime agent architecture 3.2 Resource management scheme 4 Solving benchmarking tasks 4.1 Task 1: production logistics 4.1.1 SLC detection 4.1.2 Manipulation and planning strategy 4.2 Task 2: product assembly 4.2.1 Fixture detection 4.2.2 Bolt, nut and washer detection 4.3 Manipulation and planning strategy 5 Solving showcase tasks 5.1 Manipulation of stacked non rigid objects 5.2 Manipulator for packaging 5.3 Showcase perception 5.4 Motion planing 5.5 Task planning 5.6 Safe human–robot collaboration 6 Challenge evaluation 6.1 Benchmark evaluation 6.2 Showcase evaluation 7 Conclusion Acknowledgments References PRATT 2013 10 12 G KITANO 1997 340 347 H PROCEEDINGSFIRSTINTERNATIONALCONFERENCEAUTONOMOUSAGENTS ROBOCUPROBOTWORLDCUPINITIATIVE SICILIANO 2014 1 7 B ISRROBOTIK201441STINTERNATIONALSYMPOSIUMROBOTICSPROCEEDINGS EUROCTHECHALLENGEINITIATIVEFOREUROPEANROBOTICS BISCHOFF 2010 15 16 R CULLY 2015 503 A HILDEBRANDT 2016 21 27 A AUTONOMOUSROBOTSYSTEMSCOMPETITIONSICARSC2016INTERNATIONALCONFERENCE AFLEXIBLEROBOTICFRAMEWORKFORAUTONOMOUSMANUFACTURINGPROCESSESREPORTEUROPEANROBOTICSCHALLENGESTAGE1 ZADEH 2017 81 103 S BAKLOUTI 2017 9 14 E NILSSON 1999 205 226 K CHATZILYGEROUDIS 2018 236 250 K INSAURRALDE 2015 87 104 C DEAN 1988 49 54 T AAAIVOL88 ANALYSISTIMEDEPENDENTPLANNING GREFENSTETTE 1992 189 195 J MACHINELEARNINGPROCEEDINGS1992 APPROACHANYTIMELEARNING PEDROSA 2015 457 468 E PROGRESSINARTIFICIALINTELLIGENCE17THPORTUGUESECONFERENCEARTIFICIALINTELLIGENCEEPIA2015 ASKILLBASEDARCHITECTUREFORPICKPLACEMANIPULATIONTASKS AMARAL 2017 198 203 F AUTONOMOUSROBOTSYSTEMSCOMPETITIONSICARSC2017IEEEINTERNATIONALCONFERENCE SKILLBASEDANYTIMEAGENTARCHITECTUREFORLOGISTICSMANIPULATIONTASKSEUROCCHALLENGE2STAGEIIREALISTICLABSBENCHMARKING LIM 2017 159 164 G AUTONOMOUSROBOTSYSTEMSCOMPETITIONSICARSC2017IEEEINTERNATIONALCONFERENCE RICHROBUSTHUMANROBOTINTERACTIONGESTURERECOGNITIONFORASSEMBLYTASKS LIM 2017 15 27 G IBERIANROBOTICSCONFERENCE HUMANROBOTCOLLABORATIONSAFETYMANAGEMENTFORLOGISTICSMANIPULATIONTASKS MOKHTARI 2016 993 1005 V INTELLIGENTAUTONOMOUSSYSTEMS13 GATHERINGCONCEPTUALIZINGPLANBASEDROBOTACTIVITYEXPERIENCES LIM 2019 G BALOGH 2005 17 R THRUN 2006 661 692 S BUEHLER 2009 M DARPAURBANCHALLENGEAUTONOMOUSVEHICLESINCITYTRAFFICVOL56 LIM 2017 336 341 G 2017IEEEINTERNATIONALCONFERENCEMULTISENSORFUSIONINTEGRATIONFORINTELLIGENTSYSTEMSMFI NEURALREGULARIZATIONJOINTLYINVOLVINGNEURONSCONNECTIONSFORROBUSTIMAGECLASSIFICATION RUSSELL 2010 S ARTIFICIALINTELLIGENCEAMODERNAPPROACH LIM 2018 231 236 G 2018IEEEINTERNATIONALCONFERENCEAUTONOMOUSROBOTSYSTEMSCOMPETITIONSICARSC MOBILEMANIPULATIONFORAUTONOMOUSPACKAGINGINREALISTICENVIRONMENTSEUROCCHALLENGE2STAGEIISHOWCASE LIM 2019 1 11 G LIM 2013 387 395 G INTELLIGENTAUTONOMOUSSYSTEMSVOL12 ONTOLOGYREPRESENTATIONINSTANTIATIONFORSEMANTICMAPBUILDINGBYAMOBILEROBOT LIM 2011 492 509 G RUSU 2008 927 941 R RUSU 2009 R SEMANTIC3DOBJECTMAPSFOREVERYDAYMANIPULATIONINHUMANLIVINGENVIRONMENTS OLIVEIRA 2016 614 626 M PEDROSA 2016 35 40 E 2016INTERNATIONALCONFERENCEAUTONOMOUSROBOTSYSTEMSCOMPETITIONSICARSC ASCANMATCHINGAPPROACHSLAMADYNAMICLIKELIHOODFIELD COHENOR 1995 453 461 D RUSU 2011 1 4 R ROBOTICSAUTOMATIONICRA2011IEEEINTERNATIONALCONFERENCE 3DPOINTCLOUDLIBRARYPCL LOWE 1999 1150 1157 D COMPUTERVISION1999PROCEEDINGSSEVENTHIEEEINTERNATIONALCONFERENCEVOL2 OBJECTRECOGNITIONLOCALSCALEINVARIANTFEATURES TUDICO 2017 498 509 A PORTUGUESECONFERENCEARTIFICIALINTELLIGENCE IMPROVINGBENCHMARKINGMOTIONPLANNINGFORAMOBILEMANIPULATOROPERATINGINUNSTRUCTUREDENVIRONMENTS LIMX2019X103227 LIMX2019X103227XG 2021-08-08T00:00:00.000Z 2021-08-08T00:00:00.000Z © 2019 Published by Elsevier B.V. 2019-08-10T21:40:24.934Z S0921889017307947 National Funds China National Funds for Distinguished Young Scientists FCT - Foundation for Science and Technology UID/CEC/00127/2013 This work was supported by the EuRoC Project under Grant no. 608849 and by National Funds through the FCT - Foundation for Science and Technology , in the context of the project UID/CEC/00127/2013 . Dr. Gi Hyun Lim received the B.S. degree in metallurgical engineering and the M.S. and Ph.D. degrees in electronics and computer engineering from Hanyang University, Seoul, Korea, in 1997, 2007 and 2010, respectively. He is currently a Marie Curie individual fellow in the School of Computer Science at University of Manchester, UK. His research interests lie in the area of artificial intelligence and machine learning for autonomous robots, including perception, semantics, cognition and spatiotemporal representations on neuromorphic architectures. Eurico Pedrosa is a Post-Doc Researcher at the Institute of Electronics and Informatics Engineering of Aveiro (IEETA) integrated in Intelligent Robotics and Systems group (IRIS). He got his Informatics Engineering degree from University of Aveiro in 2010 and a Computer Science Ph.D. degree from Aveiro University in 2018. His research interest are focused on intelligent robotics, robotic navigation including localization and mapping (SLAM), space representation using volumetric grids and most recently the application of radar sensors in indoor robotics. Filipe Amaral is a Research Fellow at the Institute of Electronics and Informatics Engineering of Aveiro (IEETA) integrated in Intelligent Robotics and Systems group (IRIS). He got his MSc degree in Computer and Telematics Engineering from University of Aveiro in 2014. His current research interests are in the area of autonomous mobile robotics. Prof. Dr. Artur Pereira was born in Vila Nova de Famalicão, Portugal, in April 1960. He received the Ph.D. degree in Electrical Engineering from the University of Aveiro, Portugal, in 2003. He is currently an Assistant Professor at the Department of Electronics, Telecommunications and Informatics of the University of Aveiro and a researcher at the Intelligent Robotics and Systems group (IRIS Lab) of the Instituto de Engenharia Electrónica e Informática de Aveiro. The main focus of his research is robotics at the architectural and software levels, with emphasis on simulation, navigation, localization, mapping, and machine learning. Nuno Lau is Assistant Professor at Aveiro University, Portugal and Researcher at the Institute of Electronics and Informatics Engineering of Aveiro (IEETA), where he leads the Intelligent Robotics and Systems group (IRIS). He got is Electrical Engineering Degree from Oporto University in 1993, a DEA degree in Biomedical Engineering from Claude Bernard University, France, in 1994 and the Ph.D. from Aveiro University in 2003. His research interests are focused on Intelligent Robotics, Artificial Intelligence, Multi-Agent Systems and Simulation. Nuno Lau participated in more than 15 international and national research projects, having the tasks of general or local coordinator in about half of them. Nuno Lau won more than 50 scientific awards in robotic competitions, conferences (best papers) and education. He has lectured courses at Phd and MSc levels on Intelligent Robotics, Distributed Artificial Intelligence, Computer Architecture, Programming, etc. Nuno Lau is the author of more than 150 publications in international conferences and journals. He was President of the Portuguese Robotics Society from 2015 to 2017, and is currently the Vice-President of this Society. Prof. Dr. José Luís Azevedo is currently Assistant Professor at the Department of Electronics, Telecommunications and Informatics of the University of Aveiro and a researcher at the Intelligent Robotics and Systems group (IRIS Lab) of the Institute of Electronics and Informatics Engineering of Aveiro (IEETA). He received the Ph.D. degree in Electrical Engineering from the University of Aveiro, Portugal, in 1998. His current research interests are in the area of cooperative autonomous mobile robotics. Prof. Dr. Bernardo Cunha was born in 1959 in Porto, Portugal. He earned his doctoral degree in electrical engineering at the University of Aveiro, Portugal, in 1999. He is a full time teacher at Universidade de Aveiro in the computer architecture area and an investigator at the Instituto de Engenharia Electrónica e Informática de Aveiro. Current research interests are centered in the area of cooperative autonomous mobile robotics. Simone Badini is a Mechanical Designer in the Research and Development department of IMA Spa since 2013. IMA Spa is a world leader company in the design and manufacture of automatic machines for the processing and packaging of pharmaceuticals, cosmetics, food, tea and coffee and tobacco. He got is M.Sc. degree in Mechanical Engineering from University of Bologna, Italy in 2012. He is currently project manager for the integration of cobot and autonomous mobile robot in the production lines for the IMA group. item S0921-8890(17)30794-7 S0921889017307947 10.1016/j.robot.2019.06.006 271599 2020-01-13T11:13:04.440713Z 2019-10-01 2019-10-31 true 3280747 MAIN 14 53587 849 656 IMAGE-WEB-PDF 1 gr11 88037 82 219 gr6 76125 134 219 gr10 99763 151 219 gr1 84425 55 219 gr12 78236 62 219 pic3 95379 163 140 gr13 84239 60 219 gr17 92453 164 193 gr2 91612 129 219 gr19 18466 78 219 fx1002 5080 40 219 gr9 80285 162 219 pic5 90620 164 140 pic8 92385 164 140 gr4 86357 129 219 gr7 83216 163 155 gr8 78279 144 219 pic4 91410 163 140 gr5 84112 164 138 gr3 101514 163 219 gr18 77492 164 204 pic1 90433 163 140 gr16 82949 47 219 fx1001 5682 68 219 gr14 84362 115 219 gr20 34694 98 219 pic2 92082 164 140 pic6 88104 163 140 gr21 22647 162 219 gr15 93327 108 219 pic7 96532 163 140 gr11 115147 142 378 gr6 102249 210 342 gr10 127663 261 378 gr1 119793 128 506 gr12 100014 106 376 pic3 101319 132 113 gr13 105403 103 376 gr17 149053 321 378 gr2 129409 223 378 gr19 42698 110 309 fx1002 27829 150 816 gr9 109290 277 375 pic5 98434 132 113 pic8 101766 132 113 gr4 113348 190 323 gr7 120919 318 302 gr8 117887 327 496 pic4 97712 132 113 gr5 117350 225 189 gr3 125523 242 325 gr18 101664 243 302 pic1 99455 132 113 gr16 120354 112 525 fx1001 36645 252 816 gr14 114768 194 370 gr20 52488 146 325 pic2 99552 131 112 pic6 98208 132 113 gr21 59417 279 378 gr15 119748 187 378 pic7 107374 132 113 gr11 364806 629 1674 gr6 175979 929 1514 gr10 495261 1154 1674 gr1 351578 568 2243 gr12 185445 470 1668 pic3 169551 583 500 gr13 214287 455 1666 gr17 622945 1422 1674 gr2 342433 988 1675 gr19 90504 487 1369 fx1002 103050 398 2169 gr9 245828 1230 1663 pic5 158735 584 500 pic8 168594 584 500 gr4 258891 842 1433 gr7 296978 1410 1339 gr8 281811 1449 2197 pic4 140145 583 500 gr5 232097 999 840 gr3 443350 1074 1440 gr18 160189 1077 1340 pic1 155377 583 500 gr16 409379 497 2326 fx1001 144071 670 2169 gr14 245424 859 1639 gr20 178264 647 1440 pic2 165958 583 499 pic6 138608 583 500 gr21 195782 1237 1675 gr15 306022 828 1676 pic7 174577 583 500 si27 26913 si33 1898 si34 1618 si31 7355 si3 2005 si14 1133 si6 2114 si38 3009 si21 1832 si37 4191 si18 3593 si36 1780 si16 8122 si2 1418 si8 1661 si1 1607 si9 4591 si26 2321 si19 1613 si32 6363 am 19107071 ROBOT 3227 103227 S0921-8890(17)30794-7 10.1016/j.robot.2019.06.006 Fig. 1 Human operators in a packaging industry. Fig. 2 KUKA KMR mobile manipulator. Fig. 3 Initial setup of the table for task 2. Fig. 4 Showcase environment in the gazebo simulator. Fig. 5 EuRoC software framework for C2 [23]. Fig. 6 Use case diagram of skill-based anytime agent architecture (SAAA). Fig. 7 A higher level overview of SAAA. Fig. 8 Sequence diagram of SAAA. Fig. 9 A skill-based architecture for safe human–robot collaboration. Fig. 10 Example of detection of two SLCs on a shelf. The top image is what is perceived by our detection system (plus depth). The bottom image contains a superimposed 3D model of the SLC for each detection, including the center of the SLC (red dot) and a possible pick point (green dot) . (For interpretation of the references to color in this figure legend, the reader is referred to the web version of this article.) Fig. 11 Example of nut and bolt detection. The top image contains the detection of a nut and the bottom image contains the detection of a bolt. The same detection algorithm is used for nuts and bolts. Fig. 12 Washer detection in the fixture. The top image is what is acquired by the camera. The bottom image is the result of the segmentation by intensity. Fig. 13 Snapshots of bent blank piles. Fig. 14 Gripper and blank magazine in simulator. Fig. 15 Grpeer and blank magazine in the realistic environment. Fig. 16 Two pallets and blank piles and their detection results. The red lines in center and right images indicate the pose of pallets, while the green circles indicate the positions of blank piles. Fig. 17 A sequential result of the pose estimation of a blank pile. Fig. 18 Drawing pin filter to detect outlines. Fig. 19 A task plan for 9 blank piles on two pallets. Fig. 20 Human tracking and HRI during the EuRoC evaluation. Fig. 21 Interaction tree for the showcase task. Table 1 Benckmark task 1. Team Metric 1 Metric 2 Bonus Time AutoMAP 5 5 6.22 4:56 MTC-LU-UoB-Airbus 5 4 0 18:13 RSAII 5 5 3.32 9:14 NimbRo Logistics 5 5 3.45 8:54 TIMAIRIS 5 5 10 3:04 Table 2 Benckmark task 2. Team Metric 1 Metric 2 Bonus Time AutoMAP 5 5 4.16 15.01 MTC-LU-UoB-Airbus 0 1 0 8:54 RSAII 5 5 3.78 16:31 NimbRo Logistics 4 4 0 41:27 TIMAIRIS 5 5 10 6:15 Table 3 Quantifiable evaluation. Objectives Metrics Targets Events Percent (%) O1 O1M1 6+5+3 6+5+3 100 O1 O1M2 6 6 100 O1 O1M3 5 5 100 O1 O1M4 2 2 100 O2 O2M1 6 6 100 O2 O2M2 6 6 100 O2 O2M3 6 6 100 O2 O2M4 2 2 100 O3 O3M1 3 3 100 O3 O3M2 12 12 100 O4 O4M1 4 4 100 O4 O4M2 2 2 100 Skill-based anytime agent architecture for European Robotics Challenges in realistic environments: EuRoC Challenge 2, Stage II — realistic labs Gi Hyun Lim a 1 Eurico Pedrosa a 1 Filipe Amaral a Artur Pereira a ⁎ Nuno Lau a ⁎ José Luís Azevedo a Bernardo Cunha a Simone Badini b a IEETA, Universidade de Aveiro, Aveiro, Portugal IEETA, Universidade de Aveiro Aveiro Portugal IEETA,Universidade de Aveiro, Aveiro, Portugal b IMA, Via Emilia 428-442, 40064 Ozzano dell’Emilia, Italy IMA Via Emilia 428-442 Ozzano dell’Emilia 40064 Italy IMA,Via Emilia 428-442, 40064 Ozzano dellEmilia, Italy ⁎ Corresponding authors. 1 These authors contributed equally to this work. As demands on pragmatic solutions of robotics technology increase in the manufacturing industry, deep affinities between research experts and industry users are required. The European Robotics Challenges (EuRoC) research project has proposed a scientific competition and matched up research labs with industrial end users to establish challenger teams to develop and test solutions that will be applied in the real context of the industrial end-users. The paper reports the result of TIMAIRIS who is one of 6 challenger teams to advance to the final stage out of 103 teams and technical details used in the Challenge 2 - Shop Floor Logistics and Manipulation. To address the requirements and achieve the objectives of the challenge, a skill-based anytime agent architecture has been developed and extended to make the team focus on the challenging research that addresses real issues in the user environments. Finally, shop floor logistics and manipulation scenarios have been developed and demonstrated in a realistic environment for autonomous packaging. Keywords Skill-based Anytime agent architecture Mobile manipulation Autonomous packaging European robotics challenges (EuRoC) 1 Introduction 1.1 Motivation Several robotics challenges and competitions have been launched for the exchange of research results and for comparative evaluations including manipulation, such as the DARPA Robotics Challenge [1], the RoboCup leagues [2] and the European Robotics challenges (EuRoC) project [3], since neither resources such as robots’ platforms, source codes and datasets are available to the public nor are simulators sufficiently mature to present real environments. To obtain a good result in a robotics challenge or competition, challengers need to develop a robotic system that completes given challenge tasks within a limited time. EuRoC is a research project where a robotic competition is conducted with the aim to develop and present solutions to the European manufacturing industry [3]. The EuRoC consortium has launched three industry-relevant challenges: C1 - Reconfigurable Interactive Manufacturing Cell, C2 - Shop Floor Logistics and Manipulation, and C3 - Plant Servicing and Inspection. In particular, the Challenge 2 (C2) addresses the SRA2009 [4] scenarios: Logistics and Robotic Co-Workers. Mobile manipulators are provided by the EuRoC host as a suggested solution to utilize as logistic carriers and dexterous manipulators. Each challenge team should consist of both a research group and an industry partner to show the use case in a realistic environment. Our work is being developed within the Challenge 2 context. The Challenge 2 host especially set the working time regulations to share the resources among all challenger teams and to make sure that they have the same amount of effective lab time in the realistic environment where the challengers access robotics platforms and benchmark infrastructures. As the use case scenario of TIMAIRIS, which is a collaborative challenge team between the Intelligent Robotics and Intelligent Systems (IRIS) research group from the University of Aveiro (UAVR) in Portugal and IMA S.p.A industry from Italy, an autonomous blank feeding task is investigated because it is not easily solved by a robot. Proof of such assumption is that the industrial state-of-the-art solution for this problem is to use human operators to perform it, as shown in Fig. 1. This is a tedious, repetitive and tiring task and human operators may occasionally refrain from collecting blank piles from more distance pallets. This paper presents a skill-based anytime agent architecture (SAAA) and the result of TIMAIRIS team in the second stage of C2. TIMAIRIS is one of 6 challenger teams advancing to the final stage out of 103 teams in the simulation contest, The second stage consists of three phases to be performed in a real environment: Benchmarking, Freestyle and Showcase. In the realistic labs of the EuRoC challenge tasks, the main constraint is time, not only the running time (online efficiency) in an evaluation matrix but also development time (offline efficiency) to complete the tasks in a limited time. Each challenger team is allowed to take a limited fixed time to access an experimental environment in which EuRoC hosts offer support and the mandatory robot platform is available. Especially, for the three phases of the stage II, each team has evenly-distributed eleven weeks (54 working days) to exclusively access the environment. Challenger teams are required to find efficient and robust skills and complete evaluations in the given time. SAAA provides opportunities to increase efficiency not only in autonomous execution for shop floor logistics and manipulation but also in its use of development during the challenge competition. 1.2 Related work To meet the requirements and constraints on a robotic challenge, challenger teams need an adaptive, flexible, robust and efficient robotics architecture [5,6]. Several reactive architectures are proposed to find a solution that makes a robot complete tasks on-time. By managing mission time, Zadeh et al. [7] developed an autonomous reactive architecture of unmanned vehicles in realistic ocean environment. Synchronization between high level mission and low level path planning is configured to control mission time and to guarantee termination of the mission with the best sequence of tasks fitted to available time. Baklouti et al. [8] proposed a reactive control architecture for wheelchair robot navigation without human intervention and prior knowledge of the world. Nilsson and Johansson [9] introduced a layered Open Robot Control (ORC) architecture to meet industrial demands such as computing efficiency and simple factory-floor operation with integration of online and offline robot programming. Offline programming typically done by robot programmers requires abstract modeling, whereas online programming typically done by production engineers or robot operators utilizes physical robots in real environments. Recently several trial and error methods are proposed to adapt for use by damaged robots [5,10]. Those focus on the online time challenge by reducing the number of trials to recover from damage to complete tasks. Cully et al. [5] introduced an intelligent trial and error algorithm which enables a robot to discover a compensatory behavior from damage without requiring pre-programmed contingency plans. The algorithm conducts experiments based on high-performing policies for the intact robot work on the damaged robot. While traditional reinforcement learning (RC) methods for robots need to reset their learning environments and robots to an initial state, Chatzilygeroudis et al. [10] proposed a reset-free trial-and-error learning for robot damage recovery. Insaurralde and Petillot [11] proposed a capability-oriented robot architecture that enables multiple unmanned vehicles to collaborate to autonomously carry out underwater intervention missions in a fault-tolerant manner. On the other hand, anytime approaches use iterative improvement techniques in problem solving, planning, scheduling [12] and learning [13]. Those address the online time challenge by returning results at any time. To adapt to realistic industrial environments, this paper proposes a skill-based anytime agent architecture (SAAA) by integrating previous work [14–17]. The architecture consists of a solver, modular skills and task representations. The separation of task s that organize orders of objects to assemble into graphs from an agent processing algorithm [18,19] allows a robot to start at any task state. It is not necessary to reset the robot and its environment to run from an initial state. During development, a robotics challenger team needs to repeat a subtask or to execute a skill from a specific state to refine the subtask or the skill until the time of evaluation. On the other hand a human co-worker will continue or restart a task after a task failure or a task completion at the runtime. To the best of our knowledge, robotic system architectures and anytime algorithms consider only online efficiency while the proposed architecture also takes offline efficiency into account. 2 European robotics challenges (EuRoC) Many robotic challenges have been so far launched to find competitive solutions for their applications [20]. The DARPA Grand Challenge [21] and its successive events, DARPA Urban Challenge [22] and DARPA Robotics Challenge [1], have drawn worldwide attention as robotic competitions for autonomous ground vehicles on an off-road course, for autonomous operation in a urban environment and for autonomous emergency maintenance robots, respectively. The main objective of the DARPA challenges is bridging the gap between fundamental discoveries of academia and military use. Since 1997, RoboCup [2] has been held annually to foster AI and intelligent robotics research. Initially the target of competition was a world cup with real robots, nowadays there are also other leagues such as RoboCup Industrial, RoboCup Rescue and RoboCup@Home. Especially, the RoboCup Industrial league defines two tasks: logistics and manipulation; but robots in this league have size constraints. To match the Strategic Research Agenda (SRA) for robotics [4], the EuRoC project was launched in 2014. It aims at exploiting synergies among all the actors of robotics and manufacturing to accelerate the transference of state-of-the-art technologies from academia to industry. After qualification, the members of each team are required to organize from both communities. The main motivation of the European Robotics Challenges (EuRoC) is to make use of robotics products and services by strengthening collaboration between the industrial and the research community [3]. The EuRoC is a research project based on robotics competitions that drives innovation in robotics and manufacturing through a number of application experiments. The Challenge Advisory Board of EuRoC is in charge of the evaluation of the competition project empowered on robotic platforms and benchmark infrastructures to get rid of contestants’ burden on platform-related low-level problems and maintenance. As a realization in this context, the EuRoC initiative has launched and run three challenges in parallel with different motivations and objectives. The Shop Floor Logistics and Manipulation or Challenge 2 (C2) covers application scenarios about robotic co-workers and logistics robots in industrial, professional service and domestic service sectors, which is matched to the Strategic Research Agenda (SRA) for robotics in Europe [4]. In the co-worker scenario, a robot becomes an assistant or collaborator that works literally hand-in-hand with its human counterparts in unstructured environments. Here, the robot needs to communicate with a human to take an order, to ask confirmation, and to reply to a question. Each EuRoC challenge is structured in three successive stages, over the period of 4 years: Stage I QUALIFYING: Simulation Contest, Stage II REALISTIC LABS: Benchmarking, Freestyle and Showcase and Stage III FIELD TESTS: Pilot Experiments. 2.1 Challenge 2: shop floor logistics and manipulation The Shop Floor Logistics and Manipulation challenge or Challenge 2 of EuRoC project consists of a assembly of tasks designed to be solved by a mobile robotic platform operating in industrial environment. This challenge is divided in three main stages where three different scenarios were designed and considered. Stages I and II were already completed and the Stage III will be done at the end of the EuRoC project. Briefly, the first stage was based on a stationary platform and the achieved solutions were integrated in a simulation environment. The Stage II consists in a scenario where a real Light-Weight-Robot (LBR iiwa) equipped with a two-finger jaw-gripper mounted on a mobile base (KUKA omniRob) was controlled through an intranet-based framework (similar to the one that was used in Stage I), as shown in Fig. 2. The final stage, Stage III, will be an application of all the achieved solutions in a real scenario of industry with real work pieces provided by an end-user, showing the real capabilities of this innovative solution and the contribution to the manufacturing dynamics improvement. 2.1.1 Benchmarking For the Stage II in the Challenge 2, the EuRoC host has provided a benchmark environment at DLR in a realistic factory set-up with elements from real end users. It consists of two tasks in simplified manufacturing environment: logistics and assembly. The first task of the Benchmarking phase addresses production logistics. In this task, the mobile manipulator has to bring 5 Small Load Carriers (SLCs) which are distributed in the room to a fixed target area on a table. One SLC is placed on the goal table out of the target area, two are placed on another table and two are located in a shelf. The room has enough space for the robot to move between the tables and the shelf. The start position is in the middle of the room. The setup of the room will be static over the development and evaluation. The SLCs are filled with a various number of nuts and washers from the Benchmarking task 2. For each correctly delivered SLC (its footprint has to be inside the target area) one point is awarded (max 5 points). For each SLC, if all parts in it remain within it during the transport to the goal area, another point is awarded (max 5 points). If the task is completed successfully extra points could be awarded for the execution time. The amount of points is inversely related to the best teams time (max 10 points). The second task of Benchmarking is about mobile manipulation for basic pre-assembly of products. In this task, the robot has to assemble five bolts. The layout of the room and the start position of the robot are the same as in the previous benchmark task. The assembly table is identified as “Pickup table”. On that table, there are 5 nuts, 5 bolts and 5 washers within a fixed area. Next to the parts are two fixtures attached to the table. One of the fixtures holds the washers and the other has a gap with the bolt’s head shape to allow the nut to be screwed. The parts are arranged to minimize occlusions (see Fig. 3). The bolts are upright, the nuts are flat and the washers are placed in the fixture to give a good orientation for grasping. The translation between the different parts may vary. The nuts and bolts are touching a virtual line parallel to the fixtures 10 cm and 20 cm behind, respectively. For each nut correctly screwed, one point is awarded (max 5 points). Applying a washer onto the bolt before screwing a nut gives another point (max 5 points). As in the previous task, if the task is completed successfully extra points are awarded for the execution time. Again, the amount of points is inversely related to the best teams time (max 10 points). 2.1.2 Showcase: autonomous packaging As the third and final challenge of the Stage II, the showcase runs in an simplified environment that, although not located in an industrial plant, includes the most important elements of the real environment where the task will be executed as a final product, as shown in Fig. 4. It uses real pallets with real piles of blanks and a prototype of the blank feeding mechanism of a packaging machine that includes all relevant features for the task to be performed. In this task the following issues are going to be covered: the platform will be able to recognize empty pallets, plan and replan its actions; an initial version of the multimodal interface will be used, integrating the possibility of gesture commands in the interaction with the platform (gestures will be used mostly for safe navigation); the robot will be able to navigate in an environment that includes a few humans and interact with them; the manipulation of the selected type of blanks will be demonstrated. To solve the blank feeding task using a mobile robot, several technical issues are identified. • Manipulation of stacked objects: The blank pile is not a unique rigid solid object. Not only it can bend under its own weight, but blanks can also easily break free from the pile due to the fact that a considerable amount of low friction blanks are stacked on top of each other. • Single arm manipulation: The manipulation of a blank pile is performed using a single arm with a gripper. In order not to miss any blanks out of a stack on a pallet, picking up the blank pile requires several manipulation steps and a specialized gripper. • Smooth placing of the blank pile: Blank piles have to be placed in the feeding mechanism avoiding hard collisions with the blanks that are already there and with the four blank guiding rods that prevent blanks from slipping out of the inclined magazine surface. • Shared workspace with humans: The robot has to be able to navigate in an environment that is shared with humans. This introduces safety concerns but, at the same time, it also rises the opportunity to take advantage of the human–robot proximity to explore human–robot interactions (HRI) to control the robot [16]. • Robust detection of blanks: Blanks are provided in untied piles, piled up on pallets close to each other, which can cause erroneous detection. • Handling global localization errors: The feeding of the blank magazine is an example of a manipulation action that requires a high level of precision for a proper feeding while preventing collisions between the blank magazine and the manipulator. 2.2 EuRoC platform As an objective of the EuRoC, robotics platforms and benchmark infrastructures have been developed to make challengers focus on the challenging research without efforts on platform-related low-level problems and maintenance. Especially for C2, two mobile manipulators are suggested to address logistics and robotic co-workers scenarios, as shown in Fig. 2. EuRoC hosts and robot manufacturers also provide programming and simulation frameworks, and open interfaces on lowest levels. Available EuRoC SW tools 2 2 are also provided for use in the EuRoC. Fig. 5 shows the EuRoC software framework for C2. Challengers are required to develop high-level software components with the similar functionalities but different scenarios to test and validate in meaningful contexts typically for shop floor logistics and manipulation in C2. 2.3 TIMAIRIS software architecture TIMAIRIS software is composed of three main components: a skill-based agent architecture (SAAA) [15], a human tracker and safety manager subsystem [17] and a realistic simulator [14]. TIMAIRIS software uses a skill-based anytime agent architecture [15] that has been evolving from the one used for Stage I simulation tasks [14]. The separation of task-dependent representations and a generic agent processing algorithm allow the robot to start at any task state. Human collaborators or robot operators need to repeat a task after recovering from failure or to test the skill from a given starting point. Having the same architecture performing successfully for such a different set of tasks demonstrates that this team solution is remarkably flexible and well adapted for EuRoC C2 platform and its capabilities. Ensuring safety, industrial robots need to share an environment with humans and to work hand in hand. To realize safe human–robot collaboration, a human tracker and safety manager subsystem has been integrated into the SAAA [17]. The human tracker keeps on tracking humans in a workspace. The safety manager infers whether it is in a safe state or not based on system states and human tracking information. Then, human–robot interaction module takes an order from the operator to resume or stop the paused task using gestures [16,24]. A realistic simulator has been developed for the Challenge 2 (see Fig. 4), using, as starting point, the Stage II simulator provided by the EuRoC host. The simulator allows the execution of the complete Challenge 2 tasks and was an essential tool in the development of TIMAIRIS’ Challenge 2 software. 3 Agent architecture 3.1 Skill-based anytime agent architecture To address the requirements and achieve the objectives of C2, a skill-based anytime agent architecture (SAAA) has been developed to solve the logistics and manipulation tasks [15]. This paper extends the previous architecture in the way that a plan manages more than one object and a robot explores workspace that cannot be covered by its cameras without moving the platform. In particular, the new architecture has been used to solve the Production Logistics and Product Assembly tasks previously described. These tasks have four objectives: perception, manipulation, planning and human robot interaction. Fig. 6 shows the use case diagram of SAAA at development time and/or runtime for human–robot collaboration. A robot and two types of humans are involved in the use case: a developer and a co-worker in a scenario for autonomous packaging. A robot developer sets a robot state to refine a skill which is executed at the state. It is possible that the developer repeat to execute the skill to improve performance and reduce runtime without reseting the robot and its environment. For example, a placing skill will be executed after picking and transport skills in pick-and-place tasks. To refine the placing skill, it is not efficient to run whole pick-and-place task by reseting to an initial state. A human co-worker may provide a command to start and stop a task or to change a sequence of objects to be delivered. A mobile manipulator (see Fig. 2) sequentially executes skills to complete the Production Logistics and Product Assembly task. In a higher level view of the skill-based framework, as shown in Fig. 7, the functional components are represented by boxes. A Perception module collects sensory data and processes them to extract information used by high-level modules. A Skill is the capacity of doing a particular task, such as, picking and placing an object or moving the end-effector of the manipulator to a desired pose. Perception modules and Skills collect and transmit sensory-motor data via Sensor interface and Effector interface, respectively. The Action Planner provides a plan for the target object. A plan contains a sequence of skills and their corresponding objects. The Solver is responsible for taking decisions on how to solve the current task based on the current sensory data and available Skills. To solve these tasks, an agent is required to perceive the environment through sensors and act upon that environment using actuators [25]. A skill-based agent architecture is implemented to develop a generic solution capable of handling shop floor logistics and assembly tasks by analyzing the properties of the environment. Henceforth, the proposed method has been utilized for several packing scenarios by increasing the realization during the EuRoC challenges [16,17,24,26,27]. Fig. 8 shows the sequence diagram of SAAA for autonomous packaging. To complete a task, a robot developer can set the state of a robot to start a new task from the initial state or to repeat the previous skill to continue the previously uncompleted task. When the robot start a task, the Solver [15] reads the Order graph [14] of the task and also tries to get a command from Interaction which is a module that tracks humans [17] and gets a command from a co-worker via gesture recognition [16]. The Solver requests a plan from Planner with the states of the robot and its environment, and executes a sequence of skills by following the plan. It continues until completing the task or terminated by the robot developer. when the robot stops, the developer repeats to set the state and to start the robot. The proposed algorithm is summarized in 1. In each task, the set O of objects to be manipulated, including their properties and place zones, is known in advance. The algorithm starts by building an Order Graph which represents the order of objects. The order is restricted by a direct acyclic graph (DAG), which represents a dependency graph between objects in terms of order of manipulation [14]. Leafs represent objects that need to be handled first. The dummy object λ is added to represent the graph root. To ensure that all object are eventually detected [28], a set of search poses S is estimated by the procedure buildSearchSpace with the insurances that all combined poses cover the whole working space. The set S is encoded as a circular list so that the search for poses never ends. Additionally, to improve the search [29], the vision system on the pan tilt unit is used to detect objects in the environment and the obtained poses are put in the head of S in the order defined by G . It may not detect any object, but, if it does, the system can gain in execution times due to good initial search poses. The algorithm then executes nested loops that, making the robot move around the search poses, finishing when only the root node ( λ ) remains in the Order Graph. Each search pose is explored to see if a leaf object is there. A plan is a tuple [19] consisting of a sequence of skills and their corresponding objects that allows to properly pick objects, move the end-effector of the manipulator and place the objects in the target position [30]. Those skills depend on a priori calculation of the pick and place pose. The specific plan depends on the task being solved. The Action Planner can estimate the state of task based on the input object. The plan could be related with several objects. For instance, in the assembly process several parts are added in sequence until the final assembly is produced. If the execution of the skill succeeds, the leaf corresponding to the processed object is removed from the graph. Because Order Graph and plan are separated from the agent processing algorithm, only three procedures are task dependent, buildOrderGraph, buildSearchSpace and makePlan. This formulation has two significant advantages. First, the agent can start execution at any task state, even if the agent meets a failure while execution, as it can continue the task after recovering from the failure. Second, to solve a task the developer only has to focus on the creation of a plan supported by a set of available skills. 3.2 Resource management scheme Fig. 9 shows an extension of the skill-based architecture for safe human–robot collaboration. The Human tracker keeps on tracking humans in the workspace by using laser scanners. The Human–Robot Interaction (HRI) module communicates with a human by recognizing gestures [24] and by providing information via multi-modal interfaces [16]. The Safety manager infers whether it is in a safe state or not based on system states and human tracking information. When the Safety manager decides to pause an executing task, it requests Solver to gaze at the nearest human operator, and to trigger HRI to interact with him. Then, HRI takes an order from the operator to resume or stop the paused task using gestures. To continuously monitor humans, the Human tracker and Safety manager need to be continuously active, while all other modules including skills and perceptions modules just run on request. That should cause conflicts over resources. For example, when the robot wants to recognize the pose of a blank magazine to feed a blank pile, a perception module tries to rotate the pan–tilt camera system to the blank magazine on the table. If, at the moment, a human operator approaches, the Safety manager also tries to rotate the same camera system to gaze the operator. Based on the skill-based agent architecture [14,15], a resource management scheme is added to the system architecture, as shown in Algorithm 2. When a robot starts, each module which needs to run continuously is launched and becomes a daemon. The Solver builds a resource map which lists all necessary resources for each daemon module. At every spin, which means a wake-up for all subscriptions, services, timers and so on in ROS (Robot Operating System), 3 3 the daemon checks the availability of its resources. If available, it runs normal procedures and release all resources at the end of the procedures. 4 Solving benchmarking tasks The objective of our team is to solve the tasks proposed for the EuRoC Benchmarking phase with high precision, accuracy and robustness, as fast as possible. Time is a key factor in solving the tasks at hand: not only it is an evaluation metric, but, for industrial applications, it a matter of productivity by reducing the time for development. In this section, we present our approach to solve two tasks of the Benchmarking phase -Production Logistics and Product Assembly- using the presented architecture. 4.1 Task 1: production logistics The goal of this task is to find all SLCs present in the room such as tables, shelves and workbenchs and place them in the designated target area in a workbench. Their approximate locations are known, on top of two tables and in a shelf, but their exact positions on those locations are unknown. To solve this task we start by designating several search poses that guarantees that eventually all SLCs are detected with the stereo camera mounted in the pan and tilt unit. Once an SLC is in sight, its pose should be detected, in order to pick it up. Then the SLC is placed somewhere else, in an intermediate or target area. This last step has several variations that affect the overall execution time because of the locations of SLCs. 4.1.1 SLC detection The detection of SLCs has two stages: first, color segmentation is used to define candidate regions in the image, that may contain at least an SLC; second, a 3D point cloud for each region is generated and matched against 3D template of an SLC to find its position and orientation, i.e. its pose. Color segmentation, in the HSV color space, is initially used to detect an SLC due to the SLC’s color homogeneity and good contrast with the environment. The output of the color segmentation is then used to generates blobs that represent SLC candidates. The resulting blobs must have a minimum size to be valid. The overlapping of SLCs in the image may generate a single blob for multiple SLCs, but that is not a concern as the disambiguation is deferred to the next stage. Once color segmentation is completed, the resulting blobs are used as masks to generate a point cloud for each candidate. While 3D point cloud generation and matching processes are heavy, the color segmentation is not. Thus, the SLC detection is time-optimized by reducing many candidates from the color segmentation. Let P be a point cloud and { p i } the set of points of P . The calculation of SLC’s pose relies on the processing of the point cloud P . To reduce the computational complexity of processing a point cloud with a high number of points, P is decimated by applying a voxelization filter. Then, to remove possible outliers in the point cloud a statistical outlier removal [31] is used. To address the possibility of SLCs overlap, the point cloud is divided into clusters using a euclidean cluster extractor [32], the cluster with the highest number of points being assigned to P and the remaining points being discarded – thanks to our agent architecture, discarded SLCs will be detected in the next cycle. The position of the SLC is approximately calculated from the centroid c of P , given by c = 1 n ∑ i = 1 n p i , while its orientation is initially provided by the Principal Component Analysis (PCA) of the projection of P in the X O Y plane [33]. However, this approach is not enough, as the view of the SLC may provide a partial point cloud that skews the centroid from the real center, and the orientation of the PCA has an ambiguity of π radians. The final pose of the SLC is calculated by matching P against a 3D template of the SLC that has its centroid in the origin and its bearing defined by the X axis. Before matching the point cloud, P is transformed to its origin, i.e. the inverse pose of P is applied to itself, then, the transformation that results from the matching between the template and P is the correction of the initial pose calculation. Note that because the orientation given by PCA is ambiguous, we do the matching with the initial orientation and with another rotated by π radians. To correct the pose, we use the matching transformation that provided the best matching. The algorithm used for matching is the adaptation of the scan matching algorithm proposed by Pedrosa et al. [34] to three dimensions. An example of SLC detection is shown in Fig. 10. 4.1.2 Manipulation and planning strategy To solve this task three manipulation skills were used. The pick_object and place_object are based on the skills trained in a simulation environment [14] with some minors adaptations. The pick_object_shelf skill is also derived from the pick_object skill but taking in account the space between the shelves of the shelf. So in this skill instead of approaching the object using a vertical movement it is approached at an angle of 45 degrees. This allows the arm to reach the objects on the shelf without hitting the upper level of the self. Our initial approach was to pick an SLC, hold it and deliver it to the goal area. With this approach the robot has to move across the room 4 times, 2 for the SLCs on the pickup table and 2 for the SLCs in the shelf. It takes around 15 min to complete the job, being most of this time spent on navigation between the goal table and the pickup table and shelf. In order to optimize this process a second approach was developed. Because a considerable amount of time was being spent on navigation, we manage to transport the SLCs on top of the robot platform. This way, navigation was reduced to one trip to each side: first, the two SLCs in the table are picked up and placed in the top of the robot; then, the robot moves to the shelf, pick up another SLC and also put it in its top surface; finally, the fourth SLC is picked up and held in the gripper, while the robot navigates to the target table. On the target table, the four SLCs are put in the target area, after which the fifth SLC, the one in the target table, is detected, picked and placed. With this improvement the time dropped to around 10 min. After this pick and place strategy was implemented, some improvements were accomplished, by parallelizing some steps. For example, after picking an SLC, while placing it on the top of the robot, movement to the next observation and picking position can be performed. Task time was now reduced to around 8 min. A significant amount of time was still being spent in picking the SLCs from the top of the robot and placing them on the goal area (3 SLCs from the top of the robot plus the fourth that was transported on the gripper). So our final solution was to rearrange the SLCs on top of the robot so that the manipulator can pick two at the same time. This way one of the picking from the robot’s body was eliminated. Also, by placing the fourth SLC on top of the robot aligned with the third and by picking both at once, the number of places in the target area was reduced to 3 – 2 places holding two SLCs and one holding only one SLC. The 4th SLC is placed on top of the robot while it is navigating to the target table. Also, during navigation the arm could pick the 3rd and 4th SLCs so that when the robot reaches the target table the SLCs are already grasped. These improvements dropped the time to 5 min. Furthermore, speed increasing was previously prepared through parameters in a configuration file. During the evaluation, 6 out of 7 attempts were successful and with decreasing times, which lead to the final task time of 3 min and 4 s just by increasing the speed of the movements. 4 4 4.2 Task 2: product assembly The goal of this task is to pre-assemble a set of bolts, nuts and washers using a single manipulator. Since the single arm manipulation is not able to assemble two parts, two fixtures are provided to help in the assembly: one contains the washers in an approximate upright position to facilitate picking; the other has a well with the shape of the bolt head shallow enough to hold the bolt in place when a torque is applied, i.e. it secures the bolt when screwing the nut. The specifications of the task includes the approximate locations of the assembly pieces and fixtures, but not their exact positions. To solve the task we start by defining an observation point for the camera that is mounted in the arm, that provides a complete view of all necessary elements for the task and allows the manipulation of all parts without changing the position of the platform. This is important as, if the platform does not move, the relative positions of all objects are maintained with high precision after the first detection (see Fig. 3). The robot has to detect the bolt, pick it and place it in the bolt fixture, then it has to detect the washer, pick it and place it in the bolt, and finally it has to detect a nut, pick it and screw it in the bolt. Positions are calculated using the pinhole model instead of the point cloud provided by the stereo rig. this strategy can be pursued because the dimensions of all elements in the task and a precise distance from the camera to the working table, that is inferred from the pose of the arm are known in advance. This is done to speed up detection, because the generation of depth information is computationally expensive. 4.2.1 Fixture detection The detection of the fixtures, although executed only once, is an important step. The robot does not start from the working area but has to navigate there. Thus, location errors are inevitable. The assembly area is well defined, therefore, the fixtures are used as reference points to the rest of the elements. The detection of the fixtures is done using HSV color segmentation. We start by detecting both fixtures from the observation point. Once the resulting blobs are obtained, for each blob the rotated rectangle that best encloses it is calculated. The detection from the observation point is not very precise, therefore using the information from the rotated rectangle, the camera is approximated to each fixture and the detection is repeated individually. The information about the fixture that contains the washers is used in the detection of the washers, as their relative position to the fixture is known and so the search space in the image can be reduced. The center of the rotated rectangle that derives from the bolt’s fixture coincides with screwing place. 4.2.2 Bolt, nut and washer detection The detection algorithm for the bolts and nuts is the same. We explore their shape similarity when viewed from the top, i.e. when the object is located at the image center. The detection of a bolt/nut starts by performing color segmentation, then blobs are created from the resulting segmentation. Only the blob closer to the image center and in the vicinity of the bolts virtual line is considered, the rest being discarded. We perform a shape analysis to find the vertices of its convex shape and to find afterwards two consecutive edges that resemble the bolt/nut hexagonal top in length and angle (Fig. 11). Those edges are then used to calculate the center of the bolt/nut, and its orientation. The orientation is required for the nut so that it can be picked up by its edges. The described approach assumes that the object to be detected is as much as possible in the center of the image. This is achieved by generating a hint list for bolts and nuts that gives a rough approximation of their positions. The list is populated by running the color segmentation once for the bolts and nuts from the observation position. The resulting blobs are then used as hints. When it is time to detect a bolt/nut the hint is used to approximate the camera to the object in focus. The detection of the washers uses a different strategy. Instead of color segmentation, we do an intensity filtering that keeps the pixels with higher intensity (Fig. 12). Then, from the resulting segmentation we extract several blobs validated by their size. The centers of these blobs are then used to calculate the positions of the washers. 4.3 Manipulation and planning strategy To place the bolt in the screwing fixture, the place_bolt skill takes advantage of the compliant movement of the arm. To insert the bolt head into the fixture, after aligning the bolt with the center of the fixture, the bolt is pushed against the fixture while rotating it. As soon as a drop in the bolt’s height is detected, the action finishes, as it means the bolt’s head entered the fixture. For the place_nut skill the strategy is similar. While using compliant movement of the arm, the robot starts rotating the nut while at the same time pushes it against the bolt tip. Based on how much the height of the nut dropped during the first rotation, the number of rotations is adjusted in order to be fully screwed on the bolt. In the pick_washer skill, since they are in an upright position slightly tilted, the gripper approaches the washers just like in a normal pick but with the fingers adjusted for the washer diameter. Then the gripper moves down slowly in order to push the adjacent washer and create space for the picking. Because they are tilted the robot pushes them in the opposite direction of the tilt in order to became upright and aligned with the fingers of the gripper. To place the washers on the bolt, the place_washer skill aligns the inner bottom edge of the washer with the top of the bolt, just touching it on the side. Then the washer is rotated by 60 degrees while pushing it against the bolt. This tilts the bolt a little bit making it push the washer to the correct position when it is released. The planning strategy for this task is straightforward. Not considering the perception parts, it corresponds to the following sequence of actions: first, a bolt is picked up and placed in the fixture; then, a washer is picked up and placed in the bolt; next, a nut is picked up and screwed in the bolt; finally, the assembly is picked up and placed in a target region. The same procedure applies to the other bolts, washers and nuts. The speed of the movements and the movements connecting the different skills were parameterized and optimized during evaluation, starting with safer speeds and proceeding to faster ones after the task had been completed with success. In 7 attempts to solve the task, only one of them failed to complete all the objectives. With this strategy the best achieved task time was 6 min and 15 s. 5 5 5 Solving showcase tasks 5.1 Manipulation of stacked non rigid objects Solving the showcase tasks introduced a number of technological issues. The blank pile is not a unique rigid solid object, as shown in Fig. 13. It is a stack of cardboards, that can bend under its own weight and can also be disrupted, since some blanks can break free from the pile, due to low friction between them. To prevent the breakdown of a pile, any manipulation procedure has to be aware of this fact. Blanks are provided in untied piles, piled up on pallets close to each other, which can cause erroneous detections. Blank piles have to be placed in a feeding mechanism avoiding hard collisions with blanks that can already be there and with the four blank guiding rods that prevent blanks from slipping out of the inclined magazine surface. This feeding task requires a high level of precision for a proper feeding, while preventing collisions between the blank magazine and the manipulator. The manipulation has to be performed using a single arm. Since the gripper provided by the host is not appropriate, a solution has to be revised, taking into account the aforementioned issues. Aside from the gripper design, a proper sequence of actions has to be planned to accomplish the showcase tasks. 5.2 Manipulator for packaging Regarding the gripper design, the TIMAIRIS team decided to used the gripper provided with the robotic arm and adapt it to the required manipulations. Two fingers were designed, able to grasp a pile of blanks with a maximum height of 80 mm. The closing force of 80N (or at least 50N) should be enough at least for manipulating the smaller piles. In order to grasp a pile, it should be partially dragged out of the table, as shown in Fig. 13. To do so, two thin shafts were attached to the fingers, as shown in Fig. 14(a) and Fig. 15(a). These thin shafts can slide along their own axes thanks to the presence of a spring, ensuring the existence of contact between the shafts and the interlayer and thus preventing the loss of any blank during the dragging of the pile. Warehouse or blank magazine is composed of a plate inclined by 55 ∘ and four aluminum legs that sustain the plate. The plate is ad hoc built for the industrial partner’s blanks or cardboards. On the plate, four thin rods are mounted that guide the blanks once the robot delivers the whole stack, as shown in Fig. 14(b) and Fig. 15(b). Moreover, a proximity sensor is added and connected to a led yellow light. The proximity sensor checks if the number of cardboards is below a given threshold, in which case the light is turned on, as shown in Fig. 15(b). 5.3 Showcase perception To accomplish the showcase tasks a number of perception activities must be implemented. The piles of blanks are put over two pallets, thus these pallets must be detected and located relative to the robot. The poses of the piles themselves must be precisely estimated, so the picking up could be well performed. Finally, the blank magazine must be detected and located in order to perform the feeding procedure. The detection of the pallets is done by processing the stereo images captured using the pan–tilt camera. It unfolds into three steps: first, voxel grid filtering [35] based on the height of the pallets is used to remove irrelevant points from the point cloud [36]; second, the filtered points are projected on a horizontal plane and clustering is applied to define candidate regions; finally, these regions are matched against a 3D template to find the poses of the pallets. The same approach is applied for a first rough estimation of the poses of the piles in the pallets, by using the average height of the piles and an appropriate template. Fig. 16 illustrates the detection of both pallets and piles. However, to reliably pick a blank pile up from a pallet, a robust pose estimation of piles is necessary. On the one hand, in real industry scenarios, the piles on a pallet are tightly-aligned and put close to each other. On the other hand, the patterns printed on the blanks, even for the same blank shape, are variable and can change with end users’ demands. Therefore, detection and pose estimation of blanks cannot rely on conventional approaches such as color segmentation or local feature matching such as SIFT [37]. The approximate piles’ poses estimated so far can be used to position the TCP camera, in order to obtain more reliable ones. The camera is positioned over a pile and an image is captured, as shown in Fig. 17(a). Then, a Canny edge detector is applied to that image, as shown in Fig. 17(b). The detected edges come from the blanks’ outline but also from the printed patterns on the top blank. A drawing pin filter which classifies each point with various number of neighbors is applied to detect the outline of a blank pile [26]. The kernel is defined as K D P = [ x i ] = p + h n , if x i is in the center h n , otherwise p > h × | [ x ] | , n = ∑ x i , where p and h are the values of pin and head, respectively. The p is larger than the sum of heads and n is the normalization factor of the kernel. In this work, a drawing pin kernel of size 5 × 5 with p = 50 and h = 1 is used, as shown in Fig. 18. The basic assumption is that the edges of outlines are straight lines and their points have few neighbors except those in the line, while the points in printed patterns have many neighbors. In the filtering algorithm, points with more than the kernel size are discarded, as shown in Fig. 17(c). Finally, to find the precise pose of the pile, it is matched against a template, starting from the roughly estimated pose in a spiral direction. Fig. 17(d) shows the result of the match. 5.4 Motion planing After grasping the blank pile, the arm is put in a transport pose. This pose is defined considering two requirements. In one side, the arm should be completely inside the robot footprint. This way, navigation to the blank magazine table will be much safer. In the other side, the arm pose should minimize the necessary motions to place the pile in the magazine. All of these manipulations have to be done while maintaining the blank pile in a pose that prevents it from breaking apart. In this challenge, motions have been generated in the simulator in advance and then the results are applied to the real robot. In order to achieve the best results specific filters had to be used to enhance and complete the trajectories that were derived from existing motion planners. Several different motion planners have also been tested and benchmarked for tasks of different complexities [38]. 5.5 Task planning The manipulation of the blank pile, aside from the gripper, also raises planning issues. The first relates to the order by which blank piles must be manipulated. Due to their dispositions in the pallet, certain blank piles are blocked by others and cannot be dragged before these are removed. Therefore, the order by which blank piles are manipulated has to be planned. The plan considers the blank piles available in all the pallets and gives preference to the pallet with the lowest number of blank piles, since an empty pallet can be replaced with a fully packed one. Fig. 19 shows a task plan with the sequence and dragging directions to pick up all blank piles on two pallets. The dragging itself is also a challenge. The gripper and the arm have to maintain pressure against the pallet while dragging the blank pile. Too much pressure and the pallet could move, not enough pressure and the pile can be disrupted. Therefore, the robotic arm has to be used in compliant mode and the pressure should be properly calculated. 5.6 Safe human–robot collaboration For small batch production, changing or adding new features, such as continuously changing printed patterns of blanks, can be a burden on both human operators and autonomous robots. Since industrial environments are noisy, where machines produce a continuous whirring sound, verbal communication is difficult for humans and impractical for robots. Thus, gestures have been considered as a practical alternative way of communication. Until now, gesture recognition systems in HRI have focused on small number of implicit interactions such as pointing and handing over. With respect to pointing, the target object must be in the field of view of both human and robot. Fig. 20 shows an example of human tracking and human–robot interaction during the EuRoC evaluation. When the robot detects an operator entering a region for safety handling, it stops the executing task and points the pan–tilt to the operator. To ask to fetch objects in a cluttered and unstructured environment, HRI systems need to have a rich vocabulary to designate an object [16]. Fig. 21 shows an interaction tree for the showcase task. That represents commands by sequentially encoding 8 gestures, which consist of 6 numbers 0 to 5 and thumb up/down. Gesture recognition module recognizes a one-hand gesture provided by the operator. Then HRI module tries to build a command with a sequence of gestures. Following the command, the robot continues or stops the paused task. 6 Challenge evaluation 6.1 Benchmark evaluation During the benchmark phase of the Stages II, all the Challenge 2 participants have been evaluated by developing same two tasks under the same conditions: the robot platform, EuRoC software architecture and working time. As the benchmark task 1, the robot has to pick up and place 5 SLCs into the target area to show the logistics capabilities with different payload from different location to a fixed place. The task has two metrics: a number of delivered SLCs regardless of whether parts are lost (metric 1) and a number of delivered SLCs without losing parts (metric 2). Table 1 shows the results, which are their best results out of three trials. The bonus is calculated as inverse proportion to the time difference from the best on that between the best and worst. As the benchmark task 2, the robot is required to screw nuts on 5 bolts placed in a fixed area on a table using a fixture. The task also has two metrics: a number of washers successfully put onto bolts (metric 1) and a number of bolts with a successfully screwed on nut (metric 2) Table 2 shows the results of the benchmark task 2. The bonus is calculated as same as that of the task 1 among the records of teams, who finish the assembly task. TIMAIRIS has completed the both tasks without failures in the shortest times. 6.2 Showcase evaluation TIMARIS’ showcase addresses all of these issues (and others) in the form of three challenges and two extra demos, with quantifiable metrics. The objectives and metrics are organized so that the highlights described above can be evaluated in a comprehensive and robust way. The first objective (O1) is focused on perception and includes 4 metrics: detecting the pose of blank piles, pallets and blank magazine (O1M1); recognizing the need for blank feeding (O1M2); identifying the number of piles in each pallet (O1M3); identifying the presence of humans in the vicinity of the robot (O1M4). The second objective is focused on manipulation and navigation and includes 4 metrics: correctly picking a blank pile (O2M1); transporting the piles to the blank magazine (O2M2); placing the blank piles in the blank magazine (O2M3); stopping manipulation and navigation if a human is close to the robot (O2M4). The third objective evaluates the planning capabilities and includes 2 metrics: providing a plan to pick the blank piles (O3M1); adapting navigation paths (O3M2). The last objective evaluates human robot interaction and includes 2 metrics: recognizing gesture commands provided by the human (O4M1); tracking a human for interaction (O4M2). The achieved metrics are presented in Table 3. TIMAIRIS completed the showcase with every objective and metric being accomplished as can be seen from Table 3 where targets is the number of trials in predefined task scenarios and events is the number of successes during the showcase evaluation. The metrics of O1M1 are composed of three metrics for detecting the pose of blank piles, pallets and blank magazine. In what regards Perception, Manipulation/Navigation and Planning, i.e. Objectives 1, 2 and 3 previously specified, all metrics have been achieved during the execution of the first part of the showcase evaluation that consisted of three challenges. Tracking humans with the pan–tilt camera, Metric 2 of Objective 4, was also achieved during this first part of the showcase evaluation. The gesture recognition was demonstrated during the first part of the showcase evaluation, where gesture commands have been used to start challenge execution. Safety has been demonstrated in manipulation and navigation several times. During the showcase, the gesture recognition, which includes automatic correction methods, has been presented independently and the results showed that it is very robust and adequate for this kind of interaction (see the linked video 6 6 ). The results obtained in the showcase phase provide an excellent base for the development of the pilot experiment. The pilot experiment environment is a real industrial setting but, as already referred, all the developments of showcase are directly applicable in this final environment. Some new features will have to be addressed that also depend on the speedup of the final prototype, such as considering several packaging machines and different types/shapes of blanks, enhanced safety and more challenging navigation issues. Still, the showcase results are a complete and very solid basis for the work that needs to be done in the pilot experiments. 7 Conclusion To enable the paradigm shift in the packaging industry, many developed technologies must be considered as the integration cannot be performed and only the complete set allows the execution of the task. The developed system has gradually evolved from the qualification stage in a limited time. During the Stage 2 of the EuRoC project, the proposed architecture has demonstrated the feasibility of practical use of for Shop Floor Logistics and Manipulation. It is believed that SAAA is efficient not only in autonomous execution for autonomous packaging tasks but also in its use of development during the competitive challenges and that the simple architecture and distributed skills make the system efficient. The results of benchmarking tasks in which TIMAIRIS took first place among 5 Stage 2 challenger teams was possible that our team just focused on improving individual skills to complete all tasks and to reduce running time. One of important development during the showcase is showing that autonomous blank feeding is possible in a realistic industrial environment. That is a pending task of the industry partner IMA S.p.A which is a world leading company in the design and manufacture of automatic machines for the processing and packaging. As the result of the Stage II evaluations, TIMAIRIS has been selected to advance to the final stage of the EuRoC project. Some new features will have to be addressed that also depend on the speedup of the final prototype to complete the pilot experiments. Still, the results of the Stage II are a complete and very solid basis for the work that needs to be done in the final stage of the EuRoC project. Declaration of Competing Interest The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper. Acknowledgments This work was supported by the EuRoC Project under Grant no. 608849 and by National Funds through the FCT - Foundation for Science and Technology , in the context of the project UID/CEC/00127/2013. References [1] Pratt G. Manzo J. The DARPA robotics challenge [competitions] IEEE Robot. Autom. Mag. 20 2 2013 10 12 G. Pratt, J. Manzo, The DARPA robotics challenge [competitions], IEEE Robotics & Automation Magazine 20 (2) (2013) 10–12 [2] Kitano H. Asada M. Kuniyoshi Y. Noda I. Osawa E. Robocup: the robot world cup initiative Proceedings of the First International Conference on Autonomous Agents 1997 ACM 340 347 H. Kitano, M. Asada, Y. Kuniyoshi, I. Noda, E. Osawa, Robocup: The robot world cup initiative, in: Proceedings of the first international conference on Autonomous agents, ACM, 1997, pp. 340–347 [3] Siciliano B. Caccavale F. Zwicker E. Achtelik M. Mansard N. Borst C. Achtelik M. Jepsen N.O. Awad R. Bischoff R. EuRoC-The challenge initiative for european robotics ISR/Robotik 2014; 41st International Symposium on Robotics; Proceedings of 2014 VDE 1 7 B. Siciliano, F. Caccavale, E. Zwicker, M. Achtelik, N. Mansard, C. Borst, M. Achtelik, N. O. Jepsen, R. Awad, R. Bischoff, EuRoC-the challenge initiative for european robotics, in: ISR/Robotik 2014 41st International Symposium on Robotics; Proceedings of, VDE, 2014, pp. 1–7 [4] Bischoff R. Guhl T. The strategic research agenda for robotics in europe [industrial activities] IEEE Robot. Autom. Mag. 1 17 2010 15 16 R. Bischoff, T. Guhl, The strategic research agenda for robotics in europe [industrial activities], IEEE Robotics & Automation Magazine 1 (17) (2010) 15–16 [5] Cully A. Clune J. Tarapore D. Mouret J.-B. Robots that can adapt like animals Nature 521 7553 2015 503 A. Cully, J. Clune, D. Tarapore, J.-B. Mouret, Robots that can adapt like animals, Nature 521 (7553) (2015) 503 [6] Hildebrandt A.-C. Schuetz C. Wahrmann D. Wittmann R. Rixen D. A flexible robotic framework for autonomous manufacturing processes: report from the european robotics challenge stage 1 Autonomous Robot Systems and Competitions (ICARSC), 2016 International Conference on 2016 IEEE 21 27 A.-C. Hildebrandt, C. Schuetz, D. Wahrmann, R. Wittmann, D. Rixen, A flexible robotic framework for autonomous manufacturing processes: Report from the European Robotics Challenge Stage 1, in: Autonomous Robot Systems and Competitions (ICARSC), 2016 International Conference on, IEEE, 2016, pp. 21–27 [7] Zadeh S.M. Powers D.M. Sammut K. An autonomous reactive architecture for efficient AUV mission time management in realistic dynamic ocean environment Robot. Auton. Syst. 87 2017 81 103 S. M. Zadeh, D. M. Powers, K. Sammut, An autonomous reactive architecture for efficient auv mission time management in realistic dynamic ocean environment, Robotics and Autonomous Systems 87 (2017) 81–103 [8] Baklouti E. Amor N.B. Jallouli M. Reactive control architecture for mobile robot autonomous navigation Robot. Auton. Syst. 89 2017 9 14 E. Baklouti, N. B. Amor, M. Jallouli, Reactive control architecture for mobile robot autonomous navigation, Robotics and Autonomous Systems 89 (2017) 9–14 [9] Nilsson K. Johansson R. Integrated architecture for industrial robot programming and control Robot. Auton. Syst. 29 4 1999 205 226 K. Nilsson, R. Johansson, Integrated architecture for industrial robot programming and control, Robotics and Autonomous Systems 29 (4) (1999) 205–226 [10] Chatzilygeroudis K. Vassiliades V. Mouret J.-B. Reset-free trial-and-error learning for robot damage recovery Robot. Auton. Syst. 100 2018 236 250 K. Chatzilygeroudis, V. Vassiliades, J.-B. Mouret, Reset-free trial-and-error learning for robot damage recovery, Robotics and Autonomous Systems 100 (2018) 236–250 [11] Insaurralde C.C. Petillot Y.R. Capability-oriented robot architecture for maritime autonomy Robot. Auton. Syst. 67 2015 87 104 C. C. Insaurralde, Y. R. Petillot, Capability-oriented robot architecture for maritime autonomy, Robotics and Autonomous Systems 67 (2015) 87–104 [12] Dean T.L. Boddy M.S. An analysis of time-dependent planning. AAAI, vol. 88 1988 49 54 T. L. Dean, M. S. Boddy, An analysis of time-dependent planning., in: AAAI, Vol. 88, 1988, pp. 49–54 [13] Grefenstette J.J. Ramsey C.L. An approach to anytime learning Machine Learning Proceedings 1992 1992 Elsevier 189 195 J. J. Grefenstette, C. L. Ramsey, An approach to anytime learning, in: Machine Learning Proceedings 1992, Elsevier, 1992, pp. 189–195 [14] Pedrosa E. Lau N. Pereira A. Cunha B. A skill-based architecture for pick and place manipulation tasks Progress in Artificial Intelligence: 17th Portuguese Conference on Artificial Intelligence, EPIA 2015 2015 Springer 457 468 E. Pedrosa, N. Lau, A. Pereira, B. Cunha, A skill-based architecture for pick and place manipulation tasks, in: Progress in Artificial Intelligence: 17th Portuguese Conference on Artificial Intelligence, EPIA 2015, Springer, 2015, pp. 457–468 [15] Amaral F. Pedrosa E. Lim G.H. Shafii N. Pereira A. Azevedo J.L. Cunha B. Reis L.P. Badini S. Lau N. Skill-based anytime agent architecture for logistics and manipulation tasks: EuRoC challenge 2, stage II-realistic labs: benchmarking Autonomous Robot Systems and Competitions (ICARSC), 2017 IEEE International Conference on 2017 IEEE 198 203 F. Amaral, E. Pedrosa, G. H. Lim, N. Shafii, A. Pereira, J. L. Azevedo, B. Cunha, L. P. Reis, S. Badini, N. Lau, Skill-based anytime agent architecture for logistics and manipulation tasks: EuRoC Challenge 2, Stage II-Realistic Labs: Benchmarking, in: Autonomous Robot Systems and Competitions (ICARSC), 2017 IEEE International Conference on, IEEE, 2017, pp. 198–203 [16] Lim G.H. Pedrosa E. Amaral F. Lau N. Pereira A. Dias P. Azevedo J.L. Cunha B. Reis L.P. Rich and robust human-robot interaction on gesture recognition for assembly tasks Autonomous Robot Systems and Competitions (ICARSC), 2017 IEEE International Conference on 2017 IEEE 159 164 G. H. Lim, E. Pedrosa, F. Amaral, N. Lau, A. Pereira, P. Dias, J. L. Azevedo, B. Cunha, L. P. Reis, Rich and robust human-robot interaction on gesture recognition for assembly tasks, in: Autonomous Robot Systems and Competitions (ICARSC), 2017 IEEE International Conference on, IEEE, 2017, pp. 159–164 [17] Lim G.H. Pedrosa E. Amaral F. Dias R. Pereira A. Lau N. Azevedo J.L. Cunha B. Reis L.P. Human-robot collaboration and safety management for logistics and manipulation tasks Iberian Robotics Conference 2017 Springer 15 27 G. H. Lim, E. Pedrosa, F. Amaral, R. Dias, A. Pereira, N. Lau, J. L. Azevedo, B. Cunha, L. P. Reis, Human-robot collaboration and safety management for logistics and manipulation tasks, in: Iberian Robotics conference, Springer, 2017, pp. 15–27 [18] Mokhtari V. Lim G.H. Lopes L.S. Pinho A.J. Gathering and conceptualizing plan-based robot activity experiences Intelligent Autonomous Systems 13 2016 Springer 993 1005 V. Mokhtari, G. H. Lim, L. S. Lopes, A. J. Pinho, Gathering and conceptualizing plan-based robot activity experiences, in: Intelligent Autonomous Systems 13, Springer, 2016, pp. 993–1005 [19] Lim G.H. Shared representations of actions for alternative suggestion with incomplete information Robot. Auton. Syst. 2019 G. H. Lim, Shared representations of actions for alternative suggestion with incomplete information, Robotics and Autonomous Systems. [20] Balogh R. I am a robot–competitor: a survey of robotic competitions Int. J. Adv. Robot. Syst. 2 2005 17 R. Balogh, I am a robot–competitor: A survey of robotic competitions, International Journal of Advanced Robotic Systems 2 (2005) 17 [21] Thrun S. Montemerlo M. Dahlkamp H. Stavens D. Aron A. Diebel J. Fong P. Gale J. Halpenny M. Hoffmann G. Stanley: the robot that won the DARPA grand challenge J. Field Robot. 23 9 2006 661 692 S. Thrun, M. Montemerlo, H. Dahlkamp, D. Stavens, A. Aron, J. Diebel, P. Fong, J. Gale, M. Halpenny, G. Hoffmann, et al., Stanley: The robot that won the darpa grand challenge, Journal of field Robotics 23 (9) (2006) 661–692 [22] Buehler M. Iagnemma K. Singh S. The DARPA Urban Challenge: Autonomous Vehicles in City Traffic, vol. 56 2009 Springer M. Buehler, K. Iagnemma, S. Singh, The DARPA urban challenge: autonomous vehicles in city traffic, Vol. 56, springer, 2009 [23] A. Dömel, S. Kriegel, M. Brucker, M. Suppa, Autonomous pick and place operations in industrial production, in: Ubiquitous Robots and Ambient Intelligence (URAI), 2015 12th International Conference on, 2015, pp. 356–356, [24] Lim G.H. Pedrosa E. Amaral F. Lau N. Pereira A. Azevedo J.L. Cunha B. Neural regularization jointly involving neurons and connections for robust image classification 2017 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems (MFI) 2017 IEEE 336 341 G. H. Lim, E. Pedrosa, F. Amaral, N. Lau, A. Pereira, J. L. Azevedo, B. Cunha, Neural regularization jointly involving neurons and connections for robust image classification, in: 2017 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems (MFI), IEEE, 2017, pp. 336–341 [25] Russell S. Norvig P. Artificial Intelligence: A Modern Approach third ed. 2010 Prentice Hall S. Russell, P. Norvig, Artificial Intelligence: A Modern Approach, 3rd Edition, Prentice Hall, 2010 [26] Lim G.H. Pedrosa E. Amaral F. Lau N. Pereira A. Azevedo J.L. Cunha B. Badini S. Mobile manipulation for autonomous packaging in realistic environments: euroc challenge 2, stage ii, showcase 2018 IEEE International Conference on Autonomous Robot Systems and Competitions (ICARSC) 2018 IEEE 231 236 G. H. Lim, E. Pedrosa, F. Amaral, N. Lau, A. Pereira, J. L. Azevedo, B. Cunha, S. Badini, Mobile manipulation for autonomous packaging in realistic environments: Euroc challenge 2, stage ii, showcase, in: 2018 IEEE International Conference on Autonomous Robot Systems and Competitions (ICARSC), IEEE, 2018, pp. 231–236 [27] Lim G.H. Lau N. Pedrosa E. Amaral F. Pereira A. Luís Azevedo J. Cunha B. Precise and efficient pose estimation of stacked objects for mobile manipulation in industrial robotics challenges Adv. Robot. 2019 1 11 G. H. Lim, N. Lau, E. Pedrosa, F. Amaral, A. Pereira, J. Luís Azevedo, B. Cunha, Precise and efficient pose estimation of stacked objects for mobile manipulation in industrial robotics challenges, Advanced Robotics (2019) 1–11 [28] Lim G.H. Yi C. Suh I.H. Ko D.W. Hong S.W. Ontology representation and instantiation for semantic map building by a mobile robot Intelligent Autonomous Systems, vol. 12 2013 Springer 387 395 G. H. Lim, C. Yi, I. H. Suh, D. W. Ko, S. W. Hong, Ontology representation and instantiation for semantic map building by a mobile robot, in: Intelligent Autonomous Systems 12, Springer, 2013, pp. 387–395 [29] G.H. Lim, M. Oliveira, S.H. Kasaei, L.S. Lopes, Hierarchical nearest neighbor graphs for building perceptual hierarchies, in: 22nd International Conference on Neural Information Processing, ICONIP2015, 2015. [30] Lim G.H. Suh I.H. Suh H. Ontology-based unified robot knowledge for service robots in indoor environments IEEE Trans. Syst., Man, Cybern. A 41 3 2011 492 509 10.1109/TSMCA.2010.2076404 G. H. Lim, I. H. Suh, H. Suh, Ontology-based unified robot knowledge for service robots in indoor environments, Systems, Man and Cybernetics, Part A: Systems and Humans, IEEE Transactions on 41 (3) (2011) 492 –509 doi:101109/TSMCA.20102076404 [31] Rusu R. Marton Z. Blodow N. Dolha M. Towards 3D point cloud based object maps for household environments Robot. Auton. Syst. 56 11 2008 927 941 R. B. Rusu, Z. C. Marton, N. Blodow, M. Dolha, Towards 3D point cloud based object maps for household environments, Robotics and Autonomous Systems 56 (11) (2008) 927–941 [32] Rusu R.B. Semantic 3D object maps for everyday manipulation in human living environments (Ph.D. thesis) 2009 Computer Science department, Technische Universitaet Muenchen, Germany R. B. Rusu, Semantic 3D Object Maps for Everyday Manipulation in Human Living Environments, Ph.D. thesis, Computer Science department, Technische Universitaet Muenchen, Germany (October 2009) [33] Oliveira M. Lopes L.S. Lim G.H. Kasaei S.H. Tomé A.M. Chauhan A. 3D object perception and perceptual learning in the RACE project Robot. Auton. Syst. 75 2016 614 626 M. Oliveira, L. S. Lopes, G. H. Lim, S. H. Kasaei, A. M. Tomé, A. Chauhan, 3d object perception and perceptual learning in the race project, Robotics and Autonomous Systems 75 (2016) 614–626 [34] Pedrosa E. Pereira A. Lau N. A scan matching approach to slam with a dynamic likelihood field 2016 International Conference on Autonomous Robot Systems and Competitions, ICARSC 2016 IEEE Portugal, Bragança 35 40 10.1109/ICARSC.2016.23 E. Pedrosa, A. Pereira, N. Lau, A Scan Matching Approach to SLAM with a Dynamic Likelihood Field, in: 2016 International Conference on Autonomous Robot Systems and Competitions (ICARSC), IEEE, Portugal, Bragança, 2016, pp. 35–40 doi:101109/ICARSC.201623 [35] Cohen-Or D. Kaufman A. Fundamentals of surface voxelization Graph. Models Image Process. 57 6 1995 453 461 D. Cohen-Or, A. Kaufman, Fundamentals of surface voxelization, Graphical models and image processing 57 (6) (1995) 453–461 [36] Rusu R.B. Cousins S. 3D is here: point cloud library (PCL) Robotics and Automation (ICRA), 2011 IEEE International Conference on 2011 IEEE 1 4 R. B. Rusu, S. Cousins, 3D is here: Point cloud library (PCL), in: Robotics and Automation (ICRA), 2011 IEEE International Conference on, IEEE, 2011, pp. 1–4 [37] Lowe D.G. Object recognition from local scale-invariant features Computer Vision, 1999. The Proceedings of the Seventh IEEE International Conference on, vol. 2 1999 Ieee 1150 1157 D. G. Lowe, Object recognition from local scale-invariant features, in: Computer vision, 1999 The proceedings of the seventh IEEE international conference on, Vol. 2, Ieee, 1999, pp. 1150–1157 [38] Tudico A. Lau N. Pedrosa E. Amaral F. Mazzotti C. Carricato M. Improving and benchmarking motion planning for a mobile manipulator operating in unstructured environments Portuguese Conference on Artificial Intelligence 2017 Springer 498 509 A. Tudico, N. Lau, E. Pedrosa, F. Amaral, C. Mazzotti, M. Carricato, Improving and benchmarking motion planning for a mobile manipulator operating in unstructured environments, in: Portuguese Conference on Artificial Intelligence, Springer, 2017, pp. 498–509 Dr. Gi Hyun Lim received the B.S. degree in metallurgical engineering and the M.S. and Ph.D. degrees in electronics and computer engineering from Hanyang University, Seoul, Korea, in 1997, 2007 and 2010, respectively. He is currently a Marie Curie individual fellow in the School of Computer Science at University of Manchester, UK. His research interests lie in the area of artificial intelligence and machine learning for autonomous robots, including perception, semantics, cognition and spatiotemporal representations on neuromorphic architectures. Eurico Pedrosa is a Post-Doc Researcher at the Institute of Electronics and Informatics Engineering of Aveiro (IEETA) integrated in Intelligent Robotics and Systems group (IRIS). He got his Informatics Engineering degree from University of Aveiro in 2010 and a Computer Science Ph.D. degree from Aveiro University in 2018. His research interest are focused on intelligent robotics, robotic navigation including localization and mapping (SLAM), space representation using volumetric grids and most recently the application of radar sensors in indoor robotics. Filipe Amaral is a Research Fellow at the Institute of Electronics and Informatics Engineering of Aveiro (IEETA) integrated in Intelligent Robotics and Systems group (IRIS). He got his MSc degree in Computer and Telematics Engineering from University of Aveiro in 2014. His current research interests are in the area of autonomous mobile robotics. Prof. Dr. Artur Pereira was born in Vila Nova de Famalicão, Portugal, in April 1960. He received the Ph.D. degree in Electrical Engineering from the University of Aveiro, Portugal, in 2003. He is currently an Assistant Professor at the Department of Electronics, Telecommunications and Informatics of the University of Aveiro and a researcher at the Intelligent Robotics and Systems group (IRIS Lab) of the Instituto de Engenharia Electrónica e Informática de Aveiro. The main focus of his research is robotics at the architectural and software levels, with emphasis on simulation, navigation, localization, mapping, and machine learning. Nuno Lau is Assistant Professor at Aveiro University, Portugal and Researcher at the Institute of Electronics and Informatics Engineering of Aveiro (IEETA), where he leads the Intelligent Robotics and Systems group (IRIS). He got is Electrical Engineering Degree from Oporto University in 1993, a DEA degree in Biomedical Engineering from Claude Bernard University, France, in 1994 and the Ph.D. from Aveiro University in 2003. His research interests are focused on Intelligent Robotics, Artificial Intelligence, Multi-Agent Systems and Simulation. Nuno Lau participated in more than 15 international and national research projects, having the tasks of general or local coordinator in about half of them. Nuno Lau won more than 50 scientific awards in robotic competitions, conferences (best papers) and education. He has lectured courses at Phd and MSc levels on Intelligent Robotics, Distributed Artificial Intelligence, Computer Architecture, Programming, etc. Nuno Lau is the author of more than 150 publications in international conferences and journals. He was President of the Portuguese Robotics Society from 2015 to 2017, and is currently the Vice-President of this Society. Prof. Dr. José Luís Azevedo is currently Assistant Professor at the Department of Electronics, Telecommunications and Informatics of the University of Aveiro and a researcher at the Intelligent Robotics and Systems group (IRIS Lab) of the Institute of Electronics and Informatics Engineering of Aveiro (IEETA). He received the Ph.D. degree in Electrical Engineering from the University of Aveiro, Portugal, in 1998. His current research interests are in the area of cooperative autonomous mobile robotics. Prof. Dr. Bernardo Cunha was born in 1959 in Porto, Portugal. He earned his doctoral degree in electrical engineering at the University of Aveiro, Portugal, in 1999. He is a full time teacher at Universidade de Aveiro in the computer architecture area and an investigator at the Instituto de Engenharia Electrónica e Informática de Aveiro. Current research interests are centered in the area of cooperative autonomous mobile robotics. Simone Badini is a Mechanical Designer in the Research and Development department of IMA Spa since 2013. IMA Spa is a world leader company in the design and manufacture of automatic machines for the processing and packaging of pharmaceuticals, cosmetics, food, tea and coffee and tobacco. He got is M.Sc. degree in Mechanical Engineering from University of Bologna, Italy in 2012. He is currently project manager for the integration of cobot and autonomous mobile robot in the production lines for the IMA group. "
    },
    {
        "doc_title": "Precise and efficient pose estimation of stacked objects for mobile manipulation in industrial robotics challenges",
        "doc_scopus_id": "85066896804",
        "doc_doi": "10.1080/01691864.2019.1617780",
        "doc_eid": "2-s2.0-85066896804",
        "doc_date": "2019-07-03",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Control and Systems Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2207"
            },
            {
                "area_name": "Software",
                "area_abbreviation": "COMP",
                "area_code": "1712"
            },
            {
                "area_name": "Human-Computer Interaction",
                "area_abbreviation": "COMP",
                "area_code": "1709"
            },
            {
                "area_name": "Hardware and Architecture",
                "area_abbreviation": "COMP",
                "area_code": "1708"
            },
            {
                "area_name": "Computer Science Applications",
                "area_abbreviation": "COMP",
                "area_code": "1706"
            }
        ],
        "doc_keywords": [
            "Industrial environments",
            "Industrial robotics",
            "Mobile manipulation",
            "Mobile manipulator",
            "Object manipulation",
            "Perception systems",
            "Pose estimation",
            "stacked objects"
        ],
        "doc_abstract": "© 2019, © 2019 Informa UK Limited, trading as Taylor & Francis Group and The Robotics Society of Japan.Object manipulation tasks such as picking up, carrying and placing should be executed based on the information of objects which are provided by the perception system. A precise and efficient pose estimation system has been developed to address the requirements and to achieve the objectives for autonomous packaging, specifically picking up of stacked non-rigid objects. For fine pose estimation, a drawing pin shaped kernel and pinhole filtering methods are used on the roughly estimated pose of objects. The system has been applied in a realistic industrial environment as a challenging scenario for the Challenge 2–Shop Floor Logistics and Manipulation on a mobile manipulator in the context of the European Robotics Challenges (EuRoC) project.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Multi-Agent Deep Reinforcement Learning with Emergent Communication",
        "doc_scopus_id": "85073257514",
        "doc_doi": "10.1109/IJCNN.2019.8852293",
        "doc_eid": "2-s2.0-85073257514",
        "doc_date": "2019-07-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Software",
                "area_abbreviation": "COMP",
                "area_code": "1712"
            },
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            }
        ],
        "doc_keywords": [
            "Action policies",
            "Credit assignment",
            "High level policies",
            "Non-stationary environment",
            "Partial observability",
            "Partially observable environments",
            "Single-agent",
            "State-of-the-art algorithms"
        ],
        "doc_abstract": "© 2019 IEEE.When compared with their single-agent counterpart, multi-agent systems have an additional set of challenges for reinforcement learning algorithms, including increased complexity, non-stationary environments, credit assignment, partial observability, and achieving coordination. Deep reinforcement learning has been shown to achieve successful policies through implicit coordination, but does not handle partial-observability. This paper describes a deep reinforcement learning algorithm, based on multi-agent actor-critic, that simultaneously learns action policies for each agent, and communication protocols that compensate for partial-observability and help enforce coordination. We also research the effects of noisy communication, where messages can be late, lost, noisy, or jumbled, and how that affects the learned policies. We show how agents are able to learn both high-level policies and complex communication protocols for several different partially-observable environments. We also show how our proposal outperforms other state-of-the-art algorithms that don't take advantage of communication, even with noisy communication channels.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Learning low level skills from scratch for humanoid robot soccer using deep reinforcement learning",
        "doc_scopus_id": "85068483860",
        "doc_doi": "10.1109/ICARSC.2019.8733632",
        "doc_eid": "2-s2.0-85068483860",
        "doc_date": "2019-04-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Mechanical Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2210"
            },
            {
                "area_name": "Control and Optimization",
                "area_abbreviation": "MATH",
                "area_code": "2606"
            },
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            }
        ],
        "doc_keywords": [
            "dribbling",
            "humanoid",
            "running",
            "simulation",
            "soccer"
        ],
        "doc_abstract": "© 2019 IEEE.Reinforcement learning algorithms are now more appealing than ever. Recent approaches bring power and tuning simplicity to the everyday work machine. The possibilities are endless, and the idea of automating learning without domain knowledge is quite tempting for many researchers. However, in competitive environments such as the RoboCup 3D Soccer Simulation League, there is a lot to be done regarding humanlike behaviors. Current teams use many mechanical movements to perform basic skills, such as running and dribbling the ball. This paper aims to use the PPO algorithm to optimize those skills, achieving natural gaits without sacrificing performance. We use Simspark to simulate a NAO humanoid robot, using visual and body sensors to control its actuators. Based on our results, we propose an indirect control approach and detailed parameter setups to obtain natural running and dribbling behaviors. The obtained performance is in some cases comparable or better than the top RoboCup teams. However, some skills are not ready to be applied in competitive environments yet, due to instability. This work contributes towards the improvement of RoboCup and some related technical challenges.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "A Model-Based Biped Walking Controller Based on Divergent Component of Motion",
        "doc_scopus_id": "85068445147",
        "doc_doi": "10.1109/ICARSC.2019.8733608",
        "doc_eid": "2-s2.0-85068445147",
        "doc_date": "2019-04-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Mechanical Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2210"
            },
            {
                "area_name": "Control and Optimization",
                "area_abbreviation": "MATH",
                "area_code": "2606"
            },
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            }
        ],
        "doc_keywords": [
            "Humanoid walking",
            "Inverted pendulum",
            "Optimal controller",
            "Optimal controls",
            "Push recoveries",
            "Reference trajectories",
            "Robotic community",
            "Unstable dynamics"
        ],
        "doc_abstract": "© 2019 IEEE.Biped robots have high degrees of freedom and they are naturally unstable, hence design and develop a reliable walking controller is a complex subject which is one of the interesting topics in the robotic community. In this paper, we proposed a model-based walking controller which is able to negate the effect of external impacts not only by applying compensating torques but also by adjusting the landing location of swing leg. This controller is composed of two levels of control which takes into account the stable and unstable dynamics parts of center of mass (COM). In the proposed controller, the overall dynamics of a humanoid robot is approximated using an enhanced version of Linear Inverted Pendulum Plus Flywheel Model (ELIPPFM) and, according to this dynamics model, an optimal controller is designed to track the reference trajectories. Moreover, Divergent Component of Motion (DCM) is used to define when and where a robot should take a step to prevent falling. The proposed controller has been successfully tested by performing several simulations using MATLAB. The results showed that the proposed controller is capable of controlling the balance of a simulated robot in presence of severe disturbances.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "A Non-Linear Least Squares Approach to SLAM using a Dynamic Likelihood Field",
        "doc_scopus_id": "85039043621",
        "doc_doi": "10.1007/s10846-017-0763-7",
        "doc_eid": "2-s2.0-85039043621",
        "doc_date": "2019-03-15",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Software",
                "area_abbreviation": "COMP",
                "area_code": "1712"
            },
            {
                "area_name": "Control and Systems Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2207"
            },
            {
                "area_name": "Mechanical Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2210"
            },
            {
                "area_name": "Industrial and Manufacturing Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2209"
            },
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            },
            {
                "area_name": "Electrical and Electronic Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2208"
            }
        ],
        "doc_keywords": [
            "Least-squares optimization",
            "Levenberg- Marquardt methods",
            "Likelihood field",
            "Low computational complexity",
            "Non-linear least squares",
            "Nonlinear least squares problems",
            "Scan matching",
            "SLAM"
        ],
        "doc_abstract": "© 2017, Springer Science+Business Media B.V., part of Springer Nature.This paper presents a fast scan matching approach to online SLAM supported by a dynamic likelihood field. The dynamic likelihood field plays a central role in the approach: it avoids the necessity to establish direct correspondences; it is the connection link between scan matching and the online SLAM; and it has a low computational complexity. Scan matching is formulated as a non-linear least squares problem that allows us to solve it using Gauss-Newton or Levenberg-Marquardt methods. Furthermore, to reduce the influence of outliers during optimization, a loss function is introduced. The proposed solution was evaluated using an objective benchmark designed to compare different SLAM solutions. Additionally, the execution times of our proposal were also analyzed. The obtained results show that the proposed approach provides a fast and accurate online SLAM, suitable for real-time operation.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "A Fast and Stable Omnidirectional Walking Engine for the Nao Humanoid Robot",
        "doc_scopus_id": "85076917465",
        "doc_doi": "10.1007/978-3-030-35699-6_8",
        "doc_eid": "2-s2.0-85076917465",
        "doc_date": "2019-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Desired trajectories",
            "Humanoid robot",
            "Inverted pendulum model",
            "Linear quadratic Gaussian",
            "Linear Quadratic Gaussian controllers",
            "Low-level controllers",
            "Omni-directional walkings",
            "Optimization algorithms"
        ],
        "doc_abstract": "© 2019, Springer Nature Switzerland AG.This paper proposes a framework designed to generate a closed-loop walking engine for a humanoid robot. In particular, the core of this framework is an abstract dynamics model which is composed of two masses that represent the lower and the upper body of a humanoid robot. Moreover, according to the proposed dynamics model, the low-level controller is formulated as a Linear-Quadratic-Gaussian (LQG) controller that is able to robustly track the desired trajectories. Besides, this framework is fully parametric which allows using an optimization algorithm to find the optimum parameters. To examine the performance of the proposed framework, a set of simulation using a simulated Nao robot in the RoboCup 3D simulation environment has been carried out. Simulation results show that the proposed framework is capable of providing fast and reliable omnidirectional walking. After optimizing the parameters using genetic algorithm (GA), the maximum forward walking velocity that we have achieved was 80.5 cm/s.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Learning to Run Faster in a Humanoid Robot Soccer Environment Through Reinforcement Learning",
        "doc_scopus_id": "85076895279",
        "doc_doi": "10.1007/978-3-030-35699-6_1",
        "doc_eid": "2-s2.0-85076895279",
        "doc_date": "2019-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Humanoid",
            "Humanoid robot",
            "Policy optimization",
            "Reinforcement learning techniques",
            "Robotic soccer",
            "Running",
            "Soccer",
            "Soccer simulation"
        ],
        "doc_abstract": "© 2019, Springer Nature Switzerland AG.Reinforcement learning techniques bring a new perspective to enduring problems. Developing skills from scratch is not only appealing due to the artificial creation of knowledge. It can also replace years of work and refinement in a matter of hours. From all the developed skills in the RoboCup 3D Soccer Simulation League, running is still considerably relevant to determine the winner of any match. However, current approaches do not make full use of the robotic soccer agents’ potential. To narrow this gap, we propose a way of leveraging the Proximal Policy Optimization using the information provided by the simulator for official RoboCup matches. To do this, our algorithm uses a mix of raw, computed and internally generated data. The final result is a sprinting and a stopping behavior that work in tandem to bring the agent from point a to point b in a very short time. The sprinting speed stabilizes at around 2.5 m/s, which is a great improvement over current solutions. Both the sprinting and stopping behaviors are remarkably stable.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Multi-Robot Fast-Paced Coordination with Leader Election",
        "doc_scopus_id": "85070697946",
        "doc_doi": "10.1007/978-3-030-27544-0_2",
        "doc_eid": "2-s2.0-85070697946",
        "doc_date": "2019-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Global objective",
            "Leader election",
            "Multi-agent coordinations",
            "Multi-robot systems",
            "Real time constraints",
            "Soccer-playing robots",
            "Stochastic environment",
            "Task assignment"
        ],
        "doc_abstract": "© Springer Nature Switzerland AG 2019.Coordination in Multi-Robot Systems is an active research line in Artificial Intelligence applied to Robotics. Through coordination, a team of robots can efficiently achieve their pre-defined global objective. From a wide range of multi-agent coordination sub-topics, one of the current open issues is task assignment and role selection in fast-paced environments. In homogeneous teams, where robots have the ability to dynamically change roles, working in highly dynamic and stochastic environments, it is important that any solution is able to perform and achieve results while complying with realtime constraints. In this paper, we balance the advantages and disadvantages of completely decentralised solutions and centralised ones, and then present our solution for leader election among a team, which is based on the Raft algorithm and tackles two of its limitations. The proposed solution was implemented in a real team of soccer-playing robots and the experimental results are thoroughly presented and discussed.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Adjusted Bounded Weighted Policy Learner",
        "doc_scopus_id": "85070685364",
        "doc_doi": "10.1007/978-3-030-27544-0_27",
        "doc_eid": "2-s2.0-85070685364",
        "doc_date": "2019-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Equilibrium policy",
            "Game-theoretic",
            "Multi-agent reinforcement learning",
            "Nash equilibria",
            "State-of-the-art algorithms"
        ],
        "doc_abstract": "© Springer Nature Switzerland AG 2019.The Weighted Policy Learner (WPL) algorithm has been shown to converge to Nash Equilibria (NE) in several challenging environments with minimum knowledge. However, WPL has trouble converging to deterministic strategies, since the policy update rate approaches zero. We propose a new update rule that bounds this update rate such that, in pure NE games, the algorithmâ€™s speed is not slowed down, while its behavior in stochastic NE games remains unchanged. We demonstrate our proposalâ€™s behavior in several common game-theoretic environments (with stochastic and deterministic equilibrium policies), in complex maze-related games (where some actions dominate others in most states), against the original WPL as well as other state of the art algorithms. We draw conclusions over the benefits of our solution and its advantages.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Player engagement enhancement with video games",
        "doc_scopus_id": "85065095671",
        "doc_doi": "10.1007/978-3-030-16184-2_26",
        "doc_eid": "2-s2.0-85065095671",
        "doc_date": "2019-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Control and Systems Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2207"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Design process",
            "Development costs",
            "Entertainment industry",
            "Multiplayer games",
            "New approaches",
            "Procedural content generations",
            "Research efforts",
            "Research fields"
        ],
        "doc_abstract": "© Springer Nature Switzerland AG 2019.This work aims to present and summarize the identified main research fields about player engagement enhancement with video games. The expansion of video game diversity, complexity and applicability increased development costs. New approaches aim to automatize the design process by developing algorithms that can understand players requirements and redesign games on the fly. Multiplayer games have the added benefit of socially engage all involved parties through game-play. But balancing becomes more important as feeling overwhelmed by a stronger opponent may be demotivating, as feeling underwhelmed by a weaker adversary that cannot provide enough challenge and stimulation. Our research concludes that there is still lack of research effort in the identified fields. This may be due to the lack of academy incentive on the subject. The entertainment industry depends on game quality to increase their revenue, but lack interest on sharing their knowledge. We identify potential application on Serious Games.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Automatic generation of a sub-optimal agent population with learning",
        "doc_scopus_id": "85065080073",
        "doc_doi": "10.1007/978-3-030-16184-2_7",
        "doc_eid": "2-s2.0-85065080073",
        "doc_date": "2019-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Control and Systems Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2207"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Automatic Generation",
            "General method",
            "Learning in games",
            "Machine learning agents",
            "Multiplayer games",
            "Optimal strategies",
            "Simple environments",
            "Training data"
        ],
        "doc_abstract": "© Springer Nature Switzerland AG 2019.Most modern solutions for video game balancing are directed towards specific games. We are currently researching general methods for automatic multiplayer game balancing. The problem is modeled as a meta-game, where game-play change the rules from another game. This way, a Machine Learning agent that learns to play a meta-game, learns how to change a base game following some balancing metric. But an issue resides in the generation of high volume of game-play training data, was agents of different skill compete against each other. For this end we propose the automatic generation of a population of surrogate agents by learning sampling. In Reinforcement Learning an agent learns in a trial error fashion where it improves gradually its policy, the mapping from world state to action to perform. This means that in each successful evolutionary step an agent follows a sub-optimal strategy, or eventually the optimal strategy. We store the agent policy at the end of each training episode. The process is evaluated in simple environments with distinct properties. Quality of the generated population is evaluated by the diversity of the difficulty the agents have in solving their tasks.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Multi-agent neural reinforcement-learning system with communication",
        "doc_scopus_id": "85065079756",
        "doc_doi": "10.1007/978-3-030-16184-2_1",
        "doc_eid": "2-s2.0-85065079756",
        "doc_date": "2019-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Control and Systems Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2207"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Actor-critic algorithm",
            "Complex environments",
            "Function approximators",
            "Information sharing",
            "Learning models",
            "Multi-agent environment",
            "Non-stationarities",
            "Value functions"
        ],
        "doc_abstract": "© Springer Nature Switzerland AG 2019.Deep learning models have as of late risen as popular function approximators for single-agent reinforcement learning challenges, by accurately estimating the value function of complex environments and being able to generalize to new unseen states. For multi-agent fields, agents must cope with the non-stationarity of the environment, due to the presence of other agents, and can take advantage of information sharing techniques for improved coordination. We propose an neural-based actor-critic algorithm, which learns communication protocols between agents and implicitly shares information during the learning phase. Large numbers of agents communicate with a self-learned protocol during distributed execution, and reliably learn complex strategies and protocols for partially observable multi-agent environments.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Guided Deep Reinforcement Learning in the GeoFriends2 Environment",
        "doc_scopus_id": "85056510719",
        "doc_doi": "10.1109/IJCNN.2018.8489372",
        "doc_eid": "2-s2.0-85056510719",
        "doc_date": "2018-10-10",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Software",
                "area_abbreviation": "COMP",
                "area_code": "1712"
            },
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            }
        ],
        "doc_keywords": [
            "Commodity hardware",
            "Learning environments",
            "Learning process",
            "Learning to play",
            "Motor control",
            "Multi-agent reinforcement learning",
            "Performance-oriented",
            "State-of-the-art performance"
        ],
        "doc_abstract": "© 2018 IEEE.In recent years, the artificial intelligence community has taken big strides in the application of reinforcement learning to games or similar environments using deep learning. From Atari to board games, including motor control or riddle solving, fairly generic deep learning algorithms can now achieve great policies by simply learning to play from experience, and minimal knowledge of the specific domain. However, these algorithms are very demanding in terms of time and hardware in order to achieve the results reported in the literature. So much so, that some algorithms would take years to achieve state-of-the-art performance in commodity hardware. Not only that, but even the learning environments can hinder the speed of the learning process, if they have not been performance optimized. In this paper, we evaluate a complex existing environment, and propose a performance-oriented version, which we call GeoFriends2. We describe the motivation behind the creation of our version, and how it is suitable for both single- and multi-agent reinforcement learning. We then use Asynchronous Deep Learning to create complex policies that can act as baselines for future research on this environment. We also describe a set of techniques that speed up the learning process such that tests can be run with commodity hardware in hours, and not weeks, and using much simpler network architectures.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Mobile manipulation for autonomous packaging in realistic environments: EuRoC challenge 2, stage II, showcase",
        "doc_scopus_id": "85048892736",
        "doc_doi": "10.1109/ICARSC.2018.8374188",
        "doc_eid": "2-s2.0-85048892736",
        "doc_date": "2018-06-06",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            },
            {
                "area_name": "Mechanical Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2210"
            },
            {
                "area_name": "Control and Optimization",
                "area_abbreviation": "MATH",
                "area_code": "2606"
            }
        ],
        "doc_keywords": [],
        "doc_abstract": "© 2018 IEEE.European Robotics Challenges (EuRoC) project has been launched to find competitive solutions by exploiting synergies across research institutes to industrial end-users. This paper reports the research conducted by the TIMAIRIS team to fulfill EuRoC C2 Stage II tasks. TIMAIRIS is one of the 6 EuRoC finalists (Stage III) from an initial group of 102 teams. The packaging industry is very interested in recent advances in robotics but is still quite conservative in the way it uses automation, since shapes and printed patterns of blanks vary a lot to comply with end users' demands. The use of programmable logic controllers (PLCs) is widely common but the use of more sophisticated decision mechanisms is not so common. A shop floor logistics and manipulation system has been developed and demonstrated in a realistic environment for autonomous packaging.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "An optimal closed-loop framework to develop stable walking for humanoid robot",
        "doc_scopus_id": "85048881269",
        "doc_doi": "10.1109/ICARSC.2018.8374156",
        "doc_eid": "2-s2.0-85048881269",
        "doc_date": "2018-06-06",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            },
            {
                "area_name": "Mechanical Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2210"
            },
            {
                "area_name": "Control and Optimization",
                "area_abbreviation": "MATH",
                "area_code": "2606"
            }
        ],
        "doc_keywords": [],
        "doc_abstract": "© 2018 IEEE.Bipedal robots are essentially unstable because of their complex kinematics as well as high dimensional state space dynamics, hence control and generation of stable walking is a complex subject that is still one of the active topics in the robotic community. This paper proposes a closed-loop model-based walk engine which takes into account push recovery strategies. In this paper, Linear Inverted Pendulum Plus Flywheel Model (LIPPFM) is extended and used to approximate the overall dynamics of a humanoid robot. We extended this model by releasing the height constraint of the center of mass (COM) as well as by considering the mass of pendulum to increase the accuracy of the model. In this framework, a step is composed of a double support phase in addition to a single support phase. Moreover, ZMP and reference trajectory generators are formulated based on the input parameters and tracking problem are formulated as a finite-time horizon linear quadratic regulator (LQR) problem. The proposed framework has been successfully tested by performing several simulations using MATLAB. The simulation results show this framework is capable to provide stable walking on an uneven terrain.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "A sparse-dense approach for efficient grid mapping",
        "doc_scopus_id": "85048861103",
        "doc_doi": "10.1109/ICARSC.2018.8374173",
        "doc_eid": "2-s2.0-85048861103",
        "doc_date": "2018-06-06",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            },
            {
                "area_name": "Mechanical Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2210"
            },
            {
                "area_name": "Control and Optimization",
                "area_abbreviation": "MATH",
                "area_code": "2606"
            }
        ],
        "doc_keywords": [],
        "doc_abstract": "© 2018 IEEE.The regular volumetric grid is a popular method used in mapping to represent the environment, however for large three-dimensional environments it requires a large amount of memory that may not even be available. In this paper we present a sparse-dense data structure to manage the space of a volumetric grid that provides improvements over the octree data structure, a data structure popularized by the OctoMap mapping framework. Furthermore, we propose an online data compression scheme supported by a cache mechanism that further improves the space efficiency of our approach without compromising time efficiency. The approach is evaluated using public available datasets that show an increase in space and memory efficiency over OctoMap without compromising accuracy.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "A reliable hierarchical omnidirectional walking engine for a bipedal robot by using the enhanced lip plus flywheel",
        "doc_scopus_id": "85048897160",
        "doc_doi": "10.1142/9789813231047_0049",
        "doc_eid": "2-s2.0-85048897160",
        "doc_date": "2018-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Human-Computer Interaction",
                "area_abbreviation": "COMP",
                "area_code": "1709"
            },
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            }
        ],
        "doc_keywords": [
            "Center of mass",
            "Humanoid robot",
            "Inverted pendulum",
            "Kinematics and dynamics",
            "Natural motions",
            "Omni-directional walkings",
            "Reference trajectories",
            "Vertical CoM motion"
        ],
        "doc_abstract": "© 2018 by World Scientific Publishing Co. Pte. Ltd.According to the similarity in kinematic architecture, bipedal robots are the most appropriate type of robot to operate in humanoid environments. Most of the humanoid robots have more than 20 degrees of freedom (DoF), therefore they have complex kinematics and dynamics. Due to these complexities, developing a stable walking engine is a difficult subject which is still one of the main challenges. In this paper, a hierarchical walking engine is presented which tries to fade the complexities and increases the flexibility and portability. To generate the reference trajectories of walking, Linear Inverted Pendulum Plus Flywheel Model is used. We enhanced this model to release the height constraint of the Center of Mass (CoM). This enhancement not only provides more natural motion but also it provides larger stride. The reliability of the proposed structure is verified through real experiments for an 110cm bipedal robot. The experimental results show the performance of this controller to keep robot’s stability during walking. The average speed of walking that we have achieved was 20cm/sec.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "A Hybrid ZMP-CPG Based Walk Engine for Biped Robots",
        "doc_scopus_id": "85042234860",
        "doc_doi": "10.1007/978-3-319-70836-2_61",
        "doc_eid": "2-s2.0-85042234860",
        "doc_date": "2018-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Control and Systems Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2207"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Central pattern generator",
            "CREPS-CMA",
            "Hierarchical structures",
            "Humanoid robot",
            "Omni-directional walkings",
            "Soccer simulation"
        ],
        "doc_abstract": "© Springer International Publishing AG 2018.Developing an optimized omnidirectional walking for biped robots is a challenging task due to their complex dynamics and kinematics. This paper proposes a hierarchical walk engine structure to generate fast and stable walking. In particular, this structure provides a closed-loop CPG-based omnidirectional walking that takes into account two human-inspired push recovery strategies. In addition, this structure is fully parametric and allows using a policy search algorithm to find the optimum parameters for the walking. To show the performance of the proposed structure, a set of experiments on a simulated NAO robot has been carried out. Experimental results demonstrate that the proposed structure is able to generate fast and stable omnidirectional walking. The maximum speed of forward walking that we have achieved was 59 cm/s.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Mixed-Policy Asynchronous Deep Q-Learning",
        "doc_scopus_id": "85042225806",
        "doc_doi": "10.1007/978-3-319-70836-2_11",
        "doc_eid": "2-s2.0-85042225806",
        "doc_date": "2018-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Control and Systems Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2207"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Competitive environment",
            "Complex environments",
            "Equilibrium strategy",
            "Function approximators",
            "High dimensional environment",
            "Issues and challenges",
            "Multi-agent environment",
            "Multi-agent learning"
        ],
        "doc_abstract": "© Springer International Publishing AG 2018.There are many open issues and challenges in the reinforcement learning field, such as handling high-dimensional environments. Function approximators, such as deep neural networks, have been successfully used in both single- and multi-agent environments with high dimensional state-spaces. The multi-agent learning paradigm faces even more problems, due to the effect of several agents learning simultaneously in the environment. One of its main concerns is how to learn mixed policies that prevent opponents from exploring them in competitive environments, achieving a Nash equilibrium. We propose an extension of several algorithms able to achieve Nash equilibriums in single-state games to the deep-learning paradigm. We compare their deep-learning and table-based implementations, and demonstrate how WPL is able to achieve an equilibrium strategy in a complex environment, where agents must find each other in an infinite-state game and play a modified version of the Rock Paper Scissors game.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Human-Robot Collaboration and Safety Management for Logistics and Manipulation Tasks",
        "doc_scopus_id": "85042220407",
        "doc_doi": "10.1007/978-3-319-70836-2_2",
        "doc_eid": "2-s2.0-85042220407",
        "doc_date": "2018-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Control and Systems Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2207"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Human-robot collaboration",
            "Industrial context",
            "Manipulation task",
            "Mobile manipulator",
            "Reasoning methods",
            "Region-based filtering",
            "Safety concerns",
            "Safety management"
        ],
        "doc_abstract": "© Springer International Publishing AG 2018.To realize human-robot collaboration in manufacturing, industrial robots need to share an environment with humans and to work hand in hand. This introduces safety concerns but also provides the opportunity to take advantage of human-robot interactions to control the robot. The main objective of this work is to provide HRI without compromising safety issues in a realistic industrial context. In the paper, a region-based filtering and reasoning method for safety has been developed and integrated into a human-robot collaboration system. The proposed method has been successfully demonstrated keeping safety during the showcase evaluation of the European robotics challenges with a real mobile manipulator.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Preface",
        "doc_scopus_id": "85042209079",
        "doc_doi": null,
        "doc_eid": "2-s2.0-85042209079",
        "doc_date": "2018-01-01",
        "doc_type": "Editorial",
        "doc_areas": [
            {
                "area_name": "Control and Systems Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2207"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [],
        "doc_abstract": null,
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Neural regularization jointly involving neurons and connections for robust image classification",
        "doc_scopus_id": "85042368378",
        "doc_doi": "10.1109/MFI.2017.8170451",
        "doc_eid": "2-s2.0-85042368378",
        "doc_date": "2017-12-07",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Control and Systems Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2207"
            },
            {
                "area_name": "Software",
                "area_abbreviation": "COMP",
                "area_code": "1712"
            },
            {
                "area_name": "Computer Science Applications",
                "area_abbreviation": "COMP",
                "area_code": "1706"
            }
        ],
        "doc_keywords": [
            "Classification performance",
            "Classification results",
            "Experimental analysis",
            "Fully connected neural network",
            "Fully-connected layers",
            "Prediction performance",
            "Regularization methods",
            "Regularization technique"
        ],
        "doc_abstract": "© 2017 IEEE.This paper presents an integrated neural regularization method in fully-connected neural networks that jointly combines the cutting edge of regularization techniques; Dropout [1] and DropConnect [2]. With a small number of data set, trained feed-forward networks tend to show poor prediction performance on test data which has never been introduced while training. In order to reduce the overfitting, regularization methods commonly use only a sparse subset of their inputs. While a fully-connected layer with Dropout takes account of a randomly selected subset of hidden neurons with some probability, a layer with DropConnect only keeps a randomly selected subset of connections between neurons. It has been reported that their performances are dependent on domains. Image classification results show that the integrated method provides more degrees of freedom to achieve robust image recognition in the test phase. The experimental analyses on CIFAR-10 and one-hand gesture dataset show that the method provides the opportunity to improve classification performance.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Deriving and improving CMA-ES with information geometric trust regions",
        "doc_scopus_id": "85026391666",
        "doc_doi": "10.1145/3071178.3071252",
        "doc_eid": "2-s2.0-85026391666",
        "doc_date": "2017-07-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Software",
                "area_abbreviation": "COMP",
                "area_code": "1712"
            },
            {
                "area_name": "Computer Science Applications",
                "area_abbreviation": "COMP",
                "area_code": "1706"
            },
            {
                "area_name": "Computational Theory and Mathematics",
                "area_abbreviation": "COMP",
                "area_code": "1703"
            }
        ],
        "doc_keywords": [
            "Evolution strategies",
            "Expectation-maximisation",
            "Parameter-tuning",
            "Step-size adaptations",
            "Stochastic search",
            "Stochastic search algorithms",
            "Theoretical foundations",
            "Trust region"
        ],
        "doc_abstract": "© 2017 ACM.CMA-ES is one of the most popular stochastic search algorithms. It performs favourably in many tasks without the need of extensive parameter tuning. The algorithm has many beneficial properties, including automatic step-size adaptation, efficient covariance updates that incorporates the current samples as well as the evolution path and its invariance properties. Its update rules are composed of well established heuristics where the theoretical foundations of some of these rules are also well understood. In this paper we will fully derive all CMA-ES update rules within the framework of expectation-maximisation-based stochastic search algorithms using information-geometric trust regions. We show that the use of the trust region results in similar updates to CMA-ES for the mean and the covariance matrix while it allows for the derivation of an improved update rule for the step-size. Our new algorithm, Trust-Region Co-variance Matrix Adaptation Evolution Strategy (TR-CMA-ES) is fully derived from first order optimization principles and performs favourably in compare to standard CMA-ES algorithm.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "A reliable model-based walking engine with push recovery capability",
        "doc_scopus_id": "85026890170",
        "doc_doi": "10.1109/ICARSC.2017.7964063",
        "doc_eid": "2-s2.0-85026890170",
        "doc_date": "2017-06-29",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Biomedical Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2204"
            },
            {
                "area_name": "Control and Optimization",
                "area_abbreviation": "MATH",
                "area_code": "2606"
            },
            {
                "area_name": "Mechanical Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2210"
            },
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            }
        ],
        "doc_keywords": [
            "Hierarchical structures",
            "Human environment",
            "Human-like motion",
            "Humanoid robot",
            "Humanoid soccer robots",
            "Inverted pendulum",
            "Omni-directional walkings",
            "Push recoveries"
        ],
        "doc_abstract": "© 2017 IEEE.Bipedal humanoid robots have complex dynamics and they are intrinsically unstable. Although, bipedal robots have a similar kinematic architecture to a human and they are the most appropriate type of robots to operate in human environments, developing a humanoid robot that has robust is a difficult task. This paper proposes an omnidirectional walking engine that takes into account the push recovery strategies. The walking engine has a hierarchical structure and tries to fade the complexities of the dynamic walking. In addition, it can adapt to another platform with few changes. We enhanced the Linear Inverted Pendulum Plus Flywheel Model to release the height constraint of the center of mass. This enhancement allows a more human-like motion and provides more stable walking. The proposed walking engine has been successfully tested on a real humanoid soccer robot. The experimental results show the performance of this controller to generate stable walking. The average speed of walking that we have achieved was 20cm/sec.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Real-time multi-object tracking on highly dynamic environments",
        "doc_scopus_id": "85026875635",
        "doc_doi": "10.1109/ICARSC.2017.7964072",
        "doc_eid": "2-s2.0-85026875635",
        "doc_date": "2017-06-29",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Biomedical Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2204"
            },
            {
                "area_name": "Control and Optimization",
                "area_abbreviation": "MATH",
                "area_code": "2606"
            },
            {
                "area_name": "Mechanical Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2210"
            },
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            }
        ],
        "doc_keywords": [
            "Dynamic environments",
            "Multi-object tracking",
            "Multiple moving objects",
            "Real time constraints",
            "Robotics research",
            "Soccer-playing robots",
            "Tracking objects",
            "Trade off"
        ],
        "doc_abstract": "© 2017 IEEE.An accurate representation of the environment is important to plan tasks and efficiently control an autonomous robot. Multi-object tracking has long been an important task in robotics research whenever an autonomous robot needs to plan its tasks on an environment with multiple moving objects. Specially when the application is defined by real-time constraints in a fast-paced environment, a trade-off between accuracy and performance is automatically imposed. This paper presents a solution for real-time multi-object tracking on stochastic and highly dynamic environments. Although not limited to this specific application domain, the implementation and evaluation of this solution was performed on a team of autonomous soccer-playing robots. The proposed solution is detailed from the detection and feature extraction phase to the general problem of efficiently tracking objects in the environment. Results on the real testbed are also presented and discussed.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Skill-based anytime agent architecture for logistics and manipulation tasks: EuRoC Challenge 2, Stage II - Realistic Labs: Benchmarking",
        "doc_scopus_id": "85026869156",
        "doc_doi": "10.1109/ICARSC.2017.7964075",
        "doc_eid": "2-s2.0-85026869156",
        "doc_date": "2017-06-29",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Biomedical Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2204"
            },
            {
                "area_name": "Control and Optimization",
                "area_abbreviation": "MATH",
                "area_code": "2606"
            },
            {
                "area_name": "Mechanical Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2210"
            },
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            }
        ],
        "doc_keywords": [
            "Agent architectures",
            "Continuous development",
            "Effective solution",
            "Manipulation task",
            "Planning strategies",
            "Production quality",
            "Robotic technologies",
            "Scientific competition"
        ],
        "doc_abstract": "© 2017 IEEE.Nowadays, the increase of robotic technology application to industry scenarios is notorious. Proposals for new effective solutions are in continuous development once industry needs a constantly improvement in time as well as in production quality and efficiency. The EuRoC research project proposes a scientific competition in which research and industry manufacturers joint teams are encouraged to develop and test solutions that can solve several issues as well as be useful in manufacturing improvement. This paper presents the TIMAIRIS architecture and approach used in the Challenge 2 - Stage II - Benchmarking phase, namely regarding the perception, manipulation and planning strategy that was applied to achieve the tasks objectives. The used approach proved to be quite robust and efficient, which allowed us to rank first in the Benchmarking phase.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Efficient localization based on scan matching with a continuous likelihood field",
        "doc_scopus_id": "85026864903",
        "doc_doi": "10.1109/ICARSC.2017.7964053",
        "doc_eid": "2-s2.0-85026864903",
        "doc_date": "2017-06-29",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Biomedical Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2204"
            },
            {
                "area_name": "Control and Optimization",
                "area_abbreviation": "MATH",
                "area_code": "2606"
            },
            {
                "area_name": "Mechanical Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2210"
            },
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            }
        ],
        "doc_keywords": [
            "Gauss Newton",
            "Levenberg-Marquardt method",
            "Localization algorithm",
            "Loss functions",
            "Mobile robot localization",
            "Nonlinear least squares problems",
            "Scan matching",
            "State of the art"
        ],
        "doc_abstract": "© 2017 IEEE.This paper presents a fast scan matching approach to mobile robot localization supported by a continuous likelihood field. The likelihood field plays a central role in the approach, as it avoids the necessity to establish direct correspondences; it is the connection link between scan matching and robotic localization, and it provides a reduced computational complexity. Scan matching is formulated as a non-linear least squares problem and solved by the Gauss-Newton and Levenberg-Marquardt methods. Furthermore, to reduce the influences of outliers during optimization, a loss function is introduced. The proposed solution was evaluated using a publicly available dataset and compared with AMCL, a state-of-the-art localization algorithm. Our proposal shows to be a fast and accurate localization algorithm suitable for any type of operation.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Rich and robust human-robot interaction on gesture recognition for assembly tasks",
        "doc_scopus_id": "85026864168",
        "doc_doi": "10.1109/ICARSC.2017.7964069",
        "doc_eid": "2-s2.0-85026864168",
        "doc_date": "2017-06-29",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Biomedical Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2204"
            },
            {
                "area_name": "Control and Optimization",
                "area_abbreviation": "MATH",
                "area_code": "2606"
            },
            {
                "area_name": "Mechanical Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2210"
            },
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            }
        ],
        "doc_keywords": [
            "Assembly tasks",
            "Human robot Interaction (HRI)",
            "Manufacturing enterprise",
            "Mobile manipulator",
            "Multiple feature fusion",
            "Puzzle games",
            "Robotics technology",
            "Small and medium sized enterprise"
        ],
        "doc_abstract": "© 2017 IEEE.The adoption of robotics technology has the potential to advance quality, efficiency and safety for manufacturing enterprises, in particular small and medium-sized enterprises. This paper presents a human-robot interaction (HRI) system that enables a robot to receive commands, provide information to a human teammate and ask them a favor. In order to build a robust HRI system based on gesture recognition, three key issues are addressed: richness, multiple feature fusion and failure verification. The developed system has been tested and validated in a realistic lab with a real mobile manipulator and a human teammate to solve a puzzle game.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Stochastic search in changing situations",
        "doc_scopus_id": "85046097551",
        "doc_doi": null,
        "doc_eid": "2-s2.0-85046097551",
        "doc_date": "2017-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Engineering (all)",
                "area_abbreviation": "ENGI",
                "area_code": "2200"
            }
        ],
        "doc_keywords": [
            "Context vector",
            "Information theoretic algorithm",
            "Multiple tasks",
            "Objective functions",
            "Parameter vectors",
            "Relative entropy",
            "Stochastic search",
            "Stochastic search algorithms"
        ],
        "doc_abstract": "© 2017, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.Stochastic search algorithms are black-box optimizer of an objective function. They have recently gained a lot of attention in operations research, machine learning and policy search of robot motor skills due to their ease of use and their generality. However, when the task or objective function slightly changes, many stochastic search algorithms require complete re-leaming in order to adapt thesolution to the new objective function or the new context. As such, we consider the contextual stochastic search paradigm. Here, we want to find good parameter vectors for multiple related tasks, where each task is described by a continuous context vector. Hence, the objective function might change slightly for each parameter vector evaluation. In this paper, we investigate a contextual stochastic search algorithm known as Contextual Relative Entropy Policy Search (CREPS), an information-theoretic algorithm that can learn from multiple tasks simultaneously. We show the application of CREPS for simulated robotic tasks.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Learning a humanoid kick with controlled distance",
        "doc_scopus_id": "85034212143",
        "doc_doi": "10.1007/978-3-319-68792-6_4",
        "doc_eid": "2-s2.0-85034212143",
        "doc_date": "2017-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Flexible humanoid robot",
            "Humanoid robot",
            "Motor learning",
            "Non linear",
            "Nonlinear functions",
            "Optimal controller",
            "Parametric functions",
            "Policy search"
        ],
        "doc_abstract": "© 2017, Springer International Publishing AG.We investigate the learning of a flexible humanoid robot kick controller, i.e., the controller should be applicable for multiple contexts, such as different kick distances, initial robot position with respect to the ball or both. Current approaches typically tune or optimise the parameters of the biped kick controller for a single context, such as a kick with longest distance or a kick with a specific distance. Hence our research question is that, how can we obtain a flexible kick controller that controls the robot (near) optimally for a continuous range of kick distances? The goal is to find a parametric function that given a desired kick distance, outputs the (near) optimal controller parameters. We achieve the desired flexibility of the controller by applying a contextual policy search method. With such a contextual policy search algorithm, we can generalize the robot kick controller for different distances, where the desired distance is described by a real-valued vector. We will also show that the optimal parameters of the kick controller is a non-linear function of the desired distances and a linear function will fail to properly generalize the kick controller over desired kick distances.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Contextual covariance matrix adaptation evolutionary strategies",
        "doc_scopus_id": "85031910472",
        "doc_doi": "10.24963/ijcai.2017/191",
        "doc_eid": "2-s2.0-85031910472",
        "doc_date": "2017-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            }
        ],
        "doc_keywords": [
            "Contextual learning",
            "Covariance matrix adaptation",
            "Evolutionary strategies",
            "Objective functions",
            "Pre-mature convergences",
            "Step-size controls",
            "Stochastic search algorithms",
            "Stochastic search methods"
        ],
        "doc_abstract": "Many stochastic search algorithms are designed to optimize a fixed objective function to learn a task, i.e., if the objective function changes slightly, for example, due to a change in the situation or context of the task, relearning is required to adapt to the new context. For instance, if we want to learn a kicking movement for a soccer robot, we have to relearn the movement for different ball locations. Such relearning is undesired as it is highly inefficient and many applications require a fast adaptation to a new context/situation. Therefore, we investigate contextual stochastic search algorithms that can learn multiple, similar tasks simultaneously. Current contextual stochastic search methods are based on policy search algorithms and suffer from premature convergence and the need for parameter tuning. In this paper, we extend the well known CMA-ES algorithm to the contextual setting and illustrate its performance on several contextual tasks. Our new algorithm, called contextual CMAES, leverages from contextual learning while it preserves all the features of standard CMA-ES such as stability, avoidance of premature convergence, step size control and a minimal amount of parameter tuning.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Multi-agent double deep Q-networks",
        "doc_scopus_id": "85028998868",
        "doc_doi": "10.1007/978-3-319-65340-2_11",
        "doc_eid": "2-s2.0-85028998868",
        "doc_date": "2017-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Complexity issues",
            "Function approximators",
            "High-dimensional",
            "Issues and challenges",
            "Learning fields",
            "Learning techniques",
            "Multi-agent Q-learning",
            "Transfer learning"
        ],
        "doc_abstract": "© Springer International Publishing AG 2017.There are many open issues and challenges in the multi-agent reward-based learning field. Theoretical convergence guarantees are lost, and the complexity of the action-space is also exponential to the amount of agents calculating their optimal joint-action. Function approximators, such as deep neural networks, have successfully been used in single-agent environments with high dimensional state-spaces. We propose the Multi-agent Double Deep Q-Networks algorithm, an extension of Deep Q-Networks to the multi-agent paradigm. Two common techniques of multi-agent Q-learning are used to formally describe our proposal, and are tested in a Foraging Task and a Pursuit Game. We also demonstrate how they can generalize to similar tasks and to larger teams, due to the strength of deep-learning techniques, and their viability for transfer learning approaches. With only a small fraction of the initial task’s training, we adapt to longer tasks, and we accelerate the task completion by increasing the team size, thus empirically demonstrating a solution to the complexity issues of the multi-agent field.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Improving and benchmarking motion planning for a mobile manipulator operating in unstructured environments",
        "doc_scopus_id": "85028989811",
        "doc_doi": "10.1007/978-3-319-65340-2_41",
        "doc_eid": "2-s2.0-85028989811",
        "doc_date": "2017-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Complex task",
            "Mobile manipulator",
            "Motion planners",
            "Motion planning problems",
            "Robotic agents",
            "Simulation environment",
            "Unstructured environments"
        ],
        "doc_abstract": "© Springer International Publishing AG 2017.This paper presents the use, adaptation and benchmarking of motion planning tools that will be integrated with the KUKA KMR iiwa mobile robot. The motion planning tools are integrated in the robotic agent presented in [1]. The adaptation consists on algorithms developed to increase the robustness and the efficiency to solve the motion planning problems. These algorithms combine existing motion planners with a trajectory filter developed in this work. Finally, the benchmarking of different motion planners is presented. Three motion planning tasks with a growing level of complexity are taken in consideration for the tests in a simulation environment. The motion planners that provided the best results were RRTConnect for the two less complex tasks and PRM* for the most difficult task.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "A Scan Matching Approach to SLAM with a Dynamic Likelihood Field",
        "doc_scopus_id": "85010460599",
        "doc_doi": "10.1109/ICARSC.2016.23",
        "doc_eid": "2-s2.0-85010460599",
        "doc_date": "2016-12-12",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Human-Computer Interaction",
                "area_abbreviation": "COMP",
                "area_code": "1709"
            },
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            },
            {
                "area_name": "Computer Science Applications",
                "area_abbreviation": "COMP",
                "area_code": "1706"
            }
        ],
        "doc_keywords": [
            "Gauss-Newton methods",
            "Loss functions",
            "Low computational complexity",
            "Nonlinear least squares problems",
            "Real-time operation",
            "Scan matching",
            "SLAM",
            "SLAM approach"
        ],
        "doc_abstract": "© 2016 IEEE.This paper presents a fast scan matching approach to online SLAM supported by a dynamic likelihood field. The dynamic likelihood field plays a central role in the approach, as it avoids the necessity to establish direct correspondences, it is the connection link between scan matching and the online SLAM and it has a low computational complexity. Scan matching is formulated as a non-linear least squares problem and solved by the Gauss-Newton method. Furthermore, to reduce the influences of outliers during optimization, a loss function is introduced. The proposed solution was evaluated using an objective benchmark designed to compare SLAM solutions and its execution times were also analyzed. It shows to be a fast and accurate online SLAM approach, suitable for real-time operation.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "How to Select a Suitable Action against Strong Pushes in Adult-Size Humanoid Robot: Learning from Past Experiences",
        "doc_scopus_id": "85010447569",
        "doc_doi": "10.1109/ICARSC.2016.43",
        "doc_eid": "2-s2.0-85010447569",
        "doc_date": "2016-12-12",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Human-Computer Interaction",
                "area_abbreviation": "COMP",
                "area_code": "1709"
            },
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            },
            {
                "area_name": "Computer Science Applications",
                "area_abbreviation": "COMP",
                "area_code": "1706"
            }
        ],
        "doc_keywords": [
            "Empirical experiments",
            "External disturbances",
            "Humanoid robot",
            "Joint angle",
            "Nonlinear force",
            "Out-of-control",
            "Real environments",
            "Strong collisions"
        ],
        "doc_abstract": "© 2016 IEEE.Avoiding a fall after strong collisions between two players is an important capability for an adult-size humanoid robot. Particularly in the RoboCup competitions, matches are really competitive and collisions between players are occurred frequently. In the adult-size humanoid league, robots are tall and heavy. Whenever robots contact each other during moving, several unpredicted non-linear forces are entered to the robots. As a consequence, the stability of robots goes out of control and they fall down. In order to maintain and recover balance of an adult-size humanoid robot against external disturbances, a Neural Network is used for learning from past experiments to reduce the effect of disturbances forces by providing proper step sizes and joint angles to the robot. In our approach, the robot's controller is learned using several empirical experiments and tested on a real adult-size humanoid robot namely Ariana from BehRobot humanoid team. Experiments demonstrate after receiving strong pushes during walking, Ariana can efficiently recover its stability in the real environment.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Contextual Relative Entropy Policy Search with Covariance Matrix Adaptation",
        "doc_scopus_id": "85010289552",
        "doc_doi": "10.1109/ICARSC.2016.31",
        "doc_eid": "2-s2.0-85010289552",
        "doc_date": "2016-12-12",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Human-Computer Interaction",
                "area_abbreviation": "COMP",
                "area_code": "1709"
            },
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            },
            {
                "area_name": "Computer Science Applications",
                "area_abbreviation": "COMP",
                "area_code": "1706"
            }
        ],
        "doc_keywords": [
            "Covariance matrix adaptation",
            "Objective functions",
            "Orders of magnitude",
            "Parameter vectors",
            "Pre-mature convergences",
            "Stochastic search",
            "Stochastic search algorithms",
            "Stochastic search methods"
        ],
        "doc_abstract": "© 2016 IEEE.Stochastic search algorithms are black-box optimizers of an objective function. They have recently gained a lot of attention in operations research, machine learning and policy search of robot motor skills due to their ease of use and their generality. However, with slightly different tasks or objective functions, many stochastic search algorithms require complete re-learning in order to adapt the solution to the new objective function or the new context. As such, we consider the contextual stochastic search paradigm. Here, we want to find good parameter vectors for multiple related tasks, where each task is described by a continuous context vector. Hence, the objective function might change slightly for each parameter vector evaluation. Contextual algorithms have been investigated in the field of policy search. However, contextual policy search algorithms typically suffer from premature convergence and perform unfavourably in comparison with state of the art stochastic search methods. In this paper, we investigate a contextual stochastic search algorithm known as Contextual Relative Entropy Policy Search (CREPS), an informationtheoretic algorithm that can learn for multiple tasks simultaneously. We extend that algorithm with a covariance matrix adaptation technique that alleviates the premature convergence problem. We call the new algorithm Contextual Relative Entropy Policy Search with Covariance Matrix Adaptation (CREPS-CMA). We will show that CREPS-CMA outperforms the original CREPS by orders of magnitude. We illustrate the performance of CREPS-CMA on several contextual tasks, including a complex simulated robot kick task.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Non-parametric contextual stochastic search",
        "doc_scopus_id": "85006489401",
        "doc_doi": "10.1109/IROS.2016.7759411",
        "doc_eid": "2-s2.0-85006489401",
        "doc_date": "2016-11-28",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Control and Systems Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2207"
            },
            {
                "area_name": "Software",
                "area_abbreviation": "COMP",
                "area_code": "1712"
            },
            {
                "area_name": "Computer Vision and Pattern Recognition",
                "area_abbreviation": "COMP",
                "area_code": "1707"
            },
            {
                "area_name": "Computer Science Applications",
                "area_abbreviation": "COMP",
                "area_code": "1706"
            }
        ],
        "doc_keywords": [
            "Context dependent",
            "Context features",
            "Nonparametric methods",
            "Objective functions",
            "Parameter vectors",
            "Parametric modeling",
            "Stochastic search",
            "Stochastic search algorithms"
        ],
        "doc_abstract": "© 2016 IEEE.Stochastic search algorithms are black-box optimizer of an objective function. They have recently gained a lot of attention in operations research, machine learning and policy search of robot motor skills due to their ease of use and their generality. Yet, many stochastic search algorithms require relearning if the task or objective function changes slightly to adapt the solution to the new situation or the new context. In this paper, we consider the contextual stochastic search setup. Here, we want to find multiple good parameter vectors for multiple related tasks, where each task is described by a continuous context vector. Hence, the objective function might change slightly for each parameter vector evaluation of a task or context. Contextual algorithms have been investigated in the field of policy search, however, the search distribution typically uses a parametric model that is linear in the some hand-defined context features. Finding good context features is a challenging task, and hence, non-parametric methods are often preferred over their parametric counter-parts. In this paper, we propose a non-parametric contextual stochastic search algorithm that can learn a non-parametric search distribution for multiple tasks simultaneously. In difference to existing methods, our method can also learn a context dependent covariance matrix that guides the exploration of the search process. We illustrate its performance on several non-linear contextual tasks.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Contextual Policy Search for Linear and Nonlinear Generalization of a Humanoid Walking Controller",
        "doc_scopus_id": "84958255106",
        "doc_doi": "10.1007/s10846-016-0347-y",
        "doc_eid": "2-s2.0-84958255106",
        "doc_date": "2016-09-01",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Software",
                "area_abbreviation": "COMP",
                "area_code": "1712"
            },
            {
                "area_name": "Control and Systems Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2207"
            },
            {
                "area_name": "Mechanical Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2210"
            },
            {
                "area_name": "Industrial and Manufacturing Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2209"
            },
            {
                "area_name": "Electrical and Electronic Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2208"
            },
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            }
        ],
        "doc_keywords": [
            "Controller parameter",
            "Locomotion controllers",
            "Nonlinear generalizations",
            "Policy search",
            "Radial basis functions",
            "Robot locomotion",
            "Robot skills",
            "Stochastic search"
        ],
        "doc_abstract": "© 2016, Springer Science+Business Media Dordrecht.We investigate learning of flexible robot locomotion controllers, i.e., the controllers should be applicable for multiple contexts, for example different walking speeds, various slopes of the terrain or other physical properties of the robot. In our experiments, contexts are desired walking linear speed of the gait. Current approaches for learning control parameters of biped locomotion controllers are typically only applicable for a single context. They can be used for a particular context, for example to learn a gait with highest speed, lowest energy consumption or a combination of both. The question of our research is, how can we obtain a flexible walking controller that controls the robot (near) optimally for many different contexts? We achieve the desired flexibility of the controller by applying the recently developed contextual relative entropy policy search(REPS) method which generalizes the robot walking controller for different contexts, where a context is described by a real valued vector. In this paper we also extend the contextual REPS algorithm to learn a non-linear policy instead of a linear policy over the contexts which call it RBF-REPS as it uses Radial Basis Functions. In order to validate our method, we perform three simulation experiments including a walking experiment using a simulated NAO humanoid robot. The robot learns a policy to choose the controller parameters for a continuous set of forward walking speeds.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Model-based relative entropy stochastic search",
        "doc_scopus_id": "84986320301",
        "doc_doi": "10.1145/2908961.2930952",
        "doc_eid": "2-s2.0-84986320301",
        "doc_date": "2016-07-20",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Software",
                "area_abbreviation": "COMP",
                "area_code": "1712"
            },
            {
                "area_name": "Computer Science Applications",
                "area_abbreviation": "COMP",
                "area_code": "1706"
            },
            {
                "area_name": "Computational Theory and Mathematics",
                "area_abbreviation": "COMP",
                "area_code": "1703"
            }
        ],
        "doc_keywords": [],
        "doc_abstract": null,
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Contextual stochastic search",
        "doc_scopus_id": "84986257322",
        "doc_doi": "10.1145/2908961.2909012",
        "doc_eid": "2-s2.0-84986257322",
        "doc_date": "2016-07-20",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Software",
                "area_abbreviation": "COMP",
                "area_code": "1712"
            },
            {
                "area_name": "Computer Science Applications",
                "area_abbreviation": "COMP",
                "area_code": "1706"
            },
            {
                "area_name": "Computational Theory and Mathematics",
                "area_abbreviation": "COMP",
                "area_code": "1703"
            }
        ],
        "doc_keywords": [
            "Context vector",
            "Motor skills",
            "Multiple tasks",
            "Parameter vectors",
            "Policy search",
            "Robust optimisation",
            "Stochastic search",
            "Stochastic search algorithms"
        ],
        "doc_abstract": "© 2016 Copyright held by the owner/author(s).Stochastic search algorithms have recently also gained a lot of attention in operations research, machine learning and policy search of robot motor skills due to their ease of use and their generality. Yet, many stochastic search algorithms require relearning if the task changes slightly to adapt the solution to the new situation or the new context. Therefore we consider the contextual stochastic search setup. Here, we want to find good parameter vectors for multiple related tasks, where each task is described by a continuous context vector. Hence, the objective might change slightly for each parameter vector evaluation. In this research, we investigate the contextual stochastic search algorithms that can learn from multiple tasks simultaneously.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Multi-object tracking with distributed sensing",
        "doc_scopus_id": "85015202382",
        "doc_doi": "10.1109/MFI.2016.7849548",
        "doc_eid": "2-s2.0-85015202382",
        "doc_date": "2016-07-02",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Control and Systems Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2207"
            },
            {
                "area_name": "Software",
                "area_abbreviation": "COMP",
                "area_code": "1712"
            },
            {
                "area_name": "Computer Science Applications",
                "area_abbreviation": "COMP",
                "area_code": "1706"
            }
        ],
        "doc_keywords": [
            "Distributed sensing",
            "Information merging",
            "Kalman-filtering",
            "League competition",
            "Multi-object tracking",
            "Multiple object tracking",
            "Robotic soccer",
            "Robotic soccer team"
        ],
        "doc_abstract": "© 2016 IEEE.One of the main research goals on distributed autonomous agents in a Multi-Agent System is the development of mechanisms to form a better world model using information merging from different agents. In this paper, we present a solution for robust online and real-time multiple object tracking in a multi-agent system using information gathered by various agents over time, using COP-KMeans for clustering and Kalman Filtering for object state estimation. The proposed solution was implemented on a real robotic soccer team and evaluated in the RoboCup Middle-Size League competitions. The robotic soccer was presented as one possible application for the ideas expressed on this paper.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "A coordinated team of agents to solve mazes",
        "doc_scopus_id": "84952361953",
        "doc_doi": "10.1007/978-3-319-27149-1_30",
        "doc_eid": "2-s2.0-84952361953",
        "doc_date": "2016-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Control and Systems Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2207"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Ciber mouse",
            "Collision-free",
            "Coordinated teams",
            "Degree of complexity",
            "Distributed teams",
            "Intelligent robotics",
            "Maze problems",
            "Virtual agent"
        ],
        "doc_abstract": "© Springer International Publishing Switzerland 2016.Mazes have been famously chosen as a great challenge for robots, either real or virtual, to solve, where agents have to explore the maze and fulfil goals. Mazes can be explored with greater speed by using a group of agents, as opposed to a single-agent system. There is, however, a greater degree of complexity in the implementation of a distributed team of agents that can coordinate to complete their tasks faster and more efficiently. This paper explores theCiberMouse competition problem,where a team of virtual agents need to complete tasks within an unknown maze, with as much efficiency as possible. Their solution has shown great results in the challenge and has won the CiberMouse 2015 competition. The team can solve many complex mazes, in a smart and mostly collision-free manner. Our agents struggle with very tight paths, but compensate by having flexible high-level behaviours which allow them an efficient maze exploration.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "A path planning application for a mountain vineyard autonomous robot",
        "doc_scopus_id": "84951737615",
        "doc_doi": "10.1007/978-3-319-27146-0_27",
        "doc_eid": "2-s2.0-84951737615",
        "doc_date": "2016-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Control and Systems Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2207"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Agricultural fields",
            "Autonomous navigation systems",
            "Coverage path planning",
            "Digital terrain model",
            "Mountain vineyards",
            "Near-optimal solutions",
            "Planning applications",
            "Resource management"
        ],
        "doc_abstract": "© Springer International Publishing Switzerland 2016.Coverage path planning (CPP) is a fundamental agricultural field task required for autonomous navigation systems. It is also important for resource management, increasingly demanding in terms of reducing costs and environmental polluting agents as well as increasing productivity. Additional problems arise when this task involves irregular agricultural terrains where the crop follows non-uniform configurations and extends over steep rocky slopes. For mountain vineyards, finding the optimal path to cover a restricted set of terraces, some of them with dead ends and with other constraints due to terrain morphology, is a great challenge. The problem involves other variables to be taken into account such as speed, direction and orientation of the vehicle, fuel consumption and tank capacities for chemical products. This article presents a decision graph-based approach, to solve a Rural Postman Coverage like problem using A* and Dijkstra algorithms simultaneously to find the optimal sequence of terraces that defines a selected partial coverage area of the vineyard. The decision structure is supported by a graph that contains all the information of the Digital Terrain Model (DTM) of the vineyard. In this first approach, optimality considers distance, cost and time requirements. The optimal solution was represented in a graphical user OpenGL application developed to support the path planning process. Based on the results, it was possible to prove the applicability of this approach for any vineyards which extend like routes. Near optimal solutions based on other specific criteria could also be considered for future work.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Development of an Omnidirectional Walk Engine for Soccer Humanoid Robots",
        "doc_scopus_id": "85002202482",
        "doc_doi": "10.5772/61314",
        "doc_eid": "2-s2.0-85002202482",
        "doc_date": "2015-12-29",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Software",
                "area_abbreviation": "COMP",
                "area_code": "1712"
            },
            {
                "area_name": "Computer Science Applications",
                "area_abbreviation": "COMP",
                "area_code": "1706"
            },
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            }
        ],
        "doc_keywords": [
            "Double support phase",
            "Dynamic environments",
            "Environmental disturbances",
            "Fourier approximations",
            "Fourier Series Approximation",
            "Humanoid soccer robots",
            "Omni-directional walkings",
            "Zero moment point"
        ],
        "doc_abstract": "© SAGE Publications Ltd, unless otherwise noted. Manuscript content on this site is licensed under Creative Commons Licenses.Humanoid soccer robots must be able to carry out their tasks in a highly dynamic environment which requires responsive omnidirectional walking. This paper explains a new omnidirectional walking engine for a humanoid soccer robot that mainly consists of a foot planner, a zero moment point (ZMP) trajectory generator, a centre of mass (CoM) calculator and an active balance feedback loop. An analytical approach is presented for generating the CoM trajectory, in which the cart-table motion of the equations is solved using the Fourier approximation of the ZMP. With this approach, we propose using a new time segmentation approach in order to parametrize the double-support phase. An active balance method is also proposed which keeps the robot's trunk upright when faced with environmental disturbances. The walking engine is tested on both simulated and real NAO robots. Our results are encouraging given the fact that the robot performs favourably, walking quickly and in a stable manner in any direction in comparison with the best RoboCup 3D soccer simulation teams for which the same simulator is used. In addition, the proposed analytical Fourier-based approach is compared with the well-established numerical ZMP dynamics control method. Our results show that the presented analytical approach involves less time and complexity and better accuracy compared with the ZMP preview control method.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Regularized covariance estimation for weighted maximum likelihood policy search methods",
        "doc_scopus_id": "84962214441",
        "doc_doi": "10.1109/HUMANOIDS.2015.7363529",
        "doc_eid": "2-s2.0-84962214441",
        "doc_date": "2015-12-22",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            },
            {
                "area_name": "Computer Vision and Pattern Recognition",
                "area_abbreviation": "COMP",
                "area_code": "1707"
            },
            {
                "area_name": "Hardware and Architecture",
                "area_abbreviation": "COMP",
                "area_code": "1708"
            },
            {
                "area_name": "Human-Computer Interaction",
                "area_abbreviation": "COMP",
                "area_code": "1709"
            },
            {
                "area_name": "Electrical and Electronic Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2208"
            }
        ],
        "doc_keywords": [
            "Covariance estimation",
            "Covariance matrices",
            "Maximum likelihood estimate",
            "Multivariate Gaussian Distributions",
            "Pre-mature convergences",
            "Regularization technique",
            "Sample covariance matrix",
            "Search problem"
        ],
        "doc_abstract": "© 2015 IEEE.Many episode-based (or direct) policy search algorithms, maintain a multivariate Gaussian distribution as search distribution over the parameter space of some objective function. One class of algorithms, such as episodic REPS, PoWER or PI2 uses, a weighted maximum likelihood estimate (WMLE) to update the mean and covariance matrix of this distribution in each iteration. However, due to high dimensionality of covariance matrices and limited number of samples, the WMLE is an unreliable estimator. The use of WMLE leads to over-fitted covariance estimates, and, hence the variance/entropy of the search distribution decreases too quickly, which may cause premature convergence. In order to alleviate this problem, the estimated covariance matrix can be regularized in different ways, for example by using a convex combination of the diagonal covariance estimate and the sample covariance estimate. In this paper, we propose a new covariance matrix regularization technique for policy search methods that uses the convex combination of the sample covariance matrix and the old covariance matrix used in last iteration. The combination weighting is determined by specifying the desired entropy of the new search distribution. With this mechanism, the entropy of the search distribution can be gradually decreased without damage from the maximum likelihood estimate.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Computer vision and robotic manipulation for automated feeding of cork drillers",
        "doc_scopus_id": "84941315492",
        "doc_doi": "10.1016/j.matdes.2015.05.037",
        "doc_eid": "2-s2.0-84941315492",
        "doc_date": "2015-10-05",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Materials Science (all)",
                "area_abbreviation": "MATE",
                "area_code": "2500"
            },
            {
                "area_name": "Mechanics of Materials",
                "area_abbreviation": "ENGI",
                "area_code": "2211"
            },
            {
                "area_name": "Mechanical Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2210"
            }
        ],
        "doc_keywords": [
            "Background subtraction",
            "Computer vision techniques",
            "Cork",
            "Extract informations",
            "Forest products",
            "Machine learning techniques",
            "Position and orientations",
            "Robust classification"
        ],
        "doc_abstract": "© 2015 Elsevier Ltd.The production of cork stoppers is currently a process in rapid evolution. Where in the past hand labor was common, today we observe increasing attempts to introduce technologies that increase the productivity of production lines. One these example are automated cork drillers that produce thousands of cork stoppers per hour. In order to harness this increase in productivity to its full potential, it must the followed by other processes in the production line upstream of the driller, as for example the feeding of the latter. This article presents the application of computer vision techniques that extract information of cork strips that move on a conveyor belt, to obtain automated feeding of a cork driller using a robotic manipulator. Image Processing extracts information regarding the strip position and orientation, and also which side of the strip is visible. Thus the strip is consistently placed in the driller in order to extract stoppers from the best quality cork. The segmentation of the cork strips is obtained by background subtraction. To estimate the strip visible surface, we apply Machine Learning techniques that enable a robust classification given a set of features extracted from the cork texture. In the experiences carried out, we were able to obtain 100% classification rate with a test dataset of more than a hundred cork strips.",
        "available": true,
        "clean_text": "serial JL 313059 291210 291777 291884 31 Materials & Design MATERIALSDESIGN 2015-05-20 2015-06-29 2015-07-06 2015-07-06 2015-07-06T08:46:53 S0261-3069(15)00290-3 S0261306915002903 10.1016/j.matdes.2015.05.037 S300 S300.1 FULL-TEXT 2016-09-02T13:55:06.848767-04:00 0 0 20151005 2015 2015-05-20T08:05:06.125898Z absattachment articleinfo articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid hubeid indexeddate issn issnnorm itemstage itemtransactionid itemweight openaccess openarchive pg pgfirst pglast pii piinorm pubdatestart pubdatetxt pubyr sectiontitle sortorder srctitle srctitlenorm srctype ssids alllist content subj subheadings suppl tomb volfirst volissue volumelist yearnav figure table body mmlmath acknowledge affil articletitle auth authfirstini authfull authkeywords authlast highlightsabst primabst ref specialabst 0264-1275 02641275 true 82 82 C Volume 82 35 290 296 290 296 20151005 5 October 2015 2015-10-05 2015 Special Section: Cork Material and its Applications article fla Copyright © 2015 Elsevier Ltd. All rights reserved. COMPUTERVISIONROBOTICMANIPULATIONFORAUTOMATEDFEEDINGCORKDRILLERS CUNHA J 1 Introduction 2 Material and methods 2.1 System overview 2.1.1 Conveyor belt 2.1.2 Robotic arm 2.1.3 Gripper tool 2.1.4 Vision system 2.1.5 Processing units 2.2 Software architecture 2.3 Background model 2.4 Cork strip extraction 2.5 Determining the strip visible surface 3 Results and discussion 4 Conclusions Acknowledgments References DIAS 2014 1985 2000 A BISHOP 2006 C INFORMATIONSCIENCESTATISTICS PATTERNRECOGNITIONMACHINELEARNING GONZALEZADRADOS 2000 39 45 J COSTA 2006 210 219 A PANIAGUA 2009 927 936 B PROCEEDINGS6THINTERNATIONALCONFERENCEIMAGEANALYSISRECOGNITION PERCEPTUALLYRELEVANTPATTERNRECOGNITIONAPPLIEDCORKQUALITYDETECTION PANIAGUA 2011 15 32 B CASTRO 2010 425 432 O ANJOS 2010 2085 2090 O HARALICK 1973 610 621 K BURGES 1998 121 167 C CUNHAX2015X290 CUNHAX2015X290X296 CUNHAX2015X290XJ CUNHAX2015X290X296XJ UnderEmbargo 2017-07-06T00:00:00Z item S0261-3069(15)00290-3 S0261306915002903 10.1016/j.matdes.2015.05.037 313059 2015-07-06T04:16:16.986041-04:00 2015-10-05 true 1662628 MAIN 7 55689 849 656 IMAGE-WEB-PDF 1 si6 1499 51 239 si5 1315 51 206 si4 1532 51 226 si3 1804 51 285 si2 1092 51 147 si8 247 14 41 si7 315 14 54 si1 309 12 46 gr1 11615 80 458 fx1 true 30250 200 466 gr9 8861 199 267 gr8 17480 205 467 gr7 19065 197 450 gr6 24678 214 489 gr5 31611 333 244 gr4 27246 187 333 gr3 16416 254 222 gr2 25913 217 289 gr13 32832 330 466 gr12 42491 249 488 gr11 25257 200 311 gr10 18339 94 511 gr1 3429 38 219 fx1 true 6085 94 219 gr9 2391 163 219 gr8 6558 96 219 gr7 9227 96 219 gr6 6084 96 219 gr5 10583 164 120 gr4 13089 123 219 gr3 4674 164 143 gr2 17725 164 218 gr13 5566 155 219 gr12 6081 112 219 gr11 8166 141 219 gr10 3959 40 219 JMAD 7269 S0261-3069(15)00290-3 10.1016/j.matdes.2015.05.037 Elsevier Ltd Fig. 1 Side view of a cork strip. Fig. 2 The conveyor belt used. Fig. 3 OMRON SCARA robot. Fig. 4 The custom built gripper. Fig. 5 The lighting box mounted over the conveyor belt. Fig. 6 Software workflow. Fig. 7 Model build approach applied. Fig. 8 Example of the image subtraction method to detect cork strips. Fig. 9 Position and orientation of the extracted cork strip. Fig. 10 Patch extraction process, required to extract robust features from the cork images. Fig. 11 The different image channels from which texture features are extracted. From top to bottom: gray-scale, hue, saturation and value channels, respectively. Fig. 12 The Gray Level Co-occurrence Matrix estimated from an original image. Fig. 13 A simple support vector machine visualization. Table 1 The test set confusion matrix. Predicted Back Belly Side True Back 31 0 0 Belly 0 35 0 Side 0 0 36 Computer vision and robotic manipulation for automated feeding of cork drillers João Cunha a b ⁎ Rui Ferreira a Nuno Lau a b a Departamento de Eletrónica, Telecomunicações e Informática (DETI), Universidade de Aveiro, Campus Universitário de Santiago, 3810-193 Aveiro, Portugal Departamento de Eletrónica Telecomunicações e Informática (DETI) Universidade de Aveiro Campus Universitário de Santiago 3810-193 Aveiro Portugal b Instituto de Engenharia Electrónica e Telemática de Aveiro (IEETA), Universidade de Aveiro, Campus Universitário de Santiago, 3810-193 Aveiro, Portugal Instituto de Engenharia Electrónica e Telemática de Aveiro (IEETA) Universidade de Aveiro Campus Universitário de Santiago 3810-193 Aveiro Portugal ⁎ Corresponding author at: Instituto de Engenharia Electrónica e Telemática de Aveiro (IEETA), Universidade de Aveiro, Campus Universitário de Santiago, 3810-193 Aveiro, Portugal. Graphical abstract The production of cork stoppers is currently a process in rapid evolution. Where in the past hand labor was common, today we observe increasing attempts to introduce technologies that increase the productivity of production lines. One these example are automated cork drillers that produce thousands of cork stoppers per hour. In order to harness this increase in productivity to its full potential, it must the followed by other processes in the production line upstream of the driller, as for example the feeding of the latter. This article presents the application of computer vision techniques that extract information of cork strips that move on a conveyor belt, to obtain automated feeding of a cork driller using a robotic manipulator. Image Processing extracts information regarding the strip position and orientation, and also which side of the strip is visible. Thus the strip is consistently placed in the driller in order to extract stoppers from the best quality cork. The segmentation of the cork strips is obtained by background subtraction. To estimate the strip visible surface, we apply Machine Learning techniques that enable a robust classification given a set of features extracted from the cork texture. In the experiences carried out, we were able to obtain 100% classification rate with a test dataset of more than a hundred cork strips. Keywords Cork Computer vision Machine learning Forest products 1 Introduction Cork plays a key role in the Portuguese economy [1,2]. Portugal produces around 50% of the world cork. Additionally, in order to fulfill its manufacturing sector capacity, it is the fourth largest cork importer. In sum, Portugal is the largest cork exporter in the world, with a share of 67% of all cork exports. Of all these exports, more than 42% are natural cork stoppers. Even with the growing presence of other alternative stoppers, natural cork stoppers are very in demand, and remain one of the main forces of the cork industry. To keep up with this volume of sales, the manufacturing sector must strive for a competitive edge. While some decades ago it was characterized by a traditional family-run business model, the current cork industry has undergone significant changes in the recent decades. Technology, specially in the automation field played a key role. It is estimated that around 40 million cork stoppers are produced daily in Portugal alone. Contributing to this level of productivity are automated drillers can produce several thousand cork stoppers per hour. These advances require other stages of the production line to keep up with the productivity increase while keeping errors at minimum. We propose to address the problem of feeding the automated drillers, combining machine vision and robotic manipulation to produce a fast, flexible and intelligent system capable of providing the raw material to the machines at the required rate. To solve this problem, a system must be able to detect and identify cork strips, autonomously and robustly. This is a very challenging problem since cork is an heterogeneous material with a broad range of appearances. The cork industry colloquially terms the outer and inner part of the cork bark, the back and the belly, respectively. Additionally, the system must also be able to identify the side of a cork strip. Therefore, the system must recognize three different surfaces. A promising solution to address the aforementioned issues is the application of Machine Learning [3] approaches. Machine Learning is a sub-field of Artificial Intelligence, that aims to develop and apply techniques that are able to learn directly from provided examples. Machine Learning has been successfully applied in a variety of fields such as Computer Vision, Natural Language Processing, among others. In the context of this work, Machine Learning provides a powerful alternative in order to develop a system to automate the feeding of the drillers. One can obtain with relative ease, numerous examples of cork strips to train learning algorithms. Related work pertaining the application of Computer Vision and Machine Learning in the cork industry has mostly focused on quality assessment of either planks [4] or stoppers [5–8]. Most works strive to learn from human interpretable features in order to draw comparisons with human experts. However this requires a domain knowledge that is not always available. In our work we learn from features commonly applied in the literature for surface analysis. To the best of the authors knowledge, this work represents the first development of a system designed to identify which cork surface is visible in an image. The remaining paper is structured as follows. Section 2.1 presents an overview of the components comprising the vision and manipulation system. This section also provides detailed descriptions regarding the developed work at the software level. The experiments carried out and the results obtained are presented in Sections 3 and 4 concludes the paper. 2 Material and methods Cork presents many interesting properties that help explain the wide variety of applications, ranging from construction material to fashion accessories [9]. Despite its varied use, one of the cork main applications is the production of wine stoppers. Cork stoppers represent an environmentally friendly alternative to more modern synthetic stoppers made of aluminum or plastic. Cork wine stoppers can be obtained from single cork blocks or from agglomerated granular particles that usually result from byproducts of other production processes. In the first case, cork planks are cut into long strips with roughly a cork wide. Driller machines punch cylinders of cork that make up a whole stopper. The machines are manually operated and requires great skill. Since cork is an heterogeneous material, operators need to avoid imperfections and look for the best material to extract the stoppers. This slows down the production process and as a skilled worker can produce twenty thousand stoppers a day. The alternative is to automate this process with robotic punching machines. These machines compromise the ability to avoid the material imperfections with an unparalleled productivity. Each machine can produce several thousand stoppers per hour. In order to minimize waste, the automated production process assumes that cork strips are placed in the same position. This way stoppers can be extracted from inner part of the cork, or the belly. Fig. 1 presents a side view of a cork strip, indicating the belly and the back of the cork. With the increased productivity of the driller machines, the bottleneck of the production process becomes the feeding process. If manually performed, it is a rather dull task that may carry some risks. This opens the opportunity further automate the production line, by automating the feeding process. To supply cork strips, a robotic arm is used. In order to maintain a simple conveyor system, computer vision techniques are used to detect a cork strip, estimate the position and orientation and determine the visible side in the image. The following subsections present the developed system, from both the hardware and software perspectives. 2.1 System overview The following presents the overall system. The goal is to able to automate the feeding of the drillers, speeding up the process while freeing human workers for other tasks. In order to accomplish this goal we designed a system composed of five main components: a conveyor belt, a robotic arm, a gripper tool, a vision system and the processing units. 2.1.1 Conveyor belt The main purpose of conveyor belt is to transport cork strips to the robotic manipulator. The belt is composed by a single uniform color that contrasts with the cork strips. The color used in our experiments was a dark green, however almost any other color is usable as long as the contrast requirement is met. It moves the strips at an adjustable constant speed and a digital encoder is a coupled to one of the conveyor axles to allow tracking of the moving strips (see Fig. 2 ). 2.1.2 Robotic arm The robotic arm is expected to pickup the incoming cork strips and place them inside the driller. The arm is positioned besides the conveyor belt being able to manipulate strips on a portion of the belt length. The manipulator applied is 4 Dof SCARA robotic arm by OMRON presented in Fig. 3 . The SCARA arm can only move along the three main Cartesian directions. In order to rotate the strips we coupled a custom made gripper tool. 2.1.3 Gripper tool The robotic arm was extended with the addition of a custom made gripper tool to pickup and rotate the strips placing them in the correct feeding orientation. This allows the application of a Cartesian manipulator in this type of tasks. The length of the tool arm was fixed at 20cm to allow a broad range of incoming strip orientations. The gripper is actuated by pressurized air which allows for a firm grip without damaging the cork [10]. All the development of the gripper tool was made by Azevedos Industria [11] (see Fig. 4 ). 2.1.4 Vision system The main focus of our contribution is the development of a vision system capable of detecting and identifying the cork strips that move along the conveyor belt. For initial stages of development a Microsoft Kinect depth sensor was considered. However, the large minimum range coupled with the low resolution of color images restricted the use of the sensor. With a correct placement directly on top of the conveyor belt a PtGrey Chameleon [12] camera proved sufficient. To avoid changes in lighting conditions a lighting a box was built and placed over the conveyor belt creating an area of controlled light. 2.1.5 Processing units The main processing unit acts as the brain of the system. It is a personal computer responsible for processing the images capture by the camera, extract the information regarding the position, the orientation and the visible surface of the strip. Additionally, there are two controllers, the robotic arm and the tool controllers. The robotic arm controller communicates with the computer, receiving information about the strips positions, orientations and visible surfaces. It is responsible for controlling the arm joints to move the gripper to the desired position. Additionally, conveyor encoder is connected to the arm controller, which integrates this information to track the strips moving on the conveyor belt. The tool controller is connected to arm controller and is responsible for rotating the strips to the correct feeding orientation and closing and opening the gripper, to drop and pick up cork strips, respectively (see Fig. 5 ). 2.2 Software architecture To better support the development, we chose some software frameworks that have become a standard in their areas. Although open-source, there was a special care in choosing frameworks with licenses that are compatible with commercial applications. The main framework of the system is Robot Operating System [13] (ROS). This framework created a big impact among the scientific community by defining a middleware for publisher-subscriber model, over a network of computers, in a transparent way for the developers. By defining a custom serialization ROS enables the development of in multiple programming languages. Created under an open-source philosophy, there is currently a large community of researchers that release their research through off-the-shelf ROS modules. Among these modules there drivers for commonly applied sensors in Robotics, such as cameras for computer vision applications. The Open Computer Vision (OpenCV) is current the standard choice for computer vision applications. It implements a broad collection of computer vision algorithms, spanning from basic standard operations such as image segmentation or morphological analysis, to advanced state-of-art methods. ROS integrates OpenCV, allowing interchangeability of each corresponding data models. To fulfill the goal of extracting the cork strips from the image, a pipeline was defined with three stages. The first stage builds a background model of the scene of the camera field of view. The second state uses the most recent background model and performs a background subtraction, obtaining the cork strips moving along the conveyor belt. The third and final stage of the pipeline performs a validation to guarantee only cork strips are being processed and extracts information about the position, orientation and visible surface. Fig. 6 presents the workflow diagram to better visualize the developed vision pipeline. 2.3 Background model The material used in the conveyor belt is highly reflective. In combination with the position of the light sources of the lighting box, this creates white areas in the images, corresponding to the reflected light. By producing non-uniform colored areas in the image, classic color segmentation approaches can not extract the cork strips from the background in a robust manner. Therefore we applied a background model building technique that, from a set of images, computes the most likely color value for each pixel in the image. The method estimates a probabilistic distribution based on mixture of gaussians [14]. The applied method is available off-the-shelf in OpenCV in the class BackgroundSubtractorMOG2 and was applied with default parameters. The process is extremely fast being able to update the model in real-time. Usually a full sweep of the entire belt is enough to compute a good background, which amounts to 5–10s, depending on the belt speed. In Fig. 7 a an example image of the camera field of view is presented. Fig. 7b presents an example of a computed background model after several images of the conveyor moving without cork strips. While the images are very similar, Fig. 7b appears smoothed when compared to Fig. 7a, due to the use of gaussians distributions. 2.4 Cork strip extraction The presence of a model of the background image enables a simple background subtraction in order to obtain the cork strips moving on the conveyor belt. However in order to avoid noise created by imperfections on the material of the belt or shadows projected by the presence of the cork strips, the subtraction is performed on HSV color space. This allows for a weighted difference metric, where variations in luminance are ignored whereas variations in hue are highlighted. Fig. 8 visually represents the process described above. In Fig. 8a a cork moves along the conveyor belt and enters the field of view of the camera. With the model computed in Fig. 7b, the subtraction yields the image in Fig. 8b. The subtracted image is further refined to fill eventual holes produced by darker regions of the cork. Analyzing the image blobs, we can extract a variety of information. First the blobs are validated by area in order to discard spurious artifacts subsisting in the image. The valid blobs are further processed to extract information regarding position and orientation. Fig. 9 presents a visualization of the information the extracted of a cork strip. In red we observe the minimum are rectangle enclosing the image blob representing the cork strip. From the minimum area rectangle, the inscribed eclipse is extracted from which the centroid and orientation of the strip are calculated. 2.5 Determining the strip visible surface This is the most challenging step of the developed pipeline. The goal is to determine which surface of the cork strip is facing the camera. This is extremely important as it will define how the robotic arm will feed the strip to the driller. Usually strips should be delivered with the outer part of the cork facing upwards. This way the driller can extract the stoppers from the higher quality material. Delivering a strip with the wrong orientation will most likely produce unusable stoppers with defects. On the other hand, cork presents an extreme broad range of textures where it is not uncommon to find white mold speckles. It becomes very difficult to transcribe to a few lines of code the space of all possible combinations of cork appearances. In this context, Machine Learning provides a powerful alternative to find a solution to this problem. Instead to hand-code a solution, we simply provide examples of images and apply a learning algorithm to train a classifier that is able to distinguish the different surfaces of the cork strips. Modern approaches are able to associate the examples provided to the desired outputs, and generalize to previously unseen examples afterwards. In order to apply Machine Learning techniques, we first need to extract features from the cork strip images. In order to produce robust features, from Fig. 9, the blob corresponding to the strip is aligned with the image axis, from which the largest inscribed rectangle is extracted [15]. This produces an image patch of the cork that is used for classification. In Fig. 10 , we can observe the visualization of the largest inscribed rectangle and the patch extracted. In order to analyze all the information regarding the texture of the cork, we extract information from all the channels of the image, in HSV color space and a gray-scale image. The separate channels are presented in Fig. 11 . From each channel the Gray Co-occurrence Level Matrix (GLCM) [16] is calculated. The GLCM method is a common method to extract information regarding the texture of an image. Considering an image discretized in N levels, the GLCM calculates a N × N matrix which simply counts the number of transitions between to given levels along an offset in the source image. Fig. 12 illustrates the application of the GLCM method. From the GLCM matrix we extract five features, Energy, Correlation, Homogeneity, Contrast and Entropy presented from Eqs. (1)–(5). Additionally for each image channel the mean value and variance is calculated. In total seven features are extracted for each of the for image channels processed, which amounts to 28 features used for classification of each cork strip detected. (1) Energy = ∑ i , j = 1 N p ( i , j ) 2 (2) Correlation = ∑ i , j = 1 N ( i - μ i ) ( j - μ j ) p ( i , j ) σ i σ j (3) Homogeneity = ∑ i , j = 1 N p ( i , j ) 1 + | i - j | (4) Contrast = ∑ i , j = 1 N | i - j | 2 p ( i , j ) 2 (5) Contrast = ∑ i , j = 1 N - ln ( p ( i , j ) ) p ( i , j ) Having defined the set of features to be used to classify the different cork surfaces, we then need to train a classifier using example images. For this classification task, we chose to apply the Support Vector Machine (SVM) [17] method. Note that other classifiers can be applied, such as neural networks or random forests. The classical SVM algorithm is a binary classifier. Using a kernel function a feature vector is mapped to a higher-dimensional space. In this space the SVM builds a decision boundary that maximizes the distance between the two classes. The samples that are closest to the decision boundary hyperplane are called the support vectors. Fig. 13 depicts a visualization of a two-dimensional, two-class Support Vector Machine. This technique has since been extended to multiple classes. In our approach, we apply one-versus-all SVMs, in which one SVM is trained for each class, and during classification the final class is defined by the SVM with the largest response. To obtain a non-linear decision boundary, a radial basis function kernel is used. To reduce the computational load, this stage of the pipeline, from feature extraction to classification, is only executed if a cork strip is detected in an area around the middle of the image. When a cork strip is detected and identified, its position and orientation is transformed into the robotic arm coordinate frame and the information is sent to the latter. The robotic arm then tracks the cork strip using the encoder information and when the strip enters the reachable area, the strip is picked up and feeded in the driller, depending on the visible surface identified. 3 Results and discussion To test our approach we used a dataset containing hundreds of cork strips covering a broad range of textures and sizes, representing up to a certain degree the different kinds of corks processed in the industry. As in typical Machine Learning applications, the dataset was sub-divided in a train and test datasets. In the former the data is labelled with the correct desired output and used to train the SVMs. The latter contains examples of unknown and previously unseen cork strips that are used to test the performance of the classifiers. The datasets are composed in the following manner. Train Test Belly 113 31 Back 101 35 Side 94 36 Training was performed using a grid search over the classifier parameters. After the grid search, the optimal parameters were the following. The width of the radial basis function σ was 0.1, σ = 0.1 and the parameter of the cost a misclassification was the common default value C = 1 . In total 68 support vectors were obtained. After the classifiers are trained, the samples in the test dataset are placed on the conveyor belt. All cork strips are detected and correctly identified in both the train and test datasets. Table 1 presents the confusion matrix for the cork strip classifiers in the test dataset. 4 Conclusions The article presents the application of computer vision and machine learning approaches to solve a problem of feeding cork strips into drillers. The overall system is described and the developed vision pipeline is presented, detailing each stage. The developed is able to correctly detect cork strips moving on a conveyor belt in real-time. Machine Learning approaches have proven fruitful, being able to correctly identify all previously unseen cork strips. Despite good results obtained, we cannot assume that we had access to all possible types of cork in existence. Further results with increasingly larger datasets are imperative in order to assess the limits of the system. Additionally, tests should be carried out to evaluate to contribution of the different features extracted. Due to logistic constraints, the carried out experiments do not include manipulation. While in early tests the cork strips were successfully manipulated, a load test should be carried out to find how many strips can be processed in a given amount of time. Acknowledgments The work presented was funded by Project PRODUTECH PTI (number 13851) – New Processes and Innovative Technologies for the Production Technologies Industry, through the Incentive System for Technology Research and Development in Companies (SI I&DT), under the Competitive Factors Thematic Operational Programme, of the Portuguese National Strategic Reference Framework, and European Regional Development Fund. The authors would like to acknowledge Azevedos Industria valuable contributions throughout the development of this work. References [1] P.C. Association, 2013 anual report, (accessed .09.14). [2] A. Dias J. Boschmonart-Rives S. Gonzalez-Garcia M. Demertzi X. Gabarrell L. Arroja Analysis of raw cork production in Portugal and Catalonia using life cycle assessment Int. J. Life Cycle Assess. 19 10 2014 1985 2000 [3] C.M. Bishop Pattern recognition and machine learning Information Science and Statistics Vol. 4 2006 Springer [4] J.R. Gonzalez-Adrados F. Lopes H. Pereira Quality grading of cork planks with classification models based on defect characterisation Holz als Roh und Werkstoff 58 1-2 2000 39 45 [5] A. Costa H. Pereira Decision rules for computer vision quality classification of wine natural cork stoppers Am. J. Enol. Viticul. 57 2 2006 210 219 [6] J. Lima, P. Costa, A modular approach to real-time cork classification using image processing, in: Proceedings of the 10th IEEE International Conference on Emerging Technologies and Factory Automation, Catania, Italy, 2005. [7] B. Paniagua P. Green M. Chantler M.A. Vega-Rodríguez J.A. Gómez-Pulido J.M. Sánchez-Pérez Perceptually relevant pattern recognition applied to cork quality detection M. Kamel A. Campilho Proceedings of the 6th International Conference on Image Analysis and Recognition Lecture Notes in Computer Science Vol. 5627 2009 Springer Berlin Heidelberg Halifax, Canada 927 936 [8] B. Paniagua M. Vega-Rodriguez J. Gomez-Pulido J. Sanchez-Perez Automatic texture characterization using gabor filters and neurofuzzy computing Int. J. Adv. Manuf. Technol. 52 1-4 2011 15 32 [9] O. Castro J. Silva T. Devezas A. Silva L. Gil Cork agglomerates as an ideal core material in lightweight structures Mater. Des. 31 1 2010 425 432 [10] O. Anjos H. Pereira M. Rosa Tensile properties of cork in the tangencial direction:variation with quality, porosity, density and radial position in the cork plank Mater. Des. 31 4 2010 2085 2090 [11] Azevedos Indústria – Máquinas e Equipamentos Industriais, S.A., Rua de Santo António, n°1 (Aldeia Nova) Apartado 3 4536-909 Lourosa, Portugal. [12] I. Point Grey Research, Ptgrey chameleon model, (accessed .09.14). [13] M. Quigley, K. Conley, B. Gerkey, J. Faust, T. Foote, J. Leibs, R. Wheeler, A.Y. Ng, Ros: an open-source robot operating system, in: ICRA workshop on open source software, Vol. 3, 2009, p. 5. [14] Z. Zivkovic, Improved adaptive Gausian mixture model for background subtraction, in: J. Kittler, M. Petrou, M. Nixon (Eds.), Proceedings of the 17th International Conference Pattern Recognition, Vol. 2, United Kingdom, 2014, pp. 28–31. [15] J. Tuszynski, Largest inscribed rectangle, (accessed .09.14) (July 2010). [16] K. Haralick K. Shanmugan O. Dinstain Textural features for image classification IEEE Trans. Syst., Man Cybernet. 3 6 1973 610 621 [17] C. Burges A tutorial on support vector machines for pattern recognition Knowl. Disc. Data Min. 2 2 1998 121 167 "
    },
    {
        "doc_title": "Special Issue Robótica 2014",
        "doc_scopus_id": "84946481619",
        "doc_doi": "10.1007/s10846-015-0258-3",
        "doc_eid": "2-s2.0-84946481619",
        "doc_date": "2015-09-16",
        "doc_type": "Editorial",
        "doc_areas": [
            {
                "area_name": "Software",
                "area_abbreviation": "COMP",
                "area_code": "1712"
            },
            {
                "area_name": "Control and Systems Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2207"
            },
            {
                "area_name": "Mechanical Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2210"
            },
            {
                "area_name": "Industrial and Manufacturing Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2209"
            },
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            },
            {
                "area_name": "Electrical and Electronic Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2208"
            }
        ],
        "doc_keywords": [],
        "doc_abstract": null,
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Vineyard skeletonization for autonomous robot navigation",
        "doc_scopus_id": "84933049323",
        "doc_doi": "10.1109/ICARSC.2015.16",
        "doc_eid": "2-s2.0-84933049323",
        "doc_date": "2015-05-04",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            },
            {
                "area_name": "Computer Science Applications",
                "area_abbreviation": "COMP",
                "area_code": "1706"
            },
            {
                "area_name": "Human-Computer Interaction",
                "area_abbreviation": "COMP",
                "area_code": "1709"
            }
        ],
        "doc_keywords": [
            "Autonomous navigation",
            "Autonomous robot navigation",
            "Expert recommendations",
            "Monitoring robot",
            "Navigation paths",
            "Positional errors",
            "Real trajectories",
            "Thinning algorithm"
        ],
        "doc_abstract": "© 2015 IEEE.Prior knowledge of possible routes is undoubtedly an added value for autonomous navigation in irregular agricultural terrains. This information is particularly important when it involves the navigation of a monitoring robot, which necessarily carries a wide range of expensive sensors and when the vineyard presents a non-uniform configuration and extends over a very highly uneven terrain. In such case, a small navigation positional error can result in a large vertical deviation and consequently, a serious fall, which may damage or even destroy the robot. This article presents an automated way of deriving possible routes in this kind of terrain using three curve-skeleton algorithms for the 3D surfaces of the vineyard where the robot may navigate. The skeleton curves and real trajectory were represented in a graphical user OpenGL application developed for this purpose. A thinning, a geometric and a distance field algorithm were used for this study. The skeleton curves were compared with a real navigation path made by an expert when driving a tractor while spraying of the vineyard. In order to meet expert recommendations, the thinning algorithm was validated as the most suitable to achieve the aim of the study as it minimizes the quadratic average distance function applied to the skeleton points and the real trajectory. The limits of the most suitable curve-skeleton will be used as decision making points to establish navigation criteriafor next step path planning.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Contextual policy search for generalizing a parameterized biped walking controller",
        "doc_scopus_id": "84933039217",
        "doc_doi": "10.1109/ICARSC.2015.43",
        "doc_eid": "2-s2.0-84933039217",
        "doc_date": "2015-05-04",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            },
            {
                "area_name": "Computer Science Applications",
                "area_abbreviation": "COMP",
                "area_code": "1706"
            },
            {
                "area_name": "Human-Computer Interaction",
                "area_abbreviation": "COMP",
                "area_code": "1709"
            }
        ],
        "doc_keywords": [
            "Controller parameter",
            "Flexible robots",
            "Humanoid robot",
            "Learning control",
            "Locomotion controllers",
            "Multiple contexts",
            "Real valued vector",
            "Relative entropy"
        ],
        "doc_abstract": "© 2015 IEEE.We investigate learning of flexible Robot locomotion controller, i.e., the controllers should be applicable for multiple contexts, for example different walking speeds, various slopes of the terrain or other physical properties of the robot. In our experiments, contexts are desired walking linear speed and the direction of the gait. Current approaches for learning control parameters of biped locomotion controllers are typically only applicable for a single context. They can be used for a particular context, for example to learn a gait with highest speed, lowest energy consumption or a combination of both. The question of our research is, how can we obtain a flexible walking controller that controls the robot (near) optimally for many different contexts? We achieve the desired flexibility of the controller by applying the recently developed contextual relative entropy policy search(REPS) method. With such a contextual policy search algorithm, we can generalize the robot walking controller for different contexts, where a context is described by a real valued vector. In this paper we also extend the contextual REPS algorithm to learn a non-linear policy instead of a linear one over the contexts. In order to validate our method, we perform a simulation experiment using a simulated NAO humanoid robot. The robot now learns a policy to choose the controller parameters for a continuous set of walking speeds and directions.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Improving the kicking accuracy in a soccer robot",
        "doc_scopus_id": "84955480270",
        "doc_doi": "10.1145/2695664.2695862",
        "doc_eid": "2-s2.0-84955480270",
        "doc_date": "2015-04-13",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Software",
                "area_abbreviation": "COMP",
                "area_code": "1712"
            }
        ],
        "doc_keywords": [
            "Accuracy",
            "Friction parameters",
            "Heuristic approach",
            "Kicking device",
            "Middle-Size League",
            "Physical characteristics",
            "RoboCu",
            "Target direction"
        ],
        "doc_abstract": "Copyright 2015 ACM.Most of the soccer robots in the Middle Size League of Robo-Cup use electromagnetic kicking devices that allow to kick the ball with adjustable strength. In order to be efficient to score, the kicking strength should be calculated according to several parameters, namely the physical characteristics of the kicking device, the distance to the target, the velocity of the robot and the floor friction parameters. Moreover, the kicking decision should be taken at a moment in which the actual movement of the robot would result in the ball being released to the target direction, even if it is not physically aligned with it. This paper proposes an algorithm to improve the kicking accuracy, taking into account the described parameters, in a heuristic approach. The experimental results presented in this paper show the effectiveness of the proposed solution to improve the efficiency of the kicking device.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "A Methodology for Creating an Adapted Command Language for Driving an Intelligent Wheelchair",
        "doc_scopus_id": "84945489233",
        "doc_doi": "10.1007/s10846-015-0194-2",
        "doc_eid": "2-s2.0-84945489233",
        "doc_date": "2015-02-03",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Software",
                "area_abbreviation": "COMP",
                "area_code": "1712"
            },
            {
                "area_name": "Control and Systems Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2207"
            },
            {
                "area_name": "Mechanical Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2210"
            },
            {
                "area_name": "Industrial and Manufacturing Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2209"
            },
            {
                "area_name": "Electrical and Electronic Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2208"
            },
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            }
        ],
        "doc_keywords": [
            "Command Language",
            "Data analysis system",
            "Input sequence",
            "Intelligent wheelchair",
            "Multi-modal interfaces",
            "Physical constraints",
            "Statistical evidence",
            "User Modeling"
        ],
        "doc_abstract": "© 2015, Springer Science+Business Media Dordrecht.Intelligent wheelchairs (IW) are technologies that can increase the autonomy and independence of elderly people and patients suffering from some kind of disability. Nowadays the intelligent wheelchairs and the human-machine studies are very active research areas. This paper presents a methodology and a Data Analysis System (DAS) that provides an adapted command language to an user of the IW. This command language is a set of input sequences that can be created using inputs from an input device or a combination of the inputs available in a multimodal interface. The results show that there are statistical evidences to affirm that the mean of the evaluation of the DAS generated command language is higher than the mean of the evaluation of the command language recommended by the health specialist (p value = 0.002) with a sample of 11 cerebral palsy users. This work demonstrates that it is possible to adapt an intelligent wheelchair interface to the user even when the users present heterogeneous and severe physical constraints.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Learning to Walk Fast: Optimized Hip Height Movement for Simulated and Real Humanoid Robots",
        "doc_scopus_id": "84945454328",
        "doc_doi": "10.1007/s10846-015-0191-5",
        "doc_eid": "2-s2.0-84945454328",
        "doc_date": "2015-02-01",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Software",
                "area_abbreviation": "COMP",
                "area_code": "1712"
            },
            {
                "area_name": "Control and Systems Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2207"
            },
            {
                "area_name": "Mechanical Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2210"
            },
            {
                "area_name": "Industrial and Manufacturing Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2209"
            },
            {
                "area_name": "Electrical and Electronic Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2208"
            },
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            }
        ],
        "doc_keywords": [
            "Biped walking",
            "Central pattern generator",
            "Covariance matrix adaptation evolution strategies",
            "Fourier basis functions",
            "Gait learning",
            "Generated trajectories",
            "Inverted pendulum model",
            "Numerical approaches"
        ],
        "doc_abstract": "© 2015, Springer Science+Business Media Dordrecht.The linear inverted pendulum model has been used predominantly to generate balanced humanoid walking. This model assumes that the hip height is fixed during the walk. In this paper, generating a fast walk is studied with the main focus on the effect of hip height movement. Our approach is based on modeling the hip height movement and learning its parameters in order to generate a fast walk. The hip height trajectory is generated using Fourier basis functions. The generated trajectory is the input to programmable Central Pattern Generators (CPGs) in order to modulate generated trajectories smoothly. The inverted pendulum model is utilized to model a balanced walking. A numerical approach is presented to control inverted pendulum dynamics. Covariance Matrix Adaptation Evolution Strategy (CMA-ES) is employed to search for appropriate hip height trajectory and walking parameters that optimize walking speed. This approach has been tested not only to obtain fast forward walk but also a fast side walk. Experiments are conducted on both simulated and real NAO robots. The results show that the change from the learned forward walk to learned side walk is performed stably, which confirm the important role of using CPGs. The comparison of the results of the proposed gait model (and development approach) with those obtained using fixed hip height also shows that fixed height walking is slower than variable height walking.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Adapted Control Methods for Cerebral Palsy Users of an Intelligent Wheelchair",
        "doc_scopus_id": "84921068425",
        "doc_doi": "10.1007/s10846-013-0010-9",
        "doc_eid": "2-s2.0-84921068425",
        "doc_date": "2015-02-01",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Software",
                "area_abbreviation": "COMP",
                "area_code": "1712"
            },
            {
                "area_name": "Control and Systems Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2207"
            },
            {
                "area_name": "Mechanical Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2210"
            },
            {
                "area_name": "Industrial and Manufacturing Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2209"
            },
            {
                "area_name": "Electrical and Electronic Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2208"
            },
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            }
        ],
        "doc_keywords": [
            "Cerebral palsy",
            "Electric powered wheelchairs",
            "Intelligent robotics",
            "Intelligent wheelchair",
            "Involuntary movements",
            "Realistic simulators",
            "Severe disabilities",
            "Shared control"
        ],
        "doc_abstract": "© 2014, Springer Science+Business Media Dordrecht.The development of an intelligent wheel chair (IW) platform that may be easily adapted to any commercial electric powered wheelchair and aid any person with special mobility needs is the main objective of the IntellWheels project. To be able to achieve this main objective, three distinct control methods were implemented in the IW: manual, shared and automatic. Several algorithms were developed for each of these control methods. This paper presents three of the most significant of those algorithms with emphasis on the shared control method. Experiments were performed by users suffering from cerebral palsy, using a realistic simulator, in order to validate the approach. The experiments revealed the importance of using shared (aided) controls for users with severe disabilities. The patients still felt having complete control over the wheelchair movement when using a shared control at a 50 % level and thus this control type was very well accepted. Thus it may be used in intelligent wheelchairs since it is able to correct the direction in case of involuntary movements of the user but still gives him a sense of complete control over the IW movement.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Batch Reinforcement Learning for Robotic Soccer Using the Q-Batch Update-Rule",
        "doc_scopus_id": "84945484531",
        "doc_doi": "10.1007/s10846-014-0171-1",
        "doc_eid": "2-s2.0-84945484531",
        "doc_date": "2015-01-09",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Software",
                "area_abbreviation": "COMP",
                "area_code": "1712"
            },
            {
                "area_name": "Control and Systems Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2207"
            },
            {
                "area_name": "Mechanical Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2210"
            },
            {
                "area_name": "Industrial and Manufacturing Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2209"
            },
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            },
            {
                "area_name": "Electrical and Electronic Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2208"
            }
        ],
        "doc_keywords": [
            "Adversarial environments",
            "Amount of interaction",
            "Batch reinforcement learning",
            "Class of methods",
            "Q-batch",
            "Reinforcement learning method",
            "Robotic soccer",
            "Robotics applications"
        ],
        "doc_abstract": "© 2015, Springer Science+Business Media Dordrecht.Reinforcement Learning is increasingly becoming a valuable alternative to tackle many of the challenges existing in a semi-structured, non-deterministic and adversarial environment such as robotic soccer. Batch Reinforcement Learning is a class of Reinforcement Learning methods characterized by processing a batch of interactions. By storing all past interactions, Batch RL methods are extremely data-efficient which makes this class of methods very appealing for robotics applications, specially when learning directly on physical robotic platforms.This paper presents the application of Batch Reinforcement Learning to obtain efficient robotic soccer controllers on physical platforms. To learn the controllers we propose the application of Q-Batch, a novel update-rule that exploits the episodic nature of the interactions in Batch Reinforcement Learning. The approach was validated in three different tasks with increasing difficulty. Results show the proposed approach is able to outperform hand-coded policies, for all the tasks, in a reduced amount of time. Additionally, for one of the tasks, a comparison between Q-Batch and Q-learning is carried out, and results show that, Q-Batch obtains better policies than Q-learning for the same amount of interaction time.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Model-based relative entropy Stochastic search",
        "doc_scopus_id": "84965143108",
        "doc_doi": null,
        "doc_eid": "2-s2.0-84965143108",
        "doc_date": "2015-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Computer Networks and Communications",
                "area_abbreviation": "COMP",
                "area_code": "1705"
            },
            {
                "area_name": "Information Systems",
                "area_abbreviation": "COMP",
                "area_code": "1710"
            },
            {
                "area_name": "Signal Processing",
                "area_abbreviation": "COMP",
                "area_code": "1711"
            }
        ],
        "doc_keywords": [
            "Black-box optimization",
            "Data distribution",
            "Multi-modal optimization",
            "Noisy objective function",
            "Objective functions",
            "Pre-mature convergences",
            "Quadratic approximation",
            "Stochastic search algorithms"
        ],
        "doc_abstract": "Stochastic search algorithms are general black-box optimizers. Due to their ease of use and their generality, they have recently also gained a lot of attention in operations research, machine learning and policy search. Yet, these algorithms require a lot of evaluations of the objective, scale poorly with the problem dimension, are affected by highly noisy objective functions and may converge prematurely. To alleviate these problems, we introduce a new surrogate-based stochastic search approach. We learn simple, quadratic surrogate models of the objective function. As the quality of such a quadratic approximation is limited, we do not greedily exploit the learned models. The algorithm can be misled by an inaccurate optimum introduced by the surrogate. Instead, we use information theoretic constraints to bound the 'distance' between the new and old data distribution while maximizing the objective function. Additionally the new method is able to sustain the exploration of the search distribution to avoid premature convergence. We compare our method with state of art black-box optimization methods on standard uni-modal and multi-modal optimization functions, on simulated planar robot tasks and a complex robot ball throwing task. The proposed method considerably outperforms the existing approaches.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Generalized learning to create an energy efficient ZMP-based walking",
        "doc_scopus_id": "84958549728",
        "doc_doi": "10.1007/978-3-319-18615-3_48",
        "doc_eid": "2-s2.0-84958549728",
        "doc_date": "2015-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [],
        "doc_abstract": "© Springer International Publishing Switzerland 2015.In biped locomotion, the energy minimization problem is a challenging topic. This problem cannot be solved analytically since modeling the whole robot dynamics is intractable. Using the inverted pendulum model, researchers have defined the Zero Moment Point (ZMP) target trajectory and derived the corresponding Center of Mass (CoM) motion trajectory, which enables a robot to walk stably. A changing vertical CoM position has proved to be crucial factor in reducing mechanical energy costs and generating an energy efficient walk [1]. The use of Covariance Matrix Adaptation Evolution Strategy (CMA-ES) on a Fourier basis representation, which models the vertical CoM trajectory, is investigated in this paper to achieve energy efficient walk with specific step length and period. The results show that different step lengths and step periods lead to different learned energy efficient vertical CoM trajectories. For the first time, a generalization approach is used to generalize the learned results, by using a programmable Central Pattern Generator (CPG) on the learned results. Online modulation of the trajectory is performed while the robot changes its walking speed using the CPG dynamics. This approach is implemented and evaluated on the simulated and real NAO robot.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "On the progress of soccer simulation leagues",
        "doc_scopus_id": "84958524045",
        "doc_doi": "10.1007/978-3-319-18615-3_49",
        "doc_eid": "2-s2.0-84958524045",
        "doc_date": "2015-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [],
        "doc_abstract": "© Springer International Publishing Switzerland 2015.Soccer simulation league is one of the founding leagues of RoboCup. In this paper we discuss the past, present and planned future achievements and changes. Also we summarize the connections and interleague achievements of this league and provide an overview of the community contributions that made this league successful.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Collaborative behavior in soccer: The setplay free software framework",
        "doc_scopus_id": "84958523044",
        "doc_doi": "10.1007/978-3-319-18615-3_58",
        "doc_eid": "2-s2.0-84958523044",
        "doc_date": "2015-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [],
        "doc_abstract": "© Springer International Publishing Switzerland 2015.The Setplay Framework (available from SourceForge as free software) is composed of a C++ library (Project name: fcportugalsetplays), a fully functional RoboCup Simulation 2D demonstration team (fcportugalsetplaysagent2d), and a complete graphical tool (SPlanner), that can be used to design and plan the collaborative behavior between the soccer player agents. In order to demonstrate the usage of the Setplay library, a complete 2D simulation team, based on Agent2D, was developed. This example team uses the framework to execute previously planned collaborative behavior. This framework can be used both within simulated environments, such as the Robocup Soccer Simulation leagues, and with real soccer playing robots. This paper presents the free software Setplay Framework, and provides the necessary information for any team to use the framework with the goal of providing collaborative behavior to a team of soccer playing robots.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "A new approach for dynamic strategic positioning in RoboCup middle-size league",
        "doc_scopus_id": "84945909472",
        "doc_doi": "10.1007/978-3-319-23485-4_43",
        "doc_eid": "2-s2.0-84945909472",
        "doc_date": "2015-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Best position",
            "Cooperative tasks",
            "Large parts",
            "New approaches",
            "Robotic soccer",
            "Robotic soccer team",
            "Strategic positioning",
            "Team performance"
        ],
        "doc_abstract": "© Springer International Publishing Switzerland 2015.Coordination in multi-robot or multi-agent systems has been receiving special attention in the last years and has a prominent role in the field of robotics. In the robotic soccer domain, the way that each team coordinates its robots, individually and together, in order to perform cooperative tasks is the base of its strategy and in large part dictates the success of the team in the game. In this paper we propose the use of Utility Maps to improve the strategic positioning of a robotic soccer team. Utility Maps are designed for different set pieces situations, making them more dynamic and easily adaptable to the different strategies used by the opponent teams. Our approach has been tested and successfully integrated in normal game situations to perform passes in free-play, allowing the robots to choose, in real-time, the best position to receive and pass the ball. The experimental results obtained, as well as the analysis of the team performance during the last RoboCup competition show that the use of Utility Maps increases the efficiency of the team strategy.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "A skill-based architecture for pick and place manipulation tasks",
        "doc_scopus_id": "84945908825",
        "doc_doi": "10.1007/978-3-319-23485-4_45",
        "doc_eid": "2-s2.0-84945908825",
        "doc_date": "2015-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Manipulation task",
            "Pick and place",
            "Product customization",
            "Specific tasks",
            "Unstructured environments"
        ],
        "doc_abstract": "© Springer International Publishing Switzerland 2015.Robots can play a significant role in product customization but they should leave a repetitive, low intelligence paradigm and be able to operate in unstructured environments and take decisions during the execution of the task. The EuRoC research project addresses this issue by posing as a competition to motivate researchers to present their solution to the problem. The first stage is a simulation competition where Pick & Place type of tasks are the goal and planning, perception and manipulation are the problems. This paper presents a skill-based architecture that enables a simulated moving manipulator to solve these tasks. The heuristics that were used to solve specific tasks are also presented. Using computer vision methods and the definition of a set of manipulation skills, an intelligent agent is able to solve them autonomously. The work developed in this project was used in the simulation competition of EuRoC project by team IRIS and enabled them to reach the 5th rank.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Intelligent wheelchair driving: Bridging the gap between virtual and real intelligent wheelchairs",
        "doc_scopus_id": "84945901177",
        "doc_doi": "10.1007/978-3-319-23485-4_44",
        "doc_eid": "2-s2.0-84945901177",
        "doc_date": "2015-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Autonomous navigation",
            "Electric wheelchair",
            "Environment simulators",
            "Intelligent interface",
            "Intelligent robotics",
            "Intelligent simulations",
            "Intelligent wheelchair",
            "Multi-modal interfaces"
        ],
        "doc_abstract": "© Springer International Publishing Switzerland 2015.Wheelchairs are important locomotion devices for handicapped and senior people. With the increase in the number of senior citizens and the increment of people bearing physical deficiencies, there is a growing demand for safer and more comfortable wheelchairs. So the new Intelligent Wheelchair (IW) concept was introduced. Like many other robotic systems, the main capabilities of an intelligent wheelchair should be: autonomous navigation with safety, flexibility and capability of avoiding obstacles; intelligent interface with the user; communication with other devices. In order to achieve these capabilities a good testbed is needed on which trials and users’ training may be safely conducted. This paper presents an extensible virtual environment simulator of an intelligent wheelchair to fulfill that purpose. The simulator combines the main features of robotic simulators with those built for training and evaluation of prospective wheelchair users. Experiments with the real prototype allowed having results and information to model the virtual intelligent wheelchair. Several experiments with real users of electric wheelchairs (suffering from cerebral palsy) and potential users of an intelligent wheelchair were performed. The System Usability Score allowed having the perception of the users in terms of the usability of the IW in the virtual environment. The mean score was 72 indicating a satisfactory level of the usability. It was possible to conclude with the experiments that the virtual intelligent wheelchair and environment are usable instruments to test and train potential users.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Using reinforcement learning techniques to select the best action in setplays with multiple possibilities in robocup soccer simulation teams",
        "doc_scopus_id": "84923785935",
        "doc_doi": "10.1109/SBR.LARS.Robocontrol.2014.47",
        "doc_eid": "2-s2.0-84923785935",
        "doc_date": "2015-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            },
            {
                "area_name": "Computer Vision and Pattern Recognition",
                "area_abbreviation": "COMP",
                "area_code": "1707"
            },
            {
                "area_name": "Human-Computer Interaction",
                "area_abbreviation": "COMP",
                "area_code": "1709"
            },
            {
                "area_name": "Computer Graphics and Computer-Aided Design",
                "area_abbreviation": "COMP",
                "area_code": "1704"
            }
        ],
        "doc_keywords": [
            "Course of action",
            "Free software",
            "Independent agents",
            "Multi-agent reinforcement learning",
            "Multiple choice",
            "Reinforcement learning techniques",
            "RoboCup soccer",
            "Simulated agents"
        ],
        "doc_abstract": "© 2014 IEEE.Set plays are predefined collaborative coordinate actions that players from any sport can use to gain advantage over its adversaries. Recently, a complete framework for creation and execution of this kind of coordinate behavior by teams composed of multiple independent agents was launched as free software (the Set play Framework). In this paper, an approach based on Reinforcement Learning(RL) is proposed, that allows the use of experience to devise the better course of action in set plays with multiple choices. Simulations results show that the proposed approach allows a team of simulated agents to improve its performance against a known adversary team, achieving better results than previously proposed approaches using RL.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Invited paper: Multimodal interface for an intelligent wheelchair",
        "doc_scopus_id": "84921957503",
        "doc_doi": "10.1007/978-3-319-10891-9_1",
        "doc_eid": "2-s2.0-84921957503",
        "doc_date": "2015-01-01",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Industrial and Manufacturing Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2209"
            }
        ],
        "doc_keywords": [
            "Disabled individuals",
            "Electric wheelchair",
            "Environmental perceptions",
            "Human machine interaction",
            "Intelligent robotics",
            "Intelligent wheelchair",
            "IntellWheels",
            "Multi-modal interfaces"
        ],
        "doc_abstract": "© Springer International Publishing Switzerland 2015.Since the demographics of population, with respect to age, are continuously changing, politicians and scientists start to pay more attention to the needs of senior individuals. Additionally, the well-being and needs of disabled individuals are also becoming highly valued in the political and entrepreneurial society. Intelligent wheelchairs are adapted electric wheelchairs with environmental perception, semi-autonomous behaviour and flexible human-machine-interaction. This paper presents the specification and development of a user-friendlymultimodal interface, as a component of the IntellWheels Platform project. The developed prototype combines several input modules, allowing the control of the wheelchair through flexible user defined input sequences of distinct types (speech, facial expressions, head movements and joystick). To validate the effectiveness of the prototype, two experiments were performed with a number of individuals who tested the system firstly by driving a simulated wheelchair in a virtual environment. The second experiment was performed using the real IntellWheels wheelchair prototype. The results achieved proved that the multimodal interface may be successfully used by people, due to the interaction flexibility it provides.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "3D map and DGPS validation for a vineyard autonomous navigation system",
        "doc_scopus_id": "84907366060",
        "doc_doi": "10.1007/978-3-319-10380-8_59",
        "doc_eid": "2-s2.0-84907366060",
        "doc_date": "2015-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Industrial and Manufacturing Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2209"
            }
        ],
        "doc_keywords": [
            "Agricultural process",
            "Autonomous navigation systems",
            "Digital elevation model",
            "Dynamic trajectories",
            "Equipment selection",
            "Instrumentation",
            "Navigation error",
            "Navigation paths"
        ],
        "doc_abstract": "An autonomous DGPS navigation system must use an accurate threedimensional (3D) digital map. However, it is crucial to validate it using data collected in the field. One possible way to validate the map is to employ a vehicle driven by an expert to ensure that the trajectory is plotted within the boundaries of navigation paths. It is essential to take this care, especially when the terrain is very highly uneven and small differences in position may correspond to large vertical deviations. A small navigation error can result in a serious fall, which may damage or even destroy the vehicle. In the Douro Demarcated Region, in northern Portugal, the vineyard is planted on narrow terraces built on steep hills along the winding Douro River. This paper presents the results of a dynamic trajectory survey obtained from a real navigation procedure, carried out by an expert driving an instrumented tractor during the spraying of the vineyard. The results were obtained using a DGPS (accuracy = 2 cm) and compared to an existing Digital Elevation Model (DEM) of the vineyard already created by the authors' work group, with an average accuracy of 10 cm. The results are shown in a C# developed interface with OpenGL facilities, which enable the viewing of the 3D vineyard details. The results confirm the validation of the methodology previously adopted for map extraction and respective equipment selection. The trajectory of the tractor, including some maneuvers, is drawn within the inner and outer edges of each terrace or path that exists in the vineyard. The interface can also be used as an important tool in path planning to automatically extract the topology of the vineyard and to select the best path to carry out some vineyard tasks. © 2015 Springer International Publishing.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Strategy planner: Graphical definition of soccer set-plays",
        "doc_scopus_id": "84914155590",
        "doc_doi": "10.1016/j.datak.2014.10.001",
        "doc_eid": "2-s2.0-84914155590",
        "doc_date": "2014-11-01",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Information Systems and Management",
                "area_abbreviation": "DECI",
                "area_code": "1802"
            }
        ],
        "doc_keywords": [
            "Data and knowledge visualizations",
            "Execution time",
            "Graphical tools",
            "Research topics",
            "Robotic soccer",
            "Set-play",
            "Structured text",
            "System usability"
        ],
        "doc_abstract": "© 2014 Elsevier B.V. All rights reserved.One of the research topics on multi-agent systems focuses on the development of mechanisms such as plans to empower a team of agents to cooperate in order to perform complex tasks. In many cases, the definition of these plans are based on a specific and rather complex grammar and stored in structured text files. In the context of the 2D simulated Robotic Soccer domain, a set-play language was proposed to coordinate the execution of teammates' behaviors to improve a team's overall performance. The process of manually writing set-play definitions is hazardous and can benefit from the use of a graphical tool to reach new users and allow typical users to become more productive. This work presents such a tool for which several experiments were run to measure its usability with forty two users by having them perform a set of tasks for which their execution time, number errors and satisfaction were recorded. The tool reduced the previous average time required to completely define a set-play by 90% and enabled even non-expert users to use it. Moreover, users were on average satisfied with SPlanner having ranked it with a score of 77 (out of 100) using a System Usability Scale questionnaire.",
        "available": true,
        "clean_text": "serial JL 271546 291210 291773 291813 291866 291883 31 Data & Knowledge Engineering DATAKNOWLEDGEENGINEERING 2014-10-22 2014-10-22 2014-11-20T02:34:24 S0169-023X(14)00095-0 S0169023X14000950 10.1016/j.datak.2014.10.001 S300 S300.1 FULL-TEXT 2015-05-14T05:25:39.406626-04:00 0 0 20141101 20141130 2014 2014-10-22T16:39:00.859284Z articleinfo articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid hubeid indexeddate issn issnnorm itemstage itemtransactionid itemweight openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sectiontitle sortorder srctitle srctitlenorm srctype ssids alllist content subj subheadings suppl tomb volfirst volissue volumelist yearnav figure table body mmlmath affil appendices articletitle auth authfirstini authfull authkeywords authlast footnotes primabst pubtype ref vitae 0169-023X 0169023X true 94 94 PA Volume 94, Part A 6 110 131 110 131 201411 November 2014 2014-11-01 2014-11-30 2014 Regular Articles article fla Copyright © 2014 Elsevier B.V. All rights reserved. STRATEGYPLANNERGRAPHICALDEFINITIONSOCCERSETPLAYS CRAVO J 1 Introduction 2 Related work 3 Set-play framework 3.1 Set-play formal definition 3.2 Execution of a set-play 4 Graphical definition of set-plays 4.1 Interface design 4.2 Execution flow of a set-play 4.3 Defining actions for participants 4.4 Positions of players and action targets 5 Promoting the usability of the tool 5.1 Defining set-plays using recorded matches 5.2 Easing the creation of set-plays 5.3 Enforcing logical constraints in the definition of set-plays 5.4 Simplifying the definition of steps in a set-play 5.5 Estimating automatically the abort times for steps in a set-play 6 Tool validation methodology 7 Results and discussion 7.1 Robustness of the set-plays import process 7.2 Effectiveness of the developed set-plays 7.3 SPlanner usability 8 Conclusions Appendix A Example set-play definition of a corner-kick References REIS 2001 175 197 L BALANCINGREACTIVITYSOCIALDELIBERATIONINMULTIAGENTSYSTEMSROBOCUPREALWORLDAPPLICATIONSSELECTEDPAPERSECAI2000WORKSHOPADDITIONALCONTRIBUTIONS SITUATIONBASEDSTRATEGICPOSITIONINGFORCOORDINATINGATEAMHOMOGENEOUSAGENTS DASHTI 2006 219 229 H ROBOCUP2005ROBOTSOCCERWORLDCUPIX DYNAMICPOSITIONINGBASEDVORONOICELLSDPVC AKIYAMA 2008 377 384 H ROBOCUP2007ROBOTSOCCERWORLDCUPXI MULTIAGENTPOSITIONINGMECHANISMINDYNAMICENVIRONMENT NAKANISHI 2008 488 495 R ROBOCUP2007ROBOTSOCCERWORLDCUPXI DYNAMICPOSITIONINGMETHODBASEDDOMINANTREGIONDIAGRAMREALIZESUCCESSFULCOOPERATIVEPLAY KYRYLOV 2008 228 237 V ROBOCUP2007ROBOTSOCCERWORLDCUPXI PARETOOPTIMALOFFENSIVEPLAYERPOSITIONINGINSIMULATEDSOCCER KYRYLOV 2010 179 191 V ROBOCUP2009ROBOTSOCCERWORLDCUPXIII PARETOOPTIMALCOLLABORATIVEDEFENSIVEPLAYERPOSITIONINGINSIMULATEDSOCCER RAD 2004 137 144 A ROBOCUP2003ROBOTSOCCERWORLDCUPVII SCENARIOBASEDTEAMWORKINGHOWLEARNCREATETEACHCOMPLEXPLANS OBST 2006 521 528 O ROBOCUP2005ROBOTSOCCERWORLDCUPIX FLEXIBLECOORDINATIONMULTIAGENTTEAMBEHAVIORUSINGHTNPLANNING MOTA 2010 362 367 L ROBOTICSAUTOMATIONMECHATRONICSRAM2010IEEECONFERENCESINGAPORE COORDINATIONINROBOCUPS2DSIMULATIONLEAGUESETPLAYSFLEXIBLEMULTIROBOTPLANS DICTIONARY B ALMEIDA 2010 483 490 F PROCEEDINGSMULTIAGENTLOGICSLANGUAGESORGANISATIONSFEDERATEDWORKSHOPSMALLOW2010 ASURVEYCOORDINATIONMETHODOLOGIESFORSIMULATEDROBOTICSOCCERTEAMS RILEY 2005 P COACHINGLEARNINGUSINGENVIRONMENTAGENTMODELSFORADVICE REIS 2002 183 192 L ROBOCUP2001ROBOTSOCCERWORLDCUPV COACHUNILANGASTANDARDLANGUAGEFORCOACHINGAROBOSOCCERTEAM NIELSEN J NIELSEN J REIS 2010 1 6 L INFORMATIONSYSTEMSTECHNOLOGIESCISTI20105THIBERIANCONFERENCESANTIAGODECOMPOSTELASPAIN PLAYMAKERGRAPHICALDEFINITIONFORMATIONSSETPLAYS STOYE 2008 278 285 K ROBOCUP2007ROBOTSOCCERWORLDCUPXI INTUITIVEPLANCONSTRUCTIONADAPTIVEPLANSELECTION AKIYAMA 2006 H JOINT3RDINTERNATIONALCONFERENCESOFTCOMPUTINGINTELLIGENTSYSTEMS7THINTERNATIONALSYMPOSIUMADVANCEDINTELLIGENTSYSTEMSSCISISIS2006TOKYOJAPAN TEAMFORMATIONCONSTRUCTIONUSINGAGUITOOLINROBOCUPSOCCERSIMULATION MOTA 2011 434 444 L REIS 2013 3 21 L AGENTSARTIFICIALINTELLIGENCE COORDINATIONINMULTIROBOTSYSTEMSAPPLICATIONSINROBOTICSOCCER MOTA 2012 L MULTIROBOTCOORDINATIONUSINGFLEXIBLESETPLAYSAPPLICATIONSINROBOCUPSSIMULATIONMIDDLESIZELEAGUES RIVEST 1997 R SEXPRESSIONSINTERNETDRAFT NAUR 1960 299 314 P CHEN M NODA 1998 233 250 I LAU 2007 598 N ROBOTICSOCCER FCPORTUGALHIGHLEVELCOORDINATIONMETHODOLOGIESINSOCCERROBOTICS BROOKE 1996 189 194 J USABILITYEVALUATIONININDUSTRY SUSAQUICKDIRTYUSABILITYSCALE LIKERT 1932 1 55 R DIETTERICH 1998 1895 1923 T CRAVOX2014X110 CRAVOX2014X110X131 CRAVOX2014X110XJ CRAVOX2014X110X131XJ item S0169-023X(14)00095-0 S0169023X14000950 10.1016/j.datak.2014.10.001 271546 2014-11-20T04:32:11.709034-05:00 2014-11-01 2014-11-30 true 3479634 MAIN 22 52436 849 656 IMAGE-WEB-PDF 1 si2 4133 30 280 si1 1582 34 98 gr9 43548 424 346 gr8 142019 937 621 gr7 33873 179 358 gr6 28108 168 535 gr5 18154 174 358 gr4 30790 211 539 gr3 12875 71 313 gr2 57028 434 729 gr10 43132 442 580 gr1 41055 341 535 fx9 89100 559 533 fx8 18091 94 533 fx7 48765 280 533 fx6 39534 225 533 fx5 12128 76 533 fx4 18942 113 533 fx3 34233 188 533 fx2 15813 108 504 fx18 12703 155 111 fx17 12493 155 111 fx16 12418 155 111 fx15 12733 155 111 fx14 8944 155 111 fx13 9717 155 111 fx12 130730 885 532 fx11 35127 282 533 fx10 91910 540 533 fx1 11415 72 504 gr9 8679 164 134 gr8 8712 163 108 gr7 11891 109 219 gr6 7305 69 219 gr5 8469 107 219 gr4 8838 86 219 gr3 5603 50 219 gr2 12339 130 219 gr10 14381 164 215 gr1 8228 140 219 fx9 4509 164 156 fx8 1766 39 219 fx7 4643 115 219 fx6 3876 92 219 fx5 1278 31 219 fx4 1992 46 219 fx3 3148 77 219 fx2 1687 47 219 fx18 10952 164 117 fx17 9835 164 117 fx16 8778 164 117 fx15 10151 164 117 fx14 7558 164 117 fx13 8947 164 117 fx12 2842 163 98 fx11 3334 116 219 fx10 4987 163 161 fx1 1283 31 219 DATAK 1495 S0169-023X(14)00095-0 10.1016/j.datak.2014.10.001 Elsevier B.V. Fig. 1 SPlanner tool architecture overview. Fig. 2 SPlanner main GUI for the definition of a set-play. Fig. 3 Types of players' jerseys used in SPlanner. #4 is the leader of the step and also the ball owner, #9 is an active participant in the step, #10 is an active participant in the step currently being manipulated and #11 is not participating in the step. Fig. 4 Context menu with feasible actions for the active player. Fig. 5 Graph of a set-play with all possible execution flows. Fig. 6 Iconography for player actions. Fig. 7 Types of positions (relative, absolute and undefined) for players and action targets. #4 has an undefined position (although in this case it will be within the marked region). #7 is positioned at (−10,−10) relative to the ball (which is supposed to be held by #4). #5 is absolutely positioned at (−23,30). #8 is positioned at (10,0) relative to #7 and is also performing a run to position (18,0) relative to #7. #9 does not participate in the current step, although he must have participated in one of the previous steps, has no action defined and thus his position is the same as in the previous step. Fig. 8 Step-by-step example of the definition of a corner-kick set-play with four players. Fig. 9 Changing the relativeness of players positions. Fig. 10 Defining and tuning of a corner-kick set-play against an opponent (blue team). Table 1 Average execution times (in seconds) and number of errors committed when performing set-play related tasks by three types of users. Task 1 2 3 4 5 6 7 Non-sports related users Time SPlanner 9±8 16±17 19±18 101±32 173±38 87±67 109±42 Errors SPlanner 1±1 1±1 2±2 2±1 4±3 2±2 3±2 Sports related users Time SPlanner 8±11 12±9 13±15 100±35 160±59 61±40 91±39 Errors SPlanner 0±1 1±1 1±2 2±2 4±3 2±2 2±1 FC Portugal team members Time Manual 108±15 13±5 54±23 1307±323 439±37 – – SPlanner 4±1 7±2 3±1 62±37 124±61 28±12 70±45 Errors Manual 3±1 1±1 2±3 40±14 11±5 – – SPlanner 0±0 0±0 1±2 1±1 3±1 1±1 1±1 Table 2 Average satisfaction and standard deviation of the satisfaction scores (0 to 10) given by users on the SUS questionnaire. The optimum score for each question based on the proposed satisfaction scale would be a 10. Question 1 2 3 4 5 6 7 8 9 10 Satisfaction 8±1 8±1 8±1 7±1 8±1 9±1 8±1 8±1 7±1 6±1 Editorial Strategy planner: Graphical definition of soccer set-plays João Cravo a d Fernando Almeida f g Pedro Henriques Abreu b c ⁎ Luís Paulo Reis a d Nuno Lau e f Luís Mota h d a Department of Informatics Engineering, Faculty of Engineering, University of Porto, Rua Dr. Roberto Frias, 4200-465 Porto, Portugal Department of Informatics Engineering Faculty of Engineering University of Porto Rua Dr. Roberto Frias Porto 4200-465 Portugal b Department of Informatics Engineering, Faculty of Sciences and Technology, Rua Sílvio Lima, Universidade de Coimbra — Pólo II, 3030-790 Coimbra, Portugal Department of Informatics Engineering Faculty of Sciences and Technology Universidade de Coimbra Rua Sílvio Lima Pólo II Coimbra 3030-790 Portugal c Centre for Informatics and Systems, Universidade de Coimbra, DEI, Pólo II, Pinhal de Marrocos, 3030-290 Coimbra, Portugal Centre for Informatics and Systems Universidade de Coimbra DEI, Pólo II Pinhal de Marrocos Coimbra 3030-290 Portugal d Artificial Intelligence and Computer Science Laboratory, University of Porto, Rua Dr. Roberto Frias, 4200-465 Porto, Portugal Artificial Intelligence and Computer Science Laboratory University of Porto Rua Dr. Roberto Frias Porto 4200-465 Portugal e University of Aveiro, Campus Universitrio de Santiago, 3810-193 Aveiro, Portugal University of Aveiro Campus Universitrio de Santiago Aveiro 3810-193 Portugal f Institute of Electronics and Telematics Engineering of Aveiro, Campus Universitário de Santiago, 3810-193 Aveiro, Portugal Institute of Electronics and Telematics Engineering of Aveiro Campus Universitário de Santiago Aveiro 3810-193 Portugal g Department of Informatics, Polytechnic Institute of Viseu, Campus Politécnico de Repeses, 3504-510 Viseu, Portugal Department of Informatics Polytechnic Institute of Viseu Campus Politécnico de Repeses Viseu 3504-510 Portugal h University Institute of Lisboa (ISCTE — IUL), Avenida das Foras Armadas, 1649-026 Lisboa, Portugal University Institute of Lisboa (ISCTE — IUL) Avenida das Foras Armadas Lisboa 1649-026 Portugal ⁎ Corresponding author at: Department of Informatics Engineering, Faculty of Sciences and Technology, Rua Sílvio Lima, Universidade de Coimbra — Pólo II, 3030-790 Coimbra, Portugal; Centre for Informatics and Systems, Universidade de Coimbra, DEI, Pólo II, Pinhal de Marrocos, 3030-290 Coimbra, Portugal. One of the research topics on multi-agent systems focuses on the development of mechanisms such as plans to empower a team of agents to cooperate in order to perform complex tasks. In many cases, the definition of these plans are based on a specific and rather complex grammar and stored in structured text files. In the context of the 2D simulated Robotic Soccer domain, a set-play language was proposed to coordinate the execution of teammates' behaviors to improve a team's overall performance. The process of manually writing set-play definitions is hazardous and can benefit from the use of a graphical tool to reach new users and allow typical users to become more productive. This work presents such a tool for which several experiments were run to measure its usability with forty two users by having them perform a set of tasks for which their execution time, number errors and satisfaction were recorded. The tool reduced the previous average time required to completely define a set-play by 90% and enabled even non-expert users to use it. Moreover, users were on average satisfied with SPlanner having ranked it with a score of 77 (out of 100) using a System Usability Scale questionnaire. Keywords Data and knowledge visualization Methodologies and tools Graphical planning Set-play Robotic soccer 1 Introduction Artificial Intelligence and Robotics have been two areas of research which have received a great deal of attention over the past few years. These areas of research have been fostered particularly by international initiatives like RoboCup which accommodates many challenging competitions. From these competitions the one with the most fans is undoubtedly the soccer competition due to its wide acceptance over the world. This competition places two teams of robotic agents up against each other to dispute victory in a soccer match. Teams have been improving performance by creating new strategies that currently consider the definition of strategic positioning [1–6] based on formations, tactics and set-plays [7–9]. A set-play can be part of a team's strategy and is a widely known concept in real soccer as well as in other cooperative sports to leverage a competitive advantage against an opposing team. A set-play can be described as a structured plan that describes courses of actions that a subset of players in a team should take based on the current state of a game. Some attempts to make use of set-plays have already been made in the robotic soccer domain, however the knowledge for their definition and execution is tightly coupled (hard-coded) with the soccer player agent internal implementation. A framework that promotes the decoupling of the knowledge of set-plays from the soccer player agents internal implementation using a s-expression language has recently been developed [9]. However, writing set-play definitions manually is a harsh, error-prone and time consuming process. For these reasons, a graphical tool, named Strategy Planner (SPlanner), is proposed to speed-up the definition of set-plays and reduce the amount of errors committed by abstracting the complexity of the grammar from the end users. The rest of this article is organized in the following manner. Section 2 describes some of the related work done in the context of strategy definition, with a particular emphasis on the definition of set-plays. Section 3 describes the functionality and some usage examples of the Set-play framework used as the basis of this work. Section 4 presents the developed graphical user interface (GUI) of the SPlanner tool, focusing on its integration with the Set-play framework. Section 6 describes the methodology used to perform experiments in order to validate the usefulness of the developed tool. Section 7 presents an analysis of the results obtained from the experiments performed to assess the usefulness of SPlanner. Section 8 draws the main conclusions from the developed work and establishes some pointers for future work. 2 Related work The general concept of strategy can be described as a previously planned and typically complex behavior whose goal is to make use of available resources in the most efficient and effective way [10]. The concept of strategy has been widely adopted in several domains and its definition has evolved to match the specificities of each domain. In collective sports, particularly in the soccer domain, the concept of strategy has been the main driver for the improvement of the game quality of teams over the years. The use of technologies plays an important role in the improvement of strategies. They allow for games to be recorded and afterwards analyzed. Using tailored softwares (e.g. simulators, tactical panels, analyzer) the specification of strategies and their communication to the interested parties (coaches and players) is eased. In the human soccer domain, strategy is considered to be a key point for the difference between two teams. Concepts such as game rules (how the game must be played), player roles (what type of behavior is expected from a player), coach instructions (advice given to players to adjust their behavior to become more adequate in a match), formations (players positioning in the field) and set-plays (predefined plans of action used to gain advantage over an opponent) can all play a part in a team's strategy. In the robotic soccer domain, particularly in the RoboCup competition, the previous concepts have already been researched and experimented in different teams [11] of different leagues mainly with the goal to build better coordination mechanisms that will allow teams to improve their performance and have an advantage over their opponents. Some exemplar instances of the implementation of such strategic concepts include: general dynamic positioning [1–4], coaching [12,13], defensive positioning [6], set-plays [9,7,8] and offensive positioning [5]. As corroborated by the previous citations, these concepts have been mostly tested in the 2D soccer simulation league, in particular because it provides a standardized and robust platform around which several community open-source tools have been developed that ease the development of new ideas. Several tools have been developed with the goal of assisting the definition of strategies in real soccer (e.g. Coach-Helper, Academy Soccer Coach, ForCoach Tactics, ForCoach of Soccer, Tactics Manager). These software applications are commercial and its functionality is mainly focused on the use of soccer tactical panels for the definition of team formations. In order to assess the usability of the tools some user tests and a heuristic evaluation [14] based on the following set of heuristics [15] was conducted: • Ensure the visibility of system status; • Adequately match system to real world concepts whenever possible; • Provide the user control and freedom; • Make use of standards and be consistent; • Prevent user errors; • Favor recognition rather than recall when using dialogs; • Provide flexibility and efficiency of use; • Develop esthetic and minimalist designs for dialogs; • Help users recognize, diagnose, and recover from errors; • Provide concise and step-oriented documentation focused on user tasks. The results of the heuristic evaluation led to several conclusions, from which the most important will be highlighted. The tool that was easier to use was ForCoach Soccer which when combined with ForCoach Tactics became more suitable for defining team's tactics and formations. Although these tools use the set-play concept, none of them allow to graphically or formal define set-plays or even store the set-plays created. The video-games industry has registered a trend of growth over the last few years, mostly due to the high level of realism that creators were able to imprint in their games. In this industry, there are many examples of soccer games (e.g. Hattrick, Online Football Manager, Virtual Manager, FIFA Soccer 2011, Pro Evolution Soccer 2011, Championship Manager 2010, Football Manager 2011, FIFA Manager 2011) made available to users in different platforms (e.g. online web-based, game consoles, PC) that empower them to define some kind of strategies. Once again, the video-games reality presented the same drawbacks exposed in the human soccer scenario. The online games that use web browsers are too simplistic and offer few tools for the definition of strategy. The soccer simulators tend to offer a more appealing set of tools for its diversified end users in order to allow them to adjust the complexity to best suit their skills and explore different playing styles. From the previous examples of soccer games, only FIFA Soccer 2011 and Pro Evolution Soccer 2011 provided some tools to change a team's strategy during a game although with different levels of detail. In particular, FIFA Soccer 2011 allows the definition of positions of players in the field and their mentalities. On the other hand, Pro Evolution Soccer 2011 allows the selection of predefined game strategies for different states (e.g. times) of the game. Team management games are the ones which present the most rich set of functionality devoted to the definition of strategies, since this is their main focus. Regrettably, Championship Manager 2010 was the only software to provide a worthy tool to build set-plays and was an inspiration for this work. The robotic soccer community has also developed several tools to enable the definition of strategies for teams such as Playmaker [16], Team Designer, Matchflow, B-Smart Strategist [17] and Formation Editor [18]. Playmaker constitutes a previous attempt to build a graphical tool for defining set-plays [9] but the resulting GUI was not suitable to be used by non-expert users because it was not intuitive. From the survey conducted, it was concluded that the most complete and suitable tools for defining strategies for soccer teams are embedded in soccer video-games. In the robotic soccer domain, only a few teams have reached the goal of using high-level multi-agent strategies and thus the few existing tools are very specific for each team. 3 Set-play framework The set-play framework [9] provides a language specification for defining plans (set-plays) for the soccer domain, a built-in parser and an engine that allows them to be interpreted and executed at run-time. Set-plays can be particularly useful in some situations (better exploit empty spaces in the opponent's goal area) to help the team achieve a competitive edge. Moreover, the continuous improvement of soccer agents tactics and skills requires the development of new strategies to counter them and thus the definition of set-plays can prove useful for this purpose. Set-plays can also be a means to create mixed teams (composed by heterogeneous players) because players only have to follow the steps in the set-play to be able cooperate. A set of defined set-plays can be reused in different soccer games and integrated with other existent team strategy mechanisms such as tactics and formations to better cope with opponents. This framework has been tested in the soccer simulation leagues (2D and 3D) and the Middle Size leagues of the RoboCup competition [19]. Besides the Simulation 2D league, the framework has been tested in the soccer 3D simulation leagues (also in the context of FC Portugal team) and the Middle Size league (in the context of CAMBADA team) of the RoboCup international competition [19–21]. These are very distinct leagues from the simulation 2D. The simulation 3D league uses teams of 11 simulated humanoid NAO robots. The simulator is very realistic and thus, teams must control all robot motors in order to be able to make them walk, getup or kick the ball. In the middle-size league teams of 5 real autonomous robots play soccer in a 18×12m field using a standard FIFA ball. Robots height is limited to 80cm, weight is limited at 40kg and the robots horizontal shadow must fit inside a square of 50cm. Robots are completely autonomous, although they are allowed to communicate each other, and all sensors must be mounted on the robots. The framework helped the two teams to achieve very good results in both leagues in the last three years. FC Portugal 3D team was the champion of the last three European RoboCup championships (2012–2014) and achieved several other awards such as third place in RoboCup world championship 2013 and two scientific award challenges at RoboCup. CAMBADA team achieved also very good results including third place in the last three RoboCup world championships (2012-2014) and two scientific challenges. 3.1 Set-play formal definition Setplays are meant to be freely definable through text files that can be read upon agent launching. To accomplish this goal, Setplays must have a defined syntax on which to base both the writing of Setplays and the parser which will load them. In order to keep this syntax familiar to the RoboCup community, it was based on s-expressions [22], which are already the building blocks of the communication language with the server and with the coaching language, both from the Soccer Simulation 2D league. The syntax of this Setplay definition language, written as a set of BNF statements [23], is included bellow. In terms of BNF syntax, terminal symbols are in regular type, non terminals in italics between the ‘ <’ and ‘> ’ symbols, and BNF specific symbols in bold, with the following definitions were used: ::= definition; alternative; ? 0 or 1 occurrences of the previous term; * any amount of occurrences of the previous term; + 1 or more occurrences of the previous term. Some comments will be inserted amidst the text to clarify some options. Generally speaking, the language tried to use the concepts already present in CLang [24], the standard coach language in the 2D Simulation league. In some cases, though, practical experience showed that additional concepts were necessary, which were added to the language. In general terms, one should emphasize the following options: • All references to players are done through the type PLAYER_REFERENCE; • All operators (+, −, *, /, ==, !=, <, <=, >, >=) are prefix; • Arguments of objects and functions have added labels, prefixed by a colon (e.g. :label); • All lists are built through the s-expression with the functor list, like, e.g., (list < args >). At general level, one will consider a Setplay a conjunction of a Parameter list, a Player Reference list, an Abort Condition and a Step list. Parameters will be characterized by their name and type. The available types are only numbers and spatial entities (points and regions). Players can be referred to in two different ways: either through a full identification by team and jersey number, or through the name of the role they will play in the Setplay. When in the scope of the parameter definition, the full syntax of player roles and player identification must be employed, as defined in PLAYER_REFERENCE_DEFINITION. In other situations, inside the Setplay definition, player roles can simply be referred to by their names, as per PLAYER_REFERENCE definition. Steps are, as said before, the main building blocks of Setplays, where they represent intermediary stages in Setplay execution. As such, Steps must be precisely characterized. Their id allows Steps to be referred in Transitions from other Steps. WaitTime represents the time that needs to elapse before trying to transition to another Step, while abortTime is the time after which the Setplay is to be aborted if no transition to another Step is possible. Both time intervals must be non-negative integers. The Condition can be seen as a pre-condition that must be satisfied before entering the Step. The Step also contains a list of Participants and Transitions, described hereafter. A Participation identifies a player that takes part in the Step, and may optionally also determine the player's initially desired location for this Step, which shall be done through the usage of the ‘at’ functor. Transitions are the options to move from one Setplay Step to another (through nextStep), or to finish or abandon Setplays. In the case of transitions to other Steps, a list of Directives can be used to determine the actions the player should execute, in the case of the Do directive, or avoid to execute, in the case of Dont. Actions, in the scope of the Setplay Framework, represent abstract concepts that model the different high-level behaviors a player might need to execute. To keep the maximum compatibility with previously existing concepts, all the actions defined in CLang [24] were imported, with similar meanings and syntax. Some new actions had to be added such as: receiveBall receive a pass from another player, which is, implicitly, the ball owner. Takes no arguments. attentionTo (object or region) direct visual and/or auditive attention to a particular object or region, taken as argument. seq action sequence, is simply an aggregator of actions, that are given as arguments, and should be executed in sequence. markGoal position in a location suitable for avoiding opponent shots to enter the goal. moveToOffSideLine move near the offside line, avoiding at the same time to cross it. The argument indicates the y-coordinate of the desired location. stop stop as quick as possible, making sure that any remaining inertia is adequately counter-balanced. Objects are further characterized as being mobile or static, and can include all the agents (human and robotic) as well as passive objects that can be possibly on the pitch. Static objects are not yet exhaustively defined. Conditions were originally based on CLang [24]. In this case, though, to better tune the some specific situations, several new Conditions had to be created, as follows: canPassPl check if some player in the from list can execute a pass to some player in the to list. canPassReg check if some player in the from list can execute a pass to the region given as the to argument. canShoot check if some player in the players list can shoot at goal. nearOffsideLine check if some player in the players list is near the offside line, for situations where a forward behind this line is to be done. Conditions regarding score and time are done through dedicated keywords and the usual comparison operators. Regions model sections of the pitch, and are organized around the usual concepts of arcs, triangles and rectangles. In order to use names commonly used for well known regions, a new region type was added (Named_Region), which may have a wide range of pre-defined values, inspired in part by the ones defined by Coach-Unilang [13]. As for points, there is a wide number of different operators to refer to static and dynamic points, as well as to perform some operations, namely translations, on these. 3.2 Execution of a set-play Setplays are flexible plans that, like in real soccer, may be instantiated in real-time to face distinct opponents. In order to execute set-plays, all players keep a play book with all of the set-plays definitions to be used in a match. The state of the match is continuously monitored by the set-play engine to assess whether the execution of a set-play should be started or stopped. A set-play is considered for execution whenever the entry Condition of its first Step becomes true and no other set-play is currently being executed. Whenever there are multiple eligible set-plays for execution a plugin algorithm is used to select the most relevant. Thus, the setplays to be used are selected during the game according to the opponent and game situation. For example the playbook may include distinct corner-kick setplays to be used against different opponents and distinct corner-kick setplays to be used depending on the game situation (that includes, among other factors the current score and time). The decision is up to the coach/programmer that has the advantage of being able to quickly and graphically define new setplays to face a given opponent, without the need to change or recompile the teams code. After a set-play is chosen for execution a plugin algorithm (e.g. choose players nearest the Player References expected locations in the first Step) is run by all players concurrently to determine the most suitable allocation of concrete players to the Player References in the Set-play definition. The player that determines himself to be the Leader of the first Step of the Set-play will inform other Set-play participants of the start of the new Set-play and the role that each will play. If more than one player determines himself to be the Leader of a new Set-play, for now the player with the lowest jersey number will be deemed the effective Leader1. In each Step the Leader instructs other Set-play participants of which transition to follow in order to carry on with the execution of the set-play. All participants continuously monitor the execution of the Set-play to decide whether to continue its execution. The entire execution of a Set-play will be ended if any of the following situations occur: • The Abort condition of the Set-play is evaluated as true; • The execution of the current Step has not been started, the value of Wait Timer for the current Step has been reached, the entry Condition of the Step is defined and evaluates to false; • The execution of the current Transition has not been started, the value of Abort Timer for the current Transition has been reached, the entry Condition of the Transition is defined and evaluates to false. Setplays also consider the opponent players during their execution in the game. They include conditions such as canPassPl (can pass to player), canShoot (can shoot to goal), canPassReg (can pass to region), pPos (player position). These conditions enable to consider the teammates and opponents in an appropriate way since their logic value depends on the concrete positions of the teammates and opponents during the setplay execution. In fact, the dependence of the setplay execution on the opponent players is even greater since setplays may include branches. For each possible transition the setplay framework uses the agent specific evaluation of each of the possible actions and selects, from the possible actions, the one that achieves higher evaluation. Thus, not only the transition to the next step but the concrete step and actions selected depend on both teammate and opponents behavior and position during the setplay execution. 4 Graphical definition of set-plays The SPlanner tool was developed in C++ for the Linux platform and makes use of Qt 1 1 Qt is a cross-platform application and UI framework which is available at graphical libraries to ease the integration with the majority of tools produced by the RoboCup Soccer community. An overview of the SPlanner tool architecture is presented in Fig. 1 . The development of the tool was carried out with modularity in mind, in order to easily allow the future integration of new strategy modules (e.g. formation editor, tactics manager). Several Application Programming Interfaces (APIs) interfaces were defined to abstract the import and export functionality of other plan-based frameworks, external programs and game log viewer. The application allows an integrated test and debugging of set-plays using the Soccer Server [25] simulator and monitor and the FC Portugal Visual Debugger [26], the latter two make use of generated game logs. 2 2 Structured representation of soccer scenes (players and ball positions) and play-modes. 4.1 Interface design The interaction with the main interface of SPlanner, presented in Fig. 2 , is done primarily using the mouse and keyboard. This interface depicted in Fig. 2 is organized in three main areas: the menu bar, the set-plays separators (for editing more than one set-play at once) and the set-play workspace. In the menu bar, the user can find several actions grouped in three sub-menus: File, Setplay and Help. The File menu contains options to create, import and export a set-play and exit the application. The Setplay menu contains options to start a test of a devised set-play, debug a previously executed set-play and to configure the location of the binaries of the Soccer Server simulator, Monitor tools and the FC Portugal Visual Debugger as well as the team binaries to use in the test. The Help menu contains documentation that helps to better understand what are the tasks that can be executed with the tool and how they are supposed to be executed. The central area of the set-play workspace is essentially a metaphor for the soccer pitch divided in two distinguished areas consisting of its inner bounds (game area) in which the players participating in the set-play will be positioned and their respective actions defined and the outer bounds in which a substitution bench highlighted in brown will contain the players not participating in the set-play. In the left area a panel was defined that holds general information that describes the set-play and its abort conditions (step-independent), the flow of execution of a set-play mapped into a graph (further explained in Section 4.2) and the abort and wait times for the currently chosen step. In the bottom area of this workspace a collapsible panel was create to provide additional relevant information regarding the current active player. Just above this last area, the absolute position (coordinates) of the mouse cursor (the same as the players when being dragged) is provided in real-time to the user. A wizard was designed to assist the user in the creation of set-plays in a more intuitive fashion. Based on the experience gathered from the analysis of similar software tools and after studying the typical task flow for the creation of a set-play the following steps were defined: 1. Define the type of set-play (offensive or defensive) to create; 2. Choose the game situation (e.g. free-kick) that triggers the set-play; 3. Select the location in the field (e.g. opponent front wing) that combined with the game situation will trigger the set-play. It should be noted that some positions will be omitted based on the chosen game situation (e.g. kick-off) as they can only start from one specific location. If a location in the field is chosen in third step of the previous procedure it will be visually highlighted with a textured shape for the user to know where the set-play will be triggered. Moreover, if a region in the field is chosen, the tool will constrain the ball position and consequently the leader, which is assumed to own the ball in every step. Although, the set-play grammar allows a leader to be any arbitrary player participating in a step, in the majority of cases in real or simulated soccer he will be the player that owns the ball in offensive set-plays. This assumption makes no sense for defensive set-plays as no teammate owns the ball at its start. The players that will be participating in the set-play must all be added in the first step of the set-play, although it is not mandatory that they participate in all subsequent steps. Afterwards, the user can only define new player positions for subsequent steps implicitly by assigning actions to them in transitions that lead to those steps. The tool applies an action effector model 3 3 This model can be parametrized to describe the constraints of the application domain. to the players and the ball to estimate their future positions in subsequent steps of the set-play which cannot be changed. In order to assign a player to the set of participants of a set-play, the user just needs to drag him from the team's substitution bench into the field area. At anytime during the design of a step of a set-play, it is possible to include a non-participating player (he will have a white translucent jersey shown at the right in Fig. 3 ) to that step, but only if he has already been added as a participant in the first step of the set-play. This can be accomplished automatically by adding an action to this player. The execution of the inverse action, dragging a player to his team's bench or simply out of the field, removes him from the list of the step participants. This metaphor will appear natural for users with some knowledge of the soccer domain as a strong connection exists with the reality in which players that are sitting on the substitution bench are inactive and thus not participating in the game, contrarily to the players that are positioned within the field boundaries. Players are represented by a numbered and colored jersey that provides information to about their status (see Fig. 3) and can be selected or dragged. Whenever a user clicks on a player's jersey that player becomes active and his jersey becomes yellow. An active participant is a player for which actions can be defined in the context of a particular step. In some set-plays it might not be required that a participant does something in every step. To identify this status on a player a white translucent jersey is used, as previously mentioned. These players' statuses will be made visible whenever the user attempts to redesign a step which does not involve all participants of the set-play. This representation is relevant for the user as at any given step it provides him with visual information that allows him to see where every step participant would be based on their previously executed actions. The lead player is identified by a white jersey with a ball at the top right corner. A right mouse-click on a step participant triggers the context menu depicted in Fig. 4 from which the user can specify its actions, initial position or simply remove him from the step. In this context menu, only feasible actions will be presented to the user (e.g. a pass action will only be present if the player owns the ball). Furthermore, for some specific feasible actions presented to the user, there might be only small set of relevant options to choose from and these are thus filtered for the user. For instance, in a step scene with three players A, B and C if a pass action is initially chosen for A the only possibilities for completing its definition is to select player B or C as the receivers and so only this information is presented to the user. 4.2 Execution flow of a set-play In order to provide a general comprehension of the defined set-plays execution flows a graph visualization was designed. This graph contains a representation of identifiable steps (numbered circles) and the defined transitions between them (directed arrows) in the set-play, allowing the user to understand all its possible execution flows as depicted in Fig. 5 . There can only exist one start step and any arbitrary number of intermediate and final steps. To facilitate the distinction between different types of steps (start, intermediate or final) three different color schemes were applied when rendering the drawing. The start step is filled in black and has the number 0 and the intermediate and final steps are filled in gray. Moreover, the final step is distinguished from an intermediate step by adding a double black contour to it. The rendering of the graph is done automatically in real-time as the set-play definition is updated. This rendering process was designed to be legible by clearly organizing its elements separating in horizontal levels with equally distributed spacing between step circles and alignment between different levels of execution. A new transition is added by selecting a step in the graph by right-clicking it and choosing its destination to an existing step or a new step as intended. Currently, transitions between two existing steps are not supported at this time, although they are possible. In order to achieve this the system needs to reconcile the effects of executing the actions specified for the transition from the source step to the target step which has initial constraints for the positionings of its participants. Thus, the system will need to infer which actions (essentially positionings) need to be executed by each participant in order to preserve the conformity with the participants' positionings at the beginning of the target step. 4.3 Defining actions for participants SPlanner has currently built-in support for eight actions, for which different iconographies were defined (see Fig. 6 ) to make them clearly distinguishable for the users designing a set-play. From these actions, five require the step participant to own the ball at the time of its execution (direct pass, forward pass, dribble, hold the ball and shoot) contrarily to the remaining three (wait, run and position near the opponent offside line). The actions presented to the user when he selects a participant are filtered based on this criteria to prevent semantical errors (e.g. defining a dribble action for a participant that does not own the ball). 4.4 Positions of players and action targets The positions of the set-play participants in the start of a step, as well as their predicted target positions inferred from the effects of their associated actions, can be undefined, absolute (e.g. field coordinates) or relative (e.g. to the ball or participant). Each position type is distinguished visually in the set-play representation using the iconography shown in Fig. 7 . Player and action target positions are assumed to be absolute by default as the most common scenarios for the definition of a set-play make use of well defined locations. These absolute positions have no additional visual element apart from the iconographies chosen to represent the players and their actions. Undefined positions are used to add flexibility to the execution of a set-play (e.g. prevent players from running back to a location worse than the currently occupied), as they do not impose a strict position for a step participant (e.g. the leader) at the start of a step. The uncertainty of the execution of actions in a transition between steps can make the participants occupy a position different than the one that might be expected, but that could nonetheless be relevant to proceed with the execution of the set-play. The letter R is placed on the top left corner of a player's jersey and on the middle of the iconography of an action to represent an initial relative position towards a player and for the intended action respectively. This letter can be followed by a number identifying the player to whom that player is relatively positioned (e.g. R7) or the letter B if he is positioned relatively to the ball. When the letter D is placed on the top left corner of a player's jersey it represents an undefined position for that player. In order to demonstrate the simplicity allowed by SPlanner for defining a set-play, a step-by-step example of the process for defining a corner-kick set-play with three participants is described in Fig. 8 and its manual definition is presented in the Appendix A. 5 Promoting the usability of the tool Several precautions were taken to promote a good usability of the tool. The process of designing the GUI was guided by the set of well known heuristics [15] described in Section 2. To avoid unnecessary interactions for expert-users some keyboard accelerators were defined in the tool to speed-up the definition of actions for the selected player. For instance, if the user presses the letter P in the workspace when a player that owns the ball is selected, a pass action is initiated from that player to the coordinate where the mouse pointer is located. Also, valid names for the set-play and roles for the players are automatically defined upon the creation of a set-play. An automatic step is created after the lead player executes an action that moves the ball to a new position (e.g. pass, forward or dribble). When using relative positions for players, any positional change made to the position of the players being referenced results, by default, in the re-positioning of the players making the referral as depicted in Fig. 9 . When the user drags a player j throughout the field that is used as a reference for the relative positioning of a player i , player i relative position is recalculated based on the player j new position as depicted in Fig. 9(b). However, if the user holds the Shift key while dragging player j , player i initial relative position to player j is preserved and visual feedback is provided to the user who will see also player i accompanying player j movement as depicted in Fig. 9(c). Moreover, relative target actions will always be updated in conformity with the movements of the reference object to whom they are relative to. When a pass action is defined from a sender to a receiving player who had already been assigned a run action to a given location, the execution of a forward pass is automatically assumed (see Fig. 6) to the receiving player's predicted final position after the run instead of a direct pass to his initial position at the beginning of the step. 5.1 Defining set-plays using recorded matches The log viewer embedded in SPlanner can be used to visualize a previously recorded game log of a relevant opponent and simultaneously define a set-play as depicted in Fig. 10 . By using the embedded log viewer the user can observe weaknesses in the opponents positioning scheme in different game situations (e.g. a corner-kick in this example) and try to exploit them using a tailored set-play. Also, using this game log record the time to iteratively tune and test a given set-play against a given opponent for concrete situations is greatly reduced. 5.2 Easing the creation of set-plays The creation of a set-play in SPlanner has three main phases that consist on: 1. Choosing the type of set-play and the initial situation and region where it will take place; 2. Drag the players into the field and define the actions that allow them to cooperate as intended; 3. Export the set-play for testing purposes or final use. Steps and transitions are also automatically created when the leader of a step (assumed to own the ball) performs an action (e.g. pass, dribble) that moves the ball to a new location. 5.3 Enforcing logical constraints in the definition of set-plays The grammar of the set-play framework is too extensive and allows its users to define a large variety of situations by combining its different elements. However, like many other grammars some of the combinations of its concepts, although syntacticly correct can be semantically wrong (e.g. a directive to kick the ball might be specified to a player who does not own it). To circumvent these issues SPlanner limits some of the users decisions to prevent illogical options to be taken. The main measures that were created to achieve the previous goals are: • A maximum of eleven players can participate in the set-play; • All players positions must be within the game field bounds, except in particular game situations such as kick-ins and corner-kicks; • Player actions are always constrained in order for the designed situations to be coherent and logical. For instance, a player that does not own the ball is unable to perform a pass; • Players that are the intended receivers of a pass should perform a receive ball or intercept action. However, in SPlanner this option is unavailable and it is implicitly added when a pass or forward action are designed; • Only one transition can be added between each pair of steps in order to preserve the integrity of players actions during the execution flow of the set-play; • The choice of conditions is always constrained based on the current context and in particular player's actions. For instance, if a player is going to shoot at goal, a condition to check whether that shoot can be made might be defined. However, this condition will be unavailable for a player executing a pass. 5.4 Simplifying the definition of steps in a set-play The set-play framework allows a player to perform several actions during a transition to a new step. However, in most cases this is not necessary as simpler steps could alternatively be designed and preserve a similar semantic. For instance in a given step it is possible in the grammar to instruct a player to dribble the ball to a given location and after the dribble pass it to a teammate. In our approach, these actions are performed in two sequential steps, first the dribble and only afterwards the pass. 5.5 Estimating automatically the abort times for steps in a set-play The set-play framework allows the specification of abort times (see Section 3) for each different step. Since a step might contain more than one transition and each transition might contain several directives that specify for different players the actions that they should perform, the abort time is defined as the maximum time a player will require to complete all of its actions in one of the transitions of that step as described in Algorithm 5.5.1. Algorithm 5.5.1 estimateStepAbortTime(step) This feature is very useful to the user as it relieves him from the burden of trying to figure out which would be the adequate abort times, minimizing errors in calculations, for each step of a set-play. The estimation of these timings is done resorting to the physics model incorporated in the Soccer Server simulator applied to players and the ball. Currently, for simplicity, it is assumed that players are homogeneous and thus are characterized using the same model, although in reality they can have different characteristics which the Soccer Server is already capable of assigning for a match. These automatically calculated values are not strict and the user can refine them if necessary. 6 Tool validation methodology In order to validate the developed tool four experiments were performed. The first experiment consisted on testing the correctness and robustness of the SPlanner import process and consequently the visual representation of previously defined set-plays. The set-plays used in this test have been previously exported from SPlanner or manually defined by FC Portugal team members using a text editor. The second experiment consisted on measuring the effectiveness of two of the previously created set-plays (a goalie catch and right-corner kick) with SPlanner by playing several matches using the FC Portugal team with and without an opponent. In the context of this experiment, effectiveness refers to the execution of a set-play as expected, based on its definition as perceived from the visual representation provided by SPlanner. It must be pointed out that in order to be effective, it is not required that a set-play ends with the scoring of a goal because its objective could be to simply carry the ball to a given location (e.g. a goalie catch that tries to get the ball as close to the midfield as possible using a wing). It is also possible that the execution of a set-play fails due to one of its of abort conditions. The third experiment consisted on measuring the performance of the execution of tasks related with the creation of set-plays. A group of forty two users (twenty nine with basic computer skills, three members of the FC Portugal team and ten experts in the sports domain) were invited to perform a script with seven typical tasks performed when creating a set-play (manually using a text editor and SPlanner) with different levels of complexity. Only the FC Portugal team members have had a previous contact with SPlanner and thus a baseline needed to be established for all users in order to allow a fair comparison of the results. To achieve this a brief session was privately held with each user in order to explain them the concepts associated with the definition of set-plays in the context of the set-play framework and also the main organization and most common usage patterns of the SPlanner interface. For each task two measurements were made: time elapsed between the end of the task reading and comprehension until it was correctly completed (execution time) and the number of executed actions that were unnecessarily executed, that is which were not aligned with the goal of the task (number of errors). The tasks contained in the script that was presented to users were: 1. Define an action for a player; 2. Redefine the name of a player; 3. Create a transition to a new step; 4. Build a complete set-play with three participants and three steps which starts from a corner-kick situation in a specific side with absolute positions; 5. Build a complete set-play with two participants and two steps which starts from a kick-in situation in a specific location using relative and undefined positions; 6. Import an existing set-play in order to make some modifications and afterwards export it; 7. Import a previously recorded game log and manage its visualization while defining a set-play. Tasks one to three were executed in the context of an existing set-play definition previously provided to the users. Tasks four and five were started with the SPlanner tool open in its main screen without any initial definition of a set-play. For tasks six and seven no comparison can be made with the manual process as no similar alternative is currently available. After the completion of all the tasks, a System Usability Scale (SUS) questionnaire [27] was given to users to assess their satisfaction with the system in a simplistic and subjective manner. This questionnaire was complemented with a biographical questionnaire to assess the users' familiarity with the English language, level of expertise using computers, experience with soccer video games, knowledge of the soccer domain and experience with soccer tactical panels. The SUS questionnaire was comprised of the following ten statements in which positive and negative are intercalated every two statements: 1. I would enjoy using this tool in regularly; 2. I found the tool unnecessarily complex; 3. I found the tool easy to use; 4. I would require technical support to use the tool; 5. The tool functionality is well integrated; 6. The tool functionality has many inconsistencies; 7. Most people would learn to use this tool quickly; 8. The tool was very hard to use; 9. I felt confident using the tool; 10. I needed to learn several things before being able to use the tool. In order to evaluate the previous statements a Likert scale was used. The Likert scale [28] is a well-known method for scaling responses to survey researches. Respondents are asked to specify their level of agreement on a symmetric scale of a given range for a series of statements of equal relevance. The range of the scale captures the intensity of the respondents' feelings towards the presented statements. In the context of this work, a scale with five levels of agreement (strongly disagree, disagree, neither agree nor disagree, agree, and strongly agree) with values of one to five respectively was used. To ease the interpretation of the SUS questionnaire, users' satisfaction was recorded in a scale from 0 to 100. This scale was created by applying a transformation to the Likert values associated with the answers given by the users. The satisfaction score for a user is calculated using Eq. (1). (1) ∑ i = 1 10 2.5 ∗ score i where score i = LikertValue i − 1 if i is even 5 − LikertValue i if i is odd In order to try and generalize the results to a population the Mann–Whitney test was used with a confidence interval of 95%, being the recommended level of statistical significance of p <0.05 [29]. 7 Results and discussion 7.1 Robustness of the set-plays import process In the first experiment, the import process of all the set-plays that had been previously developed in SPlanner was always executed without any errors. When trying to import some of the set-plays defined manually by FC Portugal team members some exceptions occurred. The cause of these exceptions was identified as the definition of multiple actions for a player in a step transition in these set-plays. As previously mentioned in Section 5, some measures were implemented in SPlanner to simplify the process of defining a set-play by deliberately ignoring some of the possibilities of set-play grammar, such as the previously identified cause for the exceptions. Nonetheless, the tool displayed warning messages referring to the previously identified cause and suggestions to correct the situation, but it was unable to complete the import process. This is a topic for future work, as the tool should be able to anticipate these situations and adjust the imported definitions of such set-plays in conformity with the implemented simplifications. On the other hand, the remaining set-plays that had been manually defined were successfully imported and their visual representation was accurately rendered. The rendering of these set-plays contributed to a more intuitive comprehension of their execution flows, which was much more difficult to grasp from simply reading their written definitions. 7.2 Effectiveness of the developed set-plays As expected, in the second experiment the goalie catch and right corner-kick set-plays achieved different results depending on whether opponents were used. When no opponents were up against the FC Portugal team, the set-plays went exactly as planned and an entire execution path was followed. However, when playing against an opponent two situations arose that did not allow for a set-play execution path to be completed but led to its termination as expected based on one of the abort conditions specified for the set-plays: • The opponent team intercepted the ball and the set-play was aborted, as defined in its abort conditions; • The transition into a new step took longer than it was initially expected in the set-play definition and it was immediately aborted. In particular, the goalie-catch never scored any goal as its objective was simply to get the ball to the teammate nearest to the midfield. However, the same did not occur with the corner-kick set-play which was tuned to work against a specific team (Bahia2D) using the game log viewing functionality and scored a goal in 75% of its twenty executions. 7.3 SPlanner usability In the third experiment, the manual writing of set-plays using a text-editor was initially intended to be done by all users. However, after verifying that the execution times from the most acquainted users, the FC Portugal team members were very high, it was decided that other users would require at least 2h to perform them which would make it impossible for them to voluntarily perform these tests. Some of the obtained results were grouped in different user segments (e.g. FC Portugal members, sports users) to facilitate their contextual analysis. The average execution times and the number errors committed during the execution of the proposed tasks by users are presented in Table 1 . The users satisfaction measured after completing the tasks by the SUS questionnaire is described in Table 2 . Non FC Portugal users required on average an additional 4min and 20s to complete the whole script of tasks with SPlanner in comparison with FC Portugal users. This was expected due to the higher familiarity of the FC Portugal users with the set-play framework and the development of SPlanner. With regard to the execution of the tasks in SPlanner rather than manually using a text editor (tasks 1 to 5) by FC Portugal users, a reduction of 90% in the time required to complete them was achieved. The most notorious reduction of times (more than 92% of the time required for its manual counterpart) was achieved in the execution of the simple tasks one and three and the complex task four. The lower times for completing task five when compared to task four when using SPlanner are justified by the fact that after completing task four, users had learned to avoid most of the errors committed in that task. Furthermore, non FC Portugal users executing the tasks in SPlanner have outperformed FC Portugal users that executed the tasks manually having required minus 84% (approximately 27min) of the time. This result shows that SPlanner enables all users, even non-experts, to complete the tasks faster than any FC Portugal team member would using a manual editing process. With regard to the knowledge of the soccer domain, it was inferred that users with good or better knowledge of the soccer domain took less time than users with a worse knowledge (p =0.025). These users spent on average approximately minus 3min and 20s than the remaining, a result that was expected since users with a better understanding of the soccer concepts could more easily relate with the tasks and with SPlanner. With regard to the familiarity with soccer tactical panels, it was observed that users with fewer experience required on average approximately 7min and 30s to complete all the tasks, which stands for approximately 25s more than the time required by more experienced users. This time difference is negligible and tells us that the metaphors used in the Splanner GUI were perceived by users in a similar manner. Based on the experience of users with soccer video-games, it was possible to infer that users with a good experience took less time (approximately minus 2:30min) to complete the tasks than users with a worse experience (p =0.025). We believe that this result is justified by the similarity that the SPlanner GUI has with the strategy panels that are embedded in soccer video-games. With regard to the users computer skills, it was possible to infer that users with more than basic computer skills had a better performance than users with worse skills, having required less time to complete the tasks (p =0.004) and also committed fewer errors (p =0.006). Based on the errors and remarks collected from the users during the execution of the tasks it was inferred that some parts of the interface still need to be perfected. For instance, the higher number of errors committed in task five (see Table 1) was caused by the sub-task of performing a forward pass to a player which was not intuitive to most of the users. The average user satisfaction results based on the scoring scale defined in Section 6 was of 76.79±9.5 (out of 100), having the most and the least satisfied users given a score of 93 and 58 respectively. Based on the results presented in Table 2 it can be concluded that the majority of users enjoyed using SPlanner because most of the scores per question are near the optimal. However, question ten (see page 29) stands out from the rest and despite its score is not negative it tells us that users had to make a big effort to learn how to use the system and thus improvements must be implemented to ease the learning process. It was also possible to infer that users with better computer skills were more satisfied than users with worse skills (p =0.023). This result was expected since skilled users are more at ease to learn how to use new software. Also, with regard to the experience with soccer video-games, it could be inferred that users with more experience enjoyed using SPlanner more than others with less experience (p =0.047). This conclusion is supported by the fact that the SPlanner GUI was developed based on the tactical panels available on soccer video-games, which gives the tool a more appealing look and invites game users to be more at ease to explore it. 8 Conclusions The interaction with SPlanner was not equal for all test users but, as demonstrated by the results, users were greatly satisfied with its use having ranked it with an average score of 77 (out of 100). The use of this tool also allowed typical users (FC Portugal team members) to significantly reduce the time required (up to 90% on average) to perform set-play related tasks. Furthermore, users with little knowledge of the domain were able to use the tool with relative ease thus widening the range of target users that can assist the FC Portugal team in future competitions. The reuse of previously defined set-plays not defined with SPlanner was also possible in most cases and it provided an accurate visual representation of its possible execution flows, which was much more difficult to grasp from the examination of their written definition. The tool is currently optimized for the definition of offensive set-plays, rather than defensive ones, because these are most likely to be advantageous and successful as the ball is in control of the team that is deploying them. Some compromises were made in order to make the tool more usable which ended up not using the set-play grammar to its full extent and thus it does not allow the definition of some situations. Examples of such compromises include the impossibility to add several actions for a player to execute in a given step (e.g. pass and run), which was assumed to make the graphical interface unnecessarily confusing at the moment. Special precautions were taken to improve the modularity of SPlanner in order to ease its integration with other strategic modules in the future. Further developments are possible and were identified for this tool. One of these developments consists on making the user interface more clear and intuitive. For instance, the visual distinction between start step, intermediate steps and end steps should be made more clear using different color schemes, instead of a simple contour. Extra functionality regarding the definition of set-plays should be added to SPlanner in order to make it more complete. Some examples of such functionality include but are not limited to: • Repositioning players in steps other than the first while making the necessary adjustments to their actions. For instance, if a player not participating in the set-play is added to a step other than the first, the tool should assume the specified position as the initial position for that player in the first step. Also, if the player already exists in the previous step and his previous action consisted of a run, by moving the player in the current step the target run position should be changed accordingly; • Implementing support for the drawing of regions based on the context of the soccer domain (e.g. 2D simulated soccer) to be used in the specification of conditions and target locations for players actions; • Enable players participating in a step to execute more than one action (e.g. pass and run), using a sequential numbering scheme starting at one to establish the order in which actions should be executed; • Run an animation for a specific flow of a set-play as an overlay and in parallel with a previously recorded game log to give the user a more accurate feedback on what would happen if that set-play were to be executed in a particular situation that occurred in that game log; • Add the support for the definition of defensive set-plays, adding for instance the concepts of player defensive barrier and marking. However, the actions to support the creation of these types of set-plays must still be implemented; • Improve the use of opponent players in order to allow the definition of constraints to the designed set-play in order to make it more robust; • Automatically infer the actions that should be executed when defining a transition between two existing steps. These type of automatic transitions are very useful because they provide an alternative path for the execution flow of a set-play and contribute to improve its robustness; • Support undo and redo functionality in order to quickly recover from errors committed when defining a set-play. In order to make this tool usable for other teams and leagues, an independent plug-in should be developed with its context specificities (e.g. maximum speeds, field size, number of player). Last but not least, other strategy modules such as the definition of team formation and tactics should be integrated with SPlanner (e.g. Matchflow) to further improve its usefulness. An added value will be created as formations and tactics might be used to determine which set-plays are more adequate to use against a given opponent. Appendix A Example set-play definition of a corner-kick References [1] L.P. Reis N. Lau E. Oliveira Situation based strategic positioning for coordinating a team of homogeneous agents Balancing Reactivity and Social Deliberation in Multi-Agent Systems, From RoboCup to Real-World Applications (selected papers from the ECAI 2000 Workshop and additional contributions) 2001 Springer-Verlag London, UK 175 197 [2] H.T. Dashti N. Aghaeepour S. Asadi M. Bastani Z. Delafkar F.M. Disfani S.M. Ghaderi S. Kamali S. Pashami A.F. Siahpirani Dynamic Positioning based on Voronoi Cells (DPVC) I. Noda A. Jacoff A. Bredenfeld Y. Takahashi RoboCup-2005: Robot Soccer World Cup IX Vol. 4020 of Lecture Notes in Artificial Intelligence 2006 Springer Berlin 219 229 [3] H. Akiyama I. Noda Multi-agent positioning mechanism in the dynamic environment U. Visser F. Ribeiro T. Ohashi F. Dellaert Robocup 2007: Robot Soccer World Cup XI Vol. 5001 of Lecture Notes in Artificial Intelligence 2008 Springer Berlin 377 384 [4] R. Nakanishi K. Murakami T. Naruse Dynamic positioning method based on dominant region diagram to realize successful cooperative play U. Visser F. Ribeiro T. Ohashi F. Dellaert RoboCup 2007: Robot Soccer World Cup XI Vol. 5001 of Lecture Notes in Artificial Intelligence 2008 Springer Berlin 488 495 [5] V. Kyrylov S. Razykov Pareto-optimal offensive player positioning in simulated soccer U. Visser F. Ribeiro T. Ohashi F. Dellaert RoboCup 2007: Robot Soccer World Cup XI Vol. 5001 of Lecture Notes in Artificial Intelligence 2008 Springer Berlin 228 237 [6] V. Kyrylov E. Hou Pareto-optimal collaborative defensive player positioning in simulated soccer J. Baltes M. Lagoudakis T. Naruse S. Shiry RoboCup 2009: Robot Soccer World Cup XIII Vol. 5949 of Lecture Notes in Artificial Intelligence 2010 Springer Berlin 179 191 [7] A.A. Rad N. Qaragozlou M. Zaheri Scenario-based teamworking, how to learn, create, and teach complex plans? D. Polani B. Browning A. Bonarini K. Yoshida RoboCup 2003: Robot Soccer World Cup VII Vol. 3020 of Lecture Notes in Computer Science 2004 Springer Berlin / Heidelberg 137 144 [8] O. Obst J. Boedecker Flexible coordination of multiagent team behavior using HTN planning I. Noda A. Jacoff A. Bredenfeld Y. Takahashi RoboCup 2005: Robot Soccer World Cup IX 2006 Springer Berlin 521 528 [9] L. Mota N. Lau L.P. Reis Co-ordination in RoboCup's 2D simulation league: setplays as flexible, multi-robot plans Robotics Automation and Mechatronics (RAM), 2010 IEEE Conference on, Singapore 2010 362 367 [10] B. Dictionary What is Strategy? Definition and Meaning URL 07 2011 [11] F. Almeida N. Lau L.P. Reis A survey on coordination methodologies for simulated robotic soccer teams O. Boissier A.E.F. Seghrouchni S. Hassas N. Maudet Proceedings of The Multi-Agent Logics, Languages, and Organisations Federated Workshops (MALLOW 2010) vol. 627 2010 CEUR−WS Lyon, France 483 490 [12] P. Riley Coaching: Learning and using Environment and Agent Models for Advice (PhD) 2005 Carnegie Mellon University [13] L.P. Reis N. Lau COACH UNILANG — a standard language for coaching a (robo)soccer team A. Birk S. Coradeschi S. Tadokoro RoboCup 2001: Robot Soccer World Cup V Vol. 2377 of Lecture Notes in Artificial Intelligence 2002 Springer Berlin 183 192 [14] J. Nielsen How to Conduct a Heuristic Evaluation URL 10 2011 [15] J. Nielsen Ten Usability Heuristics URL 10 2011 [16] L.P. Reis R. Lopes L. Mota N. Lau Playmaker: graphical definition of formations and setplays Information Systems and Technologies (CISTI), 2010 5th Iberian Conference on, Santiago de Compostela, Spain 2010 1 6 [17] K. Stoye C. Elfers Intuitive plan construction and adaptive plan selection U. Visser F. Ribeiro T. Ohashi F. Dellaert RoboCup 2007: Robot Soccer World Cup XI Vol. 5001 of Lecture Notes in Computer Science 2008 Springer Berlin 278 285 [18] H. Akiyama D. Katagami K. Nitta Team formation construction using a GUI tool in the RoboCup soccer simulation Joint 3rd International Conference on Soft Computing and Intelligent Systems and 7th International Symposium on Advanced Intelligent Systems (SCIS&ISIS 2006), Tokyo, Japan 2006 (TH–D2–5) [19] L. Mota L.P. Reis N. Lau Multi-robot coordination using setplays in the middle-size and simulation leagues Mechatronics 21 2 2011 434 444 10.1016/j.mechatronics.2010.05.005 (special Issue on Advances in intelligent robot design for the Robocup Middle Size League) [20] L.P. Reis F. Almeida L. Mota N. Lau Coordination in multi-robot systems: applications in robotic soccer Agents and Artificial Intelligence vol. 358 2013 Springer 3 21 [21] L. Mota Multi-robot Coordination using Flexible Setplays: Applications in Robocup's Simulation and Middle-Size Leagues (PhD) 2012 Porto University [22] R. Rivest S-Expressions Internet-Draft May 1997 MIT Laboratory for Computer Science Room 324, 545 Technology Square Cambridge, MA 02139 (URL [23] P. Naur J.W. Backus F.L. Bauer J. Green C. Katz J. McCarthy A.J. Perlis H. Rutishauser K. Samelson B. Vauquois J.H. Wegstein A. van Wijngaarden M. Woodger Report on the algorithmic language algol 60 Commun. ACM 3 6 1960 299 314 [24] M. Chen E. Foroughi F. Heintz S. Kapetanakis K. Kostiadis J. Kummeneje I. Noda O. Obst P. Riley T. Steffens Y. Wang X. Yin Users Manual: RoboCup Soccer Server Manual for Soccer Server Version 7.07 and Later URL 2003 [25] I. Noda H. Matsubara K. Hiraki I. Frank Soccer server: a tool for research on multiagent systems Appl. Artif. Intell. 12 2–3 1998 233 250 [26] N. Lau L.P. Reis FC Portugal — high-level coordination methodologies in soccer robotics P. Lima Robotic Soccer 2007 I-Technol Education and Publishing 598 [27] J. Brooke SUS: a quick and dirty usability scale P.W. Jordan B. Weerdmeester A. Thomas I.L. Mclelland Usability Evaluation in Industry 1996 Taylor and Francis London 189 194 (Ch. 5) [28] R. Likert A technique for the measurement of attitudes Arch. Psychol. 22 140 1932 1 55 [29] T.G. Dietterich Approximate statistical tests for comparing supervised classification learning algorithms Neural Comput. 10 1998 1895 1923 João Cravo holds an MSc in Informatics Engineering and Computation from the Faculty of Engineering of the University of Porto. He is currently a working at Blip.pt, a software company located in Porto, Portugal, and as a Build Master. His other interests include (but are not limited to) Artificial Intelligence, Software Engineering, Graphical User Interface Design and Robotic Soccer. Fernando Almeida is a Lecturer at the Polytechnic Institute of Viseu, Portugal. He is currently taking his PhD which focuses on Automatic Plan Extraction, Recognition and Optimization from collective sports games, with a particular emphasis in soccer. His other interests include (but are not limited to) Artificial Intelligence, Autonomous Agents, Multi-Agent Systems (MAS), Coordination in MAS, Automated Reasoning and Inference, Game Analysis and Robotic Soccer. Pedro Henriques Abreu is an Assistant Professor at Coimbra University, Portugal. He obtained his PhD in soccer teams' Modeling from the University of Porto (2011). His interests include (but are not limited to) Artificial Intelligence, automatically analysis in Game Analysis, Tactical Modeling, and Data Mining Techniques Applied to sport collective games. Luis Paulo Reis is an Associate Professor at the University of Minho, member of the Directive Board of LIACC Laboratory and coordinator of the Human–Machine Intelligent Cooperation Research Group in Portugal. He was principal investigator of more than 10 research projects in the areas of Artificial Intelligence and Robotics including FC Portugal, three times World Champion and eight times European Champion at RoboCup. He also won more than 30 other scientific awards. He supervised 13 PhD theses and 80 MSc theses to completion and is the author of more than 250 publications in international conferences and journals. He is the president of the Portuguese Robotics Society. Nuno Lau is an Assistant Professor at Aveiro University, Portugal. He got is Electrical Engineering Degree from Oporto University in 1993, a DEA degree from Claude Bernard Lyon 1 University in 1994 and the PhD from Aveiro University in 2003. His research interests include Intelligent Robotics, Artificial Intelligence, Multi-Agent Systems and Simulation. He has lectured courses at Phd and MSc levels on Distributed Artificial Intelligence, Intelligent Robotics, Computer Architecture, Programming, etc. Nuno Lau has participated, often with the coordination role, in several research projects that have been awarded international prizes. Nuno Lau is the author of more than one hundred publications in international conferences and journals. Luís Mota is an Auxiliary Professor at ISCTE — IUL, a university in Lisbon. He got his BSc and MSc from Instituto Supeior Técnico (IST, Lisbon) and his PhD from the University of Porto. He has been researching mainly in the MAS and Robotic Soccer areas. "
    },
    {
        "doc_title": "Omnidirectional walking with a compliant inverted pendulum model",
        "doc_scopus_id": "84921326259",
        "doc_doi": "10.1007/978-3-319-12027-0_39",
        "doc_eid": "2-s2.0-84921326259",
        "doc_date": "2014-01-01",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Active compliance",
            "Humanoid walking",
            "Inverted pendulum",
            "Inverted pendulum model",
            "Omni-directional walkings",
            "Stability indicators",
            "Trajectory generator",
            "Zero moment point"
        ],
        "doc_abstract": "© Springer International Publishing Switzerland 2014.In this paper, we propose a novel omnidirectional walking engine that achieves energy efficient, human like, stable and fast walking. We augment the 3D inverted pendulum with a spring model to implement a height change in the robot’s center of mass trajectory. This model is used as simplified model of the robot and the zero moment point (ZMP) criterion is used as the stability indicator. The presented walking engine consists of 5 main modules including the “next posture generator” module, the “foot trajectory generator” module, the “center of mass (CoM) trajectory generator” module, the “robot posture controller” module and “Inverse kinematics (IK) solver” module. The focus of the paper is the generation of the position of the next step and the CoM trajectory generation. For the trajectory generator, we extend the 3D-IPM with an undamped spring to implement height changes of the CoM. With this model we can implement active compliance for the robot’s gait, resulting in a more energy efficient movement. We present a modified method for solving ZMP equations which derivation is based on the new proposed model for omnidirectional walking. The walk engine is tested on simulated and a real NAO robot. We use policy search to optimize the parameters of the walking engines for the standard 3D-LIPM and our proposed model to compare the performance of both models each with their optimal parameters. We optimize the policy parameters in terms of energy efficiency for a fixed walking speed. The experimental results show the advantages of our proposed model over 3D-LIPM.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Learning robotic soccer controllers with the Q-Batch update-rule",
        "doc_scopus_id": "84905017754",
        "doc_doi": "10.1109/ICARSC.2014.6849775",
        "doc_eid": "2-s2.0-84905017754",
        "doc_date": "2014-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            },
            {
                "area_name": "Control and Systems Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2207"
            }
        ],
        "doc_keywords": [
            "Competitive environment",
            "Data collection",
            "Learning tasks",
            "Parameter-tuning",
            "Physical robots",
            "RoboCup",
            "Robotic soccer",
            "Simulated environment"
        ],
        "doc_abstract": "Robotic soccer provides a rich environment for the development of Reinforcement Learning controllers. The competitive environment imposes strong requirements on performance of the developed controllers. RL offers a valuable alternative for the development of efficient controllers while avoiding the hassle of parameter tuning a hand coded policy. This paper presents the application of a recently proposed Batch RL update-rule to learn robotic soccer controllers in the context of the RoboCup Middle Size League. The Q-Batch update-rule exploits the episodic structure of the data collection phase of Batch RL to efficiently evaluate and improve the learned policy. Three different learning tasks, with increasing difficulty, were developed and applied on a simulated environment and later on the physical robot. The performance of the learned controllers is mostly compared to hand-tuned controllers while some comparisons with other RL methods were performed. Results show that the proposed approach is able to learn the tasks in a reduced amount of time, even outperforming existing hand-coded solutions. © 2014 IEEE.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Learning a fast walk based on ZMP control and hip height movement",
        "doc_scopus_id": "84905014293",
        "doc_doi": "10.1109/ICARSC.2014.6849783",
        "doc_eid": "2-s2.0-84905014293",
        "doc_date": "2014-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            },
            {
                "area_name": "Control and Systems Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2207"
            }
        ],
        "doc_keywords": [
            "Biped walking",
            "Center of mass",
            "Covariance matrix adaptation evolution strategies",
            "Development approach",
            "Gait learning",
            "Inverted pendulum model",
            "Numerical approaches",
            "Zero moment point"
        ],
        "doc_abstract": "The Linear inverted pendulum model is widely used in biped walking approaches. This model assumes that the hip height is fixed while the robot walks. In this paper, the hip height movement, or vertical Center of Mass (CoM) trajectory, is used by a robot to achieve a faster and more stable walk. For the first time, the hip height movement is modeled in a formal way and its parameters are learned. The inverted pendulum model and a numerical approach are used to control the Zero Moment Point (ZMP) for generating a balanced walk. Covariance Matrix Adaptation Evolution Strategy (CMA-ES) is applied to optimize the hip height trajectory and walking parameters with respect to walking speed and stability. Experimental results are achieved on a simulated NAO robot. A comparison of the results of the proposed gait model (and development approach) with those obtained using fixed hip height shows that fixed height walking is slower than variable height walking. © 2014 IEEE.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "User modeling and command language adapted for driving an intelligent wheelchair",
        "doc_scopus_id": "84905014211",
        "doc_doi": "10.1109/ICARSC.2014.6849779",
        "doc_eid": "2-s2.0-84905014211",
        "doc_date": "2014-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            },
            {
                "area_name": "Control and Systems Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2207"
            }
        ],
        "doc_keywords": [
            "Cerebral palsy",
            "command language",
            "Data analysis system",
            "Intelligent wheelchair",
            "Multi-modal interfaces",
            "Physical constraints",
            "Statistical evidence",
            "User Modeling"
        ],
        "doc_abstract": "The importance and concern given to the autonomy and independence of elderly people and patients suffering from some kind of disability has been growing significantly in the last few decades. Intelligent wheelchairs (IW) are technologies that can increase the autonomy and independence of this kind of population and are nowadays a very active research area. This paper presents a Data Analysis System (DAS) that provides an adapted command language to an user of the IW. This command language is a set of input sequences that can be created using inputs from an input device or a combination of the inputs available in a multimodal interface. The results show that there are statistical evidences to affirm that the mean of the evaluation of the DAS is higher than the mean of the evaluation of the command language recommend by the health specialist (p value = 0.002) with a sample of 11 cerebral palsy users. This work demonstrates that it is possible to adapt an intelligent wheelchair interface to the user even when the users present heterogeneous and severe physical constraints. © 2014 IEEE.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Welcome message",
        "doc_scopus_id": "84904994216",
        "doc_doi": "10.1109/ICARSC.2014.6849749",
        "doc_eid": "2-s2.0-84904994216",
        "doc_date": "2014-01-01",
        "doc_type": "Editorial",
        "doc_areas": [
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            },
            {
                "area_name": "Control and Systems Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2207"
            }
        ],
        "doc_keywords": [],
        "doc_abstract": null,
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "A survey on intelligent wheelchair prototypes and simulators",
        "doc_scopus_id": "84904638428",
        "doc_doi": "10.1007/978-3-319-05951-8_52",
        "doc_eid": "2-s2.0-84904638428",
        "doc_date": "2014-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Control and Systems Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2207"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Automatic adaptation",
            "Health informatics",
            "Human computer interfaces",
            "Intelligent wheelchair",
            "Multi-modal interfaces",
            "Scientific community",
            "Simulation",
            "User characteristics"
        ],
        "doc_abstract": "Nowadays more than 700 million persons around the world have some kind of disability or handicap. During the last decades the elderly population in most of the European countries and across all the most civilized countries is also growing at an increasing pace. This phenomenon is receiving increasing attention from the scientific community, during the last years, and several solutions are being proposed in order to allow a more independent life to the people belonging to those groups. In this context Intelligent Wheelchairs (IW) are instruments that are a natural development of the scientific work that has been conducted to improve the traditional Wheelchair characteristics using health informatics, assistive robotics and human computer interface technologies. Some of the most important features of the IW are their navigation capabilities and automatic adaptation of their interface to the user. This paper presents the evolution and state of art concerning IWs prototypes and simulators and intelligent human-computer interfaces in the context of this devices. Our study enabled us to conclude that although several Intelligent Wheelchair prototypes are being developed in a large number of research projects, around the world, the adaptation of their user interface to the patient is an often neglected research topic. Thus, projects aiming at developing new concepts of Intelligent Wheelchairs are needed mainly using multimodal interfaces and wheelchair interfaces adapted to the user characteristics. © Springer International Publishing Switzerland 2014.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "CloudThinking as an intelligent infrastructure for mobile robotics",
        "doc_scopus_id": "84899947099",
        "doc_doi": "10.1007/s11277-014-1687-1",
        "doc_eid": "2-s2.0-84899947099",
        "doc_date": "2014-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Computer Science Applications",
                "area_abbreviation": "COMP",
                "area_code": "1706"
            },
            {
                "area_name": "Electrical and Electronic Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2208"
            }
        ],
        "doc_keywords": [
            "Application developers",
            "Cloud-based",
            "Communication infrastructure",
            "Intelligent infrastructures",
            "Mobile robotic",
            "Natural approaches",
            "Robotic applications",
            "Robotic systems"
        ],
        "doc_abstract": "Mobile robotics is a transforming field that presents a varying set of challenges. The discussion on the autonomy of (self-powered) robots is not settled, and as the communication infrastructure evolves, centralized concepts become more attractive over distributed concepts. This paper presents the CloudThinking architecture applied to intelligent cloud-based robotic operation. CloudThinking offloads most of complex robotic tasks to a central cloud, which retrieves inputs from the environment as a whole in order to instruct the robots to perform its actions. CloudThinking is a natural approach to the orchestration of multiple specialized robotic systems, defining the best mechanisms for reaching a goal. Furthermore, this architecture provides a set of automatic features which can be useful for application developers. These features can fully exploit novel cloud tools development as it becomes available, providing a time-resilient infrastructure of easy upgrade. The resulting approach has the potential to create a different set of market for robotic application developers. © 2014 Springer Science+Business Media New York.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Intelligent wheelchair driving: A comparative study of cerebral palsy adults with distinct boccia experience",
        "doc_scopus_id": "84898614412",
        "doc_doi": "10.1007/978-3-319-05948-8_32",
        "doc_eid": "2-s2.0-84898614412",
        "doc_date": "2014-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Control and Systems Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2207"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Assistive technology",
            "Boccia",
            "Cerebral palsy",
            "Comparative studies",
            "Electronic wheelchairs",
            "Intelligent wheelchair",
            "Perceptual skills",
            "Smart wheelchairs"
        ],
        "doc_abstract": "An electronic wheelchair facilitates the autonomy and independence of a person, however specific cognitive, sensorial and perceptual skills are needed to conduct the assistive technology. These skills are also inherent to the sport boccia. Thus, the aim of this study is to understand the relationship between the experience of the participant in driving a wheelchair in relation to their autonomy and independence and also examine the practice of boccia in relation to the cognitive skills and performance in driving an intelligent wheelchair using a simulator. It was performed an evaluation of 28 participants, 6 of whom had no experience driving an electronic wheelchair and 22 had experience, 15 practice boccia and 13 did not practice this type of adapted sports. In the collection of data was tested three interfaces command of a smart wheelchair in a simulator. It was showed a good performance of the participants with experience in using electronic wheelchair and practitioners of boccia. It was also possible to observe that the autonomous and independent participants showed good results. © Springer International Publishing Switzerland 2014.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Intelligent wheelchair simulator for users' training: Cerebral palsy children's case study",
        "doc_scopus_id": "84887925852",
        "doc_doi": null,
        "doc_eid": "2-s2.0-84887925852",
        "doc_date": "2013-11-25",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Computer Networks and Communications",
                "area_abbreviation": "COMP",
                "area_code": "1705"
            },
            {
                "area_name": "Information Systems",
                "area_abbreviation": "COMP",
                "area_code": "1710"
            }
        ],
        "doc_keywords": [
            "Cerebral palsy",
            "Children with cerebral palsies",
            "Classification system",
            "Head movements",
            "Intelligent wheelchair",
            "Motor function",
            "Multi-modal interfaces",
            "Simulation program"
        ],
        "doc_abstract": "The use of real context simulation programs for training driving skills to control an intelligent wheelchair is an emergent area. The aim of this study is to verify if the exigency of use of the simulator of the IntellWheels project is adequate to the skills of children with cerebral palsy. A group study case was performed using children with cerebral palsy classified in the levels IV and V of the Gross Motor Function Classification System, aged between 6 and 12 years old. The user's performance in a wheelchair driving game using the Joystick and the Wiimote (for head movements' recognition) and the users' opinions about the system were studied. Results suggest that the system matches the children skills and it was verified that it was easier to drive the wheelchair with the joystick for most of the participants. Generally, the participants presented positive reactions, showing themselves satisfied with the experiment and convicted about the wheelchair future usability. © 2013 AISTI.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Online SLAM based on a fast scan-matching algorithm",
        "doc_scopus_id": "84884726130",
        "doc_doi": "10.1007/978-3-642-40669-0_26",
        "doc_eid": "2-s2.0-84884726130",
        "doc_date": "2013-10-03",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "localization",
            "real-time",
            "Real-time operation",
            "Scan-matching",
            "Simultaneous localization and mapping",
            "SLAM approach"
        ],
        "doc_abstract": "This paper presents a scan-matching approach for online simultaneous localization and mapping. This approach combines a fast and efficient scan-matching algorithm for localization with dynamic and approximate likelihood fields to incrementally build a map. The achievable results of the approach are evaluated using an objective benchmark designed to compare SLAM solutions that use different methods. The result is a fast online SLAM approach suitable for real-time operations. © 2013 Springer-Verlag.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Intelligent wheelchair manual control methods: A usability study by cerebral palsy patients",
        "doc_scopus_id": "84884714624",
        "doc_doi": "10.1007/978-3-642-40669-0_24",
        "doc_eid": "2-s2.0-84884714624",
        "doc_date": "2013-10-03",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Assistive technology",
            "Cartesian coordinate system",
            "Cerebral palsy",
            "Electric wheelchair",
            "Intelligent wheelchair",
            "Physical limitations",
            "Realistic simulators",
            "Usability"
        ],
        "doc_abstract": "Assistive Technologies may greatly contribute to give autonomy and independence for individuals with physical limitations. Electric wheelchairs are examples of those assistive technologies and nowadays each time becoming more intelligent due to the use of technology that provides assisted safer driving. Usually, the user controls the electric wheelchair with a conventional analog joystick. However, this implies the need for an appropriate methodology to map the position of the joystick handle, in a Cartesian coordinate system, to the wheelchair wheels intended velocities. This mapping is very important since it will determine the response behavior of the wheelchair to the user manual control. This paper describes the implementation of several joystick mappings in an intelligent wheelchair (IW) prototype. Experiments were performed in a realistic simulator using cerebral palsy users with distinct driving abilities. The users had 6 different joystick control mapping methods and for each user the usability and the users' preference order was measured. The results achieved show that a linear mapping, with appropriate parameters, between the joystick's coordinates and the wheelchair wheel speeds is preferred by the majority of the users. © 2013 Springer-Verlag.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Omnidirectional walking and active balance for soccer humanoid robot",
        "doc_scopus_id": "84884710347",
        "doc_doi": "10.1007/978-3-642-40669-0_25",
        "doc_eid": "2-s2.0-84884710347",
        "doc_date": "2013-10-03",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Bipedal locomotion",
            "Environmental disturbances",
            "Foot Planner",
            "Gait generation",
            "Omni-directional walkings",
            "Omnidirectional walk",
            "Reference trajectories",
            "Stability measurements"
        ],
        "doc_abstract": "Soccer Humanoid robots must be able to fulfill their tasks in a highly dynamic soccer field, which requires highly responsive and dynamic locomotion. It is very difficult to keep humanoids balance during walking. The position of the Zero Moment Point (ZMP) is widely used for dynamic stability measurement in biped locomotion. In this paper, we present an omnidirectional walk engine, which mainly consist of a Foot planner, a ZMP and Center of Mass (CoM) generator and an Active balance loop. The Foot planner, based on desire walk speed vector, generates future feet step positions that are then inputs to the ZMP generator. The cart-table model and preview controller are used to generate the CoM reference trajectory from the predefined ZMP trajectory. An active balance method is presented which keeps the robot's trunk upright when faced with environmental disturbances. We have tested the biped locomotion control approach on a simulated NAO robot. Our results are encouraging given that the robot has been able to walk fast and stably in any direction with performances that compare well to the best RoboCup 2012 3D Simulation teams. © 2013 Springer-Verlag.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Aerial ball perception based on the use of a single perspective camera",
        "doc_scopus_id": "84884705454",
        "doc_doi": "10.1007/978-3-642-40669-0_21",
        "doc_eid": "2-s2.0-84884705454",
        "doc_date": "2013-10-03",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Color segmentation",
            "Hybrid process",
            "Perception-based",
            "Perspective cameras",
            "Position estimation",
            "Regions of interest",
            "Size and position",
            "Vision systems"
        ],
        "doc_abstract": "The detection of the ball when it is not on the ground is an important research line within the Middle Size League of RoboCup. A correct detection of airborne balls is particularly important for goal keepers, since shots to goal are usually made that way. To tackle this problem on the CAMBADA team , we installed a perspective camera on the robot. This paper presents an analysis of the scenario and assumptions about the use of a single perspective camera for the purpose of 3D ball perception. The algorithm is based on physical properties of the perspective vision system and an heuristic that relates the size and position of the ball detected in the image and its position in the space relative to the camera. Regarding the ball detection, we attempt an approach based on a hybrid process of color segmentation to select regions of interest and statistical analysis of a global shape context histogram. This analysis attempts to classify the candidates as round or not round. Preliminary results are presented regarding the ball detection approach that confirms its effectiveness in uncontrolled environments. Moreover, experimental results are also presented for the ball position estimation and a sensor fusion proposal is described to merge the information of the ball into the worldstate of the robot. © 2013 Springer-Verlag.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "A distributed cooperative reinforcement learning method for decision making in fire brigade teams",
        "doc_scopus_id": "84883444187",
        "doc_doi": "10.1007/978-3-642-39250-4_22",
        "doc_eid": "2-s2.0-84883444187",
        "doc_date": "2013-09-09",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Cooperation method",
            "Cooperative reinforcement learning",
            "Disaster zones",
            "Distributed coordination",
            "Dynamic environments",
            "Fire brigade",
            "Research papers",
            "RoboCup rescue"
        ],
        "doc_abstract": "Decision making in complex, multi-agent and dynamic environments such as disaster spaces is a challenging problem in Artificial Intelligence. This research paper aims at developing distributed coordination and cooperation method based on reinforcement learning to enable team of homogeneous, autonomous fire fighter agents, with similar skills to accomplish complex task allocation, with emphasis on firefighting tasks in disaster space. The main contribution is applying reinforcement learning to solve the bottleneck caused by dynamicity and variety of conditions in such situations as well as improving the distributed coordination of fire fighter agent's to extinguish fires within a disaster zone. The proposed method increases the speed of learning; it has very low memory usage and has a good scalability and robustness in the case that the number of agents and complexity of task increases. The effectiveness of the proposed method is shown through simulation results. © 2013 Springer-Verlag.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "An automatic approach to extract goal plans from soccer simulated matches",
        "doc_scopus_id": "84876308527",
        "doc_doi": "10.1007/s00500-012-0952-z",
        "doc_eid": "2-s2.0-84876308527",
        "doc_date": "2013-05-01",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Software",
                "area_abbreviation": "COMP",
                "area_code": "1712"
            },
            {
                "area_name": "Geometry and Topology",
                "area_abbreviation": "MATH",
                "area_code": "2608"
            }
        ],
        "doc_keywords": [
            "Automatic approaches",
            "Basic actions",
            "Co-operative behaviors",
            "Game analysis",
            "Optimization techniques",
            "Plan extraction",
            "Robotic soccer",
            "Set-play"
        ],
        "doc_abstract": "Soccer is a competitive and collective sport in which teammates try to combine the execution of basic actions (cooperative behavior) to lead their team to more advantageous situations. The ability to recognize, extract and reproduce such behaviors can prove useful to improve the performance of a team in future matches. This work describes a methodology for achieving just that makes use of a plan definition language to abstract the representation of relevant behaviors in order to promote their reuse. Experiments were conducted based on a set of game log files generated by the Soccer Server simulator which supports the RoboCup 2D simulated robotic soccer league. The effectiveness of the proposed approach was verified by focusing primarily on the analysis of behaviors which started from set-pieces and led to the scoring of goals while the ball possession was kept. One of the results obtained showed that a significant part of the total goals scored was based on this type of behaviors, demonstrating the potential of conducting this analysis. Other results allowed us to assess the complexity of these behaviors and infer meaningful guidelines to consider when defining plans from scratch. Some possible extensions to this work include assessing which plans have the ability to maximize the creation of goal opportunities by countering the opponent's team strategy and how the effectiveness of plans can be improved using optimization techniques. © 2012 Springer-Verlag Berlin Heidelberg.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Evaluation of distinct input methods of an intelligent wheelchair in simulated and real environments: A performance and usability study",
        "doc_scopus_id": "84877932442",
        "doc_doi": "10.1080/10400435.2012.723297",
        "doc_eid": "2-s2.0-84877932442",
        "doc_date": "2013-04-03",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Physical Therapy, Sports Therapy and Rehabilitation",
                "area_abbreviation": "HEAL",
                "area_code": "3612"
            },
            {
                "area_name": "Rehabilitation",
                "area_abbreviation": "MEDI",
                "area_code": "2742"
            }
        ],
        "doc_keywords": [
            "adaptability",
            "Assistive robotics",
            "Assistive technology",
            "Human Machine Interface",
            "Intelligent wheelchair",
            "Multi-modal interfaces",
            "Powered wheel chairs"
        ],
        "doc_abstract": "This article focuses on evaluating the usability of an intelligent wheelchair (IW) in both real and simulated environments. The wheelchair is controlled at a high-level by a flexible multimodal interface, using voice commands, facial expressions, head movements and joystick as its main inputs. A quasi-experimental design was applied including a deterministic sample with a questionnaire that enabled to apply the System Usability Scale. The subjects were divided in two independent samples: 46 individuals performing the experiment with an IW in a simulated environment (28 using different commands in a sequential way and 18 with the liberty to choose the command); 12 individuals performing the experiment with a real IW. The main conclusion achieved by this study is that the usability of the IW in a real environment is higher than in the simulated environment. However, there were not statistical evidences to affirm that there are differences between the real and simulated wheelchairs in terms of safety and control. Also, most of users considered the multimodal way of driving the wheelchair very practical and satisfactory. Thus, it may be concluded that the multimodal interfaces enables very easy and safe control of the IW both in simulated and real environments. © 2013 Copyright 2013 RESNA.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Cooperative robotics: Passes in robotic soccer",
        "doc_scopus_id": "84890888048",
        "doc_doi": "10.1109/Robotica.2013.6623532",
        "doc_eid": "2-s2.0-84890888048",
        "doc_date": "2013-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            },
            {
                "area_name": "Human-Computer Interaction",
                "area_abbreviation": "COMP",
                "area_code": "1709"
            }
        ],
        "doc_keywords": [
            "Cooperative robotics",
            "Dynamic roles",
            "Information sharing",
            "Performance measure",
            "RoboCup",
            "Robotic soccer",
            "Robotic soccer team",
            "Role assignment"
        ],
        "doc_abstract": "The coordination necessary to make a pass in CAMBADA, a robotic soccer team designed to participate in the RoboCup Middle-Size League (MSL), is presented in this paper. The approach, which relies on information sharing and integration within the team, is based on formations, flexible positionings and dynamic role and positioning assignment. Role assignment is carried out locally on each robot to increase its reactivity. Coordinated procedures for passing and setplays have also been implemented. With this design, CAMBADA reached the 3rd place in RoboCup'2010 and RoboCup'2011. Competition results and performance measures computed from logs and videos of real competition games are presented and discussed. © 2013 IEEE.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Diagonal walk reference generator based on Fourier approximation of ZMP trajectory",
        "doc_scopus_id": "84890881965",
        "doc_doi": "10.1109/Robotica.2013.6623534",
        "doc_eid": "2-s2.0-84890881965",
        "doc_date": "2013-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            },
            {
                "area_name": "Human-Computer Interaction",
                "area_abbreviation": "COMP",
                "area_code": "1709"
            }
        ],
        "doc_keywords": [
            "Biped walking",
            "diagonal walking",
            "Fourier approximations",
            "Reference generator",
            "Reference trajectories",
            "Series approximations",
            "Stability measurements",
            "Trajectory generation"
        ],
        "doc_abstract": "Humanoid robots should be capable of adjusting their walking speed and walking direction. Due to the huge design space of the controller, it is very difficult to control the balance of humanoids walk. The position of the Zero Moment Point (ZMP) is widely used for dynamic stability measurement in biped locomotion. The reference trajectory of the Center of Mass (CoM) of a humanoid can be computed from a predefined ZMP trajectory. In order to generate the CoM trajectory, many researchers represent the ZMP equation using the motion equations of simple physical system, e.g. the cart-table model. A Fourier series approximation based method, which generates the CoM trajectory, was previously proposed for straight and curve walking. This paper extends these techniques to generate side and diagonal walking. In order to generate diagonal walking, straight and side walking are combined. The proposed CoM generation approach was tested on a simulated NAO robot. Experiments indicate that the method is successful in generating stable side and diagonal walking. Comparison results of the proposed method with ZMP preview control method show the benefits of the proposed technique. © 2013 IEEE.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Manual, automatic and shared methods for controlling an intelligent wheelchair: Adaptation to cerebral palsy users",
        "doc_scopus_id": "84890873703",
        "doc_doi": "10.1109/Robotica.2013.6623523",
        "doc_eid": "2-s2.0-84890873703",
        "doc_date": "2013-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            },
            {
                "area_name": "Human-Computer Interaction",
                "area_abbreviation": "COMP",
                "area_code": "1709"
            }
        ],
        "doc_keywords": [
            "Cerebral palsy",
            "Complete control",
            "Control methods",
            "Intelligent wheelchair",
            "Involuntary movements",
            "Realistic simulators",
            "Severe disabilities",
            "Shared control"
        ],
        "doc_abstract": "The development of an intelligent wheelchair (IW) platform that may be easily adapted to any commercial wheelchair and aid any person with special mobility needs is the main objective of this project. To be able to achieve this main objective, three distinct control methods were implemented in the IW: manual, shared and automatic. Several manual, shared and automatic control algorithms were developed for this task. This paper presents three of the most significant of those algorithms with emphasis on the shared control method. Experiments were performed, using a realistic simulator, with real users suffering from cerebral palsy in order to validate the approach. These experiments enabled to conclude which were the best shared control methods to implement on the IW. The experiments also revealed the importance of using shared (aided) controls for users with severe disabilities. The patients still felt having complete control over the wheelchair movement when using a shared control at a 50% level and thus this control type was very well accepted and should be used in intelligent wheelchairs since it is able to correct the direction in case of involuntary movements of the user but still gives him a sense of complete control over the IW movement. © 2013 IEEE.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Patient classification and automatic configuration of an intelligent wheelchair",
        "doc_scopus_id": "84882280731",
        "doc_doi": "10.1007/978-3-642-36907-0_18",
        "doc_eid": "2-s2.0-84882280731",
        "doc_date": "2013-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            },
            {
                "area_name": "Mathematics (all)",
                "area_abbreviation": "MATH",
                "area_code": "2600"
            }
        ],
        "doc_keywords": [
            "Automatic configuration",
            "Facial Expressions",
            "Head movements",
            "Intelligent wheelchair",
            "Multi-modal interfaces",
            "Patient",
            "Scientific community",
            "Voice command"
        ],
        "doc_abstract": "The access to instruments that allow higher autonomy to people is increasing and the scientific community is giving special attention on designing and developing such systems. Intelligent Wheelchairs (IW) are an example of how the knowledge on robotics and artificial intelligence may be applied to this field. IWs can have different interfaces and multimodal interfaces enabling several inputs such as head movements, joystick, facial expressions and voice commands. This paper describes the foundations for creating a simple procedure for extracting user profiles, which can be used to adequately select the best IW command mode for each user. The methodology consists on an interactive wizard composed by a flexible set of simple tasks presented to the user, and a method for extracting and analyzing the user's execution of those tasks. The results showed that it is possible to extract simple user profiles, using the proposed method. © Springer-Verlag Berlin Heidelberg 2013.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Coordination in Multi-robot systems: Applications in robotic soccer",
        "doc_scopus_id": "84882278672",
        "doc_doi": "10.1007/978-3-642-36907-0_1",
        "doc_eid": "2-s2.0-84882278672",
        "doc_date": "2013-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            },
            {
                "area_name": "Mathematics (all)",
                "area_abbreviation": "MATH",
                "area_code": "2600"
            }
        ],
        "doc_keywords": [
            "Coordination",
            "Coordination frameworks",
            "Multi-robot systems",
            "RoboCup",
            "Robotic soccer",
            "Simulation league",
            "Strategic positioning",
            "Strategic reasoning"
        ],
        "doc_abstract": "This paper briefly presents the research performed in the context of FC Portugal project concerning coordination methodologies applied to robotic soccer. FC Portugal's research has been integrated in several teams that have participated with considerable success in distinct RoboCup leagues and competitions. The paper includes a brief description of the main RoboCup competitions in which FC Portugal (and associated teams) has participated with focus in the simulation leagues and related challenges. It also presents a complete state of the art concerning coordination methodologies applied to robotic soccer followed by FC Portugal main contributions on this area. The team contributions include methodologies for strategic reasoning, coaching, strategic positioning, dynamic role exchange and flexible setplay definition and execution. These methodologies compose a complete coordination framework that enable a robotic team to play soccer or execute similar tasks. © Springer-Verlag Berlin Heidelberg 2013.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Cerebral Palsy EEG signals classification: Facial expressions and thoughts for driving an intelligent wheelchair",
        "doc_scopus_id": "84873108734",
        "doc_doi": "10.1109/ICDMW.2012.89",
        "doc_eid": "2-s2.0-84873108734",
        "doc_date": "2012-12-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Software",
                "area_abbreviation": "COMP",
                "area_code": "1712"
            }
        ],
        "doc_keywords": [
            "Cerebral palsy",
            "Complex devices",
            "Data mining algorithm",
            "EEG signals classification",
            "Facial Expressions",
            "Hardware system",
            "Hjorth parameters",
            "Intelligent wheelchair",
            "Motor function",
            "Naive bayes",
            "Signal preprocessing",
            "Simulated environment",
            "Thoughts",
            "Variable selection",
            "Variable selection methods"
        ],
        "doc_abstract": "Brain Computer Interfaces (BCI) enables interaction between users and hardware systems, through the recognition of brainwave activity. However, the current BCI systems still have a very low accuracy on the recognition of facial expressions and thoughts. This makes it very difficult to use these devices to enable safe and robust commands of complex devices such as an Intelligent Wheelchair. This paper presents an approach to expand the use of a brain computer interface for driving an intelligent wheelchair by patients suffering from cerebral palsy. The approach was based on appropriate signal preprocessing based on Hjorth parameters, a forward approach for variable selection and several data mining algorithms for classification such as naive Bayes, neural networks and support vector machines. Experiments were performed using 30 individuals suffering from IV and V degrees of cerebral palsy on the Gross Motor Function (GMF) measure. The results achieved showed that the preprocessing and variable selection methods were effective enabling to improve the results of a commercial BCI product by 57%. With the developed system it was also possible for users to perform a circuit in a simulated environment using just facial expressions and thoughts. © 2012 IEEE.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Automatic extraction of goal-scoring behaviors from soccer matches",
        "doc_scopus_id": "84872282785",
        "doc_doi": "10.1109/IROS.2012.6386091",
        "doc_eid": "2-s2.0-84872282785",
        "doc_date": "2012-12-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Control and Systems Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2207"
            },
            {
                "area_name": "Software",
                "area_abbreviation": "COMP",
                "area_code": "1712"
            },
            {
                "area_name": "Computer Vision and Pattern Recognition",
                "area_abbreviation": "COMP",
                "area_code": "1707"
            },
            {
                "area_name": "Computer Science Applications",
                "area_abbreviation": "COMP",
                "area_code": "1706"
            }
        ],
        "doc_keywords": [
            "Automatic extraction",
            "Co-operative behaviors"
        ],
        "doc_abstract": "In a soccer match, a cooperative behavior emerges from the combined execution of simple actions by players. A cooperative behavior can be planned if players are previously committed to its execution prior to its start or unplanned otherwise. The ability to reproduce some of these behaviors can be useful to help a team achieve better performances. © 2012 IEEE.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Ball interception behaviour in robotic soccer",
        "doc_scopus_id": "84865712605",
        "doc_doi": "10.1007/978-3-642-32060-6_10",
        "doc_eid": "2-s2.0-84865712605",
        "doc_date": "2012-09-10",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Current velocity",
            "Maximum velocity",
            "RoboCup",
            "Robot acceleration",
            "Robot model",
            "Robotic soccer",
            "Team performance"
        ],
        "doc_abstract": "In robotic soccer the ball is the most crucial factor of the game. It is therefore extremely important for a robot to retrieve it as soon as possible. Thus ball interception is a key behaviour in robotic soccer. However, currently most MSL teams move to the ball position without considering the ball velocity. This often results in inefficient paths described by the robot. This paper presents the CAMBADA solution for a ball interception behaviour based on a uniformly accelerated robot model, where not only the ball velocity is taken into account but also the robot current velocity as well as the robot acceleration, maximum velocity and sensor-action delays are considered. The described work was introduced in the Portuguese robotics open Robótica2009 and RoboCup 2009 and improved the team performance contributing to the first and third places, respectively. © 2012 Springer-Verlag Berlin Heidelberg.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "A methodology for creating intelligent wheelchair users' profiles",
        "doc_scopus_id": "84862126300",
        "doc_doi": null,
        "doc_eid": "2-s2.0-84862126300",
        "doc_date": "2012-06-15",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            }
        ],
        "doc_keywords": [
            "Adaptive interface",
            "Command mode",
            "Facial Expressions",
            "Head movements",
            "Intelligent wheelchair",
            "Multi-modal interfaces",
            "User profile",
            "Users' profile",
            "Voice command"
        ],
        "doc_abstract": "Intelligent Wheelchair (IW) is a new concept aiming to allow higher autonomy to people with lower mobility such as disabled or elderly individuals. Some of the more recent IWs have a multimodal interface, enabling multiple command modes such as joystick, voice commands, head movements, or even facial expressions. In these IW it may be very useful to provide the user with the best way of driving it through an adaptive interface. This paper describes the foundations for creating a simple methodology for extracting user profiles, which can be used to adequately select the best IW command mode for each user. The methodology is based on an interactive wizard composed by a flexible set of simple tasks presented to the user, and a method for extracting and analyzing the user's execution of those tasks. The results achieved showed that it is possible to extract simple user profiles, using the proposed method. Thus, the approach may be further used to extract more complete user profiles, just by extending the set of tasks used, enabling the adaptation of the IW interface to each user's characteristics.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "From an autonomous soccer robot to a robotic platform for elderly care",
        "doc_scopus_id": "84861984252",
        "doc_doi": null,
        "doc_eid": "2-s2.0-84861984252",
        "doc_date": "2012-06-13",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Biomedical Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2204"
            }
        ],
        "doc_keywords": [
            "Developed countries",
            "Elderly care",
            "Hardware and software",
            "Home care",
            "Independent living",
            "Innovative solutions",
            "Number of peoples",
            "Nursing homes",
            "Robotic platforms",
            "Robotic soccer",
            "Soccer robot"
        ],
        "doc_abstract": "Current societies in developed countries face a serious problem of aged population. The growing number of people with reduced health and capabilities, allied with the fact that elders are reluctant to leave their own homes to move to nursing homes, requires innovative solutions since continuous home care can be very expensive and dedicated 24/7 care can only be accomplished by more than one care-giver. This paper presents the proposal of a robotic platform for elderly care integrated in the Living Usability Lab for Next Generation Networks. The project aims at developing technologies and services tailored to enable the active aging and independent living of the elderly population. The proposed robotic platform is based on the CAMBADA robotic soccer platform, with the necessary modifications, both at hardware and software levels, while simultaneously applying the experiences achieved in the robotic soccer environment.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "A modular real-time vision module for humanoid robots",
        "doc_scopus_id": "84857012751",
        "doc_doi": "10.1117/12.911206",
        "doc_eid": "2-s2.0-84857012751",
        "doc_date": "2012-02-16",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Electronic, Optical and Magnetic Materials",
                "area_abbreviation": "MATE",
                "area_code": "2504"
            },
            {
                "area_name": "Condensed Matter Physics",
                "area_abbreviation": "PHYS",
                "area_code": "3104"
            },
            {
                "area_name": "Computer Science Applications",
                "area_abbreviation": "COMP",
                "area_code": "1706"
            },
            {
                "area_name": "Applied Mathematics",
                "area_abbreviation": "MATH",
                "area_code": "2604"
            },
            {
                "area_name": "Electrical and Electronic Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2208"
            }
        ],
        "doc_keywords": [
            "Acquisition modules",
            "Camera calibration",
            "Camera parameter",
            "Client-server models",
            "Color calibration",
            "Color classification",
            "Color-coded environments",
            "Computational capability",
            "Field lines",
            "Hardware architecture",
            "Humanoid robot",
            "Its efficiencies",
            "Modular designs",
            "Modular vision",
            "Object Detection",
            "Processing capability",
            "Processing Time",
            "Real time",
            "Real time vision",
            "RoboCup",
            "Robotic platforms",
            "Robotic soccer",
            "Robotic vision",
            "Self calibration",
            "Self-calibration algorithms",
            "Soccer games",
            "Soccer-playing robots",
            "Vision systems",
            "Worst case scenario"
        ],
        "doc_abstract": "Robotic vision is nowadays one of the most challenging branches of robotics. In the case of a humanoid robot, a robust vision system has to provide an accurate representation of the surrounding world and to cope with all the constraints imposed by the hardware architecture and the locomotion of the robot. Usually humanoid robots have low computational capabilities that limit the complexity of the developed algorithms. Moreover, their vision system should perform in real time, therefore a compromise between complexity and processing times has to be found. This paper presents a reliable implementation of a modular vision system for a humanoid robot to be used in color-coded environments. From image acquisition, to camera calibration and object detection, the system that we propose integrates all the functionalities needed for a humanoid robot to accurately perform given tasks in color-coded environments. The main contributions of this paper are the implementation details that allow the use of the vision system in real-time, even with low processing capabilities, the innovative self-calibration algorithm for the most important parameters of the camera and its modularity that allows its use with different robotic platforms. Experimental results have been obtained with a NAO robot produced by Aldebaran, which is currently the robotic platform used in the RoboCup Standard Platform League, as well as with a humanoid build using the Bioloid Expert Kit from Robotis. As practical examples, our vision system can be efficiently used in real time for the detection of the objects of interest for a soccer playing robot (ball, field lines and goals) as well as for navigating through a maze with the help of color-coded clues. In the worst case scenario, all the objects of interest in a soccer game, using a NAO robot, with a single core 500Mhz processor, are detected in less than 30ms. Our vision system also includes an algorithm for self-calibration of the camera parameters as well as two support applications that can run on an external computer for color calibration and debugging purposes. These applications are built based on a typical client-server model, in which the main vision pipe runs as a server, allowing clients to connect and distantly monitor its performance, without interfering with its efficiency. The experimental results that we acquire prove the efficiency of our approach both in terms of accuracy and processing time. Despite having been developed for the NAO robot, the modular design of the proposed vision system allows it to be easily integrated into other humanoid robots with a minimum number of changes, mostly in the acquisition module. © 2012 SPIE-IS&T.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Development of an omnidirectional kick for a NAO humanoid robot",
        "doc_scopus_id": "84887911606",
        "doc_doi": "10.1007/978-3-642-34654-5_58",
        "doc_eid": "2-s2.0-84887911606",
        "doc_date": "2012-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Human behaviors",
            "Human players",
            "Humanoid robot",
            "Robotic behavior",
            "Robotic soccer",
            "Simulation tests"
        ],
        "doc_abstract": "This paper proposes a method to develop an omnidirectional kick behavior for a humanoid robot. The objective is to provide a humanoid with the ability to kick in different directions and to make kicks look more like those of a human player. This method uses a Path Planning module to create the trajectory that the foot must follow to propel the ball in the intended direction. Two additional modules are required when performing the movement: the Inverse Kinematics module computes the value of the joints to place the foot at a given position and the Stability module is responsible for the robot's stability. Simulation tests were performed using different ball positions, relative to the robot's orientation, and for various ball directions. The obtained results show the usefulness of the approach since the behavior performs accurately the intended motion and is able to kick the ball in all the desired directions. © Springer-Verlag Berlin Heidelberg 2012.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Optimization approach for the development of humanoid robots' behaviors",
        "doc_scopus_id": "84887902079",
        "doc_doi": "10.1007/978-3-642-34654-5_50",
        "doc_eid": "2-s2.0-84887902079",
        "doc_date": "2012-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Humanoids",
            "NAO",
            "SimSpark",
            "Simulation 3D",
            "Soccer"
        ],
        "doc_abstract": "Humanoid robots usually have a large number of degrees of freedom which turns humanoid control into a very complex problem. Humanoids are used in several RoboCup soccer leagues. In this work, the SimSpark simulator of the Simulation 3D will be used. This paper presents an automatic approach for developing humanoid behaviors based on the development of a generic optimization system. The paper describes the adopted architecture, main design choices and the results achieved with the optimization of a side kick and a forward kick. For both skills, the optimization approach allowed the creation of faster and more powerful and stable behaviors. © Springer-Verlag Berlin Heidelberg 2012.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "A reinforcement learning based method for optimizing the process of decision making in fire brigade agents",
        "doc_scopus_id": "80054820620",
        "doc_doi": "10.1007/978-3-642-24769-9_25",
        "doc_eid": "2-s2.0-80054820620",
        "doc_date": "2011-10-26",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Decision making process",
            "Dynamic environments",
            "Fire Brigade",
            "Input datas",
            "Low memory",
            "Multi agent",
            "Real time decision-making",
            "RoboCup rescue",
            "Simulation result",
            "Stochastic behavior"
        ],
        "doc_abstract": "Decision making in complex, multi agent and dynamic environments such as disaster spaces is a challenging problem in Artificial Intelligence. Uncertainty, noisy input data and stochastic behavior which are common characteristics of such environment makes real time decision making more complicated. In this paper an approach to solve the bottleneck of dynamicity and variety of conditions in such situations based on reinforcement learning is presented. This method is applied to RoboCup Rescue Simulation Fire brigade agent's decision making process and it learned a good strategy to save civilians and city from fire. The utilized method increases the speed of learning and it has very low memory usage. The effectiveness of the proposed method is shown through simulation results. © 2011 Springer-Verlag.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Humanoid behaviors: From simulation to a real robot",
        "doc_scopus_id": "80054807105",
        "doc_doi": "10.1007/978-3-642-24769-9_26",
        "doc_eid": "2-s2.0-80054807105",
        "doc_date": "2011-10-26",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Aldebaran Nao",
            "behaviors",
            "Humanoid robot",
            "Real robot",
            "simulation"
        ],
        "doc_abstract": "This paper presents the modifications needed to adapt a humanoid agent architecture and behaviors from simulation to a real robot. The experiments were conducted using the Aldebaran Nao robot model. The agent architecture was adapted from the RoboCup 3D Simulation League to the Standard Platform League with as few changes as possible. The reasons for the modifications include small differences in the dimensions and dynamics of the simulated and the real robot and the fact that the simulator does not create an exact copy of a real environment. In addition, the real robot API is different from the simulated robot API and there are a few more restrictions on the allowed joint configurations. The general approach for using behaviors developed for simulation in the real robot was to: first, (if necessary) make the simulated behavior compliant with the real robot restrictions, second, apply the simulated behavior to the real robot reducing its velocity, and finally, increase the velocity, while adapting the behavior parameters, until the behavior gets unstable or inefficient. This paper also presents an algorithm to calculate the three angles of the hip that produce the desired vertical hip rotation, since the Nao robot does not have a vertical hip joint. All simulation behaviors described in this paper were successfully adapted to the real robot. © 2011 Springer-Verlag.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "A mobile robotic platform for elderly care",
        "doc_scopus_id": "79960496492",
        "doc_doi": null,
        "doc_eid": "2-s2.0-79960496492",
        "doc_date": "2011-07-25",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Computational Theory and Mathematics",
                "area_abbreviation": "COMP",
                "area_code": "1703"
            },
            {
                "area_name": "Applied Mathematics",
                "area_abbreviation": "MATH",
                "area_code": "2604"
            }
        ],
        "doc_keywords": [
            "Elderly care",
            "Hardware and software",
            "Independent living",
            "Mobile robotic",
            "Next generation network",
            "Robotic platforms",
            "Robotic soccer"
        ],
        "doc_abstract": "This paper presents the proposal of a robotic platform for elderly care integrated in the Living Usability Lab for Next Generation Networks. The project aims at developing technologies and services tailored to enable the active aging and independent living of the elderly population. The proposed robotic platform is based on the CAMBADA robotic soccer platform, with the necessary modifications, both at hardware and software levels, while simultaneously applying the experiences achieved in the robotic soccer environment.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Biped walking using coronal and sagittal movements based on truncated Fourier series",
        "doc_scopus_id": "79953253829",
        "doc_doi": "10.1007/978-3-642-20217-9_28",
        "doc_eid": "2-s2.0-79953253829",
        "doc_date": "2011-04-05",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Biped Robot",
            "Biped walking",
            "Bipedal locomotion",
            "Coronal planes",
            "Gait generation",
            "Gait generators",
            "Humanoid robot",
            "Joint movement",
            "New model",
            "Research topics",
            "Sagittal plane",
            "Truncated Fourier series",
            "Bipedal locomotion",
            "Coronal planes",
            "Gait generation",
            "Gait generators",
            "Joint movement",
            "Research topics",
            "Sagittal plane",
            "Truncated Fourier series"
        ],
        "doc_abstract": "Biped walking by using all joint movements and DOFs in both directions (sagittal plane and coronal plane) is one of the most complicated research topics in robotics. In this paper, angular trajectories of a stable biped walking for a humanoid robot are generated by a Truncated Fourier Series (TFS) approach. The movements of legs and arms in sagittal plane are implemented by an optimized gait generator and a new model is proposed that can also produce the movement of legs in coronal plane based on TFS. Particle Swarm Optimization (PSO) is used to find the best angular trajectories and optimize TFS. Experimental results show that the using joints movements in sagittal and coronal planes to compose the walking skill allowed the biped robot to walk faster than previous methods that only used the joints in sagittal plane. © 2011 Springer-Verlag.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Robot team coordination using dynamic role and positioning assignment and role based setplays",
        "doc_scopus_id": "79952629487",
        "doc_doi": "10.1016/j.mechatronics.2010.05.010",
        "doc_eid": "2-s2.0-79952629487",
        "doc_date": "2011-01-01",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Mechanical Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2210"
            },
            {
                "area_name": "Computer Science Applications",
                "area_abbreviation": "COMP",
                "area_code": "1706"
            },
            {
                "area_name": "Electrical and Electronic Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2208"
            }
        ],
        "doc_keywords": [
            "Coordinated procedures",
            "Dynamic role assignment",
            "Information sharing",
            "Multi-robot teams",
            "Performance measure",
            "Priority-based algorithms",
            "Robotic soccer team",
            "Strategic positioning"
        ],
        "doc_abstract": "The coordination methodologies of CAMBADA, a robotic soccer team designed to participate in the RoboCup Middle-Size League (MSL), are presented in this paper. The approach, which relies on information sharing and integration within the team, is based on formations, flexible positionings and dynamic role and positioning assignment. Role assignment is carried out locally on each robot to increase its reactivity. Positioning assignment is carried out at a lower frequency by a coach agent following a new priority-based algorithm that maintains a competitive formation, covering the most important positionings when malfunctions lead to a reduction of the team size. Coordinated procedures for passing and setplays have also been implemented. With this design, CAMBADA reached the 1st place in RoboCup'2008 and the 3rd place in RoboCup'2009. Competition results and performance measures computed from logs and videos of real competition games are presented and discussed. © 2010 Elsevier Ltd. All rights reserved.",
        "available": true,
        "clean_text": "serial JL 271456 291210 291718 291787 291883 31 Mechatronics MECHATRONICS 2010-07-02 2010-07-02 2011-03-08T22:21:19 S0957-4158(10)00101-7 S0957415810001017 10.1016/j.mechatronics.2010.05.010 S300 S300.1 FULL-TEXT 2015-05-15T03:43:39.596909-04:00 0 0 20110301 20110331 2011 2010-07-02T00:00:00Z articleinfo crossmark dco dateupdated tomb dateloaded datesearch indexeddate issuelist volumelist yearnav articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids confeditor contenttype copyright dateloadedtxt docsubtype doctype doi eid ewtransactionid hubeid issfirst issn issnnorm itemstage itemtransactionid itemweight openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sectiontitle sortorder srctitle srctitlenorm srctype subheadings vol volfirst volissue figure table body acknowledge affil articletitle auth authfirstini authfull authkeywords authlast primabst ref alllist content subj ssids 0957-4158 09574158 21 21 2 2 Volume 21, Issue 2 10 445 454 445 454 201103 March 2011 2011-03-01 2011-03-31 2011 Special Issue on Advances in intelligent robot design for the Robocup Middle Size League M.J.G. van de Molengraft O. Zweigle Special Issue on Advances in intelligent robot design for the Robocup Middle Size League article fla Copyright © 2010 Elsevier Ltd. All rights reserved. ROBOTTEAMCOORDINATIONUSINGDYNAMICROLEPOSITIONINGASSIGNMENTROLEBASEDSETPLAYS LAU N 1 Introduction 2 Player architecture 3 Information sharing and integration 4 Positionings and roles in open play 4.1 Formations and strategic positionings 4.2 Roles in open play 4.3 Role and positioning assignment 5 Coordinated procedures 5.1 Passes 5.2 Set plays 6 Performance evaluation 6.1 General game features 6.2 Roles and behaviors 6.3 Coordination 6.4 Competition results 7 Conclusion Acknowledgments References NOREILS 1993 79 98 F WANG 1991 177 195 P BURGARD 2005 376 386 W CARPIN 2008 305 316 S GERKEY 2004 939 954 B STONE 1999 241 273 P REIS 2001 175 197 L BALANCINGREACTIVITYSOCIALDELIBERATIONINMULTIAGENTSYTEMSROBOCUPREALWORDAPPLICATIONS SITUATIONBASEDSTRATEGICPOSITIONINGFORCOORDINATINGATEAMHOMOGENEOUSAGENTS PAGELLO 2006 1370 1383 E BALCH 1998 926 939 T PEDREIRAS 2007 598 607 P ROBOTICSOCCER TASKMANAGEMENTFORSOFTREALTIMEAPPLICATIONSBASEDGENERALPURPOSEOPERATINGSYSTEMS NEVES 2007 499 507 A PROGRESSINARTIFICIALINTELLIGENCE OMNIDIRECTIONALVISIONSYSTEMFORSOCCERROBOTS KOK 2005 99 114 J ZWEIGLE 2006 651 659 O LAUX2011X445 LAUX2011X445X454 LAUX2011X445XN LAUX2011X445X454XN item S0957-4158(10)00101-7 S0957415810001017 10.1016/j.mechatronics.2010.05.010 271456 2011-03-10T12:04:28.246113-05:00 2011-03-01 2011-03-31 true 703428 MAIN 10 59227 849 656 IMAGE-WEB-PDF 1 gr2 34159 270 292 gr2 8280 164 177 gr3 25214 219 354 gr3 5645 135 219 gr4 33839 357 308 gr4 4859 163 141 gr5 21014 231 356 gr5 10214 142 219 gr6 17002 151 327 gr6 4599 101 219 gr7 19059 220 355 gr7 7426 136 219 gr8 27976 248 356 gr8 14225 153 219 gr1 41827 254 355 gr1 19189 156 219 MECH 1164 S0957-4158(10)00101-7 10.1016/j.mechatronics.2010.05.010 Elsevier Ltd Fig. 1 CAMBADA robotic team. Fig. 2 Layered software architecture of CAMBADA players, from [28]. Fig. 3 Target player positions for several different ball positions. Fig. 4 CAMBADA positioning assignment algorithm. Fig. 5 Sequence of passes demonstrated in the free challenge of RoboCup’2008. Fig. 6 Replacer role algorithm for corner kicks. Fig. 7 Placement of RoleBarrier players. Fig. 8 Shoot locations in the final CAMBADA (black, on the left)–Tech United (white, on the right) game in RoboCup’2008 (shoots are circles and goals are sun-like forms). Table 1 Coordinated actions in a pass. RolePasser RoleReceiver PassFlag TRYING_TO_PASS Align to receiver Align to Passer PassFlag READY Kick the ball PassFlag BALL_PASSED Move to next position Catch ball Table 2 Time distribution for different classes of game states. Game state % Time Open play 53.1 Set piece for 21.5 Set piece against 25.4 Table 3 Percentage of game time for different numbers of playing field robots. Number of robots 0 1 2 3 4 5 Time (%) 0.3 4.5 3.5 16.1 39.3 36.3 Table 4 Goal scoring performance. Result Number Missed 1 Post/bar 2 Defended 5 Goal 7 Total 15 Table 5 Average time spent by players in different roles (in %) and respective standard deviation. Role % Time RoleStriker 10.4±5.2 RoleSupporter 45.2±10.0 RoleToucher 5.9±4.1 RoleReplacer 5.6±4.6 RoleBarrier 28.4±6.5 RoleParking 4.4±6.4 Table 6 Average time spent by players in different roles (in %) for different game states. Role Open play Set piece for Set piece against RoleStriker 24.3 0.3 0.4 RoleSupporter 75.3 51.5 0.3 RoleToucher 0.4 23.7 0.0 RoleReplacer 0.0 24.5 0.0 RoleBarrier 0.0 0.0 99.3 Table 7 Average time (±standard deviation) spent by players running different behaviors. Behavior % Time (any role) % Time (striker) bMove 4.9±3.0 43.7±4.4 bMoveToAbs 74.7±12.6 25.3±4.7 bDribble 1.4±1.2 13.4±4.5 bKick 1.8±1.5 14.6±7.7 bCatchBall 0.2±0.3 Table 8 Measures related to ball possession (average±standard deviation). Average minimum distance to the ball (m) 1.25±0.33 Time with ball visible (%) 91.7±3.5 Time with ball engaged (%) 9.8±4.7 Table 9 Set-piece performance in the RoboCup’2008 final game. Set piece # Occurrences # Correct Kick-off 2 2 Free kick 1 1 Throw in 6 5 Goal kick 10 8 Corner kick 2 2 Total 21 18 Table 10 Goal scoring performance in set piece situations. Set piece # Occurrences # Success Kick-off 2 2 Free kick 1 0 Throw in 3 2 Total 6 4 Table 11 Set-piece performance in the RoboCup’2009 semi-final game. Set piece # Occurrences # Correct Kick-off 3 3 Free kick 6 4 Throw in 13 11 Goal kick 2 1 Corner kick 1 1 Total 25 20 Table 12 Outcomes of set pieces correctly executed in the RoboCup’2009 semi-final game. Outcome # Occurrences % Receiver blocked by opponent 12 60 Ball off the field through goal line 3 15 Ball hits goal framework 2 10 Goalkeeper defense 2 10 Receiver dribbling with ball 1 5 Total 20 100 Table 13 RoboCup’2008 competition results. # Games # Goals scored # Goals suffered # Points Round-robin 1 5 41 2 15 Round-robin 2 4 16 3 9 Round-robin 3 2 5 2 3 Semi-final 1 4 3 3 Final 1 7 1 3 Total 13 73 11 33 Table 14 RoboCup’2009 competition results. # Games # Goals scored # Goals suffered # Points Round-robin 1 6 38 6 15 Round-robin 2 4 23 2 12 Round-robin 3 2 7 2 6 Semi-final 1 0 2 0 3rd Place 1 3 1 3 Total 14 71 13 36 Robot team coordination using dynamic role and positioning assignment and role based setplays Nuno Lau ⁎ Luis Seabra Lopes Gustavo Corrente Nelson Filipe Ricardo Sequeira Instituto de Engenharia Electrónica e Telemática de Aveiro (IEETA), Dep. Electrónica Telecomunicações e Informática (DETI), Universidade de Aveiro, Portugal ⁎ Corresponding author. The coordination methodologies of CAMBADA, a robotic soccer team designed to participate in the RoboCup Middle-Size League (MSL), are presented in this paper. The approach, which relies on information sharing and integration within the team, is based on formations, flexible positionings and dynamic role and positioning assignment. Role assignment is carried out locally on each robot to increase its reactivity. Positioning assignment is carried out at a lower frequency by a coach agent following a new priority-based algorithm that maintains a competitive formation, covering the most important positionings when malfunctions lead to a reduction of the team size. Coordinated procedures for passing and setplays have also been implemented. With this design, CAMBADA reached the 1st place in RoboCup’2008 and the 3rd place in RoboCup’2009. Competition results and performance measures computed from logs and videos of real competition games are presented and discussed. Keywords Multi-robot team coordination Strategic positioning Dynamic role assignment Coordinated procedures 1 Introduction As robots become increasingly available in different areas of human activity, researchers are naturally prompted to investigate how robots can cooperate with each other in order to perform different tasks. Moreover, progress in wireless communication technologies enables information sharing and explicit coordination between robots. These are basic capabilities needed to support sophisticated cooperation and coordination algorithms. Given this increasing availability of robots and communication technologies, multi-robot systems have, in the last two decades, been receiving more and more attention from researchers [1–3]. Interest on multi-robot systems is further justified by the advantages they offer with respect to single robots. First, some tasks are simply too difficult or impossible to be carried out by a single robot. In other cases, by providing a larger work force, multi-robot systems can carry out tasks faster. Multi-robot systems also facilitate scalability, as larger problems can often be solved by adding more robots to the team. Finally, through their inherent redundancy, multi-robot systems offer robustness, as they may still work when a team member is damaged or malfunctioning. These advantages make multi-robot systems useful in a variety of domains, such as exploration of unknown or changing environments [4–6] (including such diverse applications as ecological monitoring, rescue, de-mining or planetary exploration), mapping [7], foraging [8], transportation [9], manufacturing [10], intrusion detection and patrolling [11,12], or even entertainment [13]. The development of multi-robot systems raises many new research issues, not found in isolated robots. These new issues are concerned with how the individual robots can coordinate their actions to carry out the assigned tasks as efficiently as possible. Among other issues, the following can be mentioned: How are different sub-tasks assigned to different robots [14,8,15]? How can different roles be assigned to different robots [16–18]? If robots need to move in formation, how can the formation be controlled [2,19,20]? How can multi-robot plans be generated and/or executed [21,22]? Which information should robots exchange in order to enable coordination [23,24]? How can multi-robot systems be debugged [25,26]? The authors have been addressing several of these issues in the robotic soccer domain, currently a popular scenario and application for research in multi-robot systems. In particular, the authors contributed to the development of CAMBADA, a RoboCup Middle-Size League (MSL) team (Fig. 1 ). The MSL is one of the most challenging leagues in RoboCup. Robotic players must be completely autonomous and must play in a field of 12m×18m [27]. Teams are composed of at most five robots with a maximum height of 80cm. Human interference is allowed only for removing malfunctioning robots and re-entering robots in the game. Building a team for the MSL is a very challenging task, both at the hardware and software levels. To be competitive, robots must be robust, fast and possess a comprehensive set of sensors. At the software level they must have an efficient set of low-level skills and must coordinate themselves to act as a team. Research conducted within CAMBADA has led to developments concerning hardware [28], computational and communications infrastructure [29–31], vision system [32,33], monitoring/debugging [25] and high-level deliberation and coordination [24,34]. This paper focuses on the last aspect, providing a detailed and up-to-date account of the currently used algorithms and their performance. The complexity inherent to the MSL and, in particular, the difficulty of developing robots with robust sensorimotor capabilities and informative perception capabilities explains why most teams have implemented relatively simple coordination capabilities. The more advanced teams achieve coordination through the assignment of different roles to the robots [35,36,18]. Typically there is, at least, an attacker, a defender, a supporter and a goalie. As perception and sensorimotor capabilities become more sophisticated it will be possible to develop more sophisticated coordination algorithms. This trend is pushed further by the increase in team size (number of robots) as well as field size. A natural source of inspiration is the RoboCup Soccer Simulation League, where teams have been using coordination layers with strategy, tactics and formations [37,16], coordination graphs [38] and reinforcement learning [39,40]. CAMBADA participated in several national and international competitions, including RoboCup world championships (5th place in 2007, 1st place in 2008, 3rd pace in 2009) and the Portuguese Open Robotics Festival (3rd place in 2006, 1st place in 2007, 2008 and 2009). The excellent results obtained in RoboCup’2008 and RoboCup’2009 are largely due to the developed coordination methodologies, as the CAMBADA robots are among the slowest in the international competitions. This paper is organized as follows: Section 2 presents the hardware and software architectures of CAMBADA players and provides details on the main software components involved in individual decisions of the players. Section 3 describes how players share information with teammates and how they integrate shared information. Sections 4 and 5 describe the adopted coordination methodologies. Section 6 presents and discusses competition results and various performance measures. Section 7 concludes the paper. 2 Player architecture CAMBADA robots (Fig. 1) were designed and completely built at the University of Aveiro. Each robot fits into a cylindrical envelope with 485mm in diameter. The mechanical structure of the players is layered and modular. Each layer can easily be replaced. The components in the lower layer, namely motors, wheels, batteries and an electromechanical kicker, are attached to an aluminum plate placed 8cm above the floor. The second layer contains the control electronics. The third layer contains a laptop computer, at 22.5cm from the floor, a catadioptric omnidirectional vision system, a frontal vision system (single camera) and an electronic compass, all close to the maximum height of 80cm. The players are capable of holonomic motion, based on three omnidirectional roller wheels. With the current motion system, the robots can move at a maximum speed of 2.0m/s. As mentioned, this is less than in many of the other MSL teams, which can currently move at speeds typically between 2.5 and 4.0m/s (e.g. [41–44]). The mentioned vision system allows detecting objects, the ball, players, and field lines on a radius of 5m around each player. The frontal camera allows detecting the ball further away but is currently not used due to software stability problems encountered when using both cameras simultaneously. Each player also carries encoders, battery status sensors and, for detecting if the ball is kickable, an infra-red presence sensor. The computational system in each robot is a set of processing nodes (several small microcontrollers for basic perception and sensorimotor control plus a laptop for high-level deliberation) connected through a Controller Area Network (CAN). All communications within the team are based on the standard wireless LAN protocol IEEE 802.11x profiting from large availability of complying equipment. The team receives referees instructions through a wired LAN TCP link. On the main processing node (laptop), CAMBADA players run several software processes that execute different activities, such as image acquisition, image analysis, integration/deliberation and communication with the low-level modules (Fig. 2 ). The order and schedule of activation of these processes is performed by a so-called process manager (Pman [31]). Pman stores the characteristics of each process to activate and allows the activation of recurrent tasks, settling phase control (through the definition of temporal offsets), precedence restrictions, priorities, etc. The Pman services allow changes in the temporal characteristics of the process schedule during run-time. The top-level processing loop starts by integrating perception information gathered locally by the player. This includes information coming from the vision processes, odometry information coming from the holonomic base, compass information and ball presence information. All this information is stored in a shared data structure called Real-Time Data Base (RTDB) [29]. The RTDB has a local area, shared only among local processes, and a global area, where players share their world models to the other players. The global area is transparently updated and replicated in all players in real-time. Every 100ms the shared area of the RTDB of each robot (and of the coach) is communicated to the other robots using UDP multicast. Sending times are chosen using an adaptive TDMA algorithm that tries to avoid collisions among packets [45]. Selflocalization uses a sensor fusion engine based on the publicly available engine described in [46]. By integrating information from field line detection, this engine produces self position estimates with a high level of confidence. Compass information is used to resolve ambiguities and detect self-localization errors. The final fusion step is to integrate local information with information shared by teammates. After this integration, part of the world state is written to the global area of the RTDB. Deliberation in CAMBADA considerably relies on the concepts of role and behavior. Behaviors are the basic sensorimotor skills of the robot, like moving to a specific position or kicking the ball. The set of behaviors that are implemented in the CAMBADA agent are adapted to its catadioptric omnidirectional vision and holonomic driving systems. The combination of these technologies enhances the set of possible behaviors when compared to a differential drive robot or to an holonomic drive robot with a limited field of view. In brief, the current set of behaviors is the following: bMove uses two symbolic parameters: the target position where to move; and the position which the CAMBADA player should be facing in its path to the target. The symbols used are OBall, TheirGoal and OurGoal. This behavior may activate the functions of avoiding obstacles and avoiding the ball (used during the game repositions to avoid collisions with the ball). bMoveToAbs is another moving behavior; it allows the movement of the player to an absolute position in the game field, and also allows the player to face any given position. Obstacle avoidance is also included. bPassiveInter moves the player to the closest point in the ball trajectory and waits there for the ball. bDribble is used to dribble the ball towards a given relative player direction. bCatchBall is used to receive a pass. The player aligns itself with the ball path and, when the ball is close, moves backwards to soften the impact and more easily engage the ball. bKick is used to kick the ball accurately to one 3D position, either for shooting to goal or passing to a teammate. Preparing for the kick involves determining the kick direction and power. Polynomial functions, whose coefficients were determined by experimentation, are used to compute kick power based on distance to target. Different functions are used according to the expected number of ball bounces, given the distance. bGoalieDefend is the main behavior of the goalie. Roles select the active behavior at each time step. During open play, the CAMBADA agents use only three roles: RoleGoalie, RoleSupporter and RoleStriker. The RoleGoalie is activated for the goalkeeper. Further details about the developed roles and respective coordination mechanisms will be presented in Sections 4 and 5. Another important component of the deliberation process in CAMBADA is based on a coach agent that runs in an external computer. The coach communicates with the robot agents using the RTDB. This agent is used to define the positionings of the robots inside the current formation, as will be explained in Section 4.3. 3 Information sharing and integration Sharing perceptional information in a team can improve the accuracy of world models and, indirectly, the team coordination [23]. Therefore, information sharing and integration is one of the key aspects in multi-robot teams. In CAMBADA, each robot uses the information shared by the other robots, obtained through the RTDB, to improve its knowledge about the current positions and velocities of the other robots and of the ball. It is very important for our coordination model that each robot keeps an accurate estimate of the absolute position of the ball, its own position and its teammates positions. The role assignment algorithm is based on the absolute positions of the ball, the robot and its teammates. The teammates positions are not obtained through the vision system. They are obtained from the teammates themselves through the RTDB. Each agent communicates its own absolute position and velocity to all teammates as well as its ball information (position, velocity, visibility and engagement in robot), current role and current behavior. Multi-robot ball position integration has been used in the Middle-Size League by several teams [35,47]. In CAMBADA, multi-robot ball position integration is used to maintain an updated estimate of the ball position, when the vision subsystem cannot detect the ball, and to validate robot’s own ball position estimate, when the vision subsystem detects a ball. Currently, a simple integration algorithm is used. When the agent does not see the ball, it analyzes the ball information of playing teammates. The analysis consists in the calculation of the mean and standard deviation of the ball positions, then discarding the values considered as outliers of ball position, and finally using the ball information of the teammate that has a shorter distance to the ball. To determine if the agent sees a fake ball, i.e., to validate the robot’s own perception, we use a similar algorithm. Communication is also used to convey the coordination status of each robot allowing robots to detect uncoordinated behavior (e.g., several robots with the same exclusive role) and to correct this situation reinforcing the reliability of coordination algorithms. The communication between the base station and the robots informs the team of the active play mode (decided by the referee). During development, the base station can be used to control several robotic agent characteristics like fixed roles, manually activated self-positioning, etc, all managed through the RTDB. 4 Positionings and roles in open play For open play, CAMBADA uses an implicit coordination model based on notions like strategic positioning, role and formation. These notions and related algorithms have been introduced and/or extensively explored in the RoboCup Soccer Simulation League [16,17]. The concept of formation adopted in CAMBADA is mostly the same as the one presented in [16]. The model that was used to define the strategic positions of the formation members for each situation is derived from [17]. However, these and other methods developed in the Simulation League assume that team size is constant. In the MSL we must deal with incomplete formations, resulting from referee orders or malfunctioning robots. 4.1 Formations and strategic positionings A formation defines a movement model for the robotic players. Formations are sets of strategic positionings, where each positioning is a movement model for a specific player. The assignment of players to specific positionings is dynamic, and it is done according to some rules described below. Each positioning is specified by three elements: Home position which is the target position of the player when the ball is at the center of the field. Region of the field where the player can move. Ball attraction parameters used to compute the target position of the player in each moment based on the current ball position. All these items of information are given in a strategy configuration file. Using different home positions and attraction parameters for the positionings allows a simple definition of defensive, wing, midfielder and attack strategic movement models. Fig. 3 shows the formation of the team used in RoboCup’2008 for several ball positions. The definition of a formation in terms of strategic positionings was introduced in the SBSP model [17] for the Soccer Simulation League. This model also introduced specific notions of tactic and strategy, which are currently not used in CAMBADA. 4.2 Roles in open play Each role has an associated hierarchical finite-state machine that decides the behavior to be used for each of its states based on the current world state [24]. Using an hierarchical finite state machine enables the modeling of transitions between states with different levels of importance. Certain super-states (states that include other states) may be exited by the activation of one of these high priority conditions, without having to consider an identical transition from each of the their substates. As mentioned before, the CAMBADA players use only three roles in play-on mode: RoleGoalie, activated for the goalkeeper, RoleSupporter and RoleStriker. RoleStriker is an “active player” role. It tries to catch the ball and score goals. The striker activates several behaviors that try to engage the ball (bMove, bMoveToAbs), get into the opponent’s side avoiding obstacles (bDribble) and shoot to the goal (bKick). The bDribble behavior can perform 180degrees turns while keeping possession of the ball. In a consistent role assignment, only one player at a time takes on the role of striker. The striker is helped by other teammates which take on RoleSupporter [24]. Supporters maintain their target positions as determined by their current positioning assignments and the current ball position. To this end, they use essentially the bMoveToAbs behavior. As a result, supporters accompany the striker as it plays along the field, without interfering. In case the ball is captured by the opponent, some supporter hopefully will be in a good position to become the new striker. Occasionally, supporters can take a more active behavior. This happens when the striker cannot progress with the ball towards the opponent goal and, instead, the ball remains behind the striker for more than some pre-defined time (2s in the adopted configuration). In this case, the closest supporter to the ball also approaches the ball, acting as “backup striker”. 4.3 Role and positioning assignment Previous work on role assignment algorithms for robotic soccer is based on the concept of role exchange, measuring the utility of that exchange to decide its activation [37,16]. However, in MSL the number of available players varies as a result of several common situations, namely hardware and software malfunctions and referee orders. As the number of robots is small and varies a lot, the usefulness of role exchanges is reduced. The algorithms used in CAMBADA for role and positioning assignment are based on considering different priorities for the different roles and positionings, so that the most important ones are always covered [34]. In CAMBADA, the algorithms for role assignment and positioning assignment are separated and run at different rates. Role assignment is decided locally by each robot, every cycle (40ms), based on its current world model. The positioning assignment is decided by the coach and communicated to the agents, through the RTDB, every second. We believe this is an improvement over previous approaches [37,16], in which role and positioning assignment were integrated. The adopted separation provides a very reactive role assignment to cope with the high dynamics of MSL games, and a more stable and consistent positioning assignment. In case the coach fails, robots are prepared to run the positioning assignment algorithm locally. During open play, from the robots that see the ball, the one that estimates having the closest distance to the ball takes on RoleStriker, and all others, except the goalie, take on RoleSupporter. Because world models are not identical, in some situations more than one robot may be assigned RoleStriker, but the results provided in Section 6 show that this situation is very rare. The positioning assignment algorithm decides the place in the formation that each robot should occupy (see Fig. 4 ). Consider a formation with N positionings and a team of K ⩽ N available field players (not counting the goalkeeper which has a fixed role). To assign the positioning to each robot, the distances of each of the robots to each of the target positions are calculated. Then the closest robot to the highest priority strategic positioning is assigned to that positioning, which is in turn the closest to the ball. From the remaining K −1 robots, the closest to the defensive positioning (second highest priority) is assigned to this positioning, then the closest to the third level priority positioning is assigned next and the algorithm continues until all active robots have positionings assigned. The robot assigned to the highest priority positioning will in most cases be locally assigned to RoleStriker and will not move to that positioning, but will position itself close to the ball assuring the stability of the assignment. This algorithm results in the RoleStriker having top priority, followed by the defensive positioning, followed by the other supporter positionings. 5 Coordinated procedures Coordinated procedures are short plans executed by at least two robots. These plans in some cases involve communication resulting in explicit coordination. In the case of CAMBADA coordinated procedures are used for passes and set plays. 5.1 Passes Passing is a coordinated behavior involving two players, in which one kicks the ball towards the other, so that the other can continue with the ball. Until now, MSL teams have shown limited success in implementing and demonstrating passes. In RoboCup’2004, some teams had already implemented passes, but the functionality was not robust enough to actually be useful in games [13,48]. The CoPS and Tribots team also support pass play [49,40]. Two player roles have recently been developed for coordinated passes in the CAMBADA team. In the general case, the player running RoleStriker may decide to take on RolePasser, choosing the player to receive the ball. After being notified, the second player takes on the RoleReceiver. These roles have not been used yet for open play in international competition games, but they have been demonstrated in RoboCup’2008 MSL Free Technical Challenge and a similar mechanism has been used for corner kicks (see below). In the free challenge, two robots alternately took on the roles of passer and receiver until one of them was in a position to score a goal (Fig. 5 ). The sequence of actions on both players is described in Table 1 . They start from their own side of the field and, after each pass, the passer moves forward in the field, then becoming the receiver of the next pass. The coordination between passer and receiver is based on passing flags, one for each player, which can take the following values: READY, TRYING_TO_PASS and BALL_PASSED. In the case of a normal game, another pass coordination variable would identify the receiver. 5.2 Set plays Another methodology implemented in CAMBADA is the use of coordinated procedures for set plays, i.e. situations when the ball is introduced in open play after a stoppage, such as kick-off, throw-in, corner kick, free kick and goal kick. Set play procedures define a sequence of behaviors for several robots in a coordinated way. For that purpose, the involved players take on specific roles. This role-based implementation of set plays not only was easy to integrate within the previous agent architecture, but also facilitated the test and tune of different possibilities allowing for very efficient final implementations. RoleToucher and RoleReplacer are used to overcome the 2008 MSL indirect rule in the case of indirect set pieces against the opponent [27]. The purpose of RoleToucher is to touch the ball and leave it to the RoleReplacer player. The replacer handles the ball only after it has been touched by the toucher. This scheme allows the replacer to score a direct goal if the opportunity arises. Two toucher–replacer procedures are implemented. In the case of corner kicks, the toucher passes the ball to the replacer and the replacer continues with the ball (see pseudo-code in Fig. 6 ). The passing algorithm is as explained above. Another toucher–replacer procedure is used in the case of throw-in, goal kick and free kick set plays. Here, the toucher approaches and touches the ball pushing it towards the replacer until the ball is engaged by the replacer, then withdraws leaving the ball to the replacer. The replacer also moves towards the ball, grabs it, waits that the toucher moves away and then shoots to the opponent goal. It should be noted that both the toucher and the replacer position themselves on the shoot line, so that, as soon as the toucher moves away, the replacer is ready to shoot. For the kick-off, a similar procedure is followed, but without reference to the shoot line, since the involved robots must be in their own side of the field. This scheme has been updated in 2009 to comply with the new rule that only allows one robot of the team performing the set piece (and none from the opponent team) within the 1m circle around the ball and obliges the ball to be immediately kicked and to roll free on the field for at least 0.5m. In 2009, the RoleReplacer passes the ball to one of, possibly multiple, robots acting as RoleReceiver. Before passing, an evaluation of the passing corridors is performed jointly by the Replacer and all Receivers and results are shared through the RTDB. It is the responsibility of the Replacer to choose the destination of the pass, which is also communicated through the RTDB before pass execution. Finally, in the case of set pieces against CAMBADA, RoleBarrier is used to protect the goal from a direct shoot. The line connecting the ball to the own goal defines the barrier positions. One player places itself on this line, as close to the ball as it is allowed. Two players place themselves near the penalty area. One player is placed near the ball, 45degrees from the mentioned line, so that it can observe the ball coming into play and report that to teammates. Finally, one player positions itself in such a way that it can oppose to the progression of the ball through the closest side of the field. The placement of players is illustrated in Fig. 7 . The assignment of the RoleBarrier, RoleReceiver, RoleReplacer and RoleToucher roles is executed by sorting the agents according to their perceived distances to the ball and selecting the closest ones, up to the maximum number of agents in each role. When selecting a role like the RoleReplacer, which is exclusive, the agent looks at the other teammates role decisions and if it finds a RoleReplacer with a lower uniform number it will never select that role. A similar approach is performed for the other exclusive roles. This assignment is always performed locally by each robot. Robots that are not assigned setplay specific roles are assigned the supporter role with a positioning that does not interfere with the setplay. As soon as the setplay finishes, either because of a timeout or because all the setplay actions have been performed with success, the robots assigned with specific setplay roles return to an open play role using the role assignment algorithm previously described. 6 Performance evaluation The CAMBADA team participated and won the MSL world championship in RoboCup’2008 (Suzhou, China, July 2008) and achieved a distinct 3rd place in RoboCup’2009 (Graz, Austria, July 2009). Most performance evaluation measures presented in this Section were obtained by analyzing log files and videos of games in the RoboCup championships. The logs are created by the coach agent. At 1s intervals, the coach takes a snapshot of relevant information retrieved from each robot, including current role, strategic positioning, behavior, self position and ball position. A software tool was developed to analyze game logs and extract relevant evaluation measures. Most of the information presented below was extracted from the RoboCup’2008 logs. As the CAMBADA team made it to the final, it was scheduled to play 13 games. One of them was not played due to absence of the opponent. For two other games, the log files were lost. Thus, the results presented below are extracted from log files of the remaining 10 games. Some additional results were extracted from the semi-final game in RoboCup’2009. Finally, RoboCup’2008 and RoboCup’2009 competition results will also be presented. 6.1 General game features Three main classes of game states are open play, set piece against CAMBADA and set piece for CAMBADA. Table 2 shows the respective time distribution in percentage of full game duration, computed over the 10 game logs mentioned above. The time spent in set pieces, considerably higher than what might be expected, results from the dynamics in MSL games. In fact, robots fast moving capabilities (up to 4m/s) and powerful ball kicking capabilities are not accompanied by sufficiently effective ball control capabilities, thus causing various types of set pieces. The time spent in set pieces justifies the investment in the development of the replacer/toucher combination in CAMBADA. A high efficiency rate in set pieces makes a real difference in the final team performance. Another common feature in MSL teams is that, due to reliability issues, the number of playing field robots is often less than the maximum of five. Table 3 shows the average percentage of game time (in the 10 mentioned game logs) for different numbers of playing field robots in the CAMBADA team. The average number of running field robots for the CAMBADA team was 3.98. This reveals the reliability problems that were experienced mostly in the beginning of the championship. These were solved to some extent during the championship and reliability improved in later games. In the final game the average number of running field robots was 4.33. Capabilities for shooting to goal, although not directly based on coordination methodologies, are essential for a team’s success. Fig. 8 shows the location from where the ball was shot to goal in the RoboCup’2008 MSL final (CAMBADA-TechUnited). CAMBADA showed good scoring abilities in the competition. Table 4 shows the results of all the shots made in the final game within 9m of the opponent goal (for larger distances, a shot does not have enough power to pose a real threat to the opponent team). A total of 15 shots were made, of which 1 was missed, 1 hit the post and another hit the bar. The remaining 12 hit the intended target within the goal. This gives an accuracy rating of 80%. From all the 15 shots made, 7 resulted in a goal being scored. This gives a goal scoring success rate (within 9m) of 46.7%. This high success rate is the result of accurate ball placing when kicking. In 5 of the 7 scored goals, the goalkeeper was actually well positioned and in the path of the ball. However, the accurate calibration and power selection for each kick made the ball reach the opponent goal at an height slightly above 80cm which effectively caused it to go over the goalkeeper, and thus creating a shot that is very difficult to defend. 6.2 Roles and behaviors Table 5 shows the average percentage of time any given player spends in each role, with respect to the total time the player is active in each game. It can be observed that players spend a considerable amount of time (45.2%) as RoleSupporter. This is to be expected since there may be up to four players with the Supporter role in open play, while there is at most one player acting as RoleStriker. This largely explains why the RoleStriker time is approximately 1/4 of the RoleSupporter time. The small deviation from the exact 1/4 relation is explained by two main factors: first, RoleSupporter is also taken by some players during set plays for CAMBADA; and, second, the number of field robots is often less than the maximum of five, as described above. It can also be seen that more time is spent in set plays against CAMBADA (28.4%, since usually four players take the Barrier role in these situations) than in set plays against the opponent (11.5% in Toucher and Replacer roles). RoleParking moves robots outside of the field at the end of the first half and at the end of the game. A more in-depth perspective is given by Table 6 , which shows the role time distribution across the three classes of game states. It can be seen that in open play basically only RoleStriker and RoleSupporter are used. In set pieces for CAMBADA, players take the roles of RoleReplacer, RoleToucher and RoleSupporter. In set pieces against CAMBADA, all field robots act is RoleBarrier. Underlying the numbers in Table 6 is the fact, already mentioned above, that CAMBADA had an average of nearly four field players. That explains why the time spent as supporter in open play is approximately three times that of striker, and the time spent as supporter in set pieces for CAMBADA is approximately two times that of toucher or replacer. Table 7 shows the average percentage of time any given player spends running each implemented behavior. The second column of the table shows such percentages irrespective of the role taken. The third column shows the percentages of time considering only the periods in which players are acting as RoleStriker. These values highlight the specificity of RoleStriker: much less time moving to absolute positions, since the striker most of the time ignores its strategic positioning assignment; much more time in moving (to the ball), dribbling and kicking. 6.3 Coordination In the final game of RoboCup’2008 (CAMBADA-TechUnited), the ball was in the opponent’s side 73% of time, mainly in the center of the field towards the opponent’s side. While this certainly results from the combination of several factors, the CAMBADA’s coordination approach has certainly helped in achieving such high field dominance. Some measures of coordination performance have been extracted. According to the logs, players change roles 2.02±1.02 times per minute. As role assignment is distributed (implicit coordination), it occasionally happens that two players take on RoleStriker at the same time. On average, all inconsistencies in the assignment of the Striker role have a combined total duration of 20.9±27.4s in a game (∼30min), i.e., the mean inconsistency time is about 1.2% of game duration. The high standard deviation results mainly from one game in which, due to magnetic interference, localization errors were higher than normal. In that game, role inconsistencies occurred 45 times for a combined total of 101s. Concerning strategic positionings, relevant mainly to supporters, the average distance of the player to its target position is 1.38±0.48m. The strategic positioning assignment for each player is changed on average 9.83±2.23 times per minute. As the CAMBADA players do not track the positions and actions of the opponent players, it is not possible to compute an exact measure of ball possession. However, the game logs enable to compute related measures, as shown in Table 8 . The closest player to the ball is at an average distance of 1.2m from the ball (the field is 18m×12 m). The ball is perceived by at least one robot of the CAMBADA team 91.7% of the time. The ball is engaged in a robots grabber device 9.8% of the time. Some additional analysis was carried out based on the logs of the RoboCup’2008 final game. Table 9 provides information on set pieces, identifying the total number of times each set piece was executed as well as the number of times it was correctly executed. In RoboCup’2008 final game there were 21 set pieces, of which 18 were correctly executed (85.7%). The failed throw-in occurred due to magnetic interference in one area of the field, causing the robot to mislocalize itself. The two missed goal kicks occurred because the movement of the robot acting as RoleToucher, while pushing the ball towards the Replacer, was not accurately aligned and did not succeed in delivering the ball to the Replacer. This can be due to some small localization errors experienced near the goal kick marker. Table 10 provides information on goal scoring success in set piece situations in which the set piece procedure was correctly executed and the distance to the opponent goal was less than 9m. In the six set pieces for CAMBADA, carried out under these conditions, four resulted in a goal being scored. This is a very good success rate. It should be noted that from the seven goals scored in this game, four resulted from set pieces. This shows the importance of having accurate, reliable and swift set pieces in MSL games. These high values were observed consistently throughout the whole championship. They were crucial in the teams success, proving to be a powerful asset for achieving victories. An identical analysis was performed based on the logs of the RoboCup’2009 semi-final game, in which CAMBADA played against the same opponent of the 2008 final: Tech United. Table 11 shows the obtained results. In RoboCup’2009 the number of set pieces in the semi-final (against Tech United) was 25, of which 20 were correctly executed (80%). It should be noticed that 2009 rules make it much more difficult to control the ball during the execution of the coordinated procedure following a set piece. While in 2008 the ball moved very little during the execution of the coordinated procedure (robots moved to touch the ball and then the replacer shoots to goal), the 2009 MSL rules make it obligatory for the ball to roll free for at least 0.5m. This gives more time for the opponent team to react and forces the interception of a moving ball, a capability that is still not perfectly performed with the current robots. The outcomes of the 20 set pieces that were correctly executed in that semi-final can be observed in Table 12 . 6.4 Competition results Tables 13 and 14 present the competition results of CAMBADA in RoboCup’2008 and RoboCup’2009. In 2008, the team won 11 out of 13 games, scoring a total of 73 goals and suffering only 11 goals. The participation in 2009 also resulted in the team winning 12 of the 14 played games, scoring a total of 71 goals, far more than any other team, and suffering 13 goals. 7 Conclusion This paper presented and evaluated the coordination methodologies of CAMBADA, one of the top teams in RoboCup MSL world championships (champion in RoboCup’2008, 3rd place winner in RoboCup’2009). During open play, an implicit coordination approach, based on formations, flexible positionings and dynamic role and positioning assignment, is used. The positioning of the team adapts to the external game conditions and maintains a strong defense and a good backup to the striker role. This is achieved through priority-based positioning/role assignment algorithms that maintain a competitive formation even when robot malfunctions decrease the number of field players. The positioning assignment algorithm is focused on covering the most important roles/positionings and differs substantially from previously presented algorithms that were based on role exchange. The success of the approach can be seen, not only from the competition results, but also from the detailed analysis of game logs and videos, as presented in the paper. More importantly, and this is one of the clearest evidences, the good competition results were obtained despite the fact that CAMBADA robots clearly move at low speed (2m/s), when compared to most of the main competitors which move faster (2.5–4m/s). The development of pre-defined role-based set plays proved to be very efficient both during the development phase, and during their execution in games. More than half of the 73 scored goals are direct result of these set plays. One of the most significant aspects of this work is the integration of the described coordination methodologies in a complex multi-robot system and their validation in the challenging RoboCup MSL competition scenario. This contrasts with many other approaches described in the literature, which are often validated in more controlled robotic environments, if not in simulation. Acknowledgments The CAMBADA team was funded by the Portuguese Government – FCT-POSI/ROBO/43908/2002 (CAMBADA) and currently FCT, PTDC/EIA/70695/2006 (ACORD). We would also like to thank the rest of the CAMBADA team for an excellent work environment. References [1] F. Noreils Toward a robot architecture integrating cooperation between mobile robots: application to indoor environment Int J Robotics Res 12 1993 79 98 [2] P. Wang Navigation strategies for multiple autonomous mobile robots moving in formation J Robotic Syst 8 2 1991 177 195 [3] Balch T, Parker L. Robot teams: from diversity to polymorphism. Natick (Massachusetts): A K Peters Ltd.; 2002. [4] Low KH, Gordon GJ, et al. Adaptive sampling for multi-robot wide-area exploration. In: Proc IEEE int conf on robotics and automation, Rome, Italy; 2007. p. 755–60. [5] Yamauchi B. Frontier-based exploration using multiple robots. In: Proc second int conf on autonomous agents; 1998. p. 47–53. [6] W. Burgard M. Moors C. Stachniss F. Schneider Coordinated multi-robot exploration IEEE Trans Robotics Autom 21 3 2005 376 386 [7] S. Carpin Fast and accurate map merging for multi-robot systems Auton Robots 25 3 2008 305 316 [8] Dahl T, Mataric M, Sukhatme G. Emergent robot differentiation for distributed multi-robot task allocation. In: Proc 7th international symposium on distributed autonomous robotic systems, Toulouse, France; 2004. p. 201–10. [9] Figueiredo L, Jesus I, Machado J, Ferreira J, de Carvalho JM. Towards the development of intelligent transportation systems. In: Proc IEEE intellig transport syst; 2001. p. 1206–11. [10] Tewolde G, Wu G, et al. Distributed multi-robot work load partition in manufacturing automation. In: Proc IEEE int conf on autom science and eng, Arlington, VA, USA, 2008. p. 504–9. [11] Fagiolini A, Pellinacci M, et al. Consensus-based distributed intrusion detection for multi-robot systems. In: Proc IEEE int conf robotics and automation, Pasadena, CA, USA; 2008. p. 120–7. [12] Agmon N, Kraus S, Kaminka G. Multi-robot perimeter patrol in adversarial settings. In: Proc IEEE int conf on robotics and automation, Pasadena CA, USA; 2008. p. 2339–45. [13] Lima P, Custdio L, Akin I, Jacoff A, Kraezschmar G, Ng BK, et al. RoboCup 2004 competitions and symposium: a small kick for robots a giant score for science. AI Mag 2005;6(2):36–61. [14] B.P. Gerkey M. Mataric A formal analysis and taxonomy of task allocation in multi-robot systems Int J Robotics Res 23 9 2004 939 954 [15] Michael N, Zavlanos M, et al. Distributed multi-robot task assignment and formation control. In: Proc IEEE int conf on robotics and automation, Pasadena CA; 2008, pp. 128–33. [16] P. Stone M. Veloso Task decomposition, dynamic role assignment and low bandwidth communication for real time strategic teamwork Artif Intell 110 2 1999 241 273 [17] L. Reis N. Lau E. Oliveira Situation based strategic positioning for coordinating a team of homogeneous agents M. Hannenbauer Balancing reactivity and social deliberation in multiagent sytems: from RoboCup to real word applications LNAI vol. 2103 2001 Springer-Verlag 175 197 [18] E. Pagello A. DGAngelo E. Menegatti Cooperation issues and distributed sensing for multirobot systems Proc IEEE 94 7 2006 1370 1383 [19] T. Balch R. Arkin Behavior-based formation control for multirobot teams IEEE Trans Robotics Autom 14 6 1998 926 939 [20] Cheah C, Hou S, Slotine J. Region following formation control for multi-robot systems. In: Proc IEEE int conf on robotics and automation, Pasadena CA, USA; 2008. p. 3796–801. [21] Joyeux S, Alami R, Lacroix S. A plan manager for multi-robot systems. In: Proc 6th int conf on field and service robotics, Chamonix, France; 2007. p. 443–52. [22] Lesser V, Decker K, Wagner T, Carver N, Garvey A, Horling B, et al. Evolution of the GPGP/TAEMS domain-independent coordination framework. In: Autonomous agents and multi-agent systems, vol. 9(1); 2004. p. 87–143. [23] Dietl M, Gutmann J-S, Nebel B. Cooperative sensing in dynamic environments. In: Proc IEEE/RSJ int conf on intelligent robots and systems (IROS’01), Maui, Hawaii; 2001. [24] Lau N, Seabra Lopes L, Corrente G. Cambada: information sharing and team coordination. In: Autonomous robot systems and competitions: proc of the 8th conference. Aveiro (Portugal): Universidade de Aveiro; 2008. p. 27–32. [25] Figueiredo J, Lau N, Pereira A. Multi-agent debugging and monitoring framework. In: Proc first IFAC workshop on multivehicle systems (MVS’06), Brazil; 2006. [26] Rosa MD, Campbell J, et al. Distributed watchpoints: debugging large multi-robot systems. In: Proc IEEE int conf on robotics and automation, Rome, Italy; 2007. p. 3723–9. [27] M.T.C. 1997–2009. Middle size robot league rules and regulations for 2009. Version – 13.1 20081212 [December 2008]. [28] Azevedo J, Cunha M, Almeida L. Hierarchical distributed architectures for autonomous mobile robots: a case study. In: Proc ETFA2007 – 12th IEEE conference on emerging technologies and factory automation, Patras, Greece; 2007. p. 973–80. [29] Almeida L, Santos F, Facchinetti T, Pedreira P, Silva V, Seabra Lopes L. Coordinating distributed autonomous agents with a real-time database: the CAMBADA project. In: C A, et al., editors. Computer and information sciences – ISCIS 2004: proc 19th international symposium, LNCS, vol. 3280, Antalya, Turkey; 2004. p. 876–86. [30] Pedreiras P, Teixeira F, Ferreira N, Almeida L, Pinho A, Santos F. Enhancing the reactivity of the vision subsystem in autonomous mobile robots using real-time techniques. In: Noda I, A J, et al., editors. RoboCup-2005: robot soccer world cup IX, LNAI, vol. 4020. Berlin: Springer; 2006. p. 371–83. [31] P. Pedreiras L. Almeida Task management for soft real-time applications based on general purpose operating systems P. Lima Robotic soccer 2007 Itech Education and Publishing Vienna (Austria) 598 607 [32] A. Neves G. Corrente A. Pinho An omnidirectional vision system for soccer robots Progress in artificial intelligence LNCS vol. 4874 2007 Springer Berlin 499 507 [33] Cunha B, Azevedo J, Lau N, Almeida L. Obtaining the inverse distance map from a non-svp hyperbolic catadioptric robotic vision system. In: Visser, U, et al., editors. RoboCup-2007: robot soccer world cup XI, LNAI. Berlin: Springer Verlag; 2008. [34] Lau N, Seabra Lopes L, Corrente G, Filipe N. Multi-robot team coordination through roles, positionings and coordinated procedures. In: Proc of the 2009 IEEE/RSJ international conference on intelligent robots and systems – IROS 2009, St. Louis, MO, USA; 2009. [35] Weigel T, Auerbach M, et al. Cs freiburg: doing the right thing in a group. In: P S., et al., editors. RoboCup-2000: robot soccer world cup IV, LNAI, vol. 2019. Springer-Verlag; 2001. p. 52–63. [36] M A, et al. Creating a robot soccer team from scratch: the brainstormers tribots. In: Proc of RoboCup 2003, Padua, Italy; 2003. [37] Reis L, Lau N. FC Portugal team description: RoboCup 2000 simulation league champion. In: Stone P, et al., editors. RoboCup-2000: robot soccer world cup IV, LNCS, vol. 2019. Springer; 2001. p. 29–40. [38] J. Kok M. Spaan N. Vlassis Non-communicative multi-robot coordination in dynamic environments Robotics Auton Syst 50 2-3 2005 99 114 [39] Riedmiller M, Gabel T. On experiences in a complex and competitive gaming domain: reinforcement learning meets RoboCup. In: Proc of the 3rd IEEE symposium on computational intelligence and games (CIG 2007). Honolulu (Hawaii):IEEE Press; 2007. p. 17–23. [40] H M, et al. Making a robot learn to play soccer using reward and punishment. In: KI 2007: Advances in artificial intelligence, LNCS, vol. 4667. Springer; 2007. p. 220–34. [41] Oubbati M, Schanz M, Buchheim T, Levi P. Velocity control of an omnidirectional RoboCup player with recurrent neural networks. In: A B, et al., editors. RoboCup 2005: robot soccer world cup IX, LNAI, vol. 4020. Springer; 2006. p. 691–701. [42] Hafner R, Lange S, Lauer M, Riedmiller M. Brainstormers tribots team description; 2008. [43] Sato Y, et al. Hibikino-musashi team description paper; 2008. [44] E.T. Group. Ethercat robots win german open, May 2008. [45] Santos F, Almeida L, Seabra Lopes L, Azevedo JL, Cunha MB. Communicating among robots in the RoboCup middle-size league. In: Baltes J, Lagoudakis MG, Naruse T, Ghidary SS, editors. RoboCup 2009: robot soccer world cup XIII, LNAI, vol. 5949. Berlin/Heidelberg: Springer; 2010. p. 320–31. [46] Lauer M, Lange S, Riedmiller M. Calculating the perfect match: an efficient and accurate approach for robot self-localisation. In: Bredenfeld A, et al., editors. RoboCup 2005: robot soccer world cup IX, LNAI, vol. 4020. Springer; 2006. [47] Ferrein A, Hermanns L, Lakemeyer G. Comparing sensor fusion techniques for ball position estimation. In: A B, et al., editors. RoboCup 2005: robot soccer world cup IX, LNAI, vol. 4020. Springer; 2006. 154–65. [48] van der Vecht B, Lima P. Formulation and implementation of relational behaviours for multi-robot cooperative systems. In: RoboCup 2004: robot soccer world cup VIII, LNAI, vol. 3276. Springer; 2005. p. 516–23. [49] O. Zweigle R. Lafrenz T. Buchheim U.-P. Kppeler H. Rajaie F. Schreiber Cooperative agent behavior based on special interaction nets Intell Auton Syst 2006 651 659 "
    },
    {
        "doc_title": "Multi-robot coordination using Setplays in the middle-size and simulation leagues",
        "doc_scopus_id": "79952629233",
        "doc_doi": "10.1016/j.mechatronics.2010.05.005",
        "doc_eid": "2-s2.0-79952629233",
        "doc_date": "2011-01-01",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Control and Systems Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2207"
            },
            {
                "area_name": "Mechanical Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2210"
            },
            {
                "area_name": "Computer Science Applications",
                "area_abbreviation": "COMP",
                "area_code": "1706"
            },
            {
                "area_name": "Electrical and Electronic Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2208"
            }
        ],
        "doc_keywords": [
            "Inter-robot communication",
            "Middle-size league",
            "Multi agent cooperation",
            "Multi-agent coordinations",
            "Multi-robot coordination",
            "Robotic soccer team",
            "Setplay",
            "Simulation league"
        ],
        "doc_abstract": "Strategic planning and multi-agent coordination are major research topics in the domain of RoboCup. Innovations in these areas are, however, often developed and applied to only a single RoboCup league and/or one domain, without proper generalization. Moreover, the more technical leagues, like middle-size and humanoid, tend to focus development on low-level skills, that often suffice to gain a competitive edge over other teams. In these leagues, the development of high-level cooperation is secondary. Although the importance of the concept of Setplay, to structure a robotic soccer team behaviour, has been acknowledged by many researchers, no general framework for the development and execution of generic Setplays has been introduced in the context of RoboCup. This paper presents such a framework for high-level Setplay definition and execution, applicable to any RoboCup cooperative league and similar domains. The framework is based on a flexible, standard and league-independent language, which defines Setplays that are interpreted and executed at run-time, using inter-robot communication. An initial major step in the development of the Setplay framework was its usage and testing in the scope of the FCPortugal team, which participates in the RoboCup 2D-simulation and 3D-simulation leagues, where it won several titles both in the 2D and 3D leagues. This framework was also recently implemented in the middle-size team CAMBADA. This team has, in the recent past and with previous versions of the control software, ranked first and third in RoboCup's 2008 and 2009 editions. The implementation is described with concrete examples of Setplay definition and execution, which shows the usefulness of this approach and motivate its use as a major coordination tool for teams participating in the simulation, small-size, middle-size, standard platform and humanoid leagues of RoboCup. © 2010 Elsevier Ltd. All rights reserved.",
        "available": true,
        "clean_text": "serial JL 271456 291210 291718 291787 291883 31 Mechatronics MECHATRONICS 2010-07-16 2010-07-16 2011-03-08T22:21:19 S0957-4158(10)00085-1 S0957415810000851 10.1016/j.mechatronics.2010.05.005 S300 S300.1 FULL-TEXT 2015-05-15T03:43:39.596909-04:00 0 0 20110301 20110331 2011 2010-07-16T00:00:00Z articleinfo crossmark dco dateupdated tomb dateloaded datesearch indexeddate issuelist volumelist yearnav articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids confeditor contenttype copyright dateloadedtxt docsubtype doctype doi eid ewtransactionid hubeid issfirst issn issnnorm itemstage itemtransactionid itemweight openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sectiontitle sortorder srctitle srctitlenorm srctype subheadings vol volfirst volissue figure body affil articletitle auth authfirstini authfull authkeywords authlast footnotes primabst ref alllist content subj ssids 0957-4158 09574158 21 21 2 2 Volume 21, Issue 2 9 434 444 434 444 201103 March 2011 2011-03-01 2011-03-31 2011 Special Issue on Advances in intelligent robot design for the Robocup Middle Size League M.J.G. van de Molengraft O. Zweigle Special Issue on Advances in intelligent robot design for the Robocup Middle Size League article fla Copyright © 2010 Elsevier Ltd. All rights reserved. MULTIROBOTCOORDINATIONUSINGSETPLAYSINMIDDLESIZESIMULATIONLEAGUES MOTA L 1 Introduction 1.1 Motivation and requirements 1.2 Article outline 2 State of the art 2.1 Coordination in the middle-size league 2.2 Coordination through positioning 2.3 Coordination through plays 3 Setplay framework 3.1 Inter-robot communication 3.2 Implementation as a C++ library 3.3 Framework usage 4 Usage in the simulation 2D league 4.1 Inter-robot communication 4.2 Example Setplay 5 Usage in the middle-size league 5.1 Inter-robot communication 5.2 Example Setplay 6 Future work and conclusions References KITANO 1997 73 85 H LAU 2007 N FCPORTUGALHIGHLEVELCOORDINATIONMETHODOLOGIESINSOCCERROBOTICS NODA 1998 233 250 I REIS 2000 29 40 L ROBOCUP2000ROBOTSOCCERWORLDCUPIV FCPORTUGALTEAMDESCRIPTIONROBOCUP2000SIMULATIONLEAGUECHAMPION REIS 2002 183 192 L ROBOCUP2001ROBOTSOCCERWORLDCUPV COACHUNILANGASTANDARDLANGUAGEFORCOACHINGAROBOSOCCERTEAM REIS 2001 175 197 L BALANCINGREACTSOCIALDELIBERATIONINMAS SITUATIONBASEDSTRATEGICPOSITIONINGFORCOORDINATINGASIMULATEDROBOSOCCERTEAM ROS 2007 R LNCS TEAMPLAYINGBEHAVIORINROBOTSOCCERACASEBASEDREASONINGAPPROACH STONE 1999 241 273 P MOTAX2011X434 MOTAX2011X434X444 MOTAX2011X434XL MOTAX2011X434X444XL item S0957-4158(10)00085-1 S0957415810000851 10.1016/j.mechatronics.2010.05.005 271456 2011-03-10T12:04:28.245691-05:00 2011-03-01 2011-03-31 true 1242211 MAIN 11 76638 849 656 IMAGE-WEB-PDF 1 gr10 115291 632 578 gr10 5233 164 150 gr11 157097 764 661 gr11 5591 164 142 gr12 34589 553 367 gr12 6907 164 109 gr2 17147 462 332 gr2 2550 164 118 gr3 46689 355 623 gr3 6419 125 219 gr4 20994 353 373 gr4 5070 164 173 gr5 35784 240 600 gr5 5205 88 219 gr6 39912 394 511 gr6 7123 164 213 gr7 41047 399 511 gr7 7248 164 210 gr8 30695 404 373 gr8 5045 164 151 gr9 32691 322 524 gr9 10586 135 219 gr1 20377 237 524 gr1 3599 99 219 MECH 1159 S0957-4158(10)00085-1 10.1016/j.mechatronics.2010.05.005 Elsevier Ltd Fig. 1 Replacer’s state machine, from [23]. Fig. 2 Receiver’s state machine, from [23]. Fig. 3 Setplay definition. Fig. 4 Transitions between Steps. Fig. 5 Action definition. Fig. 6 Condition definition. Fig. 7 Region definition. Fig. 8 Setplay interaction scheme. Fig. 9 Corner Setplay execution steps. Fig. 10 Corner Setplay definition. Fig. 11 Play-on Setplay definition. Fig. 12 Play-on Setplay execution steps. Multi-robot coordination using Setplays in the middle-size and simulation leagues Luís Mota a b ⁎ Luís Paulo Reis b c Nuno Lau d e a Instituto Universitário de Lisboa (ISCTE-IUL), Lisboa, Portugal b Laboratório de Inteligência Artificial e Ciência de Computadores (LIACC) da Universidade do Porto, Porto, Portugal c Departamento de Engenharia Informática (DEI/FEUP), Faculdade de Engenharia da Universidade do Porto, Porto, Portugal d Instituto de Engenharia Electrónica e Telemática de Aveiro (IEETA), Portugal e Departamento de Electrónica e Telecomunicações da (DETUA), Universidade de Aveiro, Portugal ⁎ Corresponding author. Strategic planning and multi-agent coordination are major research topics in the domain of RoboCup. Innovations in these areas are, however, often developed and applied to only a single RoboCup league and/or one domain, without proper generalization. Moreover, the more technical leagues, like middle-size and humanoid, tend to focus development on low-level skills, that often suffice to gain a competitive edge over other teams. In these leagues, the development of high-level cooperation is secondary. Although the importance of the concept of Setplay, to structure a robotic soccer team behaviour, has been acknowledged by many researchers, no general framework for the development and execution of generic Setplays has been introduced in the context of RoboCup. This paper presents such a framework for high-level Setplay definition and execution, applicable to any RoboCup cooperative league and similar domains. The framework is based on a flexible, standard and league-independent language, which defines Setplays that are interpreted and executed at run-time, using inter-robot communication. An initial major step in the development of the Setplay framework was its usage and testing in the scope of the FCPortugal team, which participates in the RoboCup 2D-simulation and 3D-simulation leagues, where it won several titles both in the 2D and 3D leagues. This framework was also recently implemented in the middle-size team CAMBADA. This team has, in the recent past and with previous versions of the control software, ranked first and third in RoboCup’s 2008 and 2009 editions. The implementation is described with concrete examples of Setplay definition and execution, which shows the usefulness of this approach and motivate its use as a major coordination tool for teams participating in the simulation, small-size, middle-size, standard platform and humanoid leagues of RoboCup. Keywords Multi-agent cooperation Setplay Middle-size league 1 Introduction RoboCup 1 1 [4] is an international initiative to promote Artificial Intelligence, robotics, and related fields. It fosters research by providing a standard problem where a wide range of technologies can be integrated and examined. RoboCup uses the soccer game as a central topic of research, aiming at innovations to be applied for socially significant problems and industries. Research topics include design principles of autonomous agents, strategy acquisition, real-time reasoning, robotics, and multi-agent collaboration, which this paper aims at contributing to. Robotic Soccer needs, as the research in the domain develops, coordination at team scope, which involves planning at many levels. This paper deals with representing and executing high-level, flexible plans for robots playing in different RoboCup leagues. A framework for representing, executing and evaluating such plans is presented, relying on a high-level Setplay definition language and inter-robot communication. Setplays are commonly used in many team sports such as soccer, rugby, handball, basketball and baseball. There are surely several important differences between robot soccer and human sports, but Setplays are nonetheless a useful tool for high-level coordination and cooperation, since they allow the definition of how different players interact in key situations. In the sense employed in this article, a Setplay is a freely-definable, flexible and multi-step plan, which allows alternative execution paths, involving a variable number of robots. 1.1 Motivation and requirements The CAMBADA team 2 2 has, in recent years, obtained very good results in the RoboCup competitions. The final ranks in the editions since 2007 have been 5th, 1st and 3rd. These achievements are a result of a continuous effort to enhance the team performance. Namely, the team performance was highly improved when playing set pieces, i.e., throw-ins, free-kicks, goal-kicks and other similar situations decided by the referee. In recent years, rule changes were made in order to encourage team-play [14]. With the goal of avoiding that a single player dribbles around the field before eventually shooting at goal, set-pieces must include a pass, between the two players that first touch the ball, and these must have at least one meters between them. Set pieces [7] are a very important part of CAMBADA game. For example, in the 2008 Robocup final, four of the seven goals scored resulted directly from a set piece. In a typical set piece scenario, there are three robots directly involved, while the rest are in strategic positions. A typical set piece, as it has been used in CAMBADA in recent years will be now described, to better motivate the subsequent development of the Setplay framework. Set pieces are based in two roles: Replacer, the robot that makes the pass, and Receiver, the robot that will receive the ball and then go on playing, shooting at the goal. In each set piece there will be one Replacer and two Receivers. The Replacer role (see the state machine in Fig. 1 ) is the one responsible for giving the first touch to the ball in every set piece. This role is the one in charge of beginning the set piece. It will position itself close to the ball (state “Positioning”), decide which Receiver to pass to (state “Evaluation”), align with the chosen Receiver (state “Aligned”) and, after passing (state “Pass”), it will move away. The role Receiver (see state machine in Fig. 2 ) is responsible for the positioning of two robots in the set pieces. One of those robots will receive a pass from the Replacer, as described before, after correctly positioning itself (state “Positioning”). It will then receive the ball (state “Receive”) and subsequently kick the it into the opponent goal (state “Kick”). In this previous approach, the strategy for set pieces can be parameterized in a configuration file. In that file there is information about the positioning of the Receivers for every set piece and to whom the Replacer should pass first. The configuration file is written in XML and contains many informations, such as field dimensions and other parameters [3]. However, the configuration of set-pieces is limited: the general execution is hard-coded, and only the positioning of the participating roles can be changed. In the team that played in RoboCup 2009 there was no way of defining a new Setplay, like, e.g., the Replacer passing to a ReceiverA, which would in turn pass to a ReceiverB, which would eventually shoot at goal. Since the skills of robots are continuously improving, and opponents try to react to new developments and counter them, it would be very useful for the CAMBADA team if there would be a new way of freely defining arbitrary Setplays, through configuration files or even a generic Setplay graphical editor like the one already developed for Setplay and formations definition in the FC Portugal team [11]. This kind of collective play is described and shared in a standard, league-independent and flexible way, which is interpreted and executed at run-time. The first benefit is the possibility of writing arbitrary Setplays, which are dynamically used during the game, opening horizons to new plays which will, for instance, differ from game to game, to better deal with each opponents’ characteristics. In this sense, the Setplays are also used in different leagues. Furthermore, since any player can have access to the definition of Setplays and interpret their content, Setplays can, in the future, also be a means for the creation of mixed teams, where heterogeneous robots, i.e., robots with different origin, with distinct hardware and software, would play together: when the Setplays are being executed, players simply have to follow the steps in the Setplay in order to cooperate. To fulfil these requirements, one needs a new standard language, where Setplays can be defined and interpreted by any player in any league. The basic concepts of soccer (moves, conditions, actions, skills) need a clear and concrete definition. Also, the transitions between intermediary steps have to be expressed, as well as termination conditions. Such a language is thus the scientific subject being presented in the remainder of this article. Further, a new framework has been developed in C++ to ease the implementation of Setplays in any team: this framework already provides different features: a parser for Setplay definition files and an engine to run the Setplays. As such, in order to implement Setplays in a new team, only two tasks have to be carried out: implement the testing of soccer conditions and the execution of actions in this domain. Details on these tasks will be given in Section 3.2. 1.2 Article outline A brief State of the Art in cooperative team-play in the RoboCup domain, as well as related work, are presented in Section 2. The framework that models this language is presented in Section 3, including its distribution as a C++ library. The implementation of a full-blown prototype of usage of the framework in the 2D simulation server [15] was a major step in the testing of this framework, and is described in Section 4. This implementation was done on top of the code of the FCPortugal team. 3 3 The main focus of this article, the framework implementation in the middle-size team CAMBADA is presented in Section 5. Finally, conclusions are drawn, and future lines of research are presented in Section 6. 2 State of the art 2.1 Coordination in the middle-size league The CAMBADA coordination [6] is based in Situation Based Strategic Positioning (SBSP) [18,16] strategies used in RoboCup 2D simulation league, adapted to the MSL specifications. For role assignment a dynamic algorithm that adapts the formation to a possible varying number of active robots, is used, which will assign each role/robot to the strategic positionings according to priorities and number of active robots [7]. CAMBADA has in recent years also been using simple Setplays in key situations like corners, kick-offs and free-kicks. Such Setplays can have their parameters configured, but cannot be freely defined: their execution structure is hard-coded. TechUnited [1] team has recently switched from static to dynamic assignment of roles, which is done centrally by a dedicated module, based on world-state, namely player and ball positions. The Brainstormers Tribots [5] have their roles, and the team formation, decided centrally by a dedicated, high-level module. The closest robot to the ball acts as a master and decides which play to use. Such plays are managed through communication and managed through a master player, but it is unclear how they are defined [10]. RFC Stuttgart, formerly CoPS [26], use dynamic role assignment, with sub-roles, e.g., role Defender and sub-role Left or Right. The role allocation is done locally by every robot, based on the shared world model, that integrates information from all robots. This being the case, inconsistencies are minimised, since all robots decide based on the same information. Role allocation will be potentially wrong only when the shared world model is inconsistent. Coordination in this league is thus mainly structured around positional and role-allocation techniques. Setplay based cooperation is beginning to be used in specific situations, by teams CAMBADA and Brainstormers Tribots, but only using limited and rigid techniques. 2.2 Coordination through positioning A method to achieve coordination based on repulsions and attractions called Strategic Positioning by Attraction and Repulsion (SPAR) was introduced by [24]. When an agent is positioning itself using SPAR, the agent maximizes the distance to other players and minimizes the distance to ball and to goal. This is achieved evaluating several forces: repulsion from opponents and team-mates, attraction to active team mate, ball and opponent goal. It also uses other constraints that have influence in agent’s positioning: stay in an area near home position, stay within the field boundaries, avoid being at an offside position and stay in a position where is possible to receive a pass. Later the Situation Based Strategic Positioning (SBSP) was introduced by [18,9]. If an agent is not involved, and will not be soon, in an active situation it will try to occupy its strategic position relative to the actual situation of the game, which can dynamically change when the situation changes. The dynamic changes of one player will influence the decision of others, which will avoid that several players take the same strategic position. Through the analysis of the tactic, formation, self positioning in the formation and player type, a player is able to define its base strategic positioning. This position is then adjusted accordingly to ball position and velocity and situation (i.e. attack, defence, etc.). The player type defines the player’s strategic characteristics like ball attraction, admissible regions in the field, specific positional characteristics for some regions in the field, tendency to stay behind the ball, alignment in the offside line, and attraction by specific points in the field in some situations. Using a strategic positioning like SBSP the players will be more well distributed over the field than using a active one like SPAR, this is the reason why other teams adopted SBSP as the standard positioning method. 2.3 Coordination through plays In this section, a Play is considered either a role allocation algorithm, or a small plan, involving all or part of the players in a team, which defines their positioning and/or choice of actions. A Role is a particular participation of a robot in a Play, which may include Parametres, that are variables that influence the Play’s definition and execution. The concept of Setplay is present in a teamwork and communication strategy for the 2D simulation league, presented by [25]. These Setplays, however, lack some of the most relevant features now presented. Namely, they are meant to be used only in very specific situations, like corner kicks and throw-ins, which are decided by the referee, and are unique for each of these situations. Thus, the question of Setplay activation and choice is not considered. Further, there is no mention to Parameters, though Player Roles are proposed. Most important, a Setplay is limited to a sequence of Steps, without alternatives, which excludes the need of choice announcing, and therefore the use of communication with this purpose. A strategy for role assignment in the now defunct four-legged league was introduced by [12]. This strategy implies the communication of the currently chosen Play, which provides a set of Roles to be assigned to all the available players in the team. The strategy assures coordination by the existence of a leader that selects the best momentary Play and instructs the other robots on what Roles to take. Each Role fully determines the player’s behaviour. The strategy does not, however, define a concept of Setplay with intermediary states, and Plays do not have Parameters. Also in the context of the four-legged league, [22] introduced a Case-based-reasoning inspired system, relying on the concept of Play. Plays are a more limited concept than Setplays, since they merely aim at distributing roles among all the teams players. It is therefore more of a coordination methodology than cooperation with actual plans, as is the case with Setplays. The RFC Stuttgart/CoPS team uses Special Interaction Nets [27], a simplified version of Interaction Nets adapted to cooperation in multi-agent environments. These diagrams include states, representing actions, transitions, which model conditions, eventually global, and sub-nets, with all the former components. Certain conditions can model time-dependent issues, and can be used to synchronise multi-agent behaviour. Messages can also be used to synchronise multiple networks. The model does not present a standard set of concepts, which does not enforce generalisation and may lead to the developing of very specific cooperative strategies. The Extensible Agent Behaviour Specification Language (XABSL) is a language to describe behaviours for autonomous agents based on hierarchical finite state machines, and has been used by different teams in RoboCup, namely the German Team [21]. Recent developments [20] have allowed the use of the language to develop cooperative multi-agent behaviour, through synchronisation elements, that allow the specification of minimum or maximum number of robots is a given state. This kind of cooperation does, though, not easily allow the incorporation of communication [19]. Also, the programming of cooperative behaviour requires the definition of options, through a dedicated language. The described approaches that are more than role allocation algorithms are limited in some aspects: either they do not define a standard vocabulary, they do not allow real-time definition of parameters, they can be started only in particular situations, they do not allow alternatives in the definition of Setplays or they do not allow the quick prototyping of new Setplays through easily editable files. There is, thus, place for large improvements. 3 Setplay framework As stated in Section 1, a Setplay is a freely-definable, flexible and multi-step plan, which allows alternative execution paths, involving a variable number of robots. The Setplay framework was designed with the goal of being general, flexible, parameterizable and applicable to any robotic soccer league. Its general structure is shown schematically in Fig. 3 . At the top level, a Setplay is identified by a name, and has parameters, which can be simple data types like integers and decimals, or more sophisticated concepts as points and regions. Setplays also have Player References, which identify players taking part in the Setplay. The Player References can point to specific players, or be Player Roles, i.e., abstract representations of a particular role in the Setplay, identified by a name (e.g., attacker, supporter). Parameters and Player Roles will be instantiated at run-time, allowing a flexible use of the Setplay. An abortCond exists to define conditions that, if satisfied, will make the Setplay at any moment in its’ execution. Steps are the main building block of a Setplay, which contains an arbitrary number of Steps, gathered in a list. A Step can be seen as a state in the execution of a Setplay. By convention, the first Step in a Setplay is always labelled with 0 as its id. The players participating in a Setplay will follow some, or all, of these Steps in order to accomplish the successful execution of the Setplay. A Step has an id, which is a non-negative integer. In order to control the Step’s execution, the concepts of wait time and abort time are introduced. Wait time is the amount of time the player should wait, after entering the Step, before starting the transition to another Step, or simply finishing the Setplay. The abort time is the threshold after which the players will abandon the Setplay, if it was not possible to progress from this Step to another one. A Step also has a Condition, which must be satisfied before entering the Step. A list of Participations, in this scope called participants, identify the players taking part in the Step, optionally also defining their positioning. There are several possible ways out of a Step, which are defined as Transitions, see Fig. 4 . All Transitions can have a Condition, which must be satisfied for the Transition to be followed. An Abort Transition represents a situation where the Setplay must be abandoned, either because it is no longer judged useful, or it is thought that it will not reach its goal. The Finish Transition represents that the Setplay has reached its intended goal and should stop at this point. The main Transition, that is used to link between the different Steps is defined as NextStep. It includes the id of the next Step to be reached, and contains a list of Directives that will be applied in order to accomplish the Transition. Directives connect players to Actions and can be of two kinds: Do and Don’t, meaning respectively that the contained Actions should, or should not, be executed. In this context, Actions, depicted in Fig. 5 , are abstract, high-level concepts that represent skills and moves, both simple and complex, that can be executed by a player. Examples of such Actions are passing the ball to a player or region, shooting at goal, intercepting the ball, or dribbling. In this Setplay framework, the Action concepts were inspired by the ones defined by Clang [2], the coaching language used in the simulation league. There is, however, one added Action which is absent from this language: the concept of Action Sequence, where several actions are to be executed following a particular order. Conditions model high-level characteristics of the State of the World, specifically modelling the domain of robotic soccer. Examples of such Conditions, depicted in Fig. 6 , are players and ball positions, ball ownership and play-mode. Similarly to the Actions, the majority of the Conditions in this framework were inspired in Clang. In this case, however, several new Conditions had to be introduced, in order to model complementary situations. Particularly, some Conditions refer to the possibility of accomplishing passes and shots, i.e., modelling the success of passes to players and regions, and shots at goal. One should pay special attention to this kind of Conditions: they are not based on a verifiable state-of-the world, but instead are an estimation of a success rate. This could be considered as intrinsically different from Conditions like player position, which are tangible and verifiable. Even these Conditions are, in the scope of robotic soccer, also somehow an estimation: the players do not know the real state-of-the-world, they simply have their own view, built from own observation and information shared by other team-mates. Therefore, for the sake of simplicity and expressiveness, all these concepts are indistinguishable considered Conditions. Regions are another concept in the core of the definition of Setplay, and are depicted in the diagram in Fig. 7 . Once again, these concepts originate from Clang, including spatial entities like points, Triangles, Arcs and Rectangles. Similarly, the concept of Dynamic Point, referring to the location of a player or of the ball, is also introduced. Named regions are introduced to model intuitive locations like ‘our mid-field’ or ‘their penalty box’, as defined in [17]. 3.1 Inter-robot communication A relevant issue in the usage of the framework is how to achieve coordination between the robots when executing a Setplay. Naturally, a complex Setplay must follow several steps, and all participating players must be tightly synchronized in order to achieve fruitful cooperation. The first step towards this objective was to define a communication and synchronization policy, which should be as straight-forward as possible, and can be seen in Fig. 8 . Each step will be led by the so-called lead player, who will normally be either the player with ball possession (see Section 4.1), since it is the one which has to take the most important decisions, while manipulating the ball, or a special agent (e.g. the coach, see Section 5.1). This player is determined through the Setplay definition, and it must not, naturally, be fixed throughout the Setplay, which means it can change from step to step, while monitoring the execution of the Setplay. On Setplay start, the lead player will instruct the other players on Setplay begin, communicating the Setplay number, the participating players and the other (optional) parameters (message startSetplay in Fig. 8). Along Setplay execution, the verification of step entry and the choice of a transition will be announced through stepChange and nextStep messages, as seen in Fig. 8. The entry into a new step, which is decided by the lead player in charge of the previous step, can imply the change of the lead player. Other possible messages are related to Setplay end: the lead player may verify that a Setplay is finished, when it chooses a Finish Transition, or that it must be aborted, when a Abort Transition is followed or the general Abort Condition is satisfied. Such situations will be announced through the corresponding messages. In momentary situations, the failure of the lead player, or communication problems, would impair the management of Setplay execution. Precisely to avoid these situations, Setplays have abort timeouts that will stop the execution in case of lead player’s inaction. The implementation of this communication policy is described in more detail through an example in Sections 4.2 and 5.2. 3.2 Implementation as a C++ library The Setplay framework was, from the beginning, intended to be applicable to different teams and leagues: it should be possible to mix players with different originating teams in one single team, while executing Setplays, and, further, the framework should be applied in different leagues, as described in the present article. Since the initial implementation and testing were conducted on top of the FCPortugal and CAMBADA teams, both implemented using C++, it was decided to develop a C++ library, with two goals: ease the implementation in these teams, or any other implemented in C++, and maintain common framework that would be applied to any team. This implementation intended to provide as much tools as possible, and therefore the following two features were developed: Setplay definition parser: Since Setplays can freely be defined using the model described in the last section, it was obviously necessary to develop a parser to load files and translate them to C++ objects. This parser was developed using the Spirit library included in the latest Boost 4 4 distributions. Setplay execution engine: A Setplay execution is trivially determined by its definition. Therefore, the framework can provide an execution engine to be immediately used, out-of-the-box. This way, a team using the framework does not have to worry about the execution of a Setplay: it has to define the domain specific actions and conditions (see next section), and to launch the Setplay. 3.3 Framework usage With the provided library and tools, each team wishing to use the framework only has to accomplish four tasks: Setplay definition: Each team will use a different set of Setplays, according to their strategy and skills. These Setplays can be defined directly in the Setplay definition language, as described above, or use the graphical editor [11]. Implement conditions: The conditions in the Setplay framework are league specific, and must be adapted to the teams’ State-of-the-World implementation. Each condition class has an abstract method to evaluate it that must be implemented. Implement actions: The actions in the Setplay framework are also league and team specific, and must be translated to actual actions or skills. Each Action class has an abstract method to execute it that must be implemented. Deal with communication: The Setplay framework needs messages being exchanged between the players, in order to synchronize the execution of the Setplay. The framework makes this task quite simple: at each moment it is possible, through the invocation of methods, to know if the Framework requires a message to be sent and, in this case, to access its content in plain text. In such situations, the content of the message should be transmitted to other players through the communication channels available. There is also a method to, upon reception, interpret a message. Thus, to deal with the communication issues, it suffices to check regularly if there is a message to be sent, sending it when appropriate, and, at the same time, report each received message to the framework for proper interpretation. To actually use the Setplays, the team has to start the execution of the Setplay by instantiating the parameters included in the Setplay definition, and regularly (i.e., in every execution cycle) update the Setplay status through an update method, which must supply ball and players positions, and check for message received or waiting for emission. An initial prototype [13] of the implementation of the Setplay framework was applied to the simulation 3D league, namely to the FCPortugal3D team [8], which won RoboCup 2006 in this league. This prototype was implemented on top of the 2006 simulator version, where the players were modelled as spheres. In the following year, the players were changed to humanoids, with very complex dynamics, very slow movement and unsure skills. In such an environment, there is no use for high-level coordination: there are presently only three players on each team and development focus on low-level skills. The implementation on this league was thus abandoned and was not subject of real-game testing. 4 Usage in the simulation 2D league As a primary test-bed for the Setplays, the code of the FCPortugal [16], which participates in RoboCup since 2000, was used. This code already had the main building blocks for the implementation of Setplays: a mature state-of-the-world, which considers both own observations and information shared by other players, and which includes prediction of actions’ and interactions’ effects; and a set of actions and skills that allows the easy mapping of actions as defined in the Setplay framework to concrete executions in the 2D simulator. This implementation was achieved after following several steps. First, the Setplay usage scenario was chosen: in the current level of play, it was considered interesting to use Setplays in situations like free-kicks, kick-ins and corners, since these situations are clearly announced by the server, and thus all players can prepare to participate in the Setplay. Secondly, Conditions and Actions as defined in the framework were implemented based on the existing code dealing with world-state, skills and action. Finally, the message exchange needed for the execution of Setplays was implemented, as discussed in Section 4.1. 4.1 Inter-robot communication The major challenge in this implementation was how to deal with the limited communication means allowed by the server. To cope with the limited, single-channel communication, the lead player (i.e, the player with ball possession) will be the only player allowed to send messages. The content of communication must be as concise as possible, in order to follow the 2D simulator’s limitations (messages under 10 bytes in length, only one message per team and cycle) and to leave enough place for the sharing of world-state information, necessary for the maintenance of a satisfactory and up-to-date world model by all players. In order to comply with these limitations, it was chosen to only use Setplays without arguments, since these would use much space in the startup messages (as explained in Section 3.1). The Setplay startup message does therefore only have the participating player numbers as arguments. 4.2 Example Setplay In this section, a simple example is presented, to illustrate the actual definition of Setplays, how the players in the 2D simulation league deal with it, and how inter-robot communication is deployed. A situation where a Setplay can be properly used is the corner-kick: it is an offensive situation close to the opponent goal and holes in the defense can be exploited. To keep this example clear, a simple situation, with only three participants and no opponents, will be described. The Setplay initiator triggers execution, after choosing the participating players from their distance to the positions in the Setplay, by sending a instantiation message- In this case, the lead player is nr. 10 (taking role cornerP), and the two other participants nrs. 7 and 11 (roles receiver and shooter), thus the message sent is as follows: S0 10 7 11 In step 0 of the Setplay, the participating players reach their positions, after which the cornerP tries to reach step 1, passing the ball to the receiver, as depicted in Fig. 9 a. Upon gaining possession of the ball, receiver starts being the new lead player and therefore sends a message to the other players, informing them that the Setplay is currently in step 1, and that the receiver will try to reach step 2, as follows: 1 2 When the receiver verifies that it can make a pass to the shooter, it will do so, as depicted in Fig. 9b. In this figure, the receiver is looking at the shooter in order to accomplish a good pass, as it was the case in the precedent image. Finally, as soon as it considers that shooting at goal is possible, the shooter executes the shot (see Fig. 9c) and moves to step 3, which simply finishes the Setplay. At this moment, the shooter will send a message stating that it reached step 3, and that there is no further step in the Setplay: 3 -1 The described Setplay was defined in a configuration file, read upon player startup, as seen in Fig. 10 . 5 Usage in the middle-size league After successfully having implemented the framework’s usage in the 2D simulation league, it was decided to use it in a real-world environment, the middle-size league. This league’s development in recent years has seen the leading teams’ effort to enhance the high-level performance, through team-level coordination and cooperation schemes, as seen in Section 2. Namely, as it has been described in Section 1.1, team CAMBADA has developed configurable team-play for set pieces. It was thus considered timely to take this kind of team-play one level higher: fully integrate the Setplay framework. Development was, in a first moment, conducted in a simulated environment: CAMBADA has developed a full-blown simulator to ease the development process and avoid the constant use of the robots. The simulator fully emulates the robots’ low-level functions (perceptors and actuators), and hence the high-level software can be directly applied to the robots, with only minor inconsistencies. Development in the simulated environment was quite straight-forward, and, after implementing the abstract Conditions and Actions, the robots were quickly executing Setplays. Special attention had to be given to passes between players: the canPassPl Condition had to assure that both players involved were well aligned, or else the pass would frequently fail, since the ball catching capabilities of the robots are very limited. Setplay instantiation and startup were taken care of by the team coach, which has access to the team’s shared State-of-the-World (see Section 5.1 further down for details). This intangible agent, that does not have to deal with low-level activities, has plenty computing power to manage the Setplay execution. The integration of the framework in the CAMBADA team has proven to be more challenging than in the 2D simulation team, since the low-level perception and action mechanisms are far more complex, and had to be more finely tuned. The implementation, however, did not find any major problems nor did it demand changes in the framework. 5.1 Inter-robot communication Communication in the middle-size league is not subject to strict limitations: although the robots are fully autonomous, they can freely communicate through a wireless network using standard protocol 802.11. In championship settings, it is common that the network has high traffic and is consequently over-loaded, but this situation in normally under control. In order to avoid message loss or synchronization issues, messages are repeatedly written a configurable number of times, which will ensure eventual reception of all messages. The CAMBADA team uses a black-board approach with a shared State-of-the-World. This architecture, called Real Time Database (RTDB) [6] has been used both for posting perception information and coordination flags in previous tackles at team-level coordination. The RTDB was therefore used for the posting of the Setplay messages by the coach, since these can be read by all the team robots. 5.2 Example Setplay In order to illustrate Setplay execution, a very simple interaction will be used as example, in this case in play-on mode, when the ball is in possession of our team, in a specific region (intersection of mid_left and their_back). There are two robots involved: the striker will turn and then pass the ball to the shooter, which, in turn, will position itself in a central point and, upon reception of the pass, will shoot at goal. Naturally, there can be more complex Setplays, with more parameters or extra receivers: such complexities are avoided in this example for clarity’s sake. This Setplay’s definition can be seen in Fig. 11 . The execution of this Setplay will be illustrated through images, displayed in Fig. 12 , of an actual execution in CAMBADA’s simulator, which uses the same code that runs on the actual robots. The Setplay is initiated by the coach upon verification that the conditions for entry in step 0 are satisfied: play-mode is play-on, ball is in the desired region and one player has ball possession. The participating players are chosen according to their distance from the Setplay positions. At this moment (see diagram on Fig. 12a), the coach posts the following message on the RTDB, stating that the participant players have jersey numbers 6 (representing the coach), 5 and 3: S0 6 5 3 Upon reading this message, these players position themselves in the desired positions. Since the desired pass can be accomplished, the coach will announce, as follows, that the desired next step is nr. 1, which in this case is the only available option: 0 1 This will allow the striker to rotate towards the shooter (Fig. 12b). After the players reach their positions, another step progress is announced by the coach: 1 2 The striker will then pass the ball to the shooter (see Fig. 12c). This robot will accomplish the ‘receiveBall’ action by waiting for the ball and, when it comes close, moving back to avoid it to reflect (Fig. 12d). After catching the ball, the coach will evaluate if it considers a shot at goal possible, in which case it will post a new step change message: 2 3 This triggers the preparation (see Fig. 12e) for a shot at goal through a kick behaviour, which in turn is visible on Fig. 12f. In case the shot is possible, the Setplay will be finished, with the corresponding message being written on the RTDB by the coach, where -1 stands for an inexistent state: 3 -1 6 Future work and conclusions The Setplays framework has shown to be flexible, since it allows the expression of very different plans, from a very simple kick-in in the middle-size league example, to complex corners and ball exchanges in square in the simulation league. This flexibility also entails that the framework, and its underlying Setplay definition language, is abstract enough to deal with the whole of the robotic soccer domain. Its generality is also beyond doubt, since the same framework, without any kind of change in its core, has been applied to two very different RoboCup setups. This is clearly a positive point towards a completely general Setplay framework applicable to any RoboCup league. Since the framework is presented as a stand-alone library, its usage is also quite simple: a new team wishing to use it only needs to define the domain specific concepts (actions and conditions on the State-of-the-World), and deal with Setplay selection and player and parameter choice. From this point on, it suffices to update the ball and players positions regularly to have Setplays executed. To deal with languages like the one presented in this article, the community is presently used to XML-based syntaxes. Though the proposed syntax has an expressiveness comparable to, or even higher than, XML, this is not a strict limitation. Nevertheless, it would be fairly easy to create a translator from an XML syntax to the present s-expression syntax, through style sheets or some similar technology. Other possibility would be the development of an XML parser from scratch. Such options would make the interaction with the framework more appealing to users familiar with XML. Setplays have, in the simulation league, been mainly applied in situations where the startup conditions are very clear, i.e., situations signalled by the referee and therefore known to all players. This will be further investigated in the near future: how to startup Setplays in play-on situations, and how to deal with coordination in these more complex situations, when there is no time to prepare the Setplay, extending the work already done at this level in the middle-size league. Another line of research will be the application of machine learning techniques on the selection of Setplays, considering the opponent and the game state. As a first approach, Case-based reasoning will be investigated with this goal in mind. On the long term, it also should be investigated how to extract new Setplays from real-game situations: in fact, if some team-play is successful, it could be possible to analyse logs, or images, and extract a Setplay definition for future usage. References [1] Aangenent W, de Best J, Bukkems B, Kanters F, Meessen K, Willems J et al. TechUnited eindhoven team description 2009. In: CD proceedings of RoboCup 2009 symposium; 2009. [2] Chen M, Foroughi E, Heintz F, Kapetanakis S, Kostiadis K, Kummeneje J et al. Users manual: RoboCup soccer server manual for soccer server version 7.07 and later; 2003. [3] Corrente G. Arquitectura de controlo/coordenação de uma equipa de futebol robótico. Master’s thesis, Universidade de Aveiro; 2008. [4] H. Kitano M. Asada Y. Kuniyoshi I. Noda E. Osawa H. Matsubara Robocup: a challenge problem for AI AI Mag 18 1 1997 73 85 [5] Lange S, Müller C, Welker S. Tribots: soccer strategy. RoboCup workshop Kassel 2008; 2008. [6] Lau N, Lopes LS, Corrente G. CAMBADA: information sharing and team coordination. In: Eighth conference on autonomous robot systems and competitions, Universidade de Aveiro, Aveiro, Portugal; 2008. p. 27–32. [7] Lau N, Lopes LS, Corrente G, Filipe N. Multi-robot team coordination through roles, positionings and coordinated procedures. In: 2009 IEEE/RSJ international conference on intelligent robots and systems – IROS 2009, St. Louis, USA; October 2009. [8] Lau N, Reis LP. Coordination methodologies developed for FC Portugal 3D 2006 team. In: 10th Robocup 2006 symposium CD, Bremen, Germany; 2006. [9] N. Lau L.P. Reis FC Portugal – high-level CoordinationMethodologies in soccer robotics 2007 ItechEducationandPublishing Vienna, Austria p. 598 [10] Lauer M, Hafner R, Lange S, Riedmiller M. Cognitive concepts in autonomous soccer playing robots. Cognitive Syst Res. doi:10.1016/j.cogsys.2009.12.003. [11] Lopes, R., Mota, L., Reis, L.P., Lau, N., Playmaker: Graphical Definition of Formations and Setplays, Workshop em Sistemas Inteligentes e Aplicações - 5a Conferência Ibérica de Sistemas e Tecnologias de Informação (CISTI’2010), [12] McMillen C, Veloso M. Distributed, play-based role assignment for robot teams in dynamic environments. In: 8th International symposium on distributed autonomous robotic systems (DARS 2006), Minnesota, USA; 2006. [13] Mota L, Reis LP. Setplays: achieving coordination by the appropriate use of arbitrary pre-defined flexible plans and inter-robot communication. In: Winfield AFT, Redi J, editors. First international conference on robot communication and coordination (ROBOCOMM 2007). ACM international conference proceeding series. IEEE, vol. 318; 2007. [14] MSL Technical Committee. Middle size robot league rules and regulations for 2009. Tech. rep., RoboCup Federation; 2008. [15] I. Noda H. Matsubara K. Hiraki I. Frank Soccer server: a tool for research on multiagent systems Appl Artif Intell 12 2–3 1998 233 250 [16] L.P. Reis N. Lau FC Portugal team description: Robocup 2000 simulation league champion P. Stone T. Balch G. Kraetzschmar RoboCup-2000: Robot Soccer World Cup IV LNAI vol. 2019 2000 Springer 29 40 [17] L.P. Reis N. Lau Coach unilang – a standard language for coaching a (robo) soccer team RoboCup-2001: Robot Soccer World Cup V LNAI vol. 2377 2002 Springer Verlag 183 192 [18] L.P. Reis N. Lau E. Oliveira Situation based strategic positioning for coordinating a simulated robosoccer team M. Hannebauer J. Wendler E. Pagello Balancing react and social deliberation in MAS LNAI vol. 2103 2001 Springer 175 197 [19] Risler M. Behavior control for single and multiple autonomous agents based on hierarchical finite state machines. Ph.D. thesis, Technische Universität Darmstadt; 2009. [20] Risler M, von Stryk O. Formal behavior specification of multi-robot systems using hierarchical state machines in XABSL. In: AAMAS08-workshop on formal models and methods for multi-robot systems, Estoril, Portugal; 2008. [21] Röfer T, Brose J, Carls E, Carstens J, Goehring D, Juengel M et al. Germanteam 2006 the german national robocup team. In: Robocup 2006 symposium. Deutsches Forschungszentrum fuer Kuenstliche Intelligenz, Universitaet Darmstadt, Universitaet Bremen and Humboldt-Universitaet zu Berlin; 2006. [22] R. Ros R.L. de Màntaras J.L. Arcos M. Veloso Team playing behavior in robot soccer: a case-based reasoning approach LNCS vol. 4626 2007 Springer Berlin/Heidelberg p. 46–60 [23] Sequeira RP. Strategic coordination of CAMBADA robotic soccer team. Master’s thesis, Universidade de Aveiro; 2009. [24] Stone P. Layered learning in multi-agent systems. Ph.D. thesis, CMU; 2008. [25] P. Stone M. Veloso Task decomposition, dynamic role assignment, and low-bandwidth communication for real-time strategic teamwork Artif Intell 110 2 1999 241 273 [26] Zweigle O, Käppeler U-P, Rajaie H, Hüssermann K, Lafrenz R, Tamke A et al. CoPS Stuttgart team description 2008. In: Visser U, Ribeiro F, Ohashi T, Dellaert F, editors. RoboCup 2008 symposium CD; 2008. [27] Zweigle O, Lafrenz R, Buchheim T, Käppeler U-P, Rajaie H, Schreiber F et al. Cooperative agent behavior based on special interaction nets. In: Intelligent autonomous systems, vol. 9: IAS-9; 2006. "
    },
    {
        "doc_title": "World modeling on an MSL robotic soccer team",
        "doc_scopus_id": "79952617090",
        "doc_doi": "10.1016/j.mechatronics.2010.05.011",
        "doc_eid": "2-s2.0-79952617090",
        "doc_date": "2011-01-01",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Mechanical Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2210"
            },
            {
                "area_name": "Computer Science Applications",
                "area_abbreviation": "COMP",
                "area_code": "1706"
            },
            {
                "area_name": "Electrical and Electronic Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2208"
            }
        ],
        "doc_keywords": [
            "Coordination and Control",
            "Information fusion techniques",
            "Limited information",
            "Localization algorithm",
            "Obstacle detection",
            "Sensor fusion",
            "Visual matching",
            "World model"
        ],
        "doc_abstract": "When a team of robots is built with the objective of playing soccer, the coordination and control algorithms must reason, decide and actuate based on the current conditions of the robot and its surroundings. This is where sensor and information fusion techniques appear, providing the means to build an accurate model of the world around the robot, based on its own limited sensor information and the also limited information obtained through communication with the team mates. One of the most important elements of the world model is the robot self-localization, as to be able to decide what to do in an effective way, it must know its position in the field of play. In this paper, the team localization algorithm is presented focusing on the integration of visual and compass information. An important element in a soccer game, perhaps the most important, is the ball. To improve the estimations of the ball position and velocity, two different techniques have been developed. A study of the visual sensor noise is presented and, according to this analysis, the resulting noise variation is used to define the parameters of a Kalman filter for ball position estimation. Moreover, linear regression is used for velocity estimation purposes, both for the ball and the robot. This implementation of linear regression has an adaptive buffer size so that, on hard deviations from the path (detected using the Kalman filter), the regression converges faster. A team cooperation method based on sharing the ball position is presented. Other important data during the soccer game is obstacle data. This is an important challenge for cooperation purposes, allowing the improvement of team strategy with ball covering, dribble corridor estimation, pass lines, among other strategic possibilities. Thus, detecting the obstacles is ceasing to be enough and identifying which obstacles are team mates and opponents is becoming a need. An approach for this identification is presented, considering the visual information, the known characteristics of the team robots and shared localization among team members. The described work was implemented on the CAMBADA team and allowed it to achieve particularly good performances in the last two years, with a 1st and a 3rd place in the world championship RoboCup 2008 and RoboCup 2009 editions, respectively, as well as distinctively achieve 1st place in 2008 and 2009 editions of the Portuguese Robotics Open. © 2010 Elsevier Ltd. All rights reserved.",
        "available": true,
        "clean_text": "serial JL 271456 291210 291718 291787 291883 31 Mechatronics MECHATRONICS 2010-07-01 2010-07-01 2011-03-08T22:21:19 S0957-4158(10)00102-9 S0957415810001029 10.1016/j.mechatronics.2010.05.011 S300 S300.1 FULL-TEXT 2015-05-15T03:43:39.596909-04:00 0 0 20110301 20110331 2011 2010-07-01T00:00:00Z articleinfo crossmark dco dateupdated tomb dateloaded datesearch indexeddate issuelist volumelist yearnav articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids confeditor contenttype copyright dateloadedtxt docsubtype doctype doi eid ewtransactionid hubeid issfirst issn issnnorm itemstage itemtransactionid itemweight openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sectiontitle sortorder srctitle srctitlenorm srctype subheadings vol volfirst volissue figure table body mmlmath acknowledge affil articletitle auth authfirstini authfull authkeywords authlast footnotes primabst ref alllist content subj ssids 0957-4158 09574158 21 21 2 2 Volume 21, Issue 2 7 411 422 411 422 201103 March 2011 2011-03-01 2011-03-31 2011 Special Issue on Advances in intelligent robot design for the Robocup Middle Size League M.J.G. van de Molengraft O. Zweigle Special Issue on Advances in intelligent robot design for the Robocup Middle Size League article fla Copyright © 2010 Elsevier Ltd. All rights reserved. WORLDMODELINGMSLROBOTICSOCCERTEAM SILVA J 1 Introduction 2 Related work 3 Localization 4 Ball integration 4.1 Ball position 4.2 Ball velocity 4.3 Team ball position sharing 5 Obstacle treatment 5.1 Visual obstacle detection 5.2 Obstacle selection and identification 5.3 Obstacle sharing 6 Conclusion and future work Acknowledgment References METROPOLIS 1949 335 341 N KALMAN 1960 35 45 R LUO 2002 107 119 R LEONARD 1991 376 382 J FOX 1999 391 427 D MOURIKIS 2006 666 681 A DURRANTWHYTE 2008 H SPRINGERHANDBOOKROBOTICS MULTISENSORDATAFUSION BEJCZY 2004 41 42 A ALENYA 2004 23 32 G CHROUST 2004 73 83 S THRUN 2005 W PROBABILISTICROBOTICS SICILIANO 2008 B SPRINGERHANDBOOKROBOTICS LAUER 2005 291 303 M KI2005ADVANCESINARTIFICIALINTELLIGENCE MODELINGMOVINGOBJECTSINADYNAMICALLYCHANGINGROBOTAPPLICATION FERREIN 2006 154 165 A ROBOCUP2005ROBOTSOCCERWORLDCUPIX COMPARINGSENSORFUSIONTECHNIQUESFORBALLPOSITIONESTIMATION LAUER 2006 142 153 M ROBOCUP2005ROBOTSOCCERWORLDCUPIX CALCULATINGPERFECTMATCHEFFICIENTACCURATEAPPROACHFORROBOTSELFLOCALIZATION NEVES 2007 499 507 A PROGRESSINARTIFICIALINTELLIGENCE OMNIDIRECTIONALVISIONSYSTEMFORSOCCERROBOTS CUNHA 2008 417 424 B ROBOCUP2007ROBOTSOCCERWORLDCUPXI OBTAININGINVERSEDISTANCEMAPANONSVPHYPERBOLICCATADIOPTRICROBOTICVISIONSYSTEM SILVAX2011X411 SILVAX2011X411X422 SILVAX2011X411XJ SILVAX2011X411X422XJ item S0957-4158(10)00102-9 S0957415810001029 10.1016/j.mechatronics.2010.05.011 271456 2011-03-10T12:04:28.24434-05:00 2011-03-01 2011-03-31 true 2037530 MAIN 12 77452 849 656 IMAGE-WEB-PDF 1 si1 820 43 146 si4 279 20 19 si3 279 20 19 si2 672 40 84 gr10 40478 301 366 gr10 6601 164 200 gr11 38816 374 635 gr11 3816 129 219 gr12 45526 461 779 gr12 2642 130 219 gr13 25831 160 330 gr13 9938 106 219 gr14 26031 374 628 gr14 2725 130 219 gr15 25951 161 322 gr15 10234 109 219 gr16 11424 220 243 gr16 3895 164 181 gr17 34129 332 324 gr17 9007 164 160 gr18 28869 336 320 gr18 8228 164 156 gr19 31951 292 350 gr19 4895 164 196 gr2 24610 181 349 gr2 9025 114 219 gr20 32518 300 345 gr20 5136 163 188 gr21 11053 222 356 gr21 3093 137 219 gr3 14423 252 223 gr3 4214 164 145 gr4 90061 420 715 gr4 6962 129 219 gr5 31815 170 578 gr5 3190 64 219 gr6 34213 295 372 gr6 5554 164 207 gr7 32017 304 505 gr7 3661 132 219 gr8 11017 117 266 gr8 2052 96 219 gr9 53806 297 357 gr9 9002 164 197 gr1 35942 173 489 gr1 9273 77 219 MECH 1165 S0957-4158(10)00102-9 10.1016/j.mechatronics.2010.05.011 Elsevier Ltd Fig. 1 Picture of the team robots used to obtain the results presented on this paper. Fig. 2 Captures of an image acquired by the robot camera and processed by the vision algorithms. Left (a): The image acquired by the camera. Right (b): The same image after processing with magenta dots over the detected field lines. Fig. 3 Illustration of the compass error angle intervals. Fig. 4 Illustration of two situations where relocation was forced. Dashed line represents the angle given by the compass, solid line represents the angle estimated by the localization algorithm, red lines represent the cycles on which the error between the two angles is greater than the threshold. Left (a): The camera was covered while the robot moved. The estimated orientation error degrades progressively and after getting higher than a threshold, the cycle count starts and forces relocation. Right (b): The robot tilted. The estimated orientation error is immediately affected by more than a threshold and the cycle count starts and forces relocation. Fig. 5 Noisy position of a static ball taken from a rotating robot. Fig. 6 Plot of a robot movement around a fixed ball position. The ball positions measured by the moving robot form a cloud of points (green) in the area of the real ball position (black X). (For interpretation of the references to colour in this figure legend, the reader is referred to the web version of this article.) Fig. 7 Plot of a ball movement situation. Fig. 8 Situation where a hard deviation would be detected by the filter. Positions R4,5,6, are the measured positions after the ball hits an obstacle, P4,5,6 are the predicted filtered estimations, which did not consider that something might alter the ball path. Fig. 9 Velocity representation using consecutive measures displacement. Fig. 10 Velocity representation using linear regression over Kalman filtered positions. Fig. 11 Comparison between the velocity estimated by the linear regression (blue solid line, faster convergence) and internally by the Kalman filter (red dashed line, smoother, but of slow convergence). (For interpretation of the references to colour in this figure legend, the reader is referred to the web version of this article.) Fig. 12 Diagram of the ball integration algorithm. Fig. 13 Captures of an image acquired by the robot camera and processed by the vision algorithms. The areas of interest were surrounded. (a) The image acquired by the camera. (b) The same image after processing. Obstacles are identified by their center (triangle), left and right limits (squares). It is visible that the two aligned obstacles are detected as a single larger obstacle (top right of the frames). Fig. 14 Relation between pixels and metric distances. The center of the robot is considered the origin and the metric distances are considered on the ground plane. Fig. 15 Example of an image acquired by the robot camera and processed by the vision algorithm. The areas of interest are surrounded. (a) The image acquired by the camera. (b) The same image after processing. It is visible the two possibilities of separation made: angular separation, on the bottom pair of obstacles and length separation, on the top pair of obstacles. Fig. 16 When a CAMBADA robot is on, the estimated centers of the detected obstacles are compared with the known position of the team mates and tested; the left obstacle is within the CAMBADA acceptance radius, the right one is not. Fig. 17 Illustration of single obstacles identification. (a) Image acquired from the robot camera (obstacles for identification are marked). (b) The same image after processing. (c) Image of the control station. Each robot represents itself and robot 6 (the lighter gray) draws all the five obstacles evaluated (squares with the same gray scale as itself). All team mates were correctly identified (marked by its corresponding number over the obstacle square) and the opponent is also represented with no number. Fig. 18 Illustration of multiple obstacles identification. (a) Image acquired from the robot camera (obstacle for identification marked). (b) The same image after processing. Visually, the aligned robots are only one large obstacle. (c) Image of the control station. Each robot represents itself and robot 6 (the darker gray) draws all the five obstacles (squares with the same gray scale as itself). The visual obstacle was successfully separated into the several composing obstacles, and all of them were correctly identified as the correspondent team mate (marked by its corresponding number over the obstacle square) and the opponent is also represented with no number. Fig. 19 Representation of a capture of the obstacle identification algorithm results. The path taken by the observer is represented by blue dots in the rectangular path taken. Near the center, the pivot shared position is represented by the black star and its limits by the black circle. The blob of red is the overlapping positions of the identified obstacle center, represented by a red cross. (For interpretation of the references to colour in this figure legend, the reader is referred to the web version of this article.) Fig. 20 Representation of the path taken by the team mate to identify (the red dots represent each communicated position). The observer position is represented by the black star and its limits by the black circle. (For interpretation of the references to colour in this figure legend, the reader is referred to the web version of this article.) Fig. 21 Image of the control station showing an obstacle of robot 2 that was not seen by itself (on the center of the field). In this case it assumes the obstacle by confirmation of both robots 5 and 6. Table 1 The mean and standard deviation of the capture perceived obstacle position. Perceived obstacle X Y Mean 0.05 2.01 Std 0.08 0.07 ∣Real−perceived∣=0.16. ∣Std∣=0.10. Table 2 The individual ratio of successful identification of the moving team mate for the several captures performed. Total cycles Successes % Capture 1 1798 1319 73 Capture 2 1065 748 70 Capture 3 1528 1332 87 Capture 4 1162 769 66 Capture 5 1935 1278 66 Capture 6 2152 1411 66 World modeling on an MSL robotic soccer team João Silva ⁎ Nuno Lau António J.R. Neves João Rodrigues José Luís Azevedo ATRI, IEETA/DETI, University of Aveiro, 3810-193 Aveiro, Portugal ⁎ Corresponding author. When a team of robots is built with the objective of playing soccer, the coordination and control algorithms must reason, decide and actuate based on the current conditions of the robot and its surroundings. This is where sensor and information fusion techniques appear, providing the means to build an accurate model of the world around the robot, based on its own limited sensor information and the also limited information obtained through communication with the team mates. One of the most important elements of the world model is the robot self-localization, as to be able to decide what to do in an effective way, it must know its position in the field of play. In this paper, the team localization algorithm is presented focusing on the integration of visual and compass information. An important element in a soccer game, perhaps the most important, is the ball. To improve the estimations of the ball position and velocity, two different techniques have been developed. A study of the visual sensor noise is presented and, according to this analysis, the resulting noise variation is used to define the parameters of a Kalman filter for ball position estimation. Moreover, linear regression is used for velocity estimation purposes, both for the ball and the robot. This implementation of linear regression has an adaptive buffer size so that, on hard deviations from the path (detected using the Kalman filter), the regression converges faster. A team cooperation method based on sharing the ball position is presented. Other important data during the soccer game is obstacle data. This is an important challenge for cooperation purposes, allowing the improvement of team strategy with ball covering, dribble corridor estimation, pass lines, among other strategic possibilities. Thus, detecting the obstacles is ceasing to be enough and identifying which obstacles are team mates and opponents is becoming a need. An approach for this identification is presented, considering the visual information, the known characteristics of the team robots and shared localization among team members. The described work was implemented on the CAMBADA team and allowed it to achieve particularly good performances in the last two years, with a 1st and a 3rd place in the world championship RoboCup 2008 and RoboCup 2009 editions, respectively, as well as distinctively achieve 1st place in 2008 and 2009 editions of the Portuguese Robotics Open. Keywords Sensor fusion World model Kalman filter Linear regression Obstacle detection Visual matching 1 Introduction Nowadays, there are several research domains in the area of multi robot systems. One of the most popular is robotic soccer. RoboCup 1 1 is an international joint project to promote artificial intelligence, robotics and related fields. Most of the RoboCup leagues have soccer as platform for developing technology, either at software or hardware levels, with single or multiple agents, cooperative or competitive [1]. Among RoboCup leagues, the Middle Size League (MSL) is one of the most challenging. In this league, each team is composed of up to five robots with maximum size of 50×50cm base, 80cm height and a maximum weight of 40kg, playing in a field of 18×12m. The rules of the game are similar to the official FIFA rules, with required changes to adapt for the playing robots [2]. Each robot is autonomous and has its own sensorial means. They can communicate with each other, and with an external computer acting as a coach, through a wireless network. This coach computer cannot have any sensor, it only knows what is reported by the playing robots. The agents should be able to evaluate the state of the world and make decisions suitable to fulfill the cooperative team objective. CAMBADA, Cooperative Autonomous Mobile roBots with Advanced Distributed Architecture, is the Middle Size League Robotic Soccer team from the University of Aveiro. The project started in 2003, coordinated by the IEETA 2 Instituto de Engenharia Electrónica e Telemática de Aveiro – Aveiro’s Institute of Electronic and Telematic Engineering. 2 ATRI 3 Actividade Transversal em Robótica Inteligente – Transverse Activity on Intelligent Robotics. 3 group and involves people working on several areas for building the mechanical structure of the robot, its hardware architecture and controllers and the software development in areas such as image analysis and processing, sensor and information fusion, reasoning and control (see Fig. 1 ). This paper provides a description of some sensor and information fusion techniques and algorithms used in the CAMBADA team. The data obtained by these techniques are necessary for building a world model of the robot environment. This paper includes the description of some of the elements of that model necessary for a team of robots to play soccer. In Section 2, a brief overview of some related topics and work in sensor and information fusion for world modeling are presented. Section 3 presents the team self-localization description, introducing it as the first necessary step for all the other information fusion. In Section 4, the ball integration process is presented in all its components, starting with the ball position, its velocity and finally its sharing among team mates. Section 5 presents an overview of obstacle treatment, with some visual detection details, the matching of positions for visual identification and the sharing of information among team mates. Finally, Section 6 concludes the paper. 2 Related work World modeling and sensor and information fusion are tightly related, as the latest provide the means to build the desired model. Sensor and information fusion is the process of combining sensory data, or data derived from sensory data, providing a resulting information that is better than would be possible when the sources were used individually [3]. One of the main areas where sensor fusion techniques are used is position tracking, both for self and object localization/tracking. The integration of information over time in order to filter sensor noise is essential to get better estimates. This type of integration may be performed using Kalman filter based approaches, Monte Carlo methods or Markov approaches. Generally, Monte Carlo [4] approaches have better performance in cases where great discontinuities of the output values are expected, as the assumption of Gaussian probability density functions of the Kalman filter [5] is usually less accurate. However, Kalman filtering is a very effective method if the assumptions of Gaussian noise can be met and the system can be linearized. Other common approaches are the use of the Extended and Unscented Kalman filters [6], which are prepared to deal with non-linear systems at the cost of more computational weight. A general overview of different methods of multi-sensor and information fusion is presented in [7], also with a brief description of application areas, such as robotics, military, biomedical and transportation. Applications in the robotics field include self-localization using either Kalman filter [8], Monte Carlo [9] or Markov [10] methods, or integration of information coming from several robots, to increase the accuracy of each of the robots position estimation [11]. A general recent overview of methods and architectures for multi-sensor data fusion can be found in [12]. Another recurrent problem nowadays is the fusion of visual and inertial sensors [13], where recent results have demonstrated that the visual tracking of objects may work at higher velocities and be more robust if combined with information coming from inertial sensors [14] and also that ego-motion estimation can be more precise and navigation more robust using these approaches [15]. Simultaneous Localization And Mapping (SLAM) is another common application of sensor fusion techniques, as in many cases, autonomous robots have to map the environment rather than simply localize themselves [16,17]. Particularly in RoboCup domain, several teams use this kind of approaches, not only for localization purposes, but also for position estimation and tracking of objects, namely the ball and other robots. Several teams have used Kalman filters for the ball position estimation [18–21]. In [20,21], several information fusion methods are compared for the integration of the ball position using several observers. In [21], the authors conclude that the Kalman reset filter shows the best performance. Although using well known techniques, in this paper we propose practical solutions for an efficient self-localization, ball information treatment and obstacle treatment for an MSL robotic soccer team. As far as we know, no previous work has been published focusing on these several important aspects of developing the world model of an MSL soccer team. 3 Localization Self-localization of the agent is an important issue for a soccer team, as strategic moves and positioning must be defined by positions on the field. In the MSL, the environment is partially known, as every agent knows exactly the layout of the game field but does not know the position of any other elements, either itself, other robots or the ball. Given the known map, the agent has then to locate itself. The CAMBADA team localization algorithm is based on the detected field lines, with fusion of information from the odometry sensors and an electronic compass. It is based on the approach described in [22], with some adaptations. It can be seen as an error minimization task, with a derived measure of reliability of the calculated position so that a stochastic sensor fusion process can be applied to increase the estimation accuracy [22]. From the center of the image (the center of the robot), radial sensors are created around the robot, each one represented by a line with a given angle. These are called scanlines. The image processing, in each cycle, returns a list of positions relative to the robot where the scanlines intercept the field line markings [23]. The idea is to analyze the detected line points, estimating a position, and through an error function describe the fitness of the estimation. This is done by reducing the error of the matching between the detected lines and the known field lines (Fig. 2 ). The error function must be defined considering the substantial amount of noise that affects the detected line points which would distort the representation estimation [22]. In normal operation mode, the localization is done over a limited set of base positions from which tracking is maintained. Since it is an algorithm based on optimization and since there are many local minima, the tracking only works satisfactorily if the estimations are near the solution. In situations where the robot does not possess a valid estimation, a global localization algorithm estimates the robot position on the field using a much wider set of initial estimations over which the already referred error minimization process for optimization is applied. However, this global localization algorithm is computationally heavy and time consuming. For that reason, after having an initial position, the simpler tracking localization handles the cyclic relocation. Although the odometry measurement quality quickly degrades with time, within the reduced cycle times achieved in the application, consecutive readings produce acceptable results and thus, having the visual estimation, it is fused with the odometry values to refine the estimation. This fusion is based on a Kalman filter for the robot position estimated by odometry and the robot position estimated by visual information. This approach allows the agent to estimate its position even if no visual information is available. However, it is not reliable to use only odometry values to estimate the position for more than a few cycles, as slidings and frictions on the wheels produce large errors on the estimations in short time. Due to the nature of the approach, this algorithm works acceptably with a relatively low number of points, like a few tens of points, as long as they are representative of the surroundings. Consider the case of matching a 90degrees corner. If the algorithm had access to 200 points all over the same line, it would not be capable of matching the corner. On the other hand, with only 20 or 30 points scattered over both lines, the algorithm would be capable of detecting the match. Even in situations where the points are over the same line, the merging with odometry and position tracking provide a good robustness to the algorithm [22], as long as the situation is temporary, which is usually the case. The visually estimated orientation can be ambiguous, i.e. each point on the soccer field has a symmetric position, relatively to the field center, where the robot detects exactly the same field lines. To disambiguate the symmetry problem and to detect wrong estimations, an electronic compass is used. The orientation estimated by the robot is compared to the orientation given by the compass and if the error between them is larger than a predefined threshold, actions are taken. If the error is really large (i.e. around ±180degrees), it means that the robot estimated orientation is symmetric to the real one, so it should assume the mirror position. On the other hand, if the error is larger than the acceptance threshold (i.e. a 90degrees acceptable area), a counter is incremented (Fig. 3 ). This counter will be incremented every cycle in which the error is greater than the threshold. If a given number of consecutive cycles with high errors is reached (i.e. the counter reaches a given number, currently 10), the robot considers itself “lost”, meaning that it will not continue to track its position but will instead consider the initial situation, with no a priori knowledge and thus executes the global localization algorithm. Fig. 4 shows situations where the threshold was reached and relocation was forced after some cycles. 4 Ball integration The information of the ball state (position and velocity) is, perhaps, the most important, as it is the main object of the game and it is the base over which most decisions are taken. Thus, its integration has to be as reliable as possible. To accomplish this, a Kalman filter implementation was created to filter the estimated ball position given by the visual information, and a linear regression was applied over filtered positions to estimate its velocity. 4.1 Ball position It is assumed that the ball velocity is constant between cycles. Although that is not true, due to the short time variations between cycles, around 40ms, and given the noisy environment and measurement errors, it is a quite acceptable model for the ball movement. Thus, no friction is considered to affect the ball, and the model does not include any kind of control over the ball. Therefore, given the Kalman filter formulation (described in [24]), the assumed state transition model is given by X k = 1 Δ T 0 1 X k - 1 where X k = Pos Vel is the state vector containing the position and velocity of the ball. Both are composed by the respective (x, y) coordinates. This velocity is only internally estimated by the filter, as the robot sensors can only take measurements on the ball position. After defining the state transition model based on the ball movement assumptions described above and the observation model, the description of the measurements and process noises are important issues to attend. The measurements noise can be statistically estimated by taking measurements of a static ball position at known distances. In practice, measurements of the static ball were taken while the robot was rotating around its vertical axis and this was done with the ball placed at several distances, measured with metric tape. Although real game conditions are probably more adverse, we lack the means to externally know the position of the elements on the field. For that reason, to know the real distance between the robot and the ball, we opted to use the described setup. Some of the results are illustrated in Fig. 5 . The standard deviation of those measurements can be used to calculate the variance and thus define the measurements noise parameter. A relation between the distance of the ball to the robot and the measurements standard deviation can be modeled by a 2nd degree polynomial best fitting the data set in a least-squares sense. Depending on the available data, a polynomial of another degree could be used, but we should always keep in mind the computational weight of increasing complexity. As for the process noise, this is not trivial to estimate, since there is no way to take independent measurements of the process to estimate its standard deviation. The process noise is represented by a matrix containing the covariances correspondent to the state variable vector. Based on the Kalman filter functioning, one can verify that forcing a near null process noise causes the filter to practically ignore the read measures, leading the filter to emphasize the model prediction. This makes it too smooth and therefore inappropriate. On the other hand, if it is too high, the read measures are taken too much into account and the filter returns the measures themselves. To face this situation, one has to find a compromise between stability and reaction. Since we assume an uniform movement for the ball, there are no frictions or other external forces considered. This means that accelerations are not considered in our model and thus, the position and velocity components are quite independent of each other. Since acceleration is the main element of relation between position and velocity, we considered that the errors associated to the process position and velocity estimations do not correlate. Because we assume an uniform movement model that we know is not the true nature of the system, we know that the speed calculation of the model is not very accurate. A process noise covariance matrix was empirically estimated, based on several tests, so that a good smoothness/reactivity relationship was kept. These empirically estimated values were made dependent on the measurement noise so that the Kalman filter predictions are also less accurate when the distance to the ball is too large. This was done so that the filter does not smooth the positions too much. In practice, this approach proved to improve the estimation of the ball position. Since we do not possess the means to externally know the positions of the elements on the field, a capture was made with the ball fixed at a known position on the field (0.0,2.0) (measured with metric tape). The robot was moving around the ball with a speed of 1.3±0.5m/s and the ball position measured at each moment was recorded. The ball position measured by the robot was (−0.01,2.03)±(0.05,0.06)m. Fig. 6 illustrates the capture results. This experiment gives an idea of the noise associated with the ball position detection. Note that during the experiment the distance between the robot and the ball is around 2m. Comparing the ball position cloud with the one obtained at 2m in Fig. 5 one can verify that they are similar, which is consistent with the previous experiment setup to simulate robot movement by rotation on the spot. With the presented setup experiments, the existence of noise in ball measurements became clear. With that existent noise in mind, several tests were made to validate the use of the Kalman filter to reduce it. Fig. 7 represents a capture of one of those tests, a ball movement, where the black dots are the ball positions measured by the robot visual sensors and thus are unfiltered. Red stars 4 For interpretation of color in ‘Figs. 1,2,4-7,9-11,13-15,17-20’ the reader is referred to the web version of this article. 4 represent the position estimations after applying the Kalman filter. The robot position is represented by the black star in its center and its respective radius. The ball was thrown against the robot and deviated accordingly. It is easily perceptible that the unfiltered positions are affected by much noise and the path of the ball after the collision is composed of positions that do not make much physical sense. Although we lack the means to externally provide a ground truth for the ball position during its movements, the filtered positions seem to give a much better approximation to the real path taken by the ball, as they provide a path that physically makes more sense. After producing the a priori estimation of the ball position, this estimation is compared with the read measure to detect if the variation between them is too great. If the difference between them is consistently greater than a given threshold (estimated empirically), the filter can indicate that the ball suffered a hard deviation (Fig. 8 illustrates this concept). Although hard deviations are not a serious problem for the filter (as it quickly converges to the new positions), they are used for velocity convergence (as described in the next subsection). 4.2 Ball velocity The calculation of the ball velocity is a feature becoming more and more important over the time. It allows that better decisions can be implemented based on the ball speed value and direction. Assuming the same ball movement model described before, constant ball velocity between cycles and no friction considered, one could theoretically calculate the ball velocity by simple instantaneous velocity of the ball with the first order derivative of each component Δ D Δ T , being ΔD the displacement on consecutive measures and ΔT the time interval between consecutive measures. However, given the noisy environment, it is also predictable that this approach would be greatly affected by that noise and thus its results would not be satisfactory. Fig. 9 shows a ball movement capture where the ball was moving from left to right, as indicated by the arrow in the top of the figure, and was then deviated into a downward movement near the “1st deviation” tag. While moving downward, the ball was deviated again near the “2nd deviation” tag and started to move from right to left. Finally, in the end of the capture, a new deviation occurred near tag “3rd deviation” where the ball started to move upward. The estimated ball positions are represented by the blue dots. Red lines represent the velocity vectors estimated based on consecutive positions displacement. It is clear that the velocity estimates hardly give an acceptable insight of the ball movement. To keep a calculation of the object velocity consistent with its displacement, an implementation of a linear regression algorithm was chosen. This approach based on linear regression [25] is similar to the velocity estimation described in [18]. By keeping a buffer of the last m measures of the object position and sampling instant (in this case buffers of nine samples were used), one can calculate a regression line to fit the positions of the object. Since the object position is composed by two coordinates (x, y), we actually have two linear regression calculations, one for each dimension. This is made in a transparent way, so the description is presented generally, as if only one dimension was considered. When applied over the positions estimation, the linear regression velocity estimations are much more accurate than the instant velocities calculated by Δ D Δ T , and allow a better insight of the ball movement. The same ball movement capture described earlier is represented in Fig. 10 , this time with the velocity vectors estimated by the linear regression applied over the position estimations provided by the Kalman filter. In order to try to make the regression converge more quickly on deviations of the ball path, a reset feature was implemented. This allows deletion of the older values, keeping only the n most recent ones, and provides control of the buffer size. By keeping the most recent values after a hard deviation, we reduce outliers of the previous path, thus promoting faster convergence. This reset results from the interaction with the Kalman filter described earlier by querying it for the existence of a hard deviation on the ball path. The obtained values were tested to confirm if the linear regression of the ball positions was more precise and would converge faster than the internal velocity estimated by the Kalman filter. Tests showed that the velocity estimated by the Kalman filter has a slower response than the linear regression estimation when deviations occur. Given this, the linear regression was used to estimate the velocity because quickness of convergence was preferred over the slightly smoother approximation of the Kalman filter in the steady state. That is because in the game environment the ball is very dynamic, it constantly changes its direction and thus a convergence in less than half the cycles is much preferred. Fig. 11 shows the results for a theoretical velocity scenario where the ball was moving at a constant speed of 2m/s and suddenly dropped to a constant 1m/s speed. Both the speeds estimated by the Kalman filter and the ones estimated by the linear regression are presented. 4.3 Team ball position sharing Due to the highly important role that the ball has in a soccer game, when a robot cannot detect it by its own visual sensors (omni or frontal camera), it may still know the position of the ball, through sharing of that knowledge by the other team mates. The ball data structure includes a field with the number of cycles it was not visible by the robot, meaning that the ball position given by the vision sensors can be the “last seen” position. When the ball is not visible for more than a given number of cycles, the robot assumes that it cannot detect the ball on its own. When that is the case, it uses the information of the ball communicated by the other running team mates to know where the ball is. This can be done by getting the mean and standard deviation of the positions of the ball seen by team mates. Another approach is to simply use the ball position of the team mate that has more confidence in the detection. Independently of the chosen approach, the robot assumes that ball position as correct. When detecting the ball on its own, there is also the need to validate that information. Currently the seen ball is only considered if it is within a given margin inside the field of play as there would be no point in trying to play with a ball outside the field. For ball position sharing, an approach based on the highest confidence ball position is used. This is due to the fact that the shared positions are updated with 100ms periods, with the possibility of a few more milliseconds of unknown and unpredictable delay in packet transmission. Thus, the lifetime of the information of each team mate is different, and the use of the information of the team mate with higher confidence reduces the probability of the degradation of that information during the respective lifetime. Fig. 12 illustrates the general ball integration activity diagram. 5 Obstacle treatment While playing soccer, the robots have the need to navigate around the field effectively, which means they have to reposition themselves or dribble the ball avoiding the obstacles on the field, that can be either team or opponent robots, or eventually the referee. An increasing necessity felt by the team, to improve its performance, is a better obstacle detection and sharing of obstacle information among team mates. This is important to ensure a global idea of the field occupancy, since the team formation usually keeps the robots spread across the field. Pass lines and dribbling corridors can be estimated more easily with a good coverage of field obstacles, allowing improvements on team strategy and coordination. 5.1 Visual obstacle detection The CAMBADA robots gather their information about the surroundings by means of a robotic vision system. Currently, only the omni directional camera gathers information about obstacles, as no frontal camera is being used at this time. According to RoboCup rules, the robots are mainly black. Since during the game robots play autonomously, all obstacles in the field are the robots themselves (occasionally the referee, which is recommended to wear black/dark pants). The vision algorithm detects the obstacles by evaluating blobs of black color inside the field of play [26]. Through the mapping of image positions to real metric positions [27], obstacles are identified by their center (triangle on the processed image, Fig. 13 b) and left and right limits (squares on the processed image, Fig. 13b). This is done by searching black regions on the scanlines of the vision algorithm [23], already referred in Section 3. The detection of black color on the scanlines is analyzed both in angular intervals and length intervals, to define the limits of each black blob (considering their base points which are represented by the first black pixel in each scanline). Since the vision system is a non-SVP hyperbolic catadioptric system [27], the size of objects on the image varies with the distance to the robot. Due to an inverse distance map calculation, by exploring a back-propagation ray-tracing approach and the geometric properties of the mirror surface, the relation of distances in the image and the real world is known. Fig. 14 is an illustration of how the distance in pixels, from the center of the image, is mapped to the distance in meters, on the ground plane. Through the function represented in Fig. 14, it is possible to create a normalized relation of blobs width and length with the distance. Sometimes an obstacle is separated in several blobs, mainly due to the noise in the image and problems in color classification, which leads to failure in the detection of black regions in the scanlines. To avoid these situations, an offset is considered to decide when the angular space between blobs is considered enough to represent a real obstacle separation. The same principle is considered concerning the position of the black area in consecutive scanlines. The separation offsets of a blob close to the robot are bigger than the ones at a high distance, to maintain coherent precision. The angular separation offset is considered for situations where robots are side-by-side, at the same distance, but there is no visual contact between each blob; the length separation offset is checked for situations where, on consecutive scanlines, there are blobs with visual contact but the robots are actually at different distances. Both situations are depicted in Fig. 15 . For each detected blob, their number of pixels is calculated and an estimation of the obstacles left and right limits, as well as their centers, is made. This information is made available to the integration process for filtering and treatment. 5.2 Obstacle selection and identification With the objective of refining the information of the obstacles, and have more meaningful and human readable information, the obstacles are selected and a matching is attempted, in order to try to identify them as team mates or opponents. Due to the weak precision at long distances, a first selection of the obstacles is made by selecting only the obstacles closer than a given distance as available for identification (currently 5m). Also, obstacles that are smaller than 10cm wide or outside the field of play margin are ignored. This is done because the MSL robots are rather big, and in-game situations small obstacles are not present inside the field. Also, it would be pointless to pay attention to obstacles that are outside the field of play, since the surrounding environment is completely ignorable for the game development. To be able to distinguish obstacles, identifying which of them are team mates and which are opponent robots, a fusion between the own visual information of the obstacles and the shared team mates positions is made. By creating a circle around the team mate positions with the robot radius (considered 22cm), a matching of the estimated center of visible obstacle area is made (Fig. 16 ), and the obstacle is identified as the corresponding team mate in case of a positive matching (Figs. 17 c and 18c). This matching consists on the existence of interception points between the team mate circle and the obstacle circle or if the obstacle center is inside the team mate circle (the obstacle circle can be smaller, and thus no interception points would exist). Since the detected obstacles can be large blobs, the above described identification algorithm cannot be applied directly to the visually detected obstacles. If the detected obstacle fulfills the minimum size requisites already described, it is selected as candidate for being a robot obstacle. Its size is evaluated and classified as robot if it does not exceed the maximum size allowed for MSL robots [2] (Fig. 17a and b). If the obstacle exceeds the maximum size of an MSL robot, a division of the obstacle is made, by analyzing its total size which is used to estimate how many robots are in that obstacle. This may be a common situation, robots clashing together and thus creating a compact black blob, originating a big obstacle if they are sufficiently lined up (Fig. 18 a and b). Although the computations for obstacle identification were in use during RoboCup 2009, their results are yet to be considered in the team strategy. Currently, obstacles are always considered unfriendly and thus to be avoided. Due to this fact, there is currently no data of in-game results for this part of the work. Several captures of the obstacle identification algorithm described earlier were performed and analyzed, to further illustrate the effectiveness of the algorithm. The laboratory used for the tests receives natural light which can affect the vision processing algorithms. The presented results are not treated in any way to diminish the effects of natural light, as we are interested in understanding if the algorithms can cope with those conditions which can be found in real situations. In the first test situation, a robot was positioned on the field at (−0.05,1.88) while broadcasting its position. This robot will be referred to as pivot. Another robot was moving on a rectangular path around the pivot, and a capture of its data was done. This robot will be referred to as observer. This scenario is intended to give some insight about the performance of the identification when the team mates are static or nearly static (as is the case of set plays during the games. In these situations it is important to analyze passing lines). Fig. 19 is a graphic representation of the acquired data, with the pivot represented in black. The blue dots are the positions of the path taken by the observer, which covers the rectangular path for three times. In each cycle, the center of the obstacle perceived by the observer is represented by a red ‘×’. It is visible that, as expected, the obstacle position perceived by the observer is not exactly the pivot position. The capture in question is composed of 677 cycles. The identification of the obstacle as the correspondent team mate failed to succeed in only one cycle, which corresponds to a 99.85% success rate. Considering that the pivot has 22cm radius (although it is slightly bigger), the mean of the centers of the perceived obstacle is within the real area occupied by the pivot, at nearly 16cm with a standard deviation of 10cm (Table 1 ). Another test scenario was considered for evaluation of the algorithm performance for moving obstacles. Several captures were performed to evaluate the performance of the algorithm when identifying a moving team mate. This set of six captures consisted on a robot observing a team mate moving around and registering the data about the obstacles. The path taken by the moving team mate is represented in Fig. 20 . The number of failed identifications was greater when the moving robot was farther from the observer, as expected due to the noisy nature of the measurements. The captures were performed throughout the day, with different lighting conditions but with the same robot calibration. Table 2 summarizes this set of captures, which revealed a total mean identification ratio of approximately 71%. 5.3 Obstacle sharing With the purpose of improving the global perception of the team robots, the sharing of locally known information is an important feature. Obstacle sharing allows the team robots to have a more global perception of the field occupancy, allowing them to estimate, for instance, passing and dribbling corridors more effectively. However, one has to keep in mind that, mainly due to illumination conditions and eventual reflective materials, some of the detected obstacles may not be exactly robots, but dark shadowy areas. If that is the case, the simple sharing of obstacles would propagate an eventually false obstacle among the team. Thus the algorithm for sharing the obstacles makes a fusion of the several team mates information. The fusion of the information is done mate by mate. After building the worldstate by its own means, the agent checks all the available obstacle information provided by team mates, one by one. Their obstacles are matched with the own ones. If the agent does not know an obstacle shared by the team mate, it keeps it in a temporary list of unconfirmed obstacles. This is done to all the team mates obstacles. When another team mate shares a common obstacle, that same obstacle is confirmed and is transferred to the local list of obstacles. In the current cycle, the temporary obstacles that were not confirmed are not considered. A robot does not use negative information from other robots to remove obstacles it actually saw from its local world model. An outline of the algorithm is presented next. for c:=1 to total_number_of_team_mates for o:=1 to total_obstacles_of_team_mate for m:=1 to total_own_obstacles if m matches o I already know this obstacle, do nothing else if previously known by another team mate obstacle confirmed and added else obstacle considered temporarily waits for confirmation by another team mate endif endif endfor endfor endfor The matching of the team mate obstacles with the own obstacles is done in a way similar to the matching of the obstacle identification with the team mate position described earlier. The CAMBADA team mate position in Fig. 16 is replaced by the current team mate obstacle for the matching test. Fig. 21 shows a situation where robot 2, in the goal area was too far to see the obstacle on the middle of the field. Thus, it considered the obstacle in question, only because it is identified by both robots 5 and 6, as visible in the figure. 6 Conclusion and future work The techniques chosen for information and sensor fusion proved to be effective in accomplishing their objectives. The Kalman filter allows to filter the noise on the ball position and provides an important prediction feature which allows fast detection of deviations of the ball path. The linear regression used to estimate the velocity is also effective, and combined with the deviation detection based on the Kalman filter prediction error, provides a faster way to recalculate the velocity in the new trajectory. The improvement on obstacle treatment allows modifications on the overall team strategy, particularly regarding passing possibilities. It also allows the improvement of the robots movement, since team mate obstacles can have a different treatment than the opponents, because team mates have velocities and other information available. The CAMBADA team obtained the 1st place in the last years of the Portuguese robotics open (Robótica 2007, Robótica 2008, Robótica 2009 and Robótica 2010), and internationally achieved 5th place in RoboCup 2007, 1st place in RoboCup 2008, 3rd place in RoboCup 2009 and 2nd place in GermanOpen 2010. Although the described work proved to be effective and helped to achieve good results, improving is always the aim for this kind of project. Thus, improvements on the localization algorithm are desired, as well as a different way to disambiguate symmetric positions to eventually complement or replace the compass. Another path to follow would be the improving of team strategy based on obstacle identification, creating new forms of cooperation and set plays for in-game situations. Acknowledgment This work was partially supported by project ACORD Adaptive Coordination of Robotic Teams, FCT/PTDC/EIA/70695/2006. References [1] Kitano H, Asada M, Kuniyoshi Y, Noda I, Osawa E. RoboCup: the robot world cup initiative. In: Proceedings of the first international conference on autonomous agents. New York (NY, USA): ACM; 1997. p. 340–7. [2] MSL Technical Committee 1997–2009. Middle size robot league rules and regulations for 2009; 2008. [3] Elmenreich W. Sensor fusion in time-triggered systems. Ph.D. thesis. Vienna (Austria): Technische Universitat Wien, Institut fur Technische Informatik; 2002. [4] N. Metropolis S. Ulam The Monte Carlo method J Am Stat Assoc 44 247 1949 335 341 [5] R. Kalman A new approach to linear filtering and prediction problems J Basic Eng 82 1 1960 35 45 [6] Wan E, Merwe RVD. The unscented Kalman filter for nonlinear estimation. In: IEEE adaptive systems for signal processing, communications, and control symposium; 2000. p. 153–8. [7] R. Luo C. Yih K. Su Multisensor fusion integration: approaches, applications, and future research directions IEEE Sens J 2 2 2002 107 119 [8] J. Leonard H. Durrant-Whyte Mobile robot localization by tracking geometric beacons IEEE Trans Robotics Autom 7 3 1991 376 382 [9] Dellaert F, Fox D, Burgard W, Thrun S. Monte Carlo localization for mobile robots. In: IEEE international conference on robotics and automation; 1999. p. 1322–8. [10] D. Fox W. Burgard S. Thrun Markov localization for mobile robots in dynamic environments J Artif Intell Res 11 1999 391 427 [11] A. Mourikis S. Roumeliotis Performance analysis of multirobot cooperative localization IEEE Trans Robotics 22 4 2006 666 681 [12] H. Durrant-Whyte T. Henderson Multisensor data fusion B. Siciliano O. Khatib Springer handbook of robotics 2008 Springer [13] A. Bejczy J. Dias Editorial: integration of visual and inertial sensors J Robotic Syst 21 2 2004 41 42 [14] G. Alenyá E. Martínez C. Torras Fusing visual and inertial sensing to recover robot ego-motion J Robotic Syst 21 1 2004 23 32 [15] S. Chroust M. Vincze Fusion of vision and inertial data for motion and structure estimation J Robotic Syst 21 2 2004 73 83 [16] W.B.S. Thrun D. Fox Probabilistic robotics 2005 The MIT Press [17] B. Siciliano O. Khatib Springer handbook of robotics 2008 Springer [18] M. Lauer S. Lange M. Riedmiller Modeling moving objects in a dynamically changing robot application U. Furbach KI 2005: advances in artificial intelligence Lecture notes in computer science vol. 3698 2005 Springer 291 303 [19] Xu Y, Jiang C, Tan Y. SEU-3D 2006 soccer simulation team description. In: CD proc of RoboCup symposium 2006, Bremen, Germany; 2006. [20] Marcelino P, Nunes P, Lima P, Ribeiro MI. Improving object localization through sensor fusion applied to soccer robots. In: Proc scientific meeting of the portuguese robotics open – Robótica 2003, Lisbon, Portugal; 2003. [21] A. Ferrein L. Hermanns G. Lakemeyer Comparing sensor fusion techniques for ball position estimation A. Bredenfeld A. Jacoff I. Noda Y. Takahashi RoboCup 2005: robot soccer world cup IX Lecture notes in computer science vol. 4020 2006 Springer 154 165 [22] M. Lauer S. Lange M. Riedmiller Calculating the perfect match: an efficient and accurate approach for robot self-localization A. Bredenfeld A. Jacoff I. Noda Y. Takahashi RoboCup 2005: robot soccer world cup IX Lecture notes in computer science vol. 4020 2006 Springer 142 153 [23] Neves A, Martins D, Pinho A. A hybrid vision system for soccer robots using radial search lines. In: Lopes LS, Silva F, Santos V, editors. Proc of the 8th conference on autonomous robot systems and competitions, Portuguese robotics open – Robótica 2008, Aveiro, Portugal; 2008. p. 51–5. [24] Bishop G, Welch G. An introduction to the Kalman filter. In: Proc of SIGGRAPH, Course 8, No. NC 27599-3175. NC (USA): Chapel Hill; 2001. [25] Motulsky H, Christopoulos A. Fitting models to biological data using linear and nonlinear regression. GraphPad Software Inc.; 2003. [26] A. Neves G. Corrente A. Pinho An omnidirectional vision system for soccer robots J. Neves M.F. Santos J.M. Machado Progress in artificial intelligence Lecture notes in artificial intelligence vol. 4874 2007 Springer 499 507 [27] B. Cunha J. Azevedo N. Lau L. Almeida Obtaining the inverse distance map from a non-SVP hyperbolic catadioptric robotic vision system U. Visser F. Ribeiro T. Ohashi F. Dellaert RoboCup 2007: robot soccer world cup XI Lecture notes in artificial intelligence vol. 5001 2008 Springer 417 424 "
    },
    {
        "doc_title": "A survey on coordination methodologies for simulated robotic soccer teams",
        "doc_scopus_id": "84884747113",
        "doc_doi": null,
        "doc_eid": "2-s2.0-84884747113",
        "doc_date": "2010-12-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Adversarial environments",
            "Coordination methodologies",
            "Coordination technique",
            "Distributed organizations",
            "MAS",
            "RoboCup",
            "Robotic soccer",
            "Systematic evaluation"
        ],
        "doc_abstract": "Multi-agent systems (MAS) are a research topic with ever-increasing importance. This is due to their inherently distributed organization that copes more naturally with real-life problems whose solution requires people to coordinate efforts. One of its most prominent challenges consists on the creation of efficient coordination methodologies to enable the harmonious operation of teams of agents in adversarial environments. This challenge has been promoted by the Robot World Cup (RoboCup) international initiative every year since 1995. RoboCup provides a pragmatic testbed based on standardized platforms for the systematic evaluation of developed MAS coordination techniques. This initiative encompasses a simulated robotic soccer league in which 11 against 11 simulated robots play a realistic soccer game that is particularly suited for researching coordination methodologies. This paper presents a comprehensive overview of the most relevant coordination techniques proposed up till now in the simulated robotic soccer domain.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Playmaker: Graphical definition of formations and setplays",
        "doc_scopus_id": "77957825970",
        "doc_doi": null,
        "doc_eid": "2-s2.0-77957825970",
        "doc_date": "2010-10-18",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Information Systems",
                "area_abbreviation": "COMP",
                "area_code": "1710"
            }
        ],
        "doc_keywords": [
            "Coordination methods",
            "Deep blue",
            "Distributed AI",
            "Graphical tools",
            "Robotic soccer"
        ],
        "doc_abstract": "The fall of chess as a main domain for Artificial Intelligence (AI) research, after the victory of Deep Blue over Kasparov, put forward robotic soccer as a new challenging domain for AI researchers. Robotic Soccer is very appropriate for researching in Distributed AI problems, e.g. coordination methodologies, whose results can later be applied to other domains. Coordination can be defined as the capability of several agents to work together as a team, in order to accomplish a common goal. In the context of robotic soccer, several aspects may benefit from appropriate coordination methodologies, since team play is decisive for winning the games. This paper presents a methodology to enable a team of robotic soccer agents to coordinate their positioning in the field, and a methodology that enables them to cooperatively execute predefined set plays (flexible plans). Both coordination methods are used in real soccer and sports in general, commonly known as formations and set plays respectively. However, its use in a team of autonomous agents is still unexplored and is a major innovation of this work. A graphical tool to define formations and set plays was fully developed in the context of this work offering a quicker and more appealing way to define both formations and set plays. The tool's interface was inspired on \"blackboard\" applications, used nowadays for the same purpose in real sports. The tool enables very easy definition of set plays that may then be executed in real-time during the matches. Examples of complete set plays and their practical execution are also described, showing the usefulness of the set play concept and the utility of the developed tool.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Machine Learning algorithms applied to the classification of robotic soccer formations and opponent teams",
        "doc_scopus_id": "77956086164",
        "doc_doi": "10.1109/ICCIS.2010.5518540",
        "doc_eid": "2-s2.0-77956086164",
        "doc_date": "2010-09-02",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            },
            {
                "area_name": "Computer Networks and Communications",
                "area_abbreviation": "COMP",
                "area_code": "1705"
            },
            {
                "area_name": "Information Systems",
                "area_abbreviation": "COMP",
                "area_code": "1710"
            },
            {
                "area_name": "Software",
                "area_abbreviation": "COMP",
                "area_code": "1712"
            }
        ],
        "doc_keywords": [
            "Machine-learning",
            "Principal Components",
            "RoboCup",
            "Soccer simulation",
            "Support vector"
        ],
        "doc_abstract": "Machine Learning (ML) and Knowledge Discovery (KD) are research areas with several different applications but that share a common objective of acquiring more and new information from data. This paper presents an application of several ML techniques in the identification of the opponent team and also on the classification of robotic soccer formations in the context of RoboCup international robotic soccer competition. RoboCup international project includes several distinct leagues were teams composed by different types of real or simulated robots play soccer games following a set of pre-established rules. The simulated 2D league uses simulated robots encouraging research on artificial intelligence methodologies like high-level coordination and machine learning techniques. The experimental tests performed, using four distinct datasets, enabled us to conclude that the Support Vector Machines (SVM) technique has higher accuracy than the k-Nearest Neighbor, Neural Networks and Kernel Naïve Bayes in terms of adaptation to a new kind of data. Also, the experimental results enable to conclude that using the Principal Component Analysis SVM achieves worse results than using simpler methods that have as primary assumption the distance between samples, like k-NN. © 2010 IEEE.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Co-ordination in RoboCup's 2D simulation league: Setplays as flexible, multi-robot plans",
        "doc_scopus_id": "77955694214",
        "doc_doi": "10.1109/RAMECH.2010.5513166",
        "doc_eid": "2-s2.0-77955694214",
        "doc_date": "2010-08-23",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            },
            {
                "area_name": "Control and Systems Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2207"
            },
            {
                "area_name": "Electrical and Electronic Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2208"
            }
        ],
        "doc_keywords": [
            "2D simulations",
            "First year",
            "Graphical tools",
            "Inter-robot communication",
            "Low-level skills",
            "Multi-agent coordinations",
            "Multirobots",
            "Research topics",
            "RoboCup",
            "Robotic soccer team",
            "Runtimes",
            "Simulation league"
        ],
        "doc_abstract": "Strategic planning and multi-agent coordination are major research topics in the domain of RoboCup. Research was, in the first years, directed towards development of low level skills and positional co-ordination. The competitive level has in between risen to new standards, which makes the development of high-level co-operation necessary. The importance of the concept of Setplay, i.e., small multi-robot plans to deal with particular situations, to structure a robotic soccer team behaviour, has been acknowledged by many researchers, but no general framework for the development and execution of generic Setplays has been introduced in the context of RoboCup. This paper presents such a framework for high-level Setplay definition and execution in the 2D simulation league, though applicable to any RoboCup co-operative league and similar domains. The framework is built upon a standard, flexible and league-independent language, which defines Setplays that are interpreted and executed at run-time, using inter-robot communication. A major step in the development of the Setplay framework is its usage and testing in the scope of the FCPortugal team, which participates in the RoboCup 2D-simulation league, where it won several titles. After this successful implementation, described in this paper, the framework will be used in the mid-size league, and possibly in other new environments. Recent developments have made it possible to use Setplays in play-on situations, which had not been possible before. Also, a graphical tool for Setplay definition has been developed, and used in the context of this team. ©2010 IEEE.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Sensor and information fusion applied to a robotic soccer team",
        "doc_scopus_id": "77950996272",
        "doc_doi": "10.1007/978-3-642-11876-0_32",
        "doc_eid": "2-s2.0-77950996272",
        "doc_date": "2010-04-22",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Adaptive buffer",
            "Information fusion techniques",
            "Localisation",
            "Multi-agent environment",
            "Noise variations",
            "Obstacle detection",
            "Robotic soccer team",
            "Sensor informations",
            "Team cooperation",
            "Team members",
            "Team performance",
            "Velocity estimation",
            "Visual information",
            "Visual sensor",
            "World model"
        ],
        "doc_abstract": "This paper is focused on the sensor and information fusion techniques used by a robotic soccer team. Due to the fact that the sensor information is affected by noise, and taking into account the multi-agent environment, these techniques can significantly improve the accuracy of the robot world model. One of the most important elements of the world model is the robot self-localisation. Here, the team localisation algorithm is presented focusing on the integration of visual and compass information. To improve the ball position and velocity reliability, two different techniques have been developed. A study of the visual sensor noise is presented and, according to this analysis, the resulting noise variation depending on the distance is used to define a Kalman filter for ball position. Moreover, linear regression is used for velocity estimation purposes, both for the ball and the robot. This implementation of linear regression has an adaptive buffer size so that, on hard deviations from the path (detected using the Kalman filter), the regression converges more quickly. A team cooperation method based on sharing of the ball position is presented. Besides the ball, obstacle detection and identification is also an important challenge for cooperation purposes. Detecting the obstacles is ceasing to be enough and identifying which obstacles are team mates and opponents is becoming a need. An approach for this identification is presented, considering the visual information, the known characteristics of the team robots and shared localisation among team members. The same idea of distance dependent noise, studied before, is used to improve this identification. Some of the described work, already implemented before RoboCup2008, improved the team performance, allowing it to achieve the 1st place in the Portuguese robotics open Robótica2008 and in the RoboCup2008 world championship. © 2010 Springer.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Multi-robot team coordination through roles, positionings and coordinated procedures",
        "doc_scopus_id": "76249133341",
        "doc_doi": "10.1109/IROS.2009.5354286",
        "doc_eid": "2-s2.0-76249133341",
        "doc_date": "2009-12-11",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            },
            {
                "area_name": "Computer Vision and Pattern Recognition",
                "area_abbreviation": "COMP",
                "area_code": "1707"
            },
            {
                "area_name": "Human-Computer Interaction",
                "area_abbreviation": "COMP",
                "area_code": "1709"
            },
            {
                "area_name": "Control and Systems Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2207"
            }
        ],
        "doc_keywords": [
            "Dynamic roles",
            "Information sharing",
            "Multi-robot teams",
            "Performance measure",
            "Priority-based",
            "RoboCup",
            "Robotic soccer team",
            "Team size"
        ],
        "doc_abstract": "The coordination methodologies of CAMBADA, a robotic soccer team designed to participate in the RoboCup middle-size league (MSL), are presented. The approach, which relies on information sharing and integration within the team, is based on formations, flexible positionings and dynamic role and positioning assignment. Role/positioning assignment follows a new priority-based algorithm that maintains a competitive formation, covering the most important roles/positionings when malfunctions lead to a reduction of the team size. Coordinated procedures for passing and setplays have also been implemented. With this design, CAMBADA reached the 1st place in the RoboCup'2008 world championship. Competition results and performance measures computed from logs and videos of real competition games are presented and discussed. © 2009 IEEE.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Roles, positionings and set plays to coordinate a RoboCup MSL team",
        "doc_scopus_id": "71049186908",
        "doc_doi": "10.1007/978-3-642-04686-5_27",
        "doc_eid": "2-s2.0-71049186908",
        "doc_date": "2009-11-16",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Coordinated procedures",
            "Coordination model",
            "Dynamic role assignment",
            "Multi-robot team coordination",
            "Performance measure",
            "Priority-based",
            "Real robot",
            "RoboCup",
            "Robotic soccer team",
            "Soccer simulation",
            "Strategic positioning",
            "Team coordination"
        ],
        "doc_abstract": "This paper presents the team coordination methodologies of CAMBADA, a robotic soccer team designed to participate in the RoboCup middle-size league (MSL). The coordination model extends and adapts previous work in the Soccer Simulation League to the MSL environment. The approach is based on flexible positionings and priority-based dynamic role/positioning assignment. In addition, coordinated procedures for passing and setplays have been implemented. With the described design, CAMBADA reached the 1st place in the RoboCup'2008 world championship, becoming the first Portuguese real robot team to win in RoboCup. Competition results and performance measures computed from logs and videos of real competition games are presented and discussed. © 2009 Springer Berlin Heidelberg.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Control and monitoring of a robotic soccer team: The base station application",
        "doc_scopus_id": "71049158832",
        "doc_doi": "10.1007/978-3-642-04686-5_25",
        "doc_eid": "2-s2.0-71049158832",
        "doc_date": "2009-11-16",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Autonomous robot",
            "Base station applications",
            "Control and monitoring",
            "Efficient architecture",
            "Human interference",
            "Robotic soccer",
            "Robotic soccer team",
            "Software applications"
        ],
        "doc_abstract": "In robotic soccer, teams of autonomous robots play soccer according to rules similar to the official FIFA rules. The game is refereed by a human and his orders are communicated to the teams using an application called \"Referee Box\". No human interference is allowed during the games except for removing malfunctioning robots and re-entering robots in the game. The base station, a software application as described in this paper, has a determinant role during the development of a robotic soccer team and also during a game. This application must control the agents interpreting and sending high level instructions, like Start or Stop, and monitor information of the robots, for example the position and velocity, allowing easily to attest the feasibility of the robots behavior. This paper discusses the importance of the control and monitoring of a robotic soccer team, presenting the main challenges and the approaches that were used by the CAMBADA team in the conception of the base station application. As far as we know, no previous work has been published about the study of these important problems and the discussion of an efficient architecture to a base station application. The results obtained by the team confirms the good performance of this software, both during the games and in the development of the team. © 2009 Springer Berlin Heidelberg.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Predictive control for behavior generation of omni-directional robots",
        "doc_scopus_id": "71049152967",
        "doc_doi": "10.1007/978-3-642-04686-5_23",
        "doc_eid": "2-s2.0-71049152967",
        "doc_date": "2009-11-16",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Behavior generation",
            "Continuous control",
            "Current peak",
            "Cycle time",
            "Discrete-time control",
            "Maximum acceleration",
            "Maximum velocity",
            "Medium size leagues",
            "Motion stability",
            "Omni-directional motion",
            "Omnidirectional robots",
            "Physical constraints",
            "Predictive control",
            "RoboCup",
            "Robot controls",
            "Robotic soccer team",
            "System delay"
        ],
        "doc_abstract": "This paper describes the approach developed by the CAMBADA robotic soccer team to address physical constraints regarding omni-directional motion control, with special focus on system delay. CAMBADA robots carry inherent delays which associated with discrete time control results in non-instant, non-continuous control degrading the performance over time. Besides a natural maximum velocity, CAMBADA robots have also a maximum acceleration limit implemented at software level to provide motion stability as well as current peaks avoidance on DC motors. Considering the previous constraints, such as the cycle time and the overall sensor-action delay, compensations can be made to improve the robot control. Since CAMBADA robots are among the slowest robots in the RoboCup Medium Size League, such compensations can help to improve both several behaviours as well as a better field coverage formation. © 2009 Springer Berlin Heidelberg.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Obstacle detection, identification and sharing on a robotic soccer team",
        "doc_scopus_id": "71049141838",
        "doc_doi": "10.1007/978-3-642-04686-5_29",
        "doc_eid": "2-s2.0-71049141838",
        "doc_date": "2009-11-16",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Apriori",
            "Multi-agent applications",
            "Obstacle detection",
            "Position information",
            "Robotic soccer",
            "Robotic soccer team",
            "Search lines",
            "Visual detection",
            "World model"
        ],
        "doc_abstract": "When building a representation of the environment for a robot in a multi-agent application, as is the case of robotic soccer, sensor and information fusion of several elements of the environment are an important task. To build an increasingly better world model, one of the aspects that one should consider is the treatment of obstacles. This paper gives an insight of the general steps necessary for a good obstacle representation in the robot world model. A first step is the visual detection of the obstacles in the image acquired by the robot. This is done using an algorithm based on radial search lines and colour-based blobs detection, where each obstacle is identified and delimited. After having the visually detected obstacles, a fusion with a-priori known information about the obstacles characteristics allows the obstacle separation and filtering, so that obstacles that don't fill the criteria are discarded. With the position information shared by team mates, the matching of the obstacles and the team mates positions is also possible, thus identifying each of them. Finally, and with the purpose of having a team world model as coherent as possible, the robots are able to share the obstacle information of each other. The work presented in this paper was developed for the CAMBADA robotic soccer team. After achieving the 1st place in the Portuguese robotics open Robótica2008 and in the Robocup2008 world championship, the correct treatment of obstacles was one of the new challenges proposed among the team to improve the performance for the next competitions. © 2009 Springer Berlin Heidelberg.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Automatic generation of biped walk behavior using genetic algorithms",
        "doc_scopus_id": "68749098693",
        "doc_doi": "10.1007/978-3-642-02478-8_101",
        "doc_eid": "2-s2.0-68749098693",
        "doc_date": "2009-08-20",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "3D simulations",
            "Adaptive behavior",
            "Automatic Generation",
            "Biped",
            "Biped Robot",
            "Biped walk",
            "Complex environments",
            "Degrees of freedom",
            "Humanoid",
            "Humanoid robot",
            "Joint trajectories",
            "Locomotion",
            "Offline",
            "Partial-Fourier",
            "RoboCup",
            "Walk forward",
            "Walking gait"
        ],
        "doc_abstract": "Controlling a biped robot with several degrees of freedom is a challenging task that takes the attention of several researchers in the fields of biology, physics, electronics, computer science and mechanics. For a humanoid robot to perform in complex environments, fast, stable and adaptive behaviors are required. This paper proposes a solution for automatic generation of a walking gait using genetic algorithms (GA). A method based on partial Fourier series was developed for joint trajectory planning. GAs were then used for offline generation of the parameters that define the gait. GAs proved to be a powerful method for automatic generation of humanoid behaviors resulting on a walk forward velocity of 0.51m/s which is a good result considering the results of the three best teams of RoboCup 3D simulation league for the same movement. © 2009 Springer Berlin Heidelberg.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Classification of facial expressions using data mining and machine learning algorithms",
        "doc_scopus_id": "84869050542",
        "doc_doi": null,
        "doc_eid": "2-s2.0-84869050542",
        "doc_date": "2009-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Information Systems",
                "area_abbreviation": "COMP",
                "area_code": "1710"
            }
        ],
        "doc_keywords": [
            "Comparative studies",
            "Facial Expressions",
            "Facial recognition",
            "Image processing and analysis",
            "OneR",
            "Video image"
        ],
        "doc_abstract": "Machine Facial Recognition is a problem that consists in exploring still or video images of a scene to identify or verify one or more persons in the scene using stored databases of faces. Research in Facial Recognition is multidisciplinary including disciplines like pattern recognition, image processing and analysis, computer graphics, machine learning and data mining. Sometimes applications include not only facial recognition but also facial expression characteristics identification and classification like blinking of the eyes, open/close mouth among others. This paper presents a comparative study of three algorithms for classification basic facial expressions.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Obtaining the inverse distance map from a non-SVP hyperbolic catadioptric robotic vision system",
        "doc_scopus_id": "50249091617",
        "doc_doi": "10.1007/978-3-540-68847-1_43",
        "doc_eid": "2-s2.0-50249091617",
        "doc_date": "2008-09-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Autonomous mobile robots",
            "Back-propagation",
            "Catadioptric vision",
            "Distance maps",
            "Distributed architectures",
            "General solutions",
            "International symposium",
            "Mathematical properties",
            "Mirror surfaces",
            "Mobile robotics",
            "Non-SVP catadioptric",
            "Omnidirectional vision",
            "RoboCup",
            "Robot vision",
            "Robot-soccer",
            "Robotic vision",
            "Visualization",
            "World Cup"
        ],
        "doc_abstract": "The use of single viewpoint catadioptric vision systems is a common approach in mobile robotics, despite the constraints imposed by those systems. A general solution to calculate the robot centered distances map on non-SVP catadioptric setups, exploring a back-propagation ray-tracing approach and the mathematical properties of the mirror surface is discussed in this paper. Results from this technique applied in the robots of the CAMBADA team (Cooperative Autonomous Mobile Robots with Advanced Distributed Architecture) are presented, showing the effectiveness of the solution. © 2008 Springer-Verlag Berlin Heidelberg.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "A computational study on emotions and temperament in multi-agent systems",
        "doc_scopus_id": "84860567683",
        "doc_doi": null,
        "doc_eid": "2-s2.0-84860567683",
        "doc_date": "2007-12-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            }
        ],
        "doc_keywords": [
            "Cognitive modelling",
            "Computational model",
            "Computational studies",
            "Computational system",
            "Decision mechanism",
            "Emotional quality",
            "Emotional state",
            "Human behaviors",
            "Large arrays",
            "Mind models",
            "Model-based OPC",
            "Modular approach",
            "Multi agent system (MAS)",
            "Runtimes",
            "Social interactions",
            "Team members",
            "Team performance"
        ],
        "doc_abstract": "Recent advances in neurosciences and psychology have provided evidence that affective phenomena pervade intelligence at many levels, being inseparable from the cognition-action loop. Perception, attention, memory, learning, decisionmaking, adaptation, communication and social interaction are some of the aspects influenced by them. This work draws its inspirations from neurobiology, psychophysics and sociology to approach the problem of building autonomous robots capable of interacting with each other and building strategies based on temperamental decision mechanism. Modelling emotions is a relatively recent focus in artificial intelligence and cognitive modelling. Such models can ideally inform our understanding of human behavior. We may see the development of computational models of emotion as a core research focus that will facilitate advances in the large array of computational systems that model, interpret or influence human behavior. We propose a model based on a scalable, flexible and modular approach to emotion which allows runtime evaluation between emotional quality and performance. The results achieved showed that the strategies based on temperamental decision mechanism strongly influence the system performance and there are evident dependency between emotional state of the agents and their temperamental type, as well as the dependency between the team performance and the temperamental configuration of the team members, and this enable us to conclude that the modular approach to emotional programming based on temperamental theory is the good choice to develop computational mind models for emotional behavioral Multi-Agent systems.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "A generic strategic layer for collaborative networks",
        "doc_scopus_id": "34548860908",
        "doc_doi": "10.1007/978-0-387-73798-0_28",
        "doc_eid": "2-s2.0-34548860908",
        "doc_date": "2007-09-26",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Information Systems and Management",
                "area_abbreviation": "DECI",
                "area_code": "1802"
            }
        ],
        "doc_keywords": [
            "Collaborative network",
            "Coordination layer",
            "Coordination model",
            "Graphical tools",
            "Heterogeneous agents",
            "Hierarchical approach",
            "RoboCup soccer",
            "Soccer simulation"
        ],
        "doc_abstract": "This paper presents a formal model for a multi-purpose, strategical coordination layer. Based on previous work developed for the RoboCup Soccer simulation, small-size, middle-size, legged leagues and RoboCup Rescue simulation league, a generic coordination model was built that allows the management of collaborative networks of heterogeneous agents. The model uses a multi-level hierarchical approach with the following concepts: strategy, tactics, formations, sub-tactics and roles, from high to low level. Hybrid methods are used to switch formations and tactics. In order to test the model, two strategy instances, for RoboCup Rescue Simulation and RoboCup Soccer, were developed. Strategies are designed with the help of a graphical tool. Results achieved by the team in RoboCup Rescue and Soccer Simulation competitions demonstrate the usefulness of this approach. © 2007 Springer Science+Business Media, LLC.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "FC Portugal: Search and rescue in urban catastrophes",
        "doc_scopus_id": "84969219582",
        "doc_doi": null,
        "doc_eid": "2-s2.0-84969219582",
        "doc_date": "2007-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Information Systems",
                "area_abbreviation": "COMP",
                "area_code": "1710"
            },
            {
                "area_name": "Management of Technology and Innovation",
                "area_abbreviation": "BUSI",
                "area_code": "1405"
            }
        ],
        "doc_keywords": [
            "Coordination algorithms",
            "Distributed Artificial Intelligence",
            "Heterogeneous agents",
            "Information systems planning",
            "Intelligent robotics",
            "International competitions",
            "Search and rescue",
            "Simulation systems"
        ],
        "doc_abstract": "This paper presents an overview of the RoboCup Rescue Simulation League and the rescue team FC Portugal. RoboCup Rescue Simulation is an international joint project that promotes research on distributed artificial intelligence and intelligent robotics. It offers a comprehensive urban disaster simulator and a competitive evaluation for researchers. This paper explains the objectives of the league, the mechanics of the simulator system and the main challenges in the research conducted using the RoboCup Rescue simulator. In this ever evolving and extensive urban disaster simulator, heterogeneous teams of agents try to minimize damage to both people and urban property after the occurrence of an earthquake. The city is filled with burning buildings, civilians trapped under debris and blocked roads. Teams of simulated fire brigades, policeman and ambulances collaborate in order to face the disaster. In this context, an overview of FC Portugal's rescue team is presented, including the major coordination algorithms and implemented agent's behaviours. Some of the most interesting league problems are discussed and FC Portugal's solutions are introduced. Results achieved in international competitions are also briefly presented, with emphasis on the last European championship, held in 2006, in Eindhoven, which FC Portugal won.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Bilayer agent-based model of social behavior: How temperament influence on team performance",
        "doc_scopus_id": "84857581691",
        "doc_doi": "10.7148/2007-0181",
        "doc_eid": "2-s2.0-84857581691",
        "doc_date": "2007-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Modeling and Simulation",
                "area_abbreviation": "MATH",
                "area_code": "2611"
            }
        ],
        "doc_keywords": [
            "Agent-based model",
            "Computational model",
            "Decision algorithms",
            "Decision mechanism",
            "Emotional behavior",
            "Multi agent simulation",
            "System characteristics",
            "Team configuration"
        ],
        "doc_abstract": "This paper presents the evaluation of computational mind model based on temperamental decision algorithms with emotional behaviors. Our computational model of emotion is inspired on appraisal theory and on superior nervous system characteristics. We define the model for temperamental agent with emotions. In this paper we prove that teams of the agents with different temperaments have different performances in the same simulation scenario. The result shows that strategies based on temperamental decision mechanism strongly influence system performance and there are evident dependencies between emotional states of agents and their temperamental type, as well as dependencies between the team performance and team configuration, and this enables us to conclude that modular approach to emotional programming based on temperamental theory is a good choice to develop computational mind models for emotional behavioral Multi-Agent systems. © 2007 ECMS.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Understanding dynamic agent's reasoning",
        "doc_scopus_id": "38349064849",
        "doc_doi": "10.1007/978-3-540-77002-2_46",
        "doc_eid": "2-s2.0-38349064849",
        "doc_date": "2007-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Complex agents",
            "Heterogeneous agents"
        ],
        "doc_abstract": "Heterogeneous agents that execute in dynamic, uncertain, partially cooperative, partially adversely environments have to take their decisions rapidly with an incomplete knowledge of actual environment conditions. This paper discusses different level of abstractions in agent's development for this type of domain, explains the principles of offline debugging and employs these principles in robotic agent's teams through the use of a new visual debugging tool. We argue that during the development of such complex agents, understanding agent reasoning is of crucial importance to the developer and that such understanding can only be done, in most of the cases, using an offline analysis of the agent's decisions. In order for the developer to rapidly perceive agent's reasoning we advocate visual debugging of the agent knowledge and reasoning at several levels of abstraction and at several different functional views. These principles have been applied with success in the context of a robotic soccer 2D simulation league team through the development of tools and extensive use of these analysis principles. © Springer-Verlag Berlin Heidelberg 2007.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Implementation of emotional behaviours in multi-agent system using fuzzy logic and temperamental decision mechanism",
        "doc_scopus_id": "84884755342",
        "doc_doi": null,
        "doc_eid": "2-s2.0-84884755342",
        "doc_date": "2006-12-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Analysis and evaluation",
            "Decision algorithms",
            "Decision mechanism",
            "Decision systems",
            "Emotional models",
            "Mind models",
            "Robotic experiments",
            "Simulation environment"
        ],
        "doc_abstract": "In this paper we describe our work on computational mind model for temperamental decision algorithms using Fuzzy Logic and an implementation of an emotional-behavioral multi-agent system for analysis and evaluation of different strategies based on temperamental behaviors. We describe our approach to emotional model using temperamental decision system based on theory about general types of superior nervous systems in humans and animals and we explain how we can apply Fuzzy Logic on temperamental decision system. We describe the simulation environment used in this work to test and evaluate the strategies. We have conducted a set of robotic experiments in order to test the performance of the system on its first implementation phase. The results achieved showed that the different set of temperamental characteristics influences significantly the performance of the agents and give us very positive feedback to proceed with this research and implementation in new directions.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "FC Portugal: Development and evaluation of a new RoboCup rescue team",
        "doc_scopus_id": "80051542000",
        "doc_doi": null,
        "doc_eid": "2-s2.0-80051542000",
        "doc_date": "2006-12-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Control and Systems Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2207"
            }
        ],
        "doc_keywords": [
            "Cooperation",
            "Distributed simulations",
            "Multi-robot systems",
            "Portugal",
            "RoboCup",
            "RoboCup rescue",
            "RoboCup Simulation league",
            "Search and rescue",
            "Simulation",
            "Soccer team",
            "Strategic analysis",
            "Strategic decisions"
        ],
        "doc_abstract": "FC Portugal Rescue team is the result of a cooperation project between the Universities of Aveiro and Porto in Portugal. Following previous collaborations of these two Portuguese Universities in RoboCup simulation league and associated competitions, this project intends to fully adapt the coordination methodologies developed by FC Portugal simulated soccer team to the search and rescue scenario. After FC Portugal's first successful participation in RoboCup rescue simulation league (Osaka, 2005), the team aimed at introducing new high-level strategic analysis tools in the Rescue league and developed FCPx tool. This tool enables an easy comparison of different teams' strategies, and the use of learning methodologies for high-level strategic decisions in rescue. The tool also enabled us to evaluate our coordination methodologies, analyzing the results achieved in several rescue parameters, and conclude that they are very promising for the search and rescue domain. FC Portugal Rescue team results are very promising achieving first place in RoboCup European Championship 2006 (Dutch Open) held in Eindhoven.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Multi-agent debugging and monitoring framework",
        "doc_scopus_id": "80051506774",
        "doc_doi": "10.3182/20061002-2-br-4906.00020",
        "doc_eid": "2-s2.0-80051506774",
        "doc_date": "2006-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Control and Systems Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2207"
            }
        ],
        "doc_keywords": [
            "Debug",
            "Hard task",
            "Middle sized league",
            "Monitoring frameworks",
            "Multi agent",
            "Multi systems",
            "Multi-Processes",
            "Robotic soccer team"
        ],
        "doc_abstract": "In this paper we present a framework developed for the CAMBADA Middle-sized league robotic team, which allows human developers to better understand the robots actions during a game. Robotic soccer teams are in their nature dynamic multi-process and multi-agent systems, and knowing what is happening in all processes running on the agents at the same time is a hard task. To accomplish this task we developed a framework to create log files, one per process, and to interlace them later. The logs represent robot's knowledge. The framework allows the synchronization and visualization of logs and videos. Videos give the actual real behaviors. This will allow us to understand the robot's reasoning. A GUI utility to navigate and search inside log files was also developed.",
        "available": true,
        "clean_text": "serial JL 314898 291210 291718 291882 291883 31 IFAC Proceedings Volumes IFACPROCEEDINGSVOLUMES 2016-04-23 2016-04-23 2016-04-23 2016-04-23 2016-04-23T09:02:33 S1474-6670(15)31196-4 S1474667015311964 10.3182/20061002-2-BR-4906.00020 S350 S350.1 HEAD-AND-TAIL 2022-05-20T10:40:22.839963Z 0 0 20060101 20061231 2006 2016-04-23T09:20:26.364478Z rawtext articleinfo articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid hubeid indexeddate isbn isbns isbnnorm isbnsnorm issfirst issn issnnorm issuelist itemstage itemtransactionid itemweight openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sortorder srctitle srctitlenorm srctype ssids alllist content subj tomb vol volfirst volissue volumelist yearnav affil articletitle auth authfirstini authfull authkeywords authlast primabst ref 1474-6670 14746670 978-3-902661-20-3 9783902661203 false 39 39 20 20 Volume 39, Issue 20 21 114 120 114 120 2006 2006 2006-01-01 2006-12-31 2006 1st IFAC Workshop on Multivehicle Systems article fla Copyright © 2006 IFAC. Published by Elsevier Ltd. All rights reserved. MULTIAGENTDEBUGGINGMONITORINGFRAMEWORK FIGUEIREDO J KITANO 1997 340 347 H PROCEEDINGSFIRSTINTERNATIONALCONFERENCEAUTONOMOUSAGENTSAGENTS97 ROBOCUPROBOTWORLDCUPINITIATIVE REIS 2000 29 40 L FCPORTUGALTEAMDESCRIPTIONROBOCUP2000SIMULATIONLEAGUECHAMPIONVOL2019 SILVA 2005 781 788 V TROLLTECH FIGUEIREDOX2006X114 FIGUEIREDOX2006X114X120 FIGUEIREDOX2006X114XJ FIGUEIREDOX2006X114X120XJ item S1474-6670(15)31196-4 S1474667015311964 10.3182/20061002-2-BR-4906.00020 314898 2016-04-23T04:20:26.364478-04:00 2006-01-01 2006-12-31 true 1453745 MAIN 7 49132 849 656 IMAGE-WEB-PDF 1 First IFAC Workshop on Multivehicle Systems MULTI-AGENT DEBUGGING AND MONITORING FRAMEWORK Jo~o Figueiredo, Nuno Lau, Artur Pereira a IEETA/DETI, Universidade de Aveiro joao.figueiredo@ieeta.pt, lau@det.ua.pt, artur@det.ua.pt Abstract: In this paper we present a framework developed for the CAMBADA Middle-sized league robotic team, which allows human developers to better understand the robots actions during a game. Robotic soccer teams are in their nature dynamic multi-process and multi-agent systems, and knowing what is happening in all processes running on the agents at the same time is a hard task. To accomplish this task we developed a framework to create log files, one per process, and to interlace them later. The logs represent robot's knowledge. The framework allows the synchronization and visualization of logs and videos. Videos give the actual real behaviors. This will allow us to understand the robot's reasoning. A GUI utility to navigate and search inside log files was also developed. Keywords: monitoring, debug, multi-agent, multi-systems, robotics, MSL, Middle-Sized League 1. INTRODUCTION RoboCup (Kitano et al., 1997) is an international joint project to promote AI, robotics, and related fields. It is an attempt to foster AI and intelligent robotics research by providing a standard problem where wide range of technologies can be integrated and examined. RoboCup chose to use soccer as a central topic of research, aiming at innovations developed for soccer playing robots to be applied later for socially significant problems and industries. CAMBADA (Almeida et al., 2004b) is the MiddleSized League soccer team from the University of Aveiro, and is composed of three field players and a goal-keeper. By itself the team is a dynamic multi-agent system with all players sharing their perception of the game field. Each robot is an autonomous unit, capable of making decisions in real-time based on its own sensorial data and from data received from its team mates. The software each robot runs is composed of several programs, all running simultaneously, taking large amounts of decisions in a very short period of time and performing complex tasks, which makes it very difficult to understand its reasoning while it's playing. Following the robot's reasoning based only on external observation is also difficult because it all happens very fast from the human point of view and most of the robots internal state is hidden. And we also need to consider that their decisions are based not only on information received from its own sensors but from the other team mates as well. This difficulty turns the process of tuning and debugging the decision mechanisms quite hard. To solve this problem a framework which uses the concept of layered disclosure (Stone et al., 1999) and extends its functionalities was developed. It allows each process to log its data to a separate file and later join them to analyze the information saved as if it was on a continuous time-line. This process can be performed for each robot. A GUI program that allows navigating the files, searching for specific events and synchronize 114 First IFAC Workshop on Multivehicle Systems video from the robots and other external sources was also developed. This paper is organized as follows. This introduction is followed by section 2 with the main specifications that led to the development of the framework. Sections 3 and 4 discuss log creation and log navigation, respectively. Section 5 presents the GUI application developed for navigating the logs, synchronizing videos and searching for specific events. Section 6 introduces another tool for automatically determining the robots position in the field and help on the development of a self localization technique. Section 7 presents some results and finally on section 8 the conclusion of this paper. knowledge and its real behavior. It is composed of a back end and a front end. The former is a library of functions and allows for the production of log files including video data. The latter is library of objects and a GUI application that allows the user to interact with single and multi-file logs from one or multiple agents. The tool allows for the synchronized visualization of the robot's reasoning through the contents of the log files, and of its external behavior, by displaying synchronously recorded video of the robot acting in the field. 2.1 Main Requirements To create the framework to support the manipulation of log files several key points were defined. First of all it should support generic text with information pertinent to the program. Second, it should be possible to organize the information by category, eg. vision, decision, etc and by level of detail so that when reading the log files, the user may have the ability to analyze specific parts of it. CAMBADA robots run several processes at the same time so it's easier to create the framework so that it allows each program to write its own log file. Some form of synchronization is required to later be able to open them and read the information synchronously. This allows for the production of log files in different processes in the same machine, or even in different machines, and for overall analysis of the collected information. When applied to a soccer team this allows for: · analyze together log data from different processes of a soccer player; · analyze together log data from processes on different players; · compare log data from a soccer player with data obtained with some monitoring system; · analyze the robot's reasoning; · analyze the real data on which robot's reasoning was generated. Navigating log files and searching for specific information is another aspect to include in the specification. This means that some form of bookmarking is required for fast searching. Recording video images is also required to be able to see what the robot sees at a given time and understand its decisions with the textual information. Finally and probably the most important feature of the back end is the easiness of use so that other people will rapidly adapt to its interface and use it in their software. 2. SPECIFICATION CAMBADA soccer team is composed of four players, three field players and a goal-keeper. Each robot operates autonomously processing the information obtained from the cameras, the base micro-controllers and also from the other team mates. Fig. 1. CAMBADA Soccer Player World information is shared between the robots using the RtDB TDMA protocol (Almeida et al., 2004a). The purpose of the RtDB (Santos et al., 2004) is to serve as both local and shared area for communication among processes within the same robot and communication among different robots and also to create a channel to communicate with the micro-controllers using FTT-CAN (Silva et al., 2005). The RtDB is implemented using RTAI, a real-time layer for the Linux kernel. Understanding what a particular robot is doing and why it is doing that is not easy, since it is a complex system, its world changes dynamically and it takes a lot of decisions per second. To help in this task we propose a debugging and monitoring system that simultaneously shows robot's 115 First IFAC Workshop on Multivehicle Systems 2.2 Log structure Since we will be logging multiple forms of information (text, image, bookmarking), we need to create different record types to record that information in the log files and to help navigating in them. So far we identified 4 types of records: · Text to record formatted text messages; · Video to save one image for example from the vision or from an external camera; · Bookmark to place a bookmark for a specific category and later allow seeking on the information; · Registration to register a new category of the tree to file; The information contained in the logs may be overwhelming. On the other hand it should be as easy to visualize as possible. This has led to the use of classified information: vertically by level of detail; and horizontally by subject using a tree of categories. To organize information by level of detail we use some points derived from the concept of Layered Disclosure as proposed by (Stone et al., 1999), where the relevant information is organized in layers. Layers give us the depth of the information, that is, layers with smaller numbers indicate highlevel reasoning of the robot and layers with higher numbers add more and more detail to the lower ones. We extended the concept of layered disclosure with the inclusion of a tree of categories. This concept of tree was implemented on another library for logging system events (log4cpp (Bakker et al., 2005)). The tree of categories is important to better organize the information, not only by its importance but by its type. Figure 2 shows an example of a tree of categories where it is possible to see the detailed structure of run (the agent of the robot) and vision which controls the front camera. The tree also gives the possibility to stop/start sending information of a given category to the log file in runtime or allow the person reading the files to hide categories that are not relevant for the analysis of the problem. To be able to analyze multiple log files from one robot or from multiple robots, a common time line is required in all files. This can be done including a time-stamp in each record. Time-stamps can be obtained from the computer clock or from the RtDB/RTAI (Santos et al., 2004). If we want to log data on multiple robots playing at the same time and later read it simultaneously, we need to synchronize their clocks. Synchronization can be done with NTP servers when using the computer clock as the source of time-stamps or from the RTAI layer in the Linux kernel. Fig. 2. An example of a tree of categories with two programs running 2.3 Visualization of logs Reading the log files and understanding the sequence in which the programs are executed is simple but it is highly time-consuming to do it by hand. This led us to create a second library to read log files simultaneously, interlacing them and give the person using it the impression that only one log file for each robot exists, the front end. This is done on-the-fly with all the selected log files and gives the user the exact order on which the programs ran. A GUI application was also developed in conjunction with the front end to allow navigation in the log and searching information by specific text, bookmarks, time, etc. The framework includes the set of both developed libraries and the application to interactively analyze the log. 3. LOG PRODUCTION CAMBADA robots run several processes in realtime simultaneously which makes impossible to use prints on the screen for debugging. By using the monitoring framework's back end, every running program creates its own log file. The default file type is \"Formatted Text \" where every record is encoded in plain readable text, but other formats can be developed as well.\"XML\" 1 or even a \"binary\" format are possible. Every file is composed of records. There are four types of records created so far: Registration, Text, Video, Bookmark. The type of information each record contains is described in section 2.2. Every record is composed, of: · · · · 1 a time-stamp; a type; a category; specific data. Language web site: Extensible Markup 116 First IFAC Workshop on Multivehicle Systems Here's an example of a registration and a text records: 35203551142 REGC /run/ctrlloop/decision/defender/ 35203839343 TEXT /run/ctrlloop/integration/ball/ 2 CORRIGIDA ws->ball is 1.86, 0.29 The first record has no specific data. It indicates that the program has just registered category /run/ctrlloop/decision/defender. The category being registered is defender but its full path along the tree of categories is written to the log file. The specific data of the second record is composed of a level of detail (2) and free text. It shows that the ball was seen at position (1.86, 0.29) relative to the robot's position and orientation. To write these records to file and manage the tree of categories, several functions are available to the user and they are described in section 3.1. · logRegisterSubModule - registers a new category under any other existing category and returns an handle · logEnableOutput - given the handle, enables logging of this category; it can also enable logging of all the subtree below this category · logDisableOutput - given the handle, disables logging of this category; it can also disable logging of all the subtree below this category Categories can be created and enabled/disabled on the fly when a program is running and can depend on conditions or program options, avoiding the need for recompiling. Figure 3 shows a simplified view of its components. 3.1 System Architecture When creating the back end library to write log files, one of the key aspects was to keep it as simple as possible to the user. So we decided the best is to present it as a library of functions in C. Here is a small set of the most important functions available: · logInitialize - given the file name initializes the tree of categories with the root category · logTerminate - terminates all the logging facilities of the library, closes all files and releases all memory allocated · logText - saves a text record · logBookmark - saves a bookmark · logYuv - saves a video image Using categories is optional. An user may use only the root category which is created automatically by the library. Liblog is the main block. It implements the initialization of the library and the logging functions available to the user. Names implements the functions to manage the tree of categories. Error is a common block which makes available a set of functions to analyze errors of the library. Error is used by Liblog and by Names to manage errors internally and can also be used be the user to print or analyze them. All functions provided by these blocks are developed using dynamic buffers to prevent suspending the process execution and maintain the impact on the performance to a minimum. Also, all functions have a small number of parameters and some of them are similar to system functions, making them very easy to use. Fig. 3. User interface block diagram Using long strings, like the ones shown in the records example of section 3, to identify catThe remaining blocks: crecord, cwriter and ccategories can be cumbersome and they are also egory are support classes for the objects used prone to typing errors. To overcome this, an handle/descriptor number is created for each category internally by the library: different record types, and returned to the user by the logRegisterNewModule formatted text output and each category in the tree, respectively. This means that the core of the and logRegisterSubModule functions when new framework is built in C++ because it is simple to categories are registered. The handle may be used write code that closely represents the conceptual in subsequent calls to logging functions to identify categories. model of the project using an Object Oriented programming language. The back end interface These are the most important functions to manis a wrapper to these objects in C so it will be age the tree of categories simple to use. To add new functionalities to the framework like new types of records or new log · logRegisterNewModule - registers a new category under the root of the tree and refile formats it's as easy as creating new derived turns an handle classes of these. 117 First IFAC Workshop on Multivehicle Systems 4. LOG NAVIGATION 4.1 Synchronization To read data from different log files and retrieve joined information a kind of synchronization is required. This synchronization is based on timestamps included in each record, on every file. Rebuilding the original sequence on which the records were saved to the log files is possible just by implementing an algorithm to seek the record with the closest time-stamp to the current one. Several classes that represent the front end of the framework are implemented as seen in figure 4, using C++ and the STL library to maintain the portability between multiple platforms. They implement gradually several forms of navigating the information: · CFile - Implements basic file I/O, open, read and seek functionalities; · CParser - Implements file interpretation, creates records from a file and allows sequential navigation on them and has some caching built-in; · CTimeNavigator - Extends the CParser functionalities by adding the ability to navigate using time-stamps (seek to time-stamp) besides the already existing sequential navigation; · CCursor - Uses all the functionalities of the classes above and a look ahead technique to allow sequential navigation and by timestamp on multiples files at the same time; them to the current time-stamp. Current timestamp can be interpreted as the current position of the cursor. CCursor makes available to the user, the timestamp limits for the set of files and the ability to seek to a specific position and navigate from there, forward or backwards. The tree of categories can be created by the user from the log files managed by CCursor by means of CCategory objects and CCategoryIterator iterators which implement depth-first search algoritm. Based on CCursor, it was possible to develop the GUI application (section 5) that receives the records already \"organized\" so they can be filtered and displayed according to their nature, either text or video. 5. LOGREADERQT APPLICATION To make practical use the log files in CAMBADA to debug the robot's software a GUI application was developed using the Qt framework (Trolltech, 2005). An image of the main window is shown in figure 5. So far this application has two modes of displaying information, one textual and one with video. Fig. 5. Logreader main window When LogreaderQt starts it creates a CCursor object and an empty tree of categories. The CCursor object will maintain and manage the set of log files provided by the user and it will also allow navigating the records to extract information to display and to create the tree of categories. Log files can be added and removed from the set whenever it is required. Navigation in the set of files is entirely done by CCursor object. Figure 5 shows the tree of categories, inside each window, that is created when CCursor opens files. It is possible to create empty categories on the tree and to \"mount\" log files in them, using the same analogy of a file Fig. 4. User interface block diagram 4.2 Multiple log file navigation CCursor is the top level class for this front end library of the framework. Its name comes from the analogy of a sliding cursor used to navigate all the records on multiple files. It can manipulate multiple log files at the same time and synchronize 118 First IFAC Workshop on Multivehicle Systems system. This allows to separate logs from different agents and applications if required. Filtering details and/or hiding data is possible using context menus either for categories of data or for level of detail of information. This way an user can hide everything that is not important and read only what matters most for a particular analysis. LogreaderQt gives the user several ways of searching for what he's looking for in the log. It is possible to search information using: · records - seek a number of records at a time and showing them; · time - seek some time forward or backwards in the log. The time units for the files and navigation are user selectable; · bookmarks - seek inside the log to the next or previous bookmark of the selected category; this way it's possible to jump from one control cycle to the next for example; · video - seek to the next or previous image of the selected category; · play - play mode to keep advancing the records and video until the user instructs the program to stop; · regular expressions - in the future; Finally video and text are synchronized, which means when a text record is selected the video jumps to the nearest previous image. This simplifies the process of analyzing information by the user as it allows the direct comparison of robots internal state and reality as seen by the camera. camera has its own software, figure 6, to identify the field limits, the robotic agents in the field and log their position (text and video) to a file, using the framework. Comparing this log and the robots' logs should give us the ability to identify current problems and evaluate new solutions. 7. RESULTS To demonstrate a typical application of the framework, log files were created on two robots that exhibited a strange behavior while playing soccer. The setup for the experience consisted on leaving the robots side by side and placing the ball at a distance were the problem was visible. It was clear that if they seen the ball simultaneously and if their distance to the ball was similar at that time, robot number 3 was always the one to change to striker. After opening the log files with the application it became clear were the problem was coming from. Figure 7 shows one of the images recorded by the robot's log. Figure 8 shows an excerpt of textual information from the log files. There we can see that robot number 3 detects the ball at a distance of 4 meters and robot 1 at 6 meters. Clearly robot 3 thinks it is the closest to the ball and changes its behavior to striker. The source of the problem is in the neural network that translates pixels from the image to distances in the field not being properly calibrated. After analyzing the rest of the log we also discovered that the vision of robot 3 was not returning any distances greater than 5 meters. 6. REAL POSITION MONITORING One of the problems we faced while developing the soccer team is the fact that the robot's absolute position on the field is not trustable. Moving along the field while playing, when the robot's absolute position is updated only by odometry it tends to accumulate errors after travelling a few dozen meters. Fig. 7. Log image from the vision Fig. 6. Top viewer detecting a robot top marker Facing this problem we devised a solution to help quantify the error of the current solution and test new solutions as they are implemented. Like the Robocup's Small-Sized League, we incorporated a video camera on the top of the game field. This Fig. 8. Excerpt from the textual information Like this problem, that was quickly discovered, many others can be easily spotted with the ability to cross information from multiple processes and multiple agents simultaneously if we use these tools. 119 First IFAC Workshop on Multivehicle Systems 8. CONCLUSION In this paper we presented a framework developed for debugging a robotic soccer team which proved to be useful for a human user to understand the reasoning of an agent. Although it has been developed for soccer, its implementation has been carefully done to allow it to be easily adaptable to other projects where off-line debugging of multiple autonomous robots with different categories of information is required. It's main capabilities were easiness of use on single and multi-agent systems, multiple log files per agent (reading and writing), information organization in categories and level of detail, synchronization with video and different methods of searching information in the log. Silva, Valter, Ricardo Marau, Lu´ Almeida, is J. Ferreira, M. Calha, P. Pedreiras and J. Fonseca (2005). Implementing a distributed sensing and actuation system: The CAMBADA robots case study. In: Proceedings of the 10th IEEE International Conference on Emerging Technologies and Factory Automation. Vol. 2. pp. 781­788. Stone, Peter, Patrick Riley and Manuela Veloso (1999). Layered Extrospection: Why is the agent doing what it's doing?. Fourth International Conference on Autonomous Agents (Agents-2000). Trolltech (2005). Trolltech - Cross-platform C++ GUI development Online Reference Documentation. In: REFERENCES Almeida, Lu´ is, Frederico Santos, Tullio Facchinetti, Paulo Pedreiras, Valter Silva and Lu´ Seabra Lopes (2004a). Coordinating disis tributed autonomous agents with a real-time database: The cambada project.. In: ISCIS. pp. 876­886. Almeida, Luis, Luis Seabra Lopes, P. Bartolomeu, E. Brito, M. B. Cunha, J. P. Figueiredo, P. Fonseca, C. Lima, R. Marau, N. Lau, P. Pedreiras, A. Pereira, A. Pinho, F. Santos, L. Seabra Lopes and J. Vieira (2004b). CAMBADA: Team Description Paper. In: CD of the Robocup Symposium / TDP. Bakker, Bastiaan, Cedric Le Goater, Marc Welz, Lynn Owen andSteve Ostlind, Marcel Harkema, Uwe Jger, Walter Stroebel, Glen Scott, Tony Cheung, Alex Tapaccos, Brendan B. Boerner, Paulo Pizarro, David Resnick, Aaron Ingram, Alan Anderson and Emiliano Martin (2005). Log for C++ Project Website. 0.3.5rc3 ed. Kitano, Hiroaki, Minoru Asada, Yasuo Kuniyoshi, Itsuki Noda and Eiichi Osawa (1997). RoboCup: The Robot World Cup Initiative. In: Proceedings of the First International Conference on Autonomous Agents (Agents'97) (W. Lewis Johnson and Barbara Hayes-Roth, Eds.). ACM Press. New York. pp. 340­347. Reis, Lu´ Paulo and Nuno Lau (2000). FC Portuis gal Team Description: RoboCup 2000 Simulation League Champion. pp. 29­40. Vol. 2019. Springer-Verlag. Santos, Frederico, Luis Almeida, Paulo Pedreiras, Luis S Lopes and Tullio Facchinetti (2004). An Adaptive TDMA Protocol for Soft Real-Time Wireless Communication among Mobile Autonomous Agents. WACERTS'04 RTSS'04. 120 anslates pixels from the image to distances in the field not being properly calibrated. After analyzing the rest of the log we also discovered that the vision of robot 3 was not returning any distances greater than 5 meters. 6. REAL POSITION MONITORING One of the problems we faced while developing the soccer team is the fact that the robot's absolute position on the field is not trustable. Moving along the field while playing, when the robot's absolute position is updated only by odometry it tends to accumulate errors after travelling a few dozen meters. Fig. 7. Log image from the vision Fig. 6. Top viewer detecting a robot top marker Facing this problem we devised a solution to help quantify the error of the current solution and test new solutions as they are implemented. Like the Robocup's Small-Sized League, we incorporated a video camera on the top of the game field. This Fig. 8. Excerpt from the textual information Like this problem, that was quickly discovered, many others can be easily spotted with the ability to cross information from multiple processes and multiple agents simultaneously if we use these tools. 119 First IFAC Workshop on Multivehicle Systems 8. CONCLUSION In this paper we presented a framework developed for debugging a robotic soccer team which proved to be useful for a human user to understand the reasoning of an agent. Although it has been developed for soccer, its implementation has been carefully done to allow it to be easily adaptable to other projects where off-line debugging of multiple autonomous robots with different categories of information is required. It's main capabilities were easiness of use on single and multi-agent systems, multiple log files per agent (reading and writing), information organization in categories and level of detail, synchronization with video and different methods of searching information in the log. Silva, Valter, Ricardo Marau, Lu´ Almeida, is J. Ferreira, M. Calha, P. Pedreiras and J. Fonseca (2005). Implementing a distributed sensing and actuation system: The CAMBADA robots case study. In: Proceedings of the 10th IEEE International Conference on Emerging Technologies and Factory Automation. Vol. 2. pp. 781­788. Stone, Peter, Patrick Riley and Manuela Veloso (1999). Layered Extrospection: Why is the agent doing what it's doing?. Fourth International Conference on Autonomous Agents (Agents-2000). Trolltech (2005). Trolltech - Cross-platform C++ GUI development Online Reference Documentation. In: REFERENCES Almeida, Lu´ is, Frederico Santos, Tullio Facchinetti, Paulo Pedreiras, Valter Silva and Lu´ Seabra Lopes (2004a). Coordinating disis tributed autonomous agents with a real-time database: The cambada project.. In: ISCIS. IPV 31196 S1474-6670(15)31196-4 10.3182/20061002-2-BR-4906.00020 IFAC MULTI-AGENT DEBUGGING AND MONITORING FRAMEWORK João Figueiredo Nuno Lau Artur Pereira IEETA/DETI, Universidade de Aveiro IEETA/DETI Universidade de Aveiro In this paper we present a framework developed for the CAMBADA Middle-sized league robotic team, which allows human developers to better understand the robots actions during a game. Robotic soccer teams are in their nature dynamic multi-process and multi-agent systems, and knowing what is happening in all processes running on the agents at the same time is a hard task. To accomplish this task we developed a framework to create log files, one per process, and to interlace them later. The logs represent robot's knowledge. The framework allows the synchronization and visualization of logs and videos. Videos give the actual real behaviors. This will allow us to understand the robot's reasoning. A GUI utility to navigate and search inside log files was also developed. Keywords monitoring debug multi-agent multi-systems robotics MSL Middle-Sized League References Almeida et al., 2004 Almeida, Luís, Frederico Santos, Tullio Facchinetti, Paulo Pedreiras, Valter Silva and Luís Seabra Lopes (2004a). Coordinating distributed autonomous agents with a real-time database: The cambada project. In: ISCIS. pp. 876-886. Almeida et al., 2004 Almeida, Luis, Luis Seabra Lopes, P. Bartolomeu, E. Brito, M. B. Cunha, J. P. Figueiredo, P. Fonseca, C. Lima, R. Marau, N. Lau, P. Pedreiras, A. Pereira, A. Pinho, F. Santos, L. Seabra Lopes and J. Vieira (2004b). CAMBADA: Team Description Paper. In: CD of the Robocup Symposium/TDP. Bakker et al., 2005 Bakker, Bastiaan, Cedric Le Goater, Marc Welz, Lynn Owen and Steve Ostlind, Marcel Harkema, Uwe Jger, Walter Stroebel, Glen Scott, Tony Cheung, Alex Tapaccos, Brendan B. Boerner, Paulo Pizarro, David Resnick, Aaron Ingram, Alan Anderson and Emiliano Martin (2005). Log for C++ Project Website. 0.3.5rc3 ed. Kitano et al., 1997 Hiroaki Kitano Asada Minoru Yasuo Kuniyoshi Itsuki Noda Eiichi Osawa RoboCup: The Robot World Cup Initiative W. Lewis Johnson Barbara Hayes-Roth Proceedings of the First International Conference on Autonomous Agents (Agents'97) 1997 ACM Press New York 340 347 Reis and Lau, 2000 Luís Paulo Reis Nuno Lau FC Portugal Team Description: RoboCup 2000 Simulation League Champion. Vol. 2019 2000 Springer-Verlag 29 40 Santos et al., 2004 Santos, Frederico, Luis Almeida, Paulo Pedreiras, Luis S Lopes and Tullio Facchinetti (2004). An Adaptive TDMA Protocol for Soft Real-Time Wireless Communication among Mobile Autonomous Agents. WACERTS'04 RTSS'04. Silva et al., 2005 Valter Silva Ricardo Marau Luís Almeida J. Ferreira M. Calha P. Pedreiras J. Fonseca Implementing a distributed sensing and actuation system: The CAMBADA robots case study Proceedings of the 10th IEEE International Conference on Emerging Technologies and Factory Automation 2 2005 781 788 Stone et al., 1999 Stone, Peter, Patrick Riley and Manuela Veloso (1999). Layered Extrospection: Why is the agent doing what it's doing?. Fourth International Conference on Autonomous Agents (Agents-2000). Trolltech, 2005 Trolltech Trolltech - Cross-platform C++ GUI development Online Reference Documentation. In: 2005 "
    },
    {
        "doc_title": "Lecture Notes in Artificial Intelligence: Introduction",
        "doc_scopus_id": "33744803169",
        "doc_doi": "10.1007/11595014_39",
        "doc_eid": "2-s2.0-33744803169",
        "doc_date": "2005-12-01",
        "doc_type": "Editorial",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [],
        "doc_abstract": null,
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Applying biological paradigms to emerge behaviour in RoboCup Rescue team",
        "doc_scopus_id": "33744790599",
        "doc_doi": "10.1007/11595014_42",
        "doc_eid": "2-s2.0-33744790599",
        "doc_date": "2005-12-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Biological paradigms",
            "Coordination capabilities",
            "Path Finding Algorithm",
            "RoboCup Rescue team",
            "Shortest path"
        ],
        "doc_abstract": "This paper presents a hybrid behaviour process for performing collaborative tasks and coordination capabilities in a rescue team. RoboCup Rescue simulator and its associated international competition are used as the testbed for our proposal. Unlike other published work in this field one of our main concerns is having good results on RoboCup Rescue championships by emerging behaviour in agents using a biological paradigm. The benefit comes from the hierarchic and parallel organisation of the mammalian brain. In our behaviour process, Artificial Neural Networks are used in order to make agents capable of learning information from the environment. This allows agents to improve several algorithms like their Path Finding Algorithm to find the shortest path between two points. Also, we aim to filter the most important messages that arise from the environment, to make the right choice on the best path planning among many alternatives, in a short time. A policy action was implemented using Kohonen's network, Dijkstra's and D* algorithm. This policy has achieved good results in our tests, getting our team classified for RoboCup Rescue Simulation League 2005. © Springer-Verlag Berlin Heidelberg 2005.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "COACH UNILANG - A standard language for coaching a (Robo)Soccer team",
        "doc_scopus_id": "84867449009",
        "doc_doi": "10.1007/3-540-45603-1_19",
        "doc_eid": "2-s2.0-84867449009",
        "doc_date": "2002-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Opponent modeling",
            "Player behavior",
            "Portugal",
            "RoboCup Coach",
            "Soccer team",
            "Statistical information"
        ],
        "doc_abstract": "This document introduces COACH UNILANG, a standard language for coaching (Robo)Soccer teams. This language was developed with two main objectives: to coach FC Portugal 2001 team and as a proposal to be used in Fukuoka 2002 RoboCup coach competition. This language enables high-level and low-level coaching through coach instructions. High-level coaching includes changing tactics, formations used in each situation and changing player behavior. Low-level coaching includes defining formations, situations, player behavior and positioning with high detail. The language also enables the coach (functioning like an assistant coach) to send opponent modeling information and game statistical information to the players. © 2002 Springer-Verlag Berlin Heidelberg.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "FC Portugal 2001 team description: Flexible teamwork and configurable strategy",
        "doc_scopus_id": "84867442577",
        "doc_doi": "10.1007/3-540-45603-1_72",
        "doc_eid": "2-s2.0-84867442577",
        "doc_date": "2002-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Portugal",
            "RoboCup 2001",
            "Robosoccer"
        ],
        "doc_abstract": "FC Portugal is a cooperation project between the Universities of Aveiro and Porto in Portugal. FC Portugal 2001 is our second step towards the creation of a flexible RoboSoccer team, with tactical changing abilities, that may be coached at any level, before and during the games, by human or automatic coaches. Although having the best goal average in the competition (scoring 150 goals in 13 games), the team was not able to score against the good defenses of Tsinghuaeolus and Brainstomers and finished third in RoboCup 2001. © 2002 Springer-Verlag Berlin Heidelberg.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "RoboCup-2000: The Fourth Robotic Soccer World Championships",
        "doc_scopus_id": "0035280047",
        "doc_doi": null,
        "doc_eid": "2-s2.0-0035280047",
        "doc_date": "2001-03-01",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Artificial Intelligence",
                "area_abbreviation": "COMP",
                "area_code": "1702"
            }
        ],
        "doc_keywords": [
            "Robocup soccer world championships",
            "Robocup workshop"
        ],
        "doc_abstract": "The Fourth Robotic Soccer World Championships (RoboCup-2000) was held from 27 August to 3 September 2000 at the Melbourne Exhibition Center in Melbourne, Australia. In total, 83 teams, consisting of about 500 people, participated in RoboCup-2000, and about 5000 spectators watched the events. RoboCup-2000 showed dramatic improvement over past years in each of the existing robotic soccer leagues (legged, small size, mid size, and simulation) and introduced RoboCup Jr. competitions and RoboCup Rescue and Humanoid demonstration events. The RoboCup Workshop, held in conjunction with the championships, provided a forum for the exchange of ideas and experiences among the different leagues. This article summarizes the advances seen at RoboCup-2000, including reports from the championship teams and overviews of all the RoboCup events.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "FC Portugal team description: RoboCup 2000 Simulation League Champion",
        "doc_scopus_id": "84867482860",
        "doc_doi": "10.1007/3-540-45324-5_2",
        "doc_eid": "2-s2.0-84867482860",
        "doc_date": "2001-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Amsterdam",
            "Melbourne",
            "Portugal",
            "Research development",
            "RoboCup",
            "RoboCup Simulation league",
            "Simulation league",
            "Team success"
        ],
        "doc_abstract": "FC Portugal is the result of a cooperation project between the Universities of Aveiro and Porto in Portugal. The project started in February 2000 and only three months later, in Amsterdam, FC Portugal became the first European Champion of RoboCup scoring a total of 86 goals without conceding a single goal. Three months later, in Melbourne, FC Portugal became RoboCup Simulation League World Champion scoring 94 goals, again without conceding any goal. This paper briefly describes some of the most relevant research developments and innovations that lead to FC Portugal team success. © 2001 Springer-Verlag Berlin Heidelberg.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Situation based strategic positioning for coordinating a team of homogeneous agents",
        "doc_scopus_id": "84864834168",
        "doc_doi": "10.1007/3-540-44568-4_11",
        "doc_eid": "2-s2.0-84864834168",
        "doc_date": "2001-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Agent architectures",
            "Current situation",
            "Decision modules",
            "Homogeneous agents",
            "Simulated domains",
            "Simulation league",
            "Spatial positioning",
            "Strategic positioning",
            "Agent architectures",
            "Current situation",
            "Decision modules",
            "Homogeneous agents",
            "Portugal",
            "Robosoccer",
            "Simulated domains",
            "Simulation league",
            "Spatial positioning",
            "Strategic positioning"
        ],
        "doc_abstract": "© 2001 Springer-Verlag Berlin Heidelberg.In this paper we are proposing an approach for coordinating a team of homogeneous agents based on a flexible common Team Strategy as well as on the concepts of Situation Based Strategic Positioning and Dynamic Positioning and Role Exchange. We also introduce an Agent Architecture including a specific high-level decision module capable of implementing this strategy. Our proposal is based on the formalization of what is a team strategy for competing with an opponent team having opposite goals. A team strategy is composed of a set of agent types and a set of tactics, which are also composed of several formations. Formations are used for different situations and assign each agent a default spatial positioning and an agent type (defining its behaviour at several levels). Agent's reactivity is also introduced for appropriate response to the dynamics of the current situation. However, in our approach this is done in a way that preserves team coherence instead of permitting uncoordinated agent behaviour. We have applied, with success, this coordination approach to the RoboSoccer simulated domain. The FC Portugal team, developed using this approach won the RoboCup2000 (simulation league) European and World championships scoring a total of 180 goals and conceding none.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Intelligent control and decision-making demonstrated on a simple compass-guided robot",
        "doc_scopus_id": "0034498071",
        "doc_doi": "10.1109/ICSMC.2000.884354",
        "doc_eid": "2-s2.0-0034498071",
        "doc_date": "2000-01-01",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Control and Systems Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2207"
            },
            {
                "area_name": "Hardware and Architecture",
                "area_abbreviation": "COMP",
                "area_code": "1708"
            }
        ],
        "doc_keywords": [
            "Compass guided robots",
            "Environmental exploration",
            "Task planning"
        ],
        "doc_abstract": "This paper presents the architecture and algorithms developed for Dom Dinis, a simple compass-guided robot built by the authors. This includes environment exploration, task planning and task execution. Environment exploration, based on repeating a reactive goal search, enables a progressive construction of a grid-based map. Based on the (possibly incomplete) map, the robot is able to plan its tasks. The execution capabilities of the robot include exception handling. Essential to all these capabilities is the knowledge of the robot's position in the world. The position is computed based on tracking traversed distances and followed orientations. Orientation is given by a compass. Dom Dinis doesn't use wheel encoders at all.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Development system for FPGA-based digital circuits",
        "doc_scopus_id": "0033488533",
        "doc_doi": null,
        "doc_eid": "2-s2.0-0033488533",
        "doc_date": "1999-12-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            },
            {
                "area_name": "Engineering (all)",
                "area_abbreviation": "ENGI",
                "area_code": "2200"
            }
        ],
        "doc_keywords": [
            "Dynamically reconfigurable arrays",
            "Dynamically reconfigurable hardware",
            "Logic synthesis"
        ],
        "doc_abstract": "An overview is given of some new hardware and software tools that can be used for the design of virtual circuits based on dynamically reconfigurable FPGAs. These tools provide facilities for synthesis, simulating, testing, and debugging of digital circuits based on dynamically reconfigurable hardware.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Design of virtual digital controllers based on dynamically reconfigurable FPGAs",
        "doc_scopus_id": "85051117079",
        "doc_doi": "10.1109/EURMIC.1998.711799",
        "doc_eid": "2-s2.0-85051117079",
        "doc_date": "1998-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Hardware and Architecture",
                "area_abbreviation": "COMP",
                "area_code": "1708"
            },
            {
                "area_name": "Software",
                "area_abbreviation": "COMP",
                "area_code": "1712"
            }
        ],
        "doc_keywords": [
            "Basic structure",
            "Behavioral specification",
            "Digital controllers",
            "Functional block",
            "Reconfigurable",
            "Virtual control"
        ],
        "doc_abstract": "© 1998 IEEE.This paper discusses dynamically reconfigurable FPGAs and their use for the physical implementation of digital controllers. The technique considered presents various ways of behavioral specification and logic synthesis, which can be applied to the practical design of virtual control circuits that have such properties as flexibility, extensibility and reusability. The authors have suggested the basic structure of a virtual digital controller that is composed of a formally synthesized modifiable circuit (specified by either graph-schemes or their extensions) and reusable functional blocks that are invoked in order to simplify, the description of the control algorithms.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Synthesis tools and design environment for dynamically reconfigurable FPGAs",
        "doc_scopus_id": "84956868990",
        "doc_doi": "10.1109/SBCCI.1998.715408",
        "doc_eid": "2-s2.0-84956868990",
        "doc_date": "1998-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Hardware and Architecture",
                "area_abbreviation": "COMP",
                "area_code": "1708"
            },
            {
                "area_name": "Electrical and Electronic Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2208"
            }
        ],
        "doc_keywords": [
            "Automatic translation",
            "Behavioural specifications",
            "Behavioural synthesis",
            "Design environment",
            "Dynamic re-configuration",
            "Dynamically reconfigurable fpga",
            "Hardware implementations",
            "Integrated design environments"
        ],
        "doc_abstract": "© 1998 IEEE.This paper discusses a range of problems in architectural and logic synthesis of digital devices and suggests practical approaches, methods, and tools for the automatic translation of a behavioural specification into a hardware implementation using a dynamically reconfigurable FPGA of the XC6200 family. The work described in this paper covers two basic areas. Firstly, new FPGA-oriented methods for behavioural synthesis of virtual digital circuits within predefined scopes are presented Secondly, an integrated design environment for logic synthesis (IDELS) is described which has been implemented as an extension of commercially available tools. IDELS permits synthesis in accordance with the developed design flow and offers very powerful run-time debugging facilities, including support for dynamic reconfiguration.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Integrated development environment for logic synthesis based on dynamically reconfigurable FPGAs",
        "doc_scopus_id": "84956853863",
        "doc_doi": "10.1007/bfb0055229",
        "doc_eid": "2-s2.0-84956853863",
        "doc_date": "1998-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Theoretical Computer Science",
                "area_abbreviation": "MATH",
                "area_code": "2614"
            },
            {
                "area_name": "Computer Science (all)",
                "area_abbreviation": "COMP",
                "area_code": "1700"
            }
        ],
        "doc_keywords": [
            "Digital system",
            "Integrated design environments",
            "Integrated development environment",
            "Reconfigurable",
            "VISUAL C++"
        ],
        "doc_abstract": "© Springer-Verlag Berlin Heidelberg 1998.The paper discusses the models, methods and software tools included in an Integrated Design Environment for Logic Synthesis (IDELS) that has been developed in Visual C++ and can be used for PC computers running under Windows 95/98. It is able to solve a range of problems related to the design of digital systems and their components based on dynamically reconfigurable FPGAs of the XC6200 family. The paper focuses primarily on the integrated features, the basic capabilities and the main packages of the environment itself, rather than the details of how it was implemented. However, the basic ideas behind the methods used, and some of the approaches to implementing the environment are considered, together with some of the problems that we had to address.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Quantifying the objective quality of voxel based data visualizations produced by a ray caster: A proposal",
        "doc_scopus_id": "0030721073",
        "doc_doi": null,
        "doc_eid": "2-s2.0-0030721073",
        "doc_date": "1997-01-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Software",
                "area_abbreviation": "COMP",
                "area_code": "1712"
            },
            {
                "area_name": "Signal Processing",
                "area_abbreviation": "COMP",
                "area_code": "1711"
            },
            {
                "area_name": "Computer Vision and Pattern Recognition",
                "area_abbreviation": "COMP",
                "area_code": "1707"
            }
        ],
        "doc_keywords": [
            "Volume rendering (VR) method",
            "Voxel based data set"
        ],
        "doc_abstract": "A set of parameters to assess the objective quality of visualizations of a voxel based data set, produced using a ray caster, is proposed as a first step toward the evaluation of the overall quality of these visualizations. Results obtained using synthetic data and a simple implementation of a ray caster are presented. The final goal of this evaluation will be the computation of `confidence indices' that could offer the user a `guided visualization', i.e. allow him/her to decide what are the `best' visualizations of a data set.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Feature detection using electromagnetic tomography and neural networks",
        "doc_scopus_id": "8544278035",
        "doc_doi": null,
        "doc_eid": "2-s2.0-8544278035",
        "doc_date": "1996-12-01",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Engineering (all)",
                "area_abbreviation": "ENGI",
                "area_code": "2200"
            },
            {
                "area_name": "Electrical and Electronic Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2208"
            }
        ],
        "doc_keywords": [],
        "doc_abstract": null,
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Feature detection using electromagnetic tomography and neural networks",
        "doc_scopus_id": "0030382659",
        "doc_doi": null,
        "doc_eid": "2-s2.0-0030382659",
        "doc_date": "1996-12-01",
        "doc_type": "Article",
        "doc_areas": [
            {
                "area_name": "Engineering (all)",
                "area_abbreviation": "ENGI",
                "area_code": "2200"
            },
            {
                "area_name": "Electrical and Electronic Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2208"
            }
        ],
        "doc_keywords": [
            "Electromagnetic tomography",
            "Magnetic induction tomography",
            "Neural network training"
        ],
        "doc_abstract": "Electromagnetic tomography (EMT) was used to perform feature detection of anomalies of `a priori' known objects, employing neural networks (NNs) for data processing. Investigations showed that the NNs have good discrimination properties over features for which they have been trained, performing very well even in a not very precise environment where the object was moved by hand. An estimation approach lead to simpler and faster training. For a similar resolution, the network complexity was also much lower than for the classification approach. The EMT NN combination is a very promising approach for applications requiring not an image but information on the variability of a particular feature of a given object.",
        "available": false,
        "clean_text": ""
    },
    {
        "doc_title": "Pattern recognition in raw of electrical impedance tomography using neural networks",
        "doc_scopus_id": "0027851606",
        "doc_doi": null,
        "doc_eid": "2-s2.0-0027851606",
        "doc_date": "1993-12-01",
        "doc_type": "Conference Paper",
        "doc_areas": [
            {
                "area_name": "Signal Processing",
                "area_abbreviation": "COMP",
                "area_code": "1711"
            },
            {
                "area_name": "Biomedical Engineering",
                "area_abbreviation": "ENGI",
                "area_code": "2204"
            },
            {
                "area_name": "Computer Vision and Pattern Recognition",
                "area_abbreviation": "COMP",
                "area_code": "1707"
            },
            {
                "area_name": "Health Informatics",
                "area_abbreviation": "MEDI",
                "area_code": "2718"
            }
        ],
        "doc_keywords": [
            "Electrical impedance tomography",
            "Raw data"
        ],
        "doc_abstract": "The images of Electrical Impedance Tomography are reconstructed using certain approximations and have a low spatial resolution. It is therefore proposed, in order to detect the presence of such tumors, to use neural networks for the recognition of typical patterns in the raw data rather than in the reconstructed images. The results obtained with several types of targets in vitro confirm the feasibility of this approach.",
        "available": false,
        "clean_text": ""
    }
]